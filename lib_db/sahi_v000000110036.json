{
  "PKG_INFO_LEVEL": [],
  "SupportsPkgInfo": {
    "pkg_info": [
      "self",
      "message"
    ]
  },
  "BaseSahiLogger": {
    "pkg_info": [
      "self",
      "message"
    ]
  },
  "SahiLogger": {
    "pkg_info": [
      "self",
      "message"
    ]
  },
  "SahiLoggerFormatter": {
    "grey": [],
    "yellow": [],
    "red": [],
    "bold_red": [],
    "cyan": [],
    "green": [],
    "reset": [],
    "base_format": [],
    "pkg_info_pattern": [],
    "format": [
      "self",
      "record"
    ]
  },
  "logger": [],
  "__all__": [],
  "MODEL_TYPE_TO_MODEL_CLASS_NAME": [],
  "ULTRALYTICS_MODEL_NAMES": [],
  "AutoDetectionModel": {
    "from_pretrained": [
      "model_type",
      "model_path",
      "model",
      "config_path",
      "device",
      "mask_threshold",
      "confidence_threshold",
      "category_mapping",
      "category_remapping",
      "load_at_init",
      "image_size"
    ]
  },
  "coco_app": [],
  "sahi_app": [],
  "app": [],
  "PredictionScore": {
    "__init__": [
      "self",
      "value"
    ],
    "is_greater_than_threshold": [
      "self",
      "threshold"
    ],
    "__eq__": [
      "self",
      "threshold"
    ],
    "__gt__": [
      "self",
      "threshold"
    ],
    "__lt__": [
      "self",
      "threshold"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ObjectPrediction": {
    "__init__": [
      "self",
      "bbox",
      "category_id",
      "category_name",
      "segmentation",
      "score",
      "shift_amount",
      "full_shape"
    ],
    "get_shifted_object_prediction": [
      "self"
    ],
    "to_coco_prediction": [
      "self",
      "image_id"
    ],
    "to_fiftyone_detection": [
      "self",
      "image_height",
      "image_width"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PredictionResult": {
    "__init__": [
      "self",
      "object_prediction_list",
      "image",
      "durations_in_seconds"
    ],
    "export_visuals": [
      "self",
      "export_dir",
      "text_size",
      "rect_th",
      "hide_labels",
      "hide_conf",
      "file_name"
    ],
    "to_coco_annotations": [
      "self"
    ],
    "to_coco_predictions": [
      "self",
      "image_id"
    ],
    "to_imantics_annotations": [
      "self"
    ],
    "to_fiftyone_detections": [
      "self"
    ]
  },
  "BoundingBox": {
    "__post_init__": [
      "self"
    ],
    "minx": [
      "self"
    ],
    "miny": [
      "self"
    ],
    "maxx": [
      "self"
    ],
    "maxy": [
      "self"
    ],
    "shift_x": [
      "self"
    ],
    "shift_y": [
      "self"
    ],
    "area": [
      "self"
    ],
    "get_expanded_box": [
      "self",
      "ratio",
      "max_x",
      "max_y"
    ],
    "to_xywh": [
      "self"
    ],
    "to_coco_bbox": [
      "self"
    ],
    "to_xyxy": [
      "self"
    ],
    "to_voc_bbox": [
      "self"
    ],
    "get_shifted_box": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Category": {
    "__post_init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Mask": {
    "__init__": [
      "self",
      "segmentation",
      "full_shape",
      "shift_amount"
    ],
    "from_float_mask": [
      "cls",
      "mask",
      "full_shape",
      "mask_threshold",
      "shift_amount"
    ],
    "from_bool_mask": [
      "cls",
      "bool_mask",
      "full_shape",
      "shift_amount"
    ],
    "bool_mask": [
      "self"
    ],
    "shape": [
      "self"
    ],
    "full_shape": [
      "self"
    ],
    "shift_amount": [
      "self"
    ],
    "get_shifted_mask": [
      "self"
    ]
  },
  "ObjectAnnotation": {
    "__init__": [
      "self",
      "bbox",
      "segmentation",
      "category_id",
      "category_name",
      "shift_amount",
      "full_shape"
    ],
    "from_bool_mask": [
      "cls",
      "bool_mask",
      "category_id",
      "category_name",
      "shift_amount",
      "full_shape"
    ],
    "from_coco_segmentation": [
      "cls",
      "segmentation",
      "full_shape",
      "category_id",
      "category_name",
      "shift_amount"
    ],
    "from_coco_bbox": [
      "cls",
      "bbox",
      "category_id",
      "category_name",
      "shift_amount",
      "full_shape"
    ],
    "from_coco_annotation_dict": [
      "cls",
      "annotation_dict",
      "full_shape",
      "category_name",
      "shift_amount"
    ],
    "from_shapely_annotation": [
      "cls",
      "annotation",
      "full_shape",
      "category_id",
      "category_name",
      "shift_amount"
    ],
    "from_imantics_annotation": [
      "cls",
      "annotation",
      "shift_amount",
      "full_shape"
    ],
    "to_coco_annotation": [
      "self"
    ],
    "to_coco_prediction": [
      "self"
    ],
    "to_shapely_annotation": [
      "self"
    ],
    "to_imantics_annotation": [
      "self"
    ],
    "deepcopy": [
      "self"
    ],
    "get_empty_mask": [
      "cls"
    ],
    "get_shifted_object_annotation": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "POSTPROCESS_NAME_TO_CLASS": [],
  "LOW_MODEL_CONFIDENCE": [],
  "filter_predictions": [
    "object_prediction_list",
    "exclude_classes_by_name",
    "exclude_classes_by_id"
  ],
  "get_prediction": [
    "image",
    "detection_model",
    "shift_amount",
    "full_shape",
    "postprocess",
    "verbose",
    "exclude_classes_by_name",
    "exclude_classes_by_id"
  ],
  "get_sliced_prediction": [
    "image",
    "detection_model",
    "slice_height",
    "slice_width",
    "overlap_height_ratio",
    "overlap_width_ratio",
    "perform_standard_pred",
    "postprocess_type",
    "postprocess_match_metric",
    "postprocess_match_threshold",
    "postprocess_class_agnostic",
    "verbose",
    "merge_buffer_length",
    "auto_slice_resolution",
    "slice_export_prefix",
    "slice_dir",
    "exclude_classes_by_name",
    "exclude_classes_by_id"
  ],
  "bbox_sort": [
    "a",
    "b",
    "thresh"
  ],
  "agg_prediction": [
    "result",
    "thresh"
  ],
  "predict": [
    "detection_model",
    "model_type",
    "model_path",
    "model_config_path",
    "model_confidence_threshold",
    "model_device",
    "model_category_mapping",
    "model_category_remapping",
    "source",
    "no_standard_prediction",
    "no_sliced_prediction",
    "image_size",
    "slice_height",
    "slice_width",
    "overlap_height_ratio",
    "overlap_width_ratio",
    "postprocess_type",
    "postprocess_match_metric",
    "postprocess_match_threshold",
    "postprocess_class_agnostic",
    "novisual",
    "view_video",
    "frame_skip_interval",
    "export_pickle",
    "export_crop",
    "dataset_json_path",
    "project",
    "name",
    "visual_bbox_thickness",
    "visual_text_size",
    "visual_text_thickness",
    "visual_hide_labels",
    "visual_hide_conf",
    "visual_export_format",
    "verbose",
    "return_dict",
    "force_postprocess_type",
    "exclude_classes_by_name",
    "exclude_classes_by_id"
  ],
  "predict_fiftyone": [
    "model_type",
    "model_path",
    "model_config_path",
    "model_confidence_threshold",
    "model_device",
    "model_category_mapping",
    "model_category_remapping",
    "dataset_json_path",
    "image_dir",
    "no_standard_prediction",
    "no_sliced_prediction",
    "image_size",
    "slice_height",
    "slice_width",
    "overlap_height_ratio",
    "overlap_width_ratio",
    "postprocess_type",
    "postprocess_match_metric",
    "postprocess_match_threshold",
    "postprocess_class_agnostic",
    "verbose",
    "exclude_classes_by_name",
    "exclude_classes_by_id"
  ],
  "MAX_WORKERS": [],
  "get_slice_bboxes": [
    "image_height",
    "image_width",
    "slice_height",
    "slice_width",
    "auto_slice_resolution",
    "overlap_height_ratio",
    "overlap_width_ratio"
  ],
  "annotation_inside_slice": [
    "annotation",
    "slice_bbox"
  ],
  "process_coco_annotations": [
    "coco_annotation_list",
    "slice_bbox",
    "min_area_ratio"
  ],
  "SlicedImage": {
    "__init__": [
      "self",
      "image",
      "coco_image",
      "starting_pixel"
    ]
  },
  "SliceImageResult": {
    "__init__": [
      "self",
      "original_image_size",
      "image_dir"
    ],
    "add_sliced_image": [
      "self",
      "sliced_image"
    ],
    "sliced_image_list": [
      "self"
    ],
    "images": [
      "self"
    ],
    "coco_images": [
      "self"
    ],
    "starting_pixels": [
      "self"
    ],
    "filenames": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__len__": [
      "self"
    ]
  },
  "slice_image": [
    "image",
    "coco_annotation_list",
    "output_file_name",
    "output_dir",
    "slice_height",
    "slice_width",
    "overlap_height_ratio",
    "overlap_width_ratio",
    "auto_slice_resolution",
    "min_area_ratio",
    "out_ext",
    "verbose",
    "exif_fix"
  ],
  "slice_coco": [
    "coco_annotation_file_path",
    "image_dir",
    "output_coco_annotation_file_name",
    "output_dir",
    "ignore_negative_samples",
    "slice_height",
    "slice_width",
    "overlap_height_ratio",
    "overlap_width_ratio",
    "min_area_ratio",
    "out_ext",
    "verbose",
    "exif_fix"
  ],
  "calc_ratio_and_slice": [
    "orientation",
    "slide",
    "ratio"
  ],
  "calc_resolution_factor": [
    "resolution"
  ],
  "calc_aspect_ratio_orientation": [
    "width",
    "height"
  ],
  "calc_slice_and_overlap_params": [
    "resolution",
    "height",
    "width",
    "orientation"
  ],
  "get_resolution_selector": [
    "res",
    "height",
    "width"
  ],
  "get_auto_slice_params": [
    "height",
    "width"
  ],
  "shift_bboxes": [
    "bboxes",
    "offset"
  ],
  "shift_masks": [
    "masks",
    "offset",
    "full_shape"
  ],
  "COCO_CLASSES": [],
  "get_shapely_box": [
    "x",
    "y",
    "width",
    "height"
  ],
  "get_shapely_multipolygon": [
    "coco_segmentation"
  ],
  "get_bbox_from_shapely": [
    "shapely_object"
  ],
  "ShapelyAnnotation": {
    "from_coco_segmentation": [
      "cls",
      "segmentation",
      "slice_bbox"
    ],
    "from_coco_bbox": [
      "cls",
      "bbox",
      "slice_bbox"
    ],
    "__init__": [
      "self",
      "multipolygon",
      "slice_bbox"
    ],
    "multipolygon": [
      "self",
      "multipolygon"
    ],
    "area": [
      "self"
    ],
    "to_list": [
      "self"
    ],
    "to_coco_segmentation": [
      "self"
    ],
    "to_opencv_contours": [
      "self"
    ],
    "to_xywh": [
      "self"
    ],
    "to_coco_bbox": [
      "self"
    ],
    "to_xyxy": [
      "self"
    ],
    "to_voc_bbox": [
      "self"
    ],
    "get_convex_hull_shapely_annotation": [
      "self"
    ],
    "get_simplified_shapely_annotation": [
      "self",
      "tolerance"
    ],
    "get_buffered_shapely_annotation": [
      "self",
      "distance",
      "resolution",
      "quadsegs",
      "cap_style",
      "join_style",
      "mitre_limit",
      "single_sided"
    ],
    "get_intersection": [
      "self",
      "polygon"
    ]
  },
  "Yolov5TestConstants": {
    "YOLOV5N_MODEL_URL": [],
    "YOLOV5N_MODEL_PATH": [],
    "YOLOV5S6_MODEL_URL": [],
    "YOLOV5S6_MODEL_PATH": [],
    "YOLOV5M6_MODEL_URL": [],
    "YOLOV5M6_MODEL_PATH": []
  },
  "download_yolov5n_model": [
    "destination_path"
  ],
  "download_yolov5s6_model": [
    "destination_path"
  ],
  "empty_cuda_cache": [],
  "to_float_tensor": [
    "img"
  ],
  "torch_to_numpy": [
    "img"
  ],
  "select_device": [
    "device"
  ],
  "CocoCategory": {
    "__init__": [
      "self",
      "id",
      "name",
      "supercategory"
    ],
    "from_coco_category": [
      "cls",
      "category"
    ],
    "json": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CocoAnnotation": {
    "from_coco_segmentation": [
      "cls",
      "segmentation",
      "category_id",
      "category_name",
      "iscrowd"
    ],
    "from_coco_bbox": [
      "cls",
      "bbox",
      "category_id",
      "category_name",
      "iscrowd"
    ],
    "from_coco_annotation_dict": [
      "cls",
      "annotation_dict",
      "category_name"
    ],
    "from_shapely_annotation": [
      "cls",
      "shapely_annotation",
      "category_id",
      "category_name",
      "iscrowd"
    ],
    "__init__": [
      "self",
      "category_id",
      "category_name",
      "segmentation",
      "bbox",
      "image_id",
      "iscrowd"
    ],
    "get_sliced_coco_annotation": [
      "self",
      "slice_bbox"
    ],
    "area": [
      "self"
    ],
    "bbox": [
      "self"
    ],
    "segmentation": [
      "self"
    ],
    "category_id": [
      "self",
      "i"
    ],
    "image_id": [
      "self",
      "i"
    ],
    "category_name": [
      "self",
      "n"
    ],
    "iscrowd": [
      "self"
    ],
    "json": [
      "self"
    ],
    "serialize": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CocoPrediction": {
    "from_coco_segmentation": [
      "cls",
      "segmentation",
      "category_id",
      "category_name",
      "score",
      "iscrowd",
      "image_id"
    ],
    "from_coco_bbox": [
      "cls",
      "bbox",
      "category_id",
      "category_name",
      "score",
      "iscrowd",
      "image_id"
    ],
    "from_coco_annotation_dict": [
      "cls",
      "category_name",
      "annotation_dict",
      "score",
      "image_id"
    ],
    "__init__": [
      "self",
      "segmentation",
      "bbox",
      "category_id",
      "category_name",
      "image_id",
      "score",
      "iscrowd"
    ],
    "json": [
      "self"
    ],
    "serialize": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CocoVidAnnotation": {
    "__init__": [
      "self",
      "category_id",
      "category_name",
      "bbox",
      "image_id",
      "instance_id",
      "iscrowd",
      "id"
    ],
    "json": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CocoImage": {
    "from_coco_image_dict": [
      "cls",
      "image_dict"
    ],
    "__init__": [
      "self",
      "file_name",
      "height",
      "width",
      "id"
    ],
    "add_annotation": [
      "self",
      "annotation"
    ],
    "add_prediction": [
      "self",
      "prediction"
    ],
    "json": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CocoVidImage": {
    "__init__": [
      "self",
      "file_name",
      "height",
      "width",
      "video_id",
      "frame_id",
      "id"
    ],
    "from_coco_image": [
      "cls",
      "coco_image",
      "video_id",
      "frame_id"
    ],
    "add_annotation": [
      "self",
      "annotation"
    ],
    "json": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CocoVideo": {
    "__init__": [
      "self",
      "name",
      "id",
      "fps",
      "height",
      "width"
    ],
    "add_image": [
      "self",
      "image"
    ],
    "add_cocovidimage": [
      "self",
      "cocovidimage"
    ],
    "json": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Coco": {
    "__init__": [
      "self",
      "name",
      "image_dir",
      "remapping_dict",
      "ignore_negative_samples",
      "clip_bboxes_to_img_dims",
      "image_id_setting"
    ],
    "add_categories_from_coco_category_list": [
      "self",
      "coco_category_list"
    ],
    "add_category": [
      "self",
      "category"
    ],
    "add_image": [
      "self",
      "image"
    ],
    "update_categories": [
      "self",
      "desired_name2id",
      "update_image_filenames"
    ],
    "merge": [
      "self",
      "coco",
      "desired_name2id",
      "verbose"
    ],
    "from_coco_dict_or_path": [
      "cls",
      "coco_dict_or_path",
      "image_dir",
      "remapping_dict",
      "ignore_negative_samples",
      "clip_bboxes_to_img_dims",
      "use_threads",
      "num_threads"
    ],
    "json_categories": [
      "self"
    ],
    "category_mapping": [
      "self"
    ],
    "json": [
      "self"
    ],
    "prediction_array": [
      "self"
    ],
    "stats": [
      "self"
    ],
    "calculate_stats": [
      "self"
    ],
    "split_coco_as_train_val": [
      "self",
      "train_split_rate",
      "numpy_seed"
    ],
    "export_as_yolov5": [
      "self",
      "output_dir",
      "train_split_rate",
      "numpy_seed",
      "mp",
      "disable_symlink"
    ],
    "export_as_yolo": [
      "self",
      "output_dir",
      "train_split_rate",
      "numpy_seed",
      "mp",
      "disable_symlink"
    ],
    "get_subsampled_coco": [
      "self",
      "subsample_ratio",
      "category_id"
    ],
    "get_upsampled_coco": [
      "self",
      "upsample_ratio",
      "category_id"
    ],
    "get_area_filtered_coco": [
      "self",
      "min",
      "max_val",
      "intervals_per_category"
    ],
    "get_coco_with_clipped_bboxes": [
      "self"
    ]
  },
  "export_yolo_images_and_txts_from_coco_object": [
    "output_dir",
    "coco",
    "ignore_negative_samples",
    "mp",
    "disable_symlink"
  ],
  "export_single_yolo_image_and_corresponding_txt": [
    "coco_image",
    "coco_image_dir",
    "output_dir",
    "ignore_negative_samples",
    "disable_symlink"
  ],
  "update_categories": [
    "desired_name2id",
    "coco_dict"
  ],
  "update_categories_from_file": [
    "desired_name2id",
    "coco_path",
    "save_path"
  ],
  "merge": [
    "coco_dict1",
    "coco_dict2",
    "desired_name2id"
  ],
  "merge_from_list": [
    "coco_dict_list",
    "desired_name2id",
    "verbose"
  ],
  "merge_from_file": [
    "coco_path1",
    "coco_path2",
    "save_path"
  ],
  "get_imageid2annotationlist_mapping": [
    "coco_dict"
  ],
  "create_coco_dict": [
    "images",
    "categories",
    "ignore_negative_samples",
    "image_id_setting"
  ],
  "create_coco_prediction_array": [
    "images",
    "ignore_negative_samples",
    "image_id_setting"
  ],
  "add_bbox_and_area_to_coco": [
    "source_coco_path",
    "target_coco_path",
    "add_bbox",
    "add_area"
  ],
  "DatasetClassCounts": {
    "frequencies": [
      "self"
    ],
    "__add__": [
      "self",
      "o"
    ]
  },
  "count_images_with_category": [
    "coco_file_path"
  ],
  "CocoVid": {
    "__init__": [
      "self",
      "name",
      "remapping_dict"
    ],
    "add_categories_from_coco_category_list": [
      "self",
      "coco_category_list"
    ],
    "add_category": [
      "self",
      "category"
    ],
    "json_categories": [
      "self"
    ],
    "category_mapping": [
      "self"
    ],
    "add_video": [
      "self",
      "video"
    ],
    "json": [
      "self"
    ]
  },
  "remove_invalid_coco_results": [
    "result_list_or_path",
    "dataset_dict_or_path"
  ],
  "export_coco_as_yolov5": [
    "output_dir",
    "train_coco",
    "val_coco",
    "train_split_rate",
    "numpy_seed",
    "disable_symlink"
  ],
  "export_coco_as_yolo": [
    "output_dir",
    "train_coco",
    "val_coco",
    "train_split_rate",
    "numpy_seed",
    "disable_symlink"
  ],
  "export_coco_as_yolov5_via_yml": [
    "yml_path",
    "output_dir",
    "train_split_rate",
    "numpy_seed",
    "disable_symlink"
  ],
  "export_coco_as_yolo_via_yml": [
    "yml_path",
    "output_dir",
    "train_split_rate",
    "numpy_seed",
    "disable_symlink"
  ],
  "Detectron2TestConstants": {
    "FASTERCNN_MODEL_ZOO_NAME": [],
    "RETINANET_MODEL_ZOO_NAME": [],
    "MASKRCNN_MODEL_ZOO_NAME": []
  },
  "export_cfg_as_yaml": [
    "cfg",
    "export_path"
  ],
  "fix_shift_amount_list": [
    "shift_amount_list"
  ],
  "fix_full_shape_list": [
    "full_shape_list"
  ],
  "mmdet_version_as_integer": [],
  "MmdetTestConstants": {
    "MMDET_CASCADEMASKRCNN_MODEL_URL": [],
    "MMDET_CASCADEMASKRCNN_MODEL_PATH": [],
    "MMDET_RETINANET_MODEL_URL": [],
    "MMDET_RETINANET_MODEL_PATH": [],
    "MMDET_YOLOX_TINY_MODEL_URL": [],
    "MMDET_YOLOX_TINY_MODEL_PATH": [],
    "MMDET_CASCADEMASKRCNN_CONFIG_PATH": [],
    "MMDET_RETINANET_CONFIG_PATH": [],
    "MMDET_YOLOX_TINY_CONFIG_PATH": []
  },
  "download_mmdet_cascade_mask_rcnn_model": [
    "destination_path"
  ],
  "download_mmdet_retinanet_model": [
    "destination_path"
  ],
  "download_mmdet_yolox_tiny_model": [
    "destination_path"
  ],
  "download_mmdet_config": [
    "model_name",
    "config_file_name",
    "verbose"
  ],
  "get_package_info": [
    "package_name",
    "verbose"
  ],
  "print_environment_info": [],
  "is_available": [
    "module_name"
  ],
  "check_requirements": [
    "package_names"
  ],
  "check_package_minimum_version": [
    "package_name",
    "minimum_version",
    "verbose"
  ],
  "ensure_package_minimum_version": [
    "package_name",
    "minimum_version",
    "verbose"
  ],
  "MODEL_NAME_TO_CONSTRUCTOR": [],
  "unzip": [
    "file_path",
    "dest_dir"
  ],
  "save_json": [
    "data",
    "save_path",
    "indent"
  ],
  "NumpyEncoder": {
    "default": [
      "self",
      "obj"
    ]
  },
  "load_json": [
    "load_path",
    "encoding"
  ],
  "list_files": [
    "directory",
    "contains",
    "verbose"
  ],
  "list_files_recursively": [
    "directory",
    "contains",
    "verbose"
  ],
  "get_base_filename": [
    "path"
  ],
  "get_file_extension": [
    "path"
  ],
  "load_pickle": [
    "load_path"
  ],
  "save_pickle": [
    "data",
    "save_path"
  ],
  "import_model_class": [
    "model_type",
    "class_name"
  ],
  "increment_path": [
    "path",
    "exist_ok",
    "sep"
  ],
  "download_from_url": [
    "from_url",
    "to_path"
  ],
  "is_colab": [],
  "IMAGE_EXTENSIONS_LOSSY": [],
  "IMAGE_EXTENSIONS_LOSSLESS": [],
  "IMAGE_EXTENSIONS": [],
  "VIDEO_EXTENSIONS": [],
  "Colors": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "ind",
      "bgr"
    ],
    "hex_to_rgb": [
      "hex_code"
    ]
  },
  "crop_object_predictions": [
    "image",
    "object_prediction_list",
    "output_dir",
    "file_name",
    "export_format"
  ],
  "convert_image_to": [
    "read_path",
    "extension",
    "grayscale"
  ],
  "read_large_image": [
    "image_path"
  ],
  "read_image": [
    "image_path"
  ],
  "read_image_as_pil": [
    "image",
    "exif_fix"
  ],
  "select_random_color": [],
  "apply_color_mask": [
    "image",
    "color"
  ],
  "get_video_reader": [
    "source",
    "save_dir",
    "frame_skip_interval",
    "export_visual",
    "view_visual"
  ],
  "visualize_prediction": [
    "image",
    "boxes",
    "classes",
    "masks",
    "rect_th",
    "text_size",
    "text_th",
    "color",
    "hide_labels",
    "output_dir",
    "file_name"
  ],
  "visualize_object_predictions": [
    "image",
    "object_prediction_list",
    "rect_th",
    "text_size",
    "text_th",
    "color",
    "hide_labels",
    "hide_conf",
    "output_dir",
    "file_name",
    "export_format"
  ],
  "get_coco_segmentation_from_bool_mask": [
    "bool_mask"
  ],
  "get_bool_mask_from_coco_segmentation": [
    "coco_segmentation",
    "width",
    "height"
  ],
  "get_bbox_from_bool_mask": [
    "bool_mask"
  ],
  "get_bbox_from_coco_segmentation": [
    "coco_segmentation"
  ],
  "get_coco_segmentation_from_obb_points": [
    "obb_points"
  ],
  "normalize_numpy_image": [
    "image"
  ],
  "ipython_display": [
    "image"
  ],
  "RTDETRTestConstants": {
    "RTDETRL_MODEL_URL": [],
    "RTDETRL_MODEL_PATH": [],
    "RTDETRX_MODEL_URL": [],
    "RTDETRX_MODEL_PATH": []
  },
  "download_rtdetrl_model": [
    "destination_path"
  ],
  "download_rtdetrx_model": [
    "destination_path"
  ],
  "batched_nms": [
    "predictions",
    "match_metric",
    "match_threshold"
  ],
  "nms": [
    "predictions",
    "match_metric",
    "match_threshold"
  ],
  "batched_greedy_nmm": [
    "object_predictions_as_tensor",
    "match_metric",
    "match_threshold"
  ],
  "greedy_nmm": [
    "object_predictions_as_tensor",
    "match_metric",
    "match_threshold"
  ],
  "batched_nmm": [
    "object_predictions_as_tensor",
    "match_metric",
    "match_threshold"
  ],
  "nmm": [
    "object_predictions_as_tensor",
    "match_metric",
    "match_threshold"
  ],
  "PostprocessPredictions": {
    "__init__": [
      "self",
      "match_threshold",
      "match_metric",
      "class_agnostic"
    ],
    "__call__": [
      "self",
      "predictions"
    ]
  },
  "NMSPostprocess": {
    "__call__": [
      "self",
      "object_predictions"
    ]
  },
  "NMMPostprocess": {
    "__call__": [
      "self",
      "object_predictions"
    ]
  },
  "GreedyNMMPostprocess": {
    "__call__": [
      "self",
      "object_predictions"
    ]
  },
  "LSNMSPostprocess": {
    "__call__": [
      "self",
      "object_predictions"
    ]
  },
  "ObjectPredictionList": {
    "__init__": [
      "self",
      "list"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__setitem__": [
      "self",
      "i",
      "elem"
    ],
    "__len__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "extend": [
      "self",
      "object_prediction_list"
    ],
    "totensor": [
      "self"
    ],
    "tonumpy": [
      "self"
    ],
    "tolist": [
      "self"
    ]
  },
  "repair_polygon": [
    "shapely_polygon"
  ],
  "repair_multipolygon": [
    "shapely_multipolygon"
  ],
  "coco_segmentation_to_shapely": [
    "segmentation"
  ],
  "object_prediction_list_to_torch": [
    "object_prediction_list"
  ],
  "object_prediction_list_to_numpy": [
    "object_prediction_list"
  ],
  "calculate_box_union": [
    "box1",
    "box2"
  ],
  "calculate_area": [
    "box"
  ],
  "calculate_intersection_area": [
    "box1",
    "box2"
  ],
  "calculate_bbox_iou": [
    "pred1",
    "pred2"
  ],
  "calculate_bbox_ios": [
    "pred1",
    "pred2"
  ],
  "has_match": [
    "pred1",
    "pred2",
    "match_type",
    "match_threshold"
  ],
  "get_merged_mask": [
    "pred1",
    "pred2"
  ],
  "get_merged_score": [
    "pred1",
    "pred2"
  ],
  "get_merged_bbox": [
    "pred1",
    "pred2"
  ],
  "get_merged_category": [
    "pred1",
    "pred2"
  ],
  "merge_object_prediction_pair": [
    "pred1",
    "pred2"
  ],
  "UnionMergePostprocess": {
    "__call__": [
      "self",
      "object_predictions"
    ],
    "_merge_object_prediction_pair": [
      "self",
      "pred1",
      "pred2"
    ],
    "_get_merged_category": [
      "pred1",
      "pred2"
    ],
    "_get_merged_bbox": [
      "pred1",
      "pred2"
    ],
    "_get_merged_score": [
      "pred1",
      "pred2"
    ],
    "_get_merged_mask": [
      "pred1",
      "pred2"
    ]
  },
  "Yolov5DetectionModel": {
    "__init__": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "num_categories": [
      "self"
    ],
    "has_mask": [
      "self"
    ],
    "category_names": [
      "self"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "DetectionModel": {
    "__init__": [
      "self",
      "model_path",
      "model",
      "config_path",
      "device",
      "mask_threshold",
      "confidence_threshold",
      "category_mapping",
      "category_remapping",
      "load_at_init",
      "image_size"
    ],
    "check_dependencies": [
      "self",
      "packages"
    ],
    "load_model": [
      "self"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "set_device": [
      "self",
      "device"
    ],
    "unload_model": [
      "self"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ],
    "_apply_category_remapping": [
      "self"
    ],
    "convert_original_predictions": [
      "self",
      "shift_amount",
      "full_shape"
    ],
    "object_prediction_list": [
      "self"
    ],
    "object_prediction_list_per_image": [
      "self"
    ],
    "original_predictions": [
      "self"
    ]
  },
  "UltralyticsDetectionModel": {
    "__init__": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "category_names": [
      "self"
    ],
    "num_categories": [
      "self"
    ],
    "has_mask": [
      "self"
    ],
    "is_obb": [
      "self"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "Detectron2DetectionModel": {
    "__init__": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "num_categories": [
      "self"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "DetInferencerWrapper": {
    "__init__": [
      "self",
      "model",
      "weights",
      "device",
      "scope",
      "palette",
      "image_size"
    ],
    "__call__": [
      "self",
      "images",
      "batch_size"
    ],
    "_init_pipeline": [
      "self",
      "cfg"
    ]
  },
  "MmdetDetectionModel": {
    "__init__": [
      "self",
      "model_path",
      "model",
      "config_path",
      "device",
      "mask_threshold",
      "confidence_threshold",
      "category_mapping",
      "category_remapping",
      "load_at_init",
      "image_size",
      "scope"
    ],
    "load_model": [
      "self"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "num_categories": [
      "self"
    ],
    "has_mask": [
      "self"
    ],
    "category_names": [
      "self"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "HuggingfaceDetectionModel": {
    "__init__": [
      "self",
      "model_path",
      "model",
      "processor",
      "config_path",
      "device",
      "mask_threshold",
      "confidence_threshold",
      "category_mapping",
      "category_remapping",
      "load_at_init",
      "image_size",
      "token"
    ],
    "processor": [
      "self"
    ],
    "image_shapes": [
      "self"
    ],
    "num_categories": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "set_model": [
      "self",
      "model",
      "processor"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "get_valid_predictions": [
      "self",
      "logits",
      "pred_boxes"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "RoboflowDetectionModel": {
    "__init__": [
      "self",
      "model",
      "model_path",
      "config_path",
      "device",
      "mask_threshold",
      "confidence_threshold",
      "category_mapping",
      "category_remapping",
      "load_at_init",
      "image_size",
      "api_key"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "load_model": [
      "self"
    ],
    "perform_inference": [
      "self",
      "image"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "TorchVisionDetectionModel": {
    "__init__": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "set_model": [
      "self",
      "model"
    ],
    "perform_inference": [
      "self",
      "image",
      "image_size"
    ],
    "num_categories": [
      "self"
    ],
    "has_mask": [
      "self"
    ],
    "category_names": [
      "self"
    ],
    "_create_object_prediction_list_from_original_predictions": [
      "self",
      "shift_amount_list",
      "full_shape_list"
    ]
  },
  "RTDetrDetectionModel": {
    "__init__": [
      "self"
    ],
    "load_model": [
      "self"
    ]
  },
  "_cocoeval_summarize": [
    "cocoeval",
    "ap",
    "iouThr",
    "catIdx",
    "areaRng",
    "maxDets",
    "catName",
    "nameStrLen"
  ],
  "evaluate_core": [
    "dataset_path",
    "result_path",
    "COCO",
    "COCOeval",
    "metric",
    "classwise",
    "max_detections",
    "iou_thrs",
    "metric_items",
    "out_dir",
    "areas"
  ],
  "evaluate": [
    "dataset_json_path",
    "result_json_path",
    "out_dir",
    "type",
    "classwise",
    "max_detections",
    "iou_thrs",
    "areas",
    "return_dict"
  ],
  "main": [
    "image_dir",
    "dataset_json_path"
  ],
  "COLOR_PALETTE": [],
  "_makeplot": [
    "rs",
    "ps",
    "outDir",
    "class_name",
    "iou_type"
  ],
  "_autolabel": [
    "ax",
    "rects",
    "is_percent"
  ],
  "_makebarplot": [
    "_",
    "ps",
    "outDir",
    "class_name",
    "iou_type"
  ],
  "_get_gt_area_group_numbers": [
    "cocoEval"
  ],
  "_make_gt_area_group_numbers_plot": [
    "cocoEval",
    "outDir",
    "verbose"
  ],
  "_make_gt_area_histogram_plot": [
    "cocoEval",
    "outDir"
  ],
  "_analyze_individual_category": [
    "k",
    "cocoDt",
    "cocoGt",
    "catId",
    "iou_type",
    "areas",
    "max_detections"
  ],
  "_analyse_results": [
    "res_file",
    "ann_file",
    "res_types",
    "out_dir",
    "extraplots",
    "areas",
    "max_detections"
  ],
  "analyse": [
    "dataset_json_path",
    "result_json_path",
    "out_dir",
    "type",
    "no_extraplots",
    "areas",
    "max_detections",
    "return_dict"
  ],
  "slicer": [
    "image_dir",
    "dataset_json_path",
    "slice_size",
    "overlap_ratio",
    "ignore_negative_samples",
    "output_dir",
    "min_area_ratio"
  ]
}