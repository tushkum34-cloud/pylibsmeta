{
  "LivyBatch": {
    "__init__": [
      "self",
      "url",
      "batch_id",
      "auth",
      "verify",
      "requests_session"
    ],
    "create": [
      "cls",
      "url",
      "file",
      "auth",
      "verify",
      "requests_session",
      "class_name",
      "args",
      "proxy_user",
      "jars",
      "py_files",
      "files",
      "driver_memory",
      "driver_cores",
      "executor_memory",
      "executor_cores",
      "num_executors",
      "archives",
      "queue",
      "name",
      "spark_conf"
    ],
    "wait": [
      "self"
    ],
    "state": [
      "self"
    ],
    "log": [
      "self",
      "from_",
      "size"
    ],
    "kill": [
      "self"
    ]
  },
  "Version": {
    "__init__": [
      "self",
      "version"
    ],
    "__repr__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "SparkRuntimeError": {
    "__init__": [
      "self",
      "ename",
      "evalue",
      "traceback"
    ],
    "__repr__": [
      "self"
    ]
  },
  "OutputStatus": {
    "OK": [],
    "ERROR": []
  },
  "Output": {
    "from_json": [
      "cls",
      "data"
    ],
    "raise_for_status": [
      "self"
    ]
  },
  "StatementKind": {
    "SPARK": [],
    "PYSPARK": [],
    "SPARKR": [],
    "SQL": []
  },
  "StatementState": {
    "WAITING": [],
    "RUNNING": [],
    "AVAILABLE": [],
    "ERROR": [],
    "CANCELLING": [],
    "CANCELLED": []
  },
  "Statement": {
    "from_json": [
      "cls",
      "session_id",
      "data"
    ]
  },
  "SessionKind": {
    "SPARK": [],
    "PYSPARK": [],
    "PYSPARK3": [],
    "SPARKR": [],
    "SQL": [],
    "SHARED": []
  },
  "SessionState": {
    "NOT_STARTED": [],
    "STARTING": [],
    "RECOVERING": [],
    "IDLE": [],
    "RUNNING": [],
    "BUSY": [],
    "SHUTTING_DOWN": [],
    "ERROR": [],
    "DEAD": [],
    "KILLED": [],
    "SUCCESS": []
  },
  "SESSION_STATE_NOT_READY": [],
  "SESSION_STATE_FINISHED": [],
  "Session": {
    "from_json": [
      "cls",
      "data"
    ]
  },
  "Batch": {
    "from_json": [
      "cls",
      "data"
    ]
  },
  "BatchLog": {
    "from_json": [
      "cls",
      "data"
    ]
  },
  "polling_intervals": [
    "start",
    "rest",
    "max_duration"
  ],
  "Auth": [],
  "Verify": [],
  "LOGGER": [],
  "VALID_LEGACY_SESSION_KINDS": [],
  "VALID_SESSION_KINDS": [],
  "JsonClient": {
    "__init__": [
      "self",
      "url",
      "auth",
      "verify",
      "requests_session"
    ],
    "close": [
      "self"
    ],
    "get": [
      "self",
      "endpoint",
      "params"
    ],
    "post": [
      "self",
      "endpoint",
      "data"
    ],
    "delete": [
      "self",
      "endpoint"
    ],
    "_request": [
      "self",
      "method",
      "endpoint",
      "data",
      "params"
    ]
  },
  "LivyClient": {
    "__init__": [
      "self",
      "url",
      "auth",
      "verify",
      "requests_session"
    ],
    "close": [
      "self"
    ],
    "server_version": [
      "self"
    ],
    "legacy_server": [
      "self"
    ],
    "list_sessions": [
      "self"
    ],
    "create_session": [
      "self",
      "kind",
      "proxy_user",
      "jars",
      "py_files",
      "files",
      "driver_memory",
      "driver_cores",
      "executor_memory",
      "executor_cores",
      "num_executors",
      "archives",
      "queue",
      "name",
      "spark_conf",
      "heartbeat_timeout"
    ],
    "get_session": [
      "self",
      "session_id"
    ],
    "delete_session": [
      "self",
      "session_id"
    ],
    "list_statements": [
      "self",
      "session_id"
    ],
    "create_statement": [
      "self",
      "session_id",
      "code",
      "kind"
    ],
    "get_statement": [
      "self",
      "session_id",
      "statement_id"
    ],
    "create_batch": [
      "self",
      "file",
      "class_name",
      "args",
      "proxy_user",
      "jars",
      "py_files",
      "files",
      "driver_memory",
      "driver_cores",
      "executor_memory",
      "executor_cores",
      "num_executors",
      "archives",
      "queue",
      "name",
      "spark_conf"
    ],
    "delete_batch": [
      "self",
      "batch_id"
    ],
    "get_batch": [
      "self",
      "batch_id"
    ],
    "get_batch_log": [
      "self",
      "batch_id",
      "from_",
      "size"
    ],
    "list_batches": [
      "self"
    ]
  },
  "_new_session_body": [
    "proxy_user",
    "jars",
    "py_files",
    "files",
    "driver_memory",
    "driver_cores",
    "executor_memory",
    "executor_cores",
    "num_executors",
    "archives",
    "queue",
    "name",
    "spark_conf"
  ],
  "SERIALISE_DATAFRAME_TEMPLATE_SPARK": [],
  "SERIALISE_DATAFRAME_TEMPLATE_PYSPARK": [],
  "SERIALISE_DATAFRAME_TEMPLATE_SPARKR": [],
  "_spark_serialise_dataframe_code": [
    "spark_dataframe_name",
    "session_kind"
  ],
  "_deserialise_dataframe": [
    "text"
  ],
  "_dataframe_from_json_output": [
    "json_output"
  ],
  "CREATE_DATAFRAME_TEMPLATE_SPARK": [],
  "CREATE_DATAFRAME_TEMPLATE_PYSPARK": [],
  "CREATE_DATAFRAME_TEMPLATE_SPARKR": [],
  "_spark_create_dataframe_code": [
    "session_kind",
    "spark_dataframe_name",
    "dataframe"
  ],
  "LivySession": {
    "__init__": [
      "self",
      "url",
      "session_id",
      "auth",
      "verify",
      "requests_session",
      "kind",
      "echo",
      "check"
    ],
    "create": [
      "cls",
      "url",
      "auth",
      "verify",
      "requests_session",
      "kind",
      "proxy_user",
      "jars",
      "py_files",
      "files",
      "driver_memory",
      "driver_cores",
      "executor_memory",
      "executor_cores",
      "num_executors",
      "archives",
      "queue",
      "name",
      "spark_conf",
      "heartbeat_timeout",
      "echo",
      "check"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "wait": [
      "self"
    ],
    "state": [
      "self"
    ],
    "close": [
      "self"
    ],
    "run": [
      "self",
      "code"
    ],
    "download": [
      "self",
      "dataframe_name"
    ],
    "read": [
      "self",
      "dataframe_name"
    ],
    "download_sql": [
      "self",
      "query"
    ],
    "read_sql": [
      "self",
      "code"
    ],
    "upload": [
      "self",
      "dataframe_name",
      "data"
    ],
    "_execute": [
      "self",
      "code"
    ]
  }
}