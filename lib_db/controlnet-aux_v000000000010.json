{
  "__version__": [],
  "LOGGER": [],
  "MODELS": [],
  "MODEL_PARAMS": [],
  "CHOICES": [],
  "Processor": {
    "__init__": [
      "self",
      "processor_id",
      "params"
    ],
    "load_processor": [
      "self",
      "processor_id"
    ],
    "__call__": [
      "self",
      "image",
      "to_pil"
    ]
  },
  "annotator_ckpts_path": [],
  "HWC3": [
    "x"
  ],
  "make_noise_disk": [
    "H",
    "W",
    "C",
    "F"
  ],
  "nms": [
    "x",
    "t",
    "s"
  ],
  "min_max_norm": [
    "x"
  ],
  "safe_step": [
    "x",
    "step"
  ],
  "img2mask": [
    "img",
    "H",
    "W",
    "low",
    "high"
  ],
  "resize_image": [
    "input_image",
    "resolution"
  ],
  "torch_gc": [],
  "ade_palette": [],
  "ZoeDetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "model_type",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "output_type",
      "gamma_corrected"
    ]
  },
  "infer_type": [
    "x"
  ],
  "parse_unknown": [
    "unknown_args"
  ],
  "ROOT": [],
  "HOME_DIR": [],
  "COMMON_CONFIG": [],
  "DATASETS_CONFIG": [],
  "ALL_INDOOR": [],
  "ALL_OUTDOOR": [],
  "ALL_EVAL_DATASETS": [],
  "COMMON_TRAINING_CONFIG": [],
  "flatten": [
    "config",
    "except_keys"
  ],
  "split_combined_args": [
    "kwargs"
  ],
  "parse_list": [
    "config",
    "key",
    "dtype"
  ],
  "get_model_config": [
    "model_name",
    "model_version"
  ],
  "update_model_config": [
    "config",
    "mode",
    "model_name",
    "model_version",
    "strict"
  ],
  "check_choices": [
    "name",
    "value",
    "choices"
  ],
  "KEYS_TYPE_BOOL": [],
  "get_config": [
    "model_name",
    "mode",
    "dataset"
  ],
  "change_dataset": [
    "config",
    "new_dataset"
  ],
  "EasyDict": {
    "__init__": [
      "self",
      "d"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__setitem__": [],
    "update": [
      "self",
      "e"
    ],
    "pop": [
      "self",
      "k",
      "d"
    ]
  },
  "DepthModel": {
    "__init__": [
      "self"
    ],
    "to": [
      "self",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_infer": [
      "self",
      "x"
    ],
    "_infer_with_pad_aug": [
      "self",
      "x",
      "pad_input",
      "fh",
      "fw",
      "upsampling_mode",
      "padding_mode"
    ],
    "infer_with_flip_aug": [
      "self",
      "x",
      "pad_input"
    ],
    "infer": [
      "self",
      "x",
      "pad_input",
      "with_flip_aug"
    ],
    "infer_pil": [
      "self",
      "pil_img",
      "pad_input",
      "with_flip_aug",
      "output_type"
    ]
  },
  "build_model": [
    "config"
  ],
  "load_state_dict": [
    "model",
    "state_dict"
  ],
  "load_wts": [
    "model",
    "checkpoint_path"
  ],
  "load_state_dict_from_url": [
    "model",
    "url"
  ],
  "load_state_from_resource": [
    "model",
    "resource"
  ],
  "log_binom": [
    "n",
    "k",
    "eps"
  ],
  "LogBinomial": {
    "__init__": [
      "self",
      "n_classes",
      "act"
    ],
    "forward": [
      "self",
      "x",
      "t",
      "eps"
    ]
  },
  "ConditionalLogBinomial": {
    "__init__": [
      "self",
      "in_features",
      "condition_dim",
      "n_classes",
      "bottleneck_factor",
      "p_eps",
      "max_temp",
      "min_temp",
      "act"
    ],
    "forward": [
      "self",
      "x",
      "cond"
    ]
  },
  "SeedBinRegressor": {
    "__init__": [
      "self",
      "in_features",
      "n_bins",
      "mlp_dim",
      "min_depth",
      "max_depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SeedBinRegressorUnnormed": {
    "__init__": [
      "self",
      "in_features",
      "n_bins",
      "mlp_dim",
      "min_depth",
      "max_depth"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Projector": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "mlp_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearSplitter": {
    "__init__": [
      "self",
      "in_features",
      "prev_nbins",
      "split_factor",
      "mlp_dim",
      "min_depth",
      "max_depth"
    ],
    "forward": [
      "self",
      "x",
      "b_prev",
      "prev_b_embedding",
      "interpolate",
      "is_for_query"
    ]
  },
  "exp_attractor": [
    "dx",
    "alpha",
    "gamma"
  ],
  "inv_attractor": [
    "dx",
    "alpha",
    "gamma"
  ],
  "AttractorLayer": {
    "__init__": [
      "self",
      "in_features",
      "n_bins",
      "n_attractors",
      "mlp_dim",
      "min_depth",
      "max_depth",
      "alpha",
      "gamma",
      "kind",
      "attractor_type",
      "memory_efficient"
    ],
    "forward": [
      "self",
      "x",
      "b_prev",
      "prev_b_embedding",
      "interpolate",
      "is_for_query"
    ]
  },
  "AttractorLayerUnnormed": {
    "__init__": [
      "self",
      "in_features",
      "n_bins",
      "n_attractors",
      "mlp_dim",
      "min_depth",
      "max_depth",
      "alpha",
      "gamma",
      "kind",
      "attractor_type",
      "memory_efficient"
    ],
    "forward": [
      "self",
      "x",
      "b_prev",
      "prev_b_embedding",
      "interpolate",
      "is_for_query"
    ]
  },
  "PatchTransformerEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "patch_size",
      "embedding_dim",
      "num_heads",
      "use_class_token"
    ],
    "positional_encoding_1d": [
      "self",
      "sequence_length",
      "batch_size",
      "embedding_dim",
      "device"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "denormalize": [
    "x"
  ],
  "get_activation": [
    "name",
    "bank"
  ],
  "Resize": {
    "__init__": [
      "self",
      "width",
      "height",
      "resize_target",
      "keep_aspect_ratio",
      "ensure_multiple_of",
      "resize_method"
    ],
    "constrain_to_multiple_of": [
      "self",
      "x",
      "min_val",
      "max_val"
    ],
    "get_size": [
      "self",
      "width",
      "height"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "PrepForMidas": {
    "__init__": [
      "self",
      "resize_mode",
      "keep_aspect_ratio",
      "img_size",
      "do_resize"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "MidasCore": {
    "__init__": [
      "self",
      "midas",
      "trainable",
      "fetch_features",
      "layer_names",
      "freeze_bn",
      "keep_aspect_ratio",
      "img_size"
    ],
    "set_trainable": [
      "self",
      "trainable"
    ],
    "set_fetch_features": [
      "self",
      "fetch_features"
    ],
    "freeze": [
      "self"
    ],
    "unfreeze": [
      "self"
    ],
    "freeze_bn": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "denorm",
      "return_rel_depth"
    ],
    "get_rel_pos_params": [
      "self"
    ],
    "get_enc_params_except_rel_pos": [
      "self"
    ],
    "freeze_encoder": [
      "self",
      "freeze_rel_pos"
    ],
    "attach_hooks": [
      "self",
      "midas"
    ],
    "remove_hooks": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "set_output_channels": [
      "self",
      "model_type"
    ],
    "build": [
      "midas_model_type",
      "train_midas",
      "use_pretrained_midas",
      "fetch_features",
      "freeze_bn",
      "force_keep_ar",
      "force_reload"
    ],
    "build_from_config": [
      "config"
    ],
    "parse_img_size": [
      "config"
    ]
  },
  "nchannels2models": [],
  "MIDAS_SETTINGS": [],
  "dependencies": [],
  "DPT_BEiT_L_512": [
    "pretrained"
  ],
  "DPT_BEiT_L_384": [
    "pretrained"
  ],
  "DPT_BEiT_B_384": [
    "pretrained"
  ],
  "DPT_SwinV2_L_384": [
    "pretrained"
  ],
  "DPT_SwinV2_B_384": [
    "pretrained"
  ],
  "DPT_SwinV2_T_256": [
    "pretrained"
  ],
  "DPT_Swin_L_384": [
    "pretrained"
  ],
  "DPT_Next_ViT_L_384": [
    "pretrained"
  ],
  "DPT_LeViT_224": [
    "pretrained"
  ],
  "DPT_Large": [
    "pretrained"
  ],
  "DPT_Hybrid": [
    "pretrained"
  ],
  "MiDaS": [
    "pretrained"
  ],
  "MiDaS_small": [
    "pretrained"
  ],
  "transforms": [],
  "_make_encoder": [
    "backbone",
    "features",
    "use_pretrained",
    "groups",
    "expand",
    "exportable",
    "hooks",
    "use_vit_only",
    "use_readout",
    "in_features"
  ],
  "_make_scratch": [
    "in_shape",
    "out_shape",
    "groups",
    "expand"
  ],
  "_make_pretrained_efficientnet_lite3": [
    "use_pretrained",
    "exportable"
  ],
  "_make_efficientnet_backbone": [
    "effnet"
  ],
  "_make_resnet_backbone": [
    "resnet"
  ],
  "_make_pretrained_resnext101_wsl": [
    "use_pretrained"
  ],
  "Interpolate": {
    "__init__": [
      "self",
      "scale_factor",
      "mode",
      "align_corners"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualConvUnit": {
    "__init__": [
      "self",
      "features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeatureFusionBlock": {
    "__init__": [
      "self",
      "features"
    ],
    "forward": [
      "self"
    ]
  },
  "ResidualConvUnit_custom": {
    "__init__": [
      "self",
      "features",
      "activation",
      "bn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeatureFusionBlock_custom": {
    "__init__": [
      "self",
      "features",
      "activation",
      "deconv",
      "bn",
      "expand",
      "align_corners",
      "size"
    ],
    "forward": [
      "self"
    ]
  },
  "MidasNet_small": {
    "__init__": [
      "self",
      "path",
      "features",
      "backbone",
      "non_negative",
      "exportable",
      "channels_last",
      "align_corners",
      "blocks"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "fuse_model": [
    "m"
  ],
  "apply_min_size": [
    "sample",
    "size",
    "image_interpolation_method"
  ],
  "NormalizeImage": {
    "__init__": [
      "self",
      "mean",
      "std"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "PrepareForNet": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "sample"
    ]
  },
  "BaseModel": {
    "load": [
      "self",
      "path"
    ]
  },
  "MidasNet": {
    "__init__": [
      "self",
      "path",
      "features",
      "non_negative"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "default_models": [],
  "load_model": [
    "device",
    "model_path",
    "model_type",
    "optimize",
    "height",
    "square"
  ],
  "_make_fusion_block": [
    "features",
    "use_bn",
    "size"
  ],
  "DPT": {
    "__init__": [
      "self",
      "head",
      "features",
      "backbone",
      "readout",
      "channels_last",
      "use_bn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DPTDepthModel": {
    "__init__": [
      "self",
      "path",
      "non_negative"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "timm_version": [],
  "is_new_timm": [],
  "create_model_adapter": [
    "model_name",
    "pretrained"
  ],
  "forward_swin": [
    "pretrained",
    "x"
  ],
  "_make_swin_backbone": [
    "model",
    "hooks",
    "patch_grid"
  ],
  "activations": [],
  "Slice": {
    "__init__": [
      "self",
      "start_index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AddReadout": {
    "__init__": [
      "self",
      "start_index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ProjectReadout": {
    "__init__": [
      "self",
      "in_features",
      "start_index"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Transpose": {
    "__init__": [
      "self",
      "dim0",
      "dim1"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_drop_path": [
    "module"
  ],
  "forward_default": [
    "pretrained",
    "x",
    "function_name"
  ],
  "forward_adapted_unflatten": [
    "pretrained",
    "x",
    "function_name"
  ],
  "get_readout_oper": [
    "vit_features",
    "features",
    "use_readout",
    "start_index"
  ],
  "make_backbone_default": [
    "model",
    "features",
    "size",
    "hooks",
    "vit_features",
    "use_readout",
    "start_index",
    "start_index_readout"
  ],
  "forward_next_vit": [
    "pretrained",
    "x"
  ],
  "_make_next_vit_backbone": [
    "model",
    "hooks"
  ],
  "_make_pretrained_next_vit_large_6m": [
    "hooks"
  ],
  "_make_pretrained_swin2l24_384": [
    "pretrained",
    "hooks"
  ],
  "_make_pretrained_swin2b24_384": [
    "pretrained",
    "hooks"
  ],
  "_make_pretrained_swin2t16_256": [
    "pretrained",
    "hooks"
  ],
  "_make_pretrained_swinl12_384": [
    "pretrained",
    "hooks"
  ],
  "forward_beit": [
    "pretrained",
    "x"
  ],
  "patch_embed_forward": [
    "self",
    "x"
  ],
  "_get_rel_pos_bias": [
    "self",
    "window_size"
  ],
  "attention_forward": [
    "self",
    "x",
    "resolution",
    "shared_rel_pos_bias"
  ],
  "block_forward": [
    "self",
    "x",
    "resolution",
    "shared_rel_pos_bias"
  ],
  "beit_forward_features": [
    "self",
    "x"
  ],
  "_make_beit_backbone": [
    "model",
    "features",
    "size",
    "hooks",
    "vit_features",
    "use_readout",
    "start_index",
    "start_index_readout"
  ],
  "_make_pretrained_beitl16_512": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_beitl16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_beitb16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "forward_levit": [
    "pretrained",
    "x"
  ],
  "_make_levit_backbone": [
    "model",
    "hooks",
    "patch_grid"
  ],
  "ConvTransposeNorm": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "kernel_size",
      "stride",
      "pad",
      "dilation",
      "groups",
      "bn_weight_init"
    ],
    "fuse": [
      "self"
    ]
  },
  "stem_b4_transpose": [
    "in_chs",
    "out_chs",
    "activation"
  ],
  "_make_pretrained_levit_384": [
    "pretrained",
    "hooks"
  ],
  "forward_vit": [
    "pretrained",
    "x"
  ],
  "_resize_pos_embed": [
    "self",
    "posemb",
    "gs_h",
    "gs_w"
  ],
  "forward_flex": [
    "self",
    "x"
  ],
  "_make_vit_b16_backbone": [
    "model",
    "features",
    "size",
    "hooks",
    "vit_features",
    "use_readout",
    "start_index",
    "start_index_readout"
  ],
  "_make_pretrained_vitl16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_vitb16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_vit_b_rn50_backbone": [
    "model",
    "features",
    "size",
    "hooks",
    "vit_features",
    "patch_size",
    "number_stages",
    "use_vit_only",
    "use_readout",
    "start_index"
  ],
  "_make_pretrained_vitb_rn50_384": [
    "pretrained",
    "use_readout",
    "hooks",
    "use_vit_only"
  ],
  "ZoeDepthNK": {
    "__init__": [
      "self",
      "core",
      "bin_conf",
      "bin_centers_type",
      "bin_embedding_dim",
      "n_attractors",
      "attractor_alpha",
      "attractor_gamma",
      "attractor_kind",
      "attractor_type",
      "min_temp",
      "max_temp",
      "memory_efficient",
      "train_midas",
      "is_midas_pretrained",
      "midas_lr_factor",
      "encoder_lr_factor",
      "pos_enc_lr_factor",
      "inverse_midas"
    ],
    "forward": [
      "self",
      "x",
      "return_final_centers",
      "denorm",
      "return_probs"
    ],
    "get_lr_params": [
      "self",
      "lr"
    ],
    "get_conf_parameters": [
      "self",
      "conf_name"
    ],
    "freeze_conf": [
      "self",
      "conf_name"
    ],
    "unfreeze_conf": [
      "self",
      "conf_name"
    ],
    "freeze_all_confs": [
      "self"
    ],
    "build": [
      "midas_model_type",
      "pretrained_resource",
      "use_pretrained_midas",
      "train_midas",
      "freeze_midas_bn"
    ],
    "build_from_config": [
      "config"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "all_versions": [],
  "get_version": [],
  "ZoeDepth": {
    "__init__": [
      "self",
      "core",
      "n_bins",
      "bin_centers_type",
      "bin_embedding_dim",
      "min_depth",
      "max_depth",
      "n_attractors",
      "attractor_alpha",
      "attractor_gamma",
      "attractor_kind",
      "attractor_type",
      "min_temp",
      "max_temp",
      "train_midas",
      "midas_lr_factor",
      "encoder_lr_factor",
      "pos_enc_lr_factor",
      "inverse_midas"
    ],
    "forward": [
      "self",
      "x",
      "return_final_centers",
      "denorm",
      "return_probs"
    ],
    "get_lr_params": [
      "self",
      "lr"
    ],
    "build": [
      "midas_model_type",
      "pretrained_resource",
      "use_pretrained_midas",
      "train_midas",
      "freeze_midas_bn"
    ],
    "build_from_config": [
      "config"
    ],
    "load_state_dict": [
      "self",
      "state_dict",
      "strict"
    ]
  },
  "CannyDetector": {
    "__call__": [
      "self",
      "input_image",
      "low_threshold",
      "high_threshold",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "UnetGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "num_downs",
      "ngf",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "UnetSkipConnectionBlock": {
    "__init__": [
      "self",
      "outer_nc",
      "inner_nc",
      "input_nc",
      "submodule",
      "outermost",
      "innermost",
      "norm_layer",
      "use_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LineartAnimeDetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "ContentShuffleDetector": {
    "__call__": [
      "self",
      "input_image",
      "h",
      "w",
      "f",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "ColorShuffleDetector": {
    "__call__": [
      "self",
      "img"
    ]
  },
  "GrayDetector": {
    "__call__": [
      "self",
      "img"
    ]
  },
  "DownSampleDetector": {
    "__call__": [
      "self",
      "img",
      "level",
      "k"
    ]
  },
  "Image2MaskShuffleDetector": {
    "__init__": [
      "self",
      "resolution"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "deccode_output_score_and_ptss": [
    "tpMap",
    "topk_n",
    "ksize"
  ],
  "pred_lines": [
    "image",
    "model",
    "input_shape",
    "score_thr",
    "dist_thr"
  ],
  "pred_squares": [
    "image",
    "model",
    "input_shape",
    "params"
  ],
  "MLSDdetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "thr_v",
      "thr_d",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "BlockTypeA": {
    "__init__": [
      "self",
      "in_c1",
      "in_c2",
      "out_c1",
      "out_c2",
      "upscale"
    ],
    "forward": [
      "self",
      "a",
      "b"
    ]
  },
  "BlockTypeB": {
    "__init__": [
      "self",
      "in_c",
      "out_c"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BlockTypeC": {
    "__init__": [
      "self",
      "in_c",
      "out_c"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_make_divisible": [
    "v",
    "divisor",
    "min_value"
  ],
  "ConvBNReLU": {
    "__init__": [
      "self",
      "in_planes",
      "out_planes",
      "kernel_size",
      "stride",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InvertedResidual": {
    "__init__": [
      "self",
      "inp",
      "oup",
      "stride",
      "expand_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MobileNetV2": {
    "__init__": [
      "self",
      "pretrained"
    ],
    "_forward_impl": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_load_pretrained_model": [
      "self"
    ]
  },
  "MobileV2_MLSD_Tiny": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MobileV2_MLSD_Large": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "load_checkpoint": [
    "fpath",
    "model"
  ],
  "NormalBaeDetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "NNET": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_1x_lr_params": [
      "self"
    ],
    "get_10x_lr_params": [
      "self"
    ]
  },
  "Encoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "num_classes"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "UpSampleBN": {
    "__init__": [
      "self",
      "skip_input",
      "output_features"
    ],
    "forward": [
      "self",
      "x",
      "concat_with"
    ]
  },
  "UpSampleGN": {
    "__init__": [
      "self",
      "skip_input",
      "output_features"
    ],
    "forward": [
      "self",
      "x",
      "concat_with"
    ]
  },
  "Conv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "norm_normalize": [
    "norm_out"
  ],
  "sample_points": [
    "init_normal",
    "gt_norm_mask",
    "sampling_ratio",
    "beta"
  ],
  "parser": [],
  "main": [],
  "traverse_graph": [
    "graph",
    "prefix"
  ],
  "AverageMeter": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "update": [
      "self",
      "val",
      "n"
    ]
  },
  "accuracy": [
    "output",
    "target",
    "topk"
  ],
  "get_outdir": [
    "path"
  ],
  "here": [],
  "has_native_amp": [],
  "accuracy_np": [
    "output",
    "target"
  ],
  "__all__": [],
  "model_urls": [],
  "GenEfficientNet": {
    "__init__": [
      "self",
      "block_args",
      "num_classes",
      "in_chans",
      "num_features",
      "stem_size",
      "fix_stem",
      "channel_multiplier",
      "channel_divisor",
      "channel_min",
      "pad_type",
      "act_layer",
      "drop_rate",
      "drop_connect_rate",
      "se_kwargs",
      "norm_layer",
      "norm_kwargs",
      "weight_init"
    ],
    "features": [
      "self",
      "x"
    ],
    "as_sequential": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_create_model": [
    "model_kwargs",
    "variant",
    "pretrained"
  ],
  "_gen_mnasnet_a1": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_mnasnet_b1": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_mnasnet_small": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_mobilenet_v2": [
    "variant",
    "channel_multiplier",
    "depth_multiplier",
    "fix_stem_head",
    "pretrained"
  ],
  "_gen_fbnetc": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_spnasnet": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_efficientnet": [
    "variant",
    "channel_multiplier",
    "depth_multiplier",
    "pretrained"
  ],
  "_gen_efficientnet_edge": [
    "variant",
    "channel_multiplier",
    "depth_multiplier",
    "pretrained"
  ],
  "_gen_efficientnet_condconv": [
    "variant",
    "channel_multiplier",
    "depth_multiplier",
    "experts_multiplier",
    "pretrained"
  ],
  "_gen_efficientnet_lite": [
    "variant",
    "channel_multiplier",
    "depth_multiplier",
    "pretrained"
  ],
  "_gen_mixnet_s": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_mixnet_m": [
    "variant",
    "channel_multiplier",
    "depth_multiplier",
    "pretrained"
  ],
  "mnasnet_050": [
    "pretrained"
  ],
  "mnasnet_075": [
    "pretrained"
  ],
  "mnasnet_100": [
    "pretrained"
  ],
  "mnasnet_b1": [
    "pretrained"
  ],
  "mnasnet_140": [
    "pretrained"
  ],
  "semnasnet_050": [
    "pretrained"
  ],
  "semnasnet_075": [
    "pretrained"
  ],
  "semnasnet_100": [
    "pretrained"
  ],
  "mnasnet_a1": [
    "pretrained"
  ],
  "semnasnet_140": [
    "pretrained"
  ],
  "mnasnet_small": [
    "pretrained"
  ],
  "mobilenetv2_100": [
    "pretrained"
  ],
  "mobilenetv2_140": [
    "pretrained"
  ],
  "mobilenetv2_110d": [
    "pretrained"
  ],
  "mobilenetv2_120d": [
    "pretrained"
  ],
  "fbnetc_100": [
    "pretrained"
  ],
  "spnasnet_100": [
    "pretrained"
  ],
  "efficientnet_b0": [
    "pretrained"
  ],
  "efficientnet_b1": [
    "pretrained"
  ],
  "efficientnet_b2": [
    "pretrained"
  ],
  "efficientnet_b3": [
    "pretrained"
  ],
  "efficientnet_b4": [
    "pretrained"
  ],
  "efficientnet_b5": [
    "pretrained"
  ],
  "efficientnet_b6": [
    "pretrained"
  ],
  "efficientnet_b7": [
    "pretrained"
  ],
  "efficientnet_b8": [
    "pretrained"
  ],
  "efficientnet_l2": [
    "pretrained"
  ],
  "efficientnet_es": [
    "pretrained"
  ],
  "efficientnet_em": [
    "pretrained"
  ],
  "efficientnet_el": [
    "pretrained"
  ],
  "efficientnet_cc_b0_4e": [
    "pretrained"
  ],
  "efficientnet_cc_b0_8e": [
    "pretrained"
  ],
  "efficientnet_cc_b1_8e": [
    "pretrained"
  ],
  "efficientnet_lite0": [
    "pretrained"
  ],
  "efficientnet_lite1": [
    "pretrained"
  ],
  "efficientnet_lite2": [
    "pretrained"
  ],
  "efficientnet_lite3": [
    "pretrained"
  ],
  "efficientnet_lite4": [
    "pretrained"
  ],
  "tf_efficientnet_b0": [
    "pretrained"
  ],
  "tf_efficientnet_b1": [
    "pretrained"
  ],
  "tf_efficientnet_b2": [
    "pretrained"
  ],
  "tf_efficientnet_b3": [
    "pretrained"
  ],
  "tf_efficientnet_b4": [
    "pretrained"
  ],
  "tf_efficientnet_b5": [
    "pretrained"
  ],
  "tf_efficientnet_b6": [
    "pretrained"
  ],
  "tf_efficientnet_b7": [
    "pretrained"
  ],
  "tf_efficientnet_b8": [
    "pretrained"
  ],
  "tf_efficientnet_b0_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b1_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b2_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b3_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b4_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b5_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b6_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b7_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b8_ap": [
    "pretrained"
  ],
  "tf_efficientnet_b0_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b1_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b2_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b3_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b4_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b5_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b6_ns": [
    "pretrained"
  ],
  "tf_efficientnet_b7_ns": [
    "pretrained"
  ],
  "tf_efficientnet_l2_ns_475": [
    "pretrained"
  ],
  "tf_efficientnet_l2_ns": [
    "pretrained"
  ],
  "tf_efficientnet_es": [
    "pretrained"
  ],
  "tf_efficientnet_em": [
    "pretrained"
  ],
  "tf_efficientnet_el": [
    "pretrained"
  ],
  "tf_efficientnet_cc_b0_4e": [
    "pretrained"
  ],
  "tf_efficientnet_cc_b0_8e": [
    "pretrained"
  ],
  "tf_efficientnet_cc_b1_8e": [
    "pretrained"
  ],
  "tf_efficientnet_lite0": [
    "pretrained"
  ],
  "tf_efficientnet_lite1": [
    "pretrained"
  ],
  "tf_efficientnet_lite2": [
    "pretrained"
  ],
  "tf_efficientnet_lite3": [
    "pretrained"
  ],
  "tf_efficientnet_lite4": [
    "pretrained"
  ],
  "mixnet_s": [
    "pretrained"
  ],
  "mixnet_m": [
    "pretrained"
  ],
  "mixnet_l": [
    "pretrained"
  ],
  "mixnet_xl": [
    "pretrained"
  ],
  "mixnet_xxl": [
    "pretrained"
  ],
  "tf_mixnet_s": [
    "pretrained"
  ],
  "tf_mixnet_m": [
    "pretrained"
  ],
  "tf_mixnet_l": [
    "pretrained"
  ],
  "BN_MOMENTUM_TF_DEFAULT": [],
  "BN_EPS_TF_DEFAULT": [],
  "_BN_ARGS_TF": [],
  "get_bn_args_tf": [],
  "resolve_bn_args": [
    "kwargs"
  ],
  "_SE_ARGS_DEFAULT": [],
  "resolve_se_args": [
    "kwargs",
    "in_chs",
    "act_layer"
  ],
  "resolve_act_layer": [
    "kwargs",
    "default"
  ],
  "make_divisible": [
    "v",
    "divisor",
    "min_value"
  ],
  "round_channels": [
    "channels",
    "multiplier",
    "divisor",
    "channel_min"
  ],
  "drop_connect": [
    "inputs",
    "training",
    "drop_connect_rate"
  ],
  "SqueezeExcite": {
    "__init__": [
      "self",
      "in_chs",
      "se_ratio",
      "reduced_base_chs",
      "act_layer",
      "gate_fn",
      "divisor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBnAct": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "kernel_size",
      "stride",
      "pad_type",
      "act_layer",
      "norm_layer",
      "norm_kwargs"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthwiseSeparableConv": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "dw_kernel_size",
      "stride",
      "pad_type",
      "act_layer",
      "noskip",
      "pw_kernel_size",
      "pw_act",
      "se_ratio",
      "se_kwargs",
      "norm_layer",
      "norm_kwargs",
      "drop_connect_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CondConvResidual": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "dw_kernel_size",
      "stride",
      "pad_type",
      "act_layer",
      "noskip",
      "exp_ratio",
      "exp_kernel_size",
      "pw_kernel_size",
      "se_ratio",
      "se_kwargs",
      "norm_layer",
      "norm_kwargs",
      "num_experts",
      "drop_connect_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EdgeResidual": {
    "__init__": [
      "self",
      "in_chs",
      "out_chs",
      "exp_kernel_size",
      "exp_ratio",
      "fake_in_chs",
      "stride",
      "pad_type",
      "act_layer",
      "noskip",
      "pw_kernel_size",
      "se_ratio",
      "se_kwargs",
      "norm_layer",
      "norm_kwargs",
      "drop_connect_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "EfficientNetBuilder": {
    "__init__": [
      "self",
      "channel_multiplier",
      "channel_divisor",
      "channel_min",
      "pad_type",
      "act_layer",
      "se_kwargs",
      "norm_layer",
      "norm_kwargs",
      "drop_connect_rate"
    ],
    "_round_channels": [
      "self",
      "chs"
    ],
    "_make_block": [
      "self",
      "ba"
    ],
    "_make_stack": [
      "self",
      "stack_args"
    ],
    "__call__": [
      "self",
      "in_chs",
      "block_args"
    ]
  },
  "_parse_ksize": [
    "ss"
  ],
  "_decode_block_str": [
    "block_str"
  ],
  "_scale_stage_depth": [
    "stack_args",
    "repeats",
    "depth_multiplier",
    "depth_trunc"
  ],
  "decode_arch_def": [
    "arch_def",
    "depth_multiplier",
    "depth_trunc",
    "experts_multiplier",
    "fix_first_last"
  ],
  "initialize_weight_goog": [
    "m",
    "n",
    "fix_group_fanout"
  ],
  "initialize_weight_default": [
    "m",
    "n"
  ],
  "MobileNetV3": {
    "__init__": [
      "self",
      "block_args",
      "num_classes",
      "in_chans",
      "stem_size",
      "num_features",
      "head_bias",
      "channel_multiplier",
      "pad_type",
      "act_layer",
      "drop_rate",
      "drop_connect_rate",
      "se_kwargs",
      "norm_layer",
      "norm_kwargs",
      "weight_init"
    ],
    "as_sequential": [
      "self"
    ],
    "features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_gen_mobilenet_v3_rw": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "_gen_mobilenet_v3": [
    "variant",
    "channel_multiplier",
    "pretrained"
  ],
  "mobilenetv3_rw": [
    "pretrained"
  ],
  "mobilenetv3_large_075": [
    "pretrained"
  ],
  "mobilenetv3_large_100": [
    "pretrained"
  ],
  "mobilenetv3_large_minimal_100": [
    "pretrained"
  ],
  "mobilenetv3_small_075": [
    "pretrained"
  ],
  "mobilenetv3_small_100": [
    "pretrained"
  ],
  "mobilenetv3_small_minimal_100": [
    "pretrained"
  ],
  "tf_mobilenetv3_large_075": [
    "pretrained"
  ],
  "tf_mobilenetv3_large_100": [
    "pretrained"
  ],
  "tf_mobilenetv3_large_minimal_100": [
    "pretrained"
  ],
  "tf_mobilenetv3_small_075": [
    "pretrained"
  ],
  "tf_mobilenetv3_small_100": [
    "pretrained"
  ],
  "tf_mobilenetv3_small_minimal_100": [
    "pretrained"
  ],
  "load_pretrained": [
    "model",
    "url",
    "filter_fn",
    "strict"
  ],
  "_ntuple": [
    "n"
  ],
  "_single": [],
  "_pair": [],
  "_triple": [],
  "_quadruple": [],
  "_is_static_pad": [
    "kernel_size",
    "stride",
    "dilation"
  ],
  "_get_padding": [
    "kernel_size",
    "stride",
    "dilation"
  ],
  "_calc_same_pad": [
    "i",
    "k",
    "s",
    "d"
  ],
  "_same_pad_arg": [
    "input_size",
    "kernel_size",
    "stride",
    "dilation"
  ],
  "_split_channels": [
    "num_chan",
    "num_groups"
  ],
  "conv2d_same": [
    "x",
    "weight",
    "bias",
    "stride",
    "padding",
    "dilation",
    "groups"
  ],
  "Conv2dSame": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv2dSameExport": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_padding_value": [
    "padding",
    "kernel_size"
  ],
  "create_conv2d_pad": [
    "in_chs",
    "out_chs",
    "kernel_size"
  ],
  "MixedConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "depthwise"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_condconv_initializer": [
    "initializer",
    "num_experts",
    "expert_shape"
  ],
  "CondConv2d": {
    "__constants__": [],
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "num_experts"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "routing_weights"
    ]
  },
  "select_conv2d": [
    "in_chs",
    "out_chs",
    "kernel_size"
  ],
  "_NO_JIT": [],
  "_NO_ACTIVATION_JIT": [],
  "_EXPORTABLE": [],
  "_SCRIPTABLE": [],
  "is_no_jit": [],
  "set_no_jit": {
    "__init__": [
      "self",
      "mode"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "is_exportable": [],
  "set_exportable": {
    "__init__": [
      "self",
      "mode"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "is_scriptable": [],
  "set_scriptable": {
    "__init__": [
      "self",
      "mode"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "set_layer_config": {
    "__init__": [
      "self",
      "scriptable",
      "exportable",
      "no_jit",
      "no_activation_jit"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "layer_config_kwargs": [
    "kwargs"
  ],
  "create_model": [
    "model_name",
    "pretrained",
    "num_classes",
    "in_chans",
    "checkpoint_path"
  ],
  "swish": [
    "x",
    "inplace"
  ],
  "Swish": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "mish": [
    "x",
    "inplace"
  ],
  "Mish": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "sigmoid": [
    "x",
    "inplace"
  ],
  "Sigmoid": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "tanh": [
    "x",
    "inplace"
  ],
  "Tanh": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_swish": [
    "x",
    "inplace"
  ],
  "HardSwish": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_sigmoid": [
    "x",
    "inplace"
  ],
  "HardSigmoid": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_has_silu": [],
  "_ACT_FN_DEFAULT": [],
  "_ACT_FN_JIT": [],
  "_ACT_FN_ME": [],
  "_ACT_LAYER_DEFAULT": [],
  "_ACT_LAYER_JIT": [],
  "_ACT_LAYER_ME": [],
  "_OVERRIDE_FN": [],
  "_OVERRIDE_LAYER": [],
  "add_override_act_fn": [
    "name",
    "fn"
  ],
  "update_override_act_fn": [
    "overrides"
  ],
  "clear_override_act_fn": [],
  "add_override_act_layer": [
    "name",
    "fn"
  ],
  "update_override_act_layer": [
    "overrides"
  ],
  "clear_override_act_layer": [],
  "get_act_fn": [
    "name"
  ],
  "get_act_layer": [
    "name"
  ],
  "swish_jit_fwd": [
    "x"
  ],
  "swish_jit_bwd": [
    "x",
    "grad_output"
  ],
  "SwishJitAutoFn": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "swish_me": [
    "x",
    "inplace"
  ],
  "SwishMe": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "mish_jit_fwd": [
    "x"
  ],
  "mish_jit_bwd": [
    "x",
    "grad_output"
  ],
  "MishJitAutoFn": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "mish_me": [
    "x",
    "inplace"
  ],
  "MishMe": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_sigmoid_jit_fwd": [
    "x",
    "inplace"
  ],
  "hard_sigmoid_jit_bwd": [
    "x",
    "grad_output"
  ],
  "HardSigmoidJitAutoFn": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "hard_sigmoid_me": [
    "x",
    "inplace"
  ],
  "HardSigmoidMe": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_swish_jit_fwd": [
    "x"
  ],
  "hard_swish_jit_bwd": [
    "x",
    "grad_output"
  ],
  "HardSwishJitAutoFn": {
    "forward": [
      "ctx",
      "x"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "hard_swish_me": [
    "x",
    "inplace"
  ],
  "HardSwishMe": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "swish_jit": [
    "x",
    "inplace"
  ],
  "mish_jit": [
    "x",
    "_inplace"
  ],
  "SwishJit": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MishJit": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_sigmoid_jit": [
    "x",
    "inplace"
  ],
  "HardSigmoidJit": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "hard_swish_jit": [
    "x",
    "inplace"
  ],
  "HardSwishJit": {
    "__init__": [
      "self",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "draw_pose": [
    "pose",
    "H",
    "W"
  ],
  "DWposeDetector": {
    "__init__": [
      "self",
      "det_config",
      "det_ckpt",
      "pose_config",
      "pose_ckpt",
      "device"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "eps": [],
  "smart_resize": [
    "x",
    "s"
  ],
  "smart_resize_k": [
    "x",
    "fx",
    "fy"
  ],
  "padRightDownCorner": [
    "img",
    "stride",
    "padValue"
  ],
  "transfer": [
    "model",
    "model_weights"
  ],
  "draw_bodypose": [
    "canvas",
    "candidate",
    "subset"
  ],
  "draw_handpose": [
    "canvas",
    "all_hand_peaks"
  ],
  "draw_facepose": [
    "canvas",
    "all_lmks"
  ],
  "handDetect": [
    "candidate",
    "subset",
    "oriImg"
  ],
  "faceDetect": [
    "candidate",
    "subset",
    "oriImg"
  ],
  "npmax": [
    "array"
  ],
  "Wholebody": {
    "__init__": [
      "self",
      "det_config",
      "det_ckpt",
      "pose_config",
      "pose_ckpt",
      "device"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "oriImg"
    ]
  },
  "img_scale": [],
  "model": [],
  "data_root": [],
  "dataset_type": [],
  "backend_args": [],
  "train_pipeline": [],
  "train_dataset": [],
  "test_pipeline": [],
  "train_dataloader": [],
  "val_dataloader": [],
  "test_dataloader": [],
  "val_evaluator": [],
  "test_evaluator": [],
  "max_epochs": [],
  "num_last_epochs": [],
  "interval": [],
  "train_cfg": [],
  "base_lr": [],
  "optim_wrapper": [],
  "param_scheduler": [],
  "default_hooks": [],
  "custom_hooks": [],
  "auto_scale_lr": [],
  "stage2_num_epochs": [],
  "randomness": [],
  "codec": [],
  "data_mode": [],
  "val_pipeline": [],
  "train_pipeline_stage2": [],
  "datasets": [],
  "dataset_coco": [],
  "scene": [],
  "Hand": {
    "__init__": [
      "self",
      "model_path"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "oriImgRaw"
    ]
  },
  "HandResult": [],
  "FaceResult": [],
  "PoseResult": {},
  "draw_poses": [
    "poses",
    "H",
    "W",
    "draw_body",
    "draw_hand",
    "draw_face"
  ],
  "OpenposeDetector": {
    "__init__": [
      "self",
      "body_estimation",
      "hand_estimation",
      "face_estimation"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "hand_filename",
      "face_filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "detect_hands": [
      "self",
      "body",
      "oriImg"
    ],
    "detect_face": [
      "self",
      "body",
      "oriImg"
    ],
    "detect_poses": [
      "self",
      "oriImg",
      "include_hand",
      "include_face"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "include_body",
      "include_hand",
      "include_face",
      "hand_and_face",
      "output_type"
    ]
  },
  "make_layers": [
    "block",
    "no_relu_layers"
  ],
  "bodypose_model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "handpose_model": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FaceNet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LOG": [],
  "TOTEN": [],
  "TOPIL": [],
  "params": [],
  "Face": {
    "__init__": [
      "self",
      "face_model_path",
      "inference_size",
      "gaussian_sigma",
      "heatmap_peak_thresh"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "face_img"
    ],
    "compute_peaks_from_heatmaps": [
      "self",
      "heatmaps"
    ]
  },
  "Keypoint": {},
  "BodyResult": {},
  "Body": {
    "__init__": [
      "self",
      "model_path"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "oriImg"
    ],
    "format_body_result": [
      "candidate",
      "subset"
    ]
  },
  "build_sam_vit_h": [
    "checkpoint"
  ],
  "build_sam": [],
  "build_sam_vit_l": [
    "checkpoint"
  ],
  "build_sam_vit_b": [
    "checkpoint"
  ],
  "build_sam_vit_t": [
    "checkpoint"
  ],
  "sam_model_registry": [],
  "_build_sam": [
    "encoder_embed_dim",
    "encoder_depth",
    "encoder_num_heads",
    "encoder_global_attn_indexes",
    "checkpoint"
  ],
  "SamAutomaticMaskGenerator": {
    "__init__": [
      "self",
      "model",
      "points_per_side",
      "points_per_batch",
      "pred_iou_thresh",
      "stability_score_thresh",
      "stability_score_offset",
      "box_nms_thresh",
      "crop_n_layers",
      "crop_nms_thresh",
      "crop_overlap_ratio",
      "crop_n_points_downscale_factor",
      "point_grids",
      "min_mask_region_area",
      "output_mode"
    ],
    "generate": [
      "self",
      "image"
    ],
    "_generate_masks": [
      "self",
      "image"
    ],
    "_process_crop": [
      "self",
      "image",
      "crop_box",
      "crop_layer_idx",
      "orig_size"
    ],
    "_process_batch": [
      "self",
      "points",
      "im_size",
      "crop_box",
      "orig_size"
    ],
    "postprocess_small_regions": [
      "mask_data",
      "min_area",
      "nms_thresh"
    ]
  },
  "SamDetector": {
    "__init__": [
      "self",
      "mask_generator"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "model_type",
      "filename",
      "subfolder",
      "cache_dir"
    ],
    "show_anns": [
      "self",
      "anns"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "SamPredictor": {
    "__init__": [
      "self",
      "sam_model"
    ],
    "set_image": [
      "self",
      "image",
      "image_format"
    ],
    "set_torch_image": [
      "self",
      "transformed_image",
      "original_image_size"
    ],
    "predict": [
      "self",
      "point_coords",
      "point_labels",
      "box",
      "mask_input",
      "multimask_output",
      "return_logits"
    ],
    "predict_torch": [
      "self",
      "point_coords",
      "point_labels",
      "boxes",
      "mask_input",
      "multimask_output",
      "return_logits"
    ],
    "get_image_embedding": [
      "self"
    ],
    "device": [
      "self"
    ],
    "reset_image": [
      "self"
    ]
  },
  "MLPBlock": {
    "__init__": [
      "self",
      "embedding_dim",
      "mlp_dim",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm2d": {
    "__init__": [
      "self",
      "num_channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PromptEncoder": {
    "__init__": [
      "self",
      "embed_dim",
      "image_embedding_size",
      "input_image_size",
      "mask_in_chans",
      "activation"
    ],
    "get_dense_pe": [
      "self"
    ],
    "_embed_points": [
      "self",
      "points",
      "labels",
      "pad"
    ],
    "_embed_boxes": [
      "self",
      "boxes"
    ],
    "_embed_masks": [
      "self",
      "masks"
    ],
    "_get_batch_size": [
      "self",
      "points",
      "boxes",
      "masks"
    ],
    "_get_device": [
      "self"
    ],
    "forward": [
      "self",
      "points",
      "boxes",
      "masks"
    ]
  },
  "PositionEmbeddingRandom": {
    "__init__": [
      "self",
      "num_pos_feats",
      "scale"
    ],
    "_pe_encoding": [
      "self",
      "coords"
    ],
    "forward": [
      "self",
      "size"
    ],
    "forward_with_coords": [
      "self",
      "coords_input",
      "image_size"
    ]
  },
  "Sam": {
    "__init__": [
      "self",
      "image_encoder",
      "prompt_encoder",
      "mask_decoder",
      "pixel_mean",
      "pixel_std"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "batched_input",
      "multimask_output"
    ],
    "postprocess_masks": [
      "self",
      "masks",
      "input_size",
      "original_size"
    ],
    "preprocess": [
      "self",
      "x"
    ]
  },
  "MaskDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "image_embeddings",
      "image_pe",
      "sparse_prompt_embeddings",
      "dense_prompt_embeddings",
      "multimask_output"
    ],
    "predict_masks": [
      "self",
      "image_embeddings",
      "image_pe",
      "sparse_prompt_embeddings",
      "dense_prompt_embeddings"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim",
      "num_layers",
      "sigmoid_output"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TwoWayTransformer": {
    "__init__": [
      "self",
      "depth",
      "embedding_dim",
      "num_heads",
      "mlp_dim",
      "activation",
      "attention_downsample_rate"
    ],
    "forward": [
      "self",
      "image_embedding",
      "image_pe",
      "point_embedding"
    ]
  },
  "TwoWayAttentionBlock": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_heads",
      "mlp_dim",
      "activation",
      "attention_downsample_rate",
      "skip_first_layer_pe"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "query_pe",
      "key_pe"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "embedding_dim",
      "num_heads",
      "downsample_rate"
    ],
    "_separate_heads": [
      "self",
      "x",
      "num_heads"
    ],
    "_recombine_heads": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v"
    ]
  },
  "ImageEncoderViT": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "out_chans",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_abs_pos",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "global_attn_indexes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_unpartition": [
    "windows",
    "window_size",
    "pad_hw",
    "hw"
  ],
  "get_rel_pos": [
    "q_size",
    "k_size",
    "rel_pos"
  ],
  "add_decomposed_rel_pos": [
    "attn",
    "q",
    "rel_pos_h",
    "rel_pos_w",
    "q_size",
    "k_size"
  ],
  "PatchEmbed": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv2d_BN": {
    "__init__": [
      "self",
      "a",
      "b",
      "ks",
      "stride",
      "pad",
      "dilation",
      "groups",
      "bn_weight_init"
    ],
    "fuse": [
      "self"
    ]
  },
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "__repr__": [
      "self"
    ]
  },
  "MBConv": {
    "__init__": [
      "self",
      "in_chans",
      "out_chans",
      "expand_ratio",
      "activation",
      "drop_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchMerging": {
    "__init__": [
      "self",
      "input_resolution",
      "dim",
      "out_dim",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvLayer": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "depth",
      "activation",
      "drop_path",
      "downsample",
      "use_checkpoint",
      "out_dim",
      "conv_expand_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Mlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TinyViTBlock": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "drop",
      "drop_path",
      "local_conv_size",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "BasicLayer": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "drop",
      "drop_path",
      "downsample",
      "use_checkpoint",
      "local_conv_size",
      "activation",
      "out_dim"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "TinyViT": {
    "__init__": [
      "self",
      "img_size",
      "in_chans",
      "num_classes",
      "embed_dims",
      "depths",
      "num_heads",
      "window_sizes",
      "mlp_ratio",
      "drop_rate",
      "drop_path_rate",
      "use_checkpoint",
      "mbconv_expand_ratio",
      "local_conv_size",
      "layer_lr_decay"
    ],
    "set_layer_lr_decay": [
      "self",
      "layer_lr_decay"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "no_weight_decay_keywords": [
      "self"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_checkpoint_url_format": [],
  "_provided_checkpoints": [],
  "register_tiny_vit_model": [
    "fn"
  ],
  "tiny_vit_5m_224": [
    "pretrained",
    "num_classes",
    "drop_path_rate"
  ],
  "tiny_vit_11m_224": [
    "pretrained",
    "num_classes",
    "drop_path_rate"
  ],
  "tiny_vit_21m_224": [
    "pretrained",
    "num_classes",
    "drop_path_rate"
  ],
  "tiny_vit_21m_384": [
    "pretrained",
    "num_classes",
    "drop_path_rate"
  ],
  "tiny_vit_21m_512": [
    "pretrained",
    "num_classes",
    "drop_path_rate"
  ],
  "ResizeLongestSide": {
    "__init__": [
      "self",
      "target_length"
    ],
    "apply_image": [
      "self",
      "image"
    ],
    "apply_coords": [
      "self",
      "coords",
      "original_size"
    ],
    "apply_boxes": [
      "self",
      "boxes",
      "original_size"
    ],
    "apply_image_torch": [
      "self",
      "image"
    ],
    "apply_coords_torch": [
      "self",
      "coords",
      "original_size"
    ],
    "apply_boxes_torch": [
      "self",
      "boxes",
      "original_size"
    ],
    "get_preprocess_shape": [
      "oldh",
      "oldw",
      "long_side_length"
    ]
  },
  "SamOnnxModel": {
    "__init__": [
      "self",
      "model",
      "return_single_mask",
      "use_stability_score",
      "return_extra_metrics"
    ],
    "resize_longest_image_size": [
      "input_image_size",
      "longest_side"
    ],
    "_embed_points": [
      "self",
      "point_coords",
      "point_labels"
    ],
    "_embed_masks": [
      "self",
      "input_mask",
      "has_mask_input"
    ],
    "mask_postprocessing": [
      "self",
      "masks",
      "orig_im_size"
    ],
    "select_masks": [
      "self",
      "masks",
      "iou_preds",
      "num_points"
    ],
    "forward": [
      "self",
      "image_embeddings",
      "point_coords",
      "point_labels",
      "mask_input",
      "has_mask_input",
      "orig_im_size"
    ]
  },
  "MaskData": {
    "__init__": [
      "self"
    ],
    "__setitem__": [
      "self",
      "key",
      "item"
    ],
    "__delitem__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "items": [
      "self"
    ],
    "filter": [
      "self",
      "keep"
    ],
    "cat": [
      "self",
      "new_stats"
    ],
    "to_numpy": [
      "self"
    ]
  },
  "is_box_near_crop_edge": [
    "boxes",
    "crop_box",
    "orig_box",
    "atol"
  ],
  "box_xyxy_to_xywh": [
    "box_xyxy"
  ],
  "batch_iterator": [
    "batch_size"
  ],
  "mask_to_rle_pytorch": [
    "tensor"
  ],
  "rle_to_mask": [
    "rle"
  ],
  "area_from_rle": [
    "rle"
  ],
  "calculate_stability_score": [
    "masks",
    "mask_threshold",
    "threshold_offset"
  ],
  "build_point_grid": [
    "n_per_side"
  ],
  "build_all_layer_point_grids": [
    "n_per_side",
    "n_layers",
    "scale_per_layer"
  ],
  "generate_crop_boxes": [
    "im_size",
    "n_layers",
    "overlap_ratio"
  ],
  "uncrop_boxes_xyxy": [
    "boxes",
    "crop_box"
  ],
  "uncrop_points": [
    "points",
    "crop_box"
  ],
  "uncrop_masks": [
    "masks",
    "crop_box",
    "orig_h",
    "orig_w"
  ],
  "remove_small_regions": [
    "mask",
    "area_thresh",
    "mode"
  ],
  "coco_encode_rle": [
    "uncompressed_rle"
  ],
  "batched_mask_to_box": [
    "masks"
  ],
  "norm_layer": [],
  "ResidualBlock": {
    "__init__": [
      "self",
      "in_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Generator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "n_residual_blocks",
      "sigmoid"
    ],
    "forward": [
      "self",
      "x",
      "cond"
    ]
  },
  "LineartDetector": {
    "__init__": [
      "self",
      "model",
      "coarse_model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "coarse_filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "coarse",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "MediapipeFaceDetector": {
    "__call__": [
      "self",
      "input_image",
      "max_faces",
      "min_confidence",
      "output_type",
      "detect_resolution",
      "image_resolution"
    ]
  },
  "draw_pupils": [
    "image",
    "landmark_list",
    "drawing_spec",
    "halfwidth"
  ],
  "reverse_channels": [
    "image"
  ],
  "generate_annotation": [
    "img_rgb",
    "max_faces",
    "min_confidence"
  ],
  "AnylineDetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "subfolder"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "guassian_sigma",
      "intensity_threshold",
      "output_type"
    ],
    "get_intensity_mask": [
      "self",
      "image_array",
      "lower_bound",
      "upper_bound"
    ],
    "combine_layers": [
      "self",
      "base_layer",
      "top_layer"
    ]
  },
  "Smish": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "TEEDdetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "subfolder"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "safe_steps",
      "output_type"
    ]
  },
  "smish": [
    "input"
  ],
  "weight_init": [
    "m"
  ],
  "CoFusion": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CoFusion2": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DoubleFusion": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_DenseLayer": {
    "__init__": [
      "self",
      "input_features",
      "out_features"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_DenseBlock": {
    "__init__": [
      "self",
      "num_layers",
      "input_features",
      "out_features"
    ]
  },
  "UpConvBlock": {
    "__init__": [
      "self",
      "in_features",
      "up_scale"
    ],
    "make_deconv_layers": [
      "self",
      "in_features",
      "up_scale"
    ],
    "compute_out_features": [
      "self",
      "idx",
      "up_scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SingleConvBlock": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "stride",
      "use_ac"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DoubleConvBlock": {
    "__init__": [
      "self",
      "in_features",
      "mid_features",
      "out_features",
      "stride",
      "use_act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TED": {
    "__init__": [
      "self"
    ],
    "slice": [
      "self",
      "tensor",
      "slice_shape"
    ],
    "resize_input": [
      "self",
      "tensor"
    ],
    "crop_bdcn": [
      "data1",
      "h",
      "w",
      "crop_h",
      "crop_w"
    ],
    "forward": [
      "self",
      "x",
      "single_test"
    ]
  },
  "LineartStandardDetector": {
    "__call__": [
      "self",
      "input_image",
      "guassian_sigma",
      "intensity_threshold",
      "detect_resolution",
      "output_type"
    ]
  },
  "PidiNetDetector": {
    "__init__": [
      "self",
      "netNetwork"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "safe",
      "output_type",
      "scribble",
      "apply_filter"
    ]
  },
  "img2tensor": [
    "imgs",
    "bgr2rgb",
    "float32"
  ],
  "nets": [],
  "createConvFunc": [
    "op_type"
  ],
  "CSAM": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CDCM": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MapReduce": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PDCBlock": {
    "__init__": [
      "self",
      "pdc",
      "inplane",
      "ouplane",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PDCBlock_converted": {
    "__init__": [
      "self",
      "pdc",
      "inplane",
      "ouplane",
      "stride"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PiDiNet": {
    "__init__": [
      "self",
      "inplane",
      "pdcs",
      "dil",
      "sa",
      "convert"
    ],
    "get_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "config_model": [
    "model"
  ],
  "pidinet": [],
  "ControlNetHED_Apache2": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "HEDdetector": {
    "__init__": [
      "self",
      "netNetwork"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "detect_resolution",
      "image_resolution",
      "safe",
      "output_type",
      "scribble"
    ]
  },
  "read_pfm": [
    "path"
  ],
  "write_pfm": [
    "path",
    "image",
    "scale"
  ],
  "read_image": [
    "path"
  ],
  "resize_depth": [
    "depth",
    "width",
    "height"
  ],
  "write_depth": [
    "path",
    "depth",
    "bits"
  ],
  "ISL_PATHS": [],
  "remote_model_path": [],
  "disabled_train": [
    "self",
    "mode"
  ],
  "load_midas_transform": [
    "model_type"
  ],
  "MiDaSInference": {
    "MODEL_TYPES_TORCH_HUB": [],
    "MODEL_TYPES_ISL": [],
    "__init__": [
      "self",
      "model_type",
      "model_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MidasDetector": {
    "__init__": [
      "self",
      "model"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "model_type",
      "filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "a",
      "bg_th",
      "depth_and_normal",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "_make_pretrained_deitb16_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "_make_pretrained_deitb16_distil_384": [
    "pretrained",
    "use_readout",
    "hooks"
  ],
  "LeresDetector": {
    "__init__": [
      "self",
      "model",
      "pix2pixmodel"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path",
      "filename",
      "pix2pix_filename",
      "cache_dir",
      "local_files_only"
    ],
    "to": [
      "self",
      "device"
    ],
    "__call__": [
      "self",
      "input_image",
      "thr_a",
      "thr_b",
      "boost",
      "detect_resolution",
      "image_resolution",
      "output_type"
    ]
  },
  "BaseOptions": {
    "__init__": [
      "self"
    ],
    "initialize": [
      "self",
      "parser"
    ],
    "gather_options": [
      "self"
    ],
    "print_options": [
      "self",
      "opt"
    ],
    "parse": [
      "self"
    ]
  },
  "TestOptions": {
    "initialize": [
      "self",
      "parser"
    ]
  },
  "find_model_using_name": [
    "model_name"
  ],
  "get_option_setter": [
    "model_name"
  ],
  "BaseModelHG": {
    "name": [
      "self"
    ],
    "initialize": [
      "self",
      "opt"
    ],
    "set_input": [
      "self",
      "input"
    ],
    "forward": [
      "self"
    ],
    "test": [
      "self"
    ],
    "get_image_paths": [
      "self"
    ],
    "optimize_parameters": [
      "self"
    ],
    "get_current_visuals": [
      "self"
    ],
    "get_current_errors": [
      "self"
    ],
    "save": [
      "self",
      "label"
    ],
    "save_network": [
      "self",
      "network",
      "network_label",
      "epoch_label",
      "gpu_ids"
    ],
    "load_network": [
      "self",
      "network",
      "network_label",
      "epoch_label"
    ],
    "update_learning_rate": []
  },
  "Pix2Pix4DepthModel": {
    "modify_commandline_options": [
      "parser",
      "is_train"
    ],
    "__init__": [
      "self",
      "opt"
    ],
    "set_input_train": [
      "self",
      "input"
    ],
    "set_input": [
      "self",
      "outer",
      "inner"
    ],
    "normalize": [
      "self",
      "input"
    ],
    "forward": [
      "self"
    ],
    "backward_D": [
      "self"
    ],
    "backward_G": [
      "self"
    ],
    "optimize_parameters": [
      "self"
    ]
  },
  "Identity": {
    "forward": [
      "self",
      "x"
    ]
  },
  "get_norm_layer": [
    "norm_type"
  ],
  "get_scheduler": [
    "optimizer",
    "opt"
  ],
  "init_weights": [
    "net",
    "init_type",
    "init_gain"
  ],
  "init_net": [
    "net",
    "init_type",
    "init_gain",
    "gpu_ids"
  ],
  "define_G": [
    "input_nc",
    "output_nc",
    "ngf",
    "netG",
    "norm",
    "use_dropout",
    "init_type",
    "init_gain",
    "gpu_ids"
  ],
  "define_D": [
    "input_nc",
    "ndf",
    "netD",
    "n_layers_D",
    "norm",
    "init_type",
    "init_gain",
    "gpu_ids"
  ],
  "GANLoss": {
    "__init__": [
      "self",
      "gan_mode",
      "target_real_label",
      "target_fake_label"
    ],
    "get_target_tensor": [
      "self",
      "prediction",
      "target_is_real"
    ],
    "__call__": [
      "self",
      "prediction",
      "target_is_real"
    ]
  },
  "cal_gradient_penalty": [
    "netD",
    "real_data",
    "fake_data",
    "device",
    "type",
    "constant",
    "lambda_gp"
  ],
  "ResnetGenerator": {
    "__init__": [
      "self",
      "input_nc",
      "output_nc",
      "ngf",
      "norm_layer",
      "use_dropout",
      "n_blocks",
      "padding_type"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ResnetBlock": {
    "__init__": [
      "self",
      "dim",
      "padding_type",
      "norm_layer",
      "use_dropout",
      "use_bias"
    ],
    "build_conv_block": [
      "self",
      "dim",
      "padding_type",
      "norm_layer",
      "use_dropout",
      "use_bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NLayerDiscriminator": {
    "__init__": [
      "self",
      "input_nc",
      "ndf",
      "n_layers",
      "norm_layer"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "PixelDiscriminator": {
    "__init__": [
      "self",
      "input_nc",
      "ndf",
      "norm_layer"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "tensor2im": [
    "input_image",
    "imtype"
  ],
  "diagnose_network": [
    "net",
    "name"
  ],
  "save_image": [
    "image_numpy",
    "image_path",
    "aspect_ratio"
  ],
  "print_numpy": [
    "x",
    "val",
    "shp"
  ],
  "mkdirs": [
    "paths"
  ],
  "mkdir": [
    "path"
  ],
  "conv3x3": [
    "in_planes",
    "out_planes",
    "stride",
    "groups",
    "dilation"
  ],
  "conv1x1": [
    "in_planes",
    "out_planes",
    "stride"
  ],
  "BasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "groups",
      "base_width",
      "dilation",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Bottleneck": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "groups",
      "base_width",
      "dilation",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNet": {
    "__init__": [
      "self",
      "block",
      "layers",
      "num_classes",
      "zero_init_residual",
      "groups",
      "width_per_group",
      "replace_stride_with_dilation",
      "norm_layer"
    ],
    "_make_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride",
      "dilate"
    ],
    "_forward_impl": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "resnext101_32x8d": [
    "pretrained"
  ],
  "resnet50_stride32": [],
  "resnext101_stride32x8d": [],
  "DepthNet": {
    "__factory": [],
    "__init__": [
      "self",
      "backbone",
      "depth",
      "upfactors"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FTB": {
    "__init__": [
      "self",
      "inchannels",
      "midchannels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_params": [
      "self"
    ]
  },
  "ATA": {
    "__init__": [
      "self",
      "inchannels",
      "reduction"
    ],
    "forward": [
      "self",
      "low_x",
      "high_x"
    ],
    "init_params": [
      "self"
    ]
  },
  "FFM": {
    "__init__": [
      "self",
      "inchannels",
      "midchannels",
      "outchannels",
      "upfactor"
    ],
    "forward": [
      "self",
      "low_x",
      "high_x"
    ],
    "init_params": [
      "self"
    ]
  },
  "AO": {
    "__init__": [
      "self",
      "inchannels",
      "outchannels",
      "upfactor"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_params": [
      "self"
    ]
  },
  "ResidualConv": {
    "__init__": [
      "self",
      "inchannels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "init_params": [
      "self"
    ]
  },
  "FeatureFusion": {
    "__init__": [
      "self",
      "inchannels",
      "outchannels"
    ],
    "forward": [
      "self",
      "lowfeat",
      "highfeat"
    ],
    "init_params": [
      "self"
    ]
  },
  "SenceUnderstand": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x"
    ],
    "initial_params": [
      "self",
      "dev"
    ]
  },
  "resnet18": [
    "pretrained"
  ],
  "resnet34": [
    "pretrained"
  ],
  "resnet50": [
    "pretrained"
  ],
  "resnet101": [
    "pretrained"
  ],
  "resnet152": [
    "pretrained"
  ],
  "RelDepthModel": {
    "__init__": [
      "self",
      "backbone"
    ],
    "inference": [
      "self",
      "rgb"
    ]
  },
  "get_func": [
    "func_name"
  ],
  "load_ckpt": [
    "args",
    "depth_model",
    "shift_model",
    "focal_model"
  ],
  "strip_prefix_if_present": [
    "state_dict",
    "prefix"
  ],
  "whole_size_threshold": [],
  "pix2pixsize": [],
  "scale_torch": [
    "img"
  ],
  "estimateleres": [
    "img",
    "model",
    "w",
    "h"
  ],
  "generatemask": [
    "size"
  ],
  "resizewithpool": [
    "img",
    "size"
  ],
  "rgb2gray": [
    "rgb"
  ],
  "calculateprocessingres": [
    "img",
    "basesize",
    "confidence",
    "scale_threshold",
    "whole_size_threshold"
  ],
  "doubleestimate": [
    "img",
    "size1",
    "size2",
    "pix2pixsize",
    "model",
    "net_type",
    "pix2pixmodel"
  ],
  "singleestimate": [
    "img",
    "msize",
    "model",
    "net_type"
  ],
  "applyGridpatch": [
    "blsize",
    "stride",
    "img",
    "box"
  ],
  "generatepatchs": [
    "img",
    "base_size"
  ],
  "getGF_fromintegral": [
    "integralimage",
    "rect"
  ],
  "adaptiveselection": [
    "integral_grad",
    "patch_bound_list",
    "gf"
  ],
  "impatch": [
    "image",
    "rect"
  ],
  "ImageandPatchs": {
    "__init__": [
      "self",
      "root_dir",
      "name",
      "patchsinfo",
      "rgb_image",
      "scale"
    ],
    "__len__": [
      "self"
    ],
    "set_base_estimate": [
      "self",
      "est"
    ],
    "set_updated_estimate": [
      "self",
      "est"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "print_options": [
      "self",
      "opt"
    ],
    "parse": [
      "self"
    ]
  },
  "estimateboost": [
    "img",
    "model",
    "model_type",
    "pix2pixmodel",
    "max_res",
    "depthmap_script_boost_rmax"
  ]
}