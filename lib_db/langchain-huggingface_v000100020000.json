{
  "__all__": [],
  "_MIN_OPTIMUM_VERSION": [],
  "HuggingFaceEmbeddings": {
    "__init__": [
      "self"
    ],
    "model_config": [],
    "_embed": [
      "self",
      "texts",
      "encode_kwargs"
    ],
    "embed_documents": [
      "self",
      "texts"
    ],
    "embed_query": [
      "self",
      "text"
    ]
  },
  "DEFAULT_MODEL": [],
  "VALID_TASKS": [],
  "HuggingFaceEndpointEmbeddings": {
    "model_config": [],
    "validate_environment": [
      "self"
    ],
    "embed_documents": [
      "self",
      "texts"
    ],
    "aembed_documents": [
      "self",
      "texts"
    ],
    "embed_query": [
      "self",
      "text"
    ],
    "aembed_query": [
      "self",
      "text"
    ]
  },
  "DEFAULT_MODEL_ID": [],
  "DEFAULT_TASK": [],
  "DEFAULT_BATCH_SIZE": [],
  "logger": [],
  "HuggingFacePipeline": {
    "model_config": [],
    "pre_init_validator": [
      "cls",
      "values"
    ],
    "from_model_id": [
      "cls",
      "model_id",
      "task",
      "backend",
      "device",
      "device_map",
      "model_kwargs",
      "pipeline_kwargs",
      "batch_size"
    ],
    "_identifying_params": [
      "self"
    ],
    "_llm_type": [
      "self"
    ],
    "_generate": [
      "self",
      "prompts",
      "stop",
      "run_manager"
    ],
    "_stream": [
      "self",
      "prompt",
      "stop",
      "run_manager"
    ]
  },
  "HuggingFaceEndpoint": {
    "model_config": [],
    "build_extra": [
      "cls",
      "values"
    ],
    "validate_environment": [
      "self"
    ],
    "_default_params": [
      "self"
    ],
    "_identifying_params": [
      "self"
    ],
    "_llm_type": [
      "self"
    ],
    "_invocation_params": [
      "self",
      "runtime_stop"
    ],
    "_call": [
      "self",
      "prompt",
      "stop",
      "run_manager"
    ],
    "_acall": [
      "self",
      "prompt",
      "stop",
      "run_manager"
    ],
    "_stream": [
      "self",
      "prompt",
      "stop",
      "run_manager"
    ],
    "_astream": [
      "self",
      "prompt",
      "stop",
      "run_manager"
    ]
  },
  "STR_OPERATION_TO_FUNC": [],
  "_optimum_available": [],
  "_optimum_version": [],
  "_optimum_intel_available": [],
  "_optimum_intel_version": [],
  "_ipex_available": [],
  "_openvino_available": [],
  "compare_versions": [
    "library_or_version",
    "operation",
    "requirement_version"
  ],
  "is_optimum_available": [],
  "is_optimum_intel_available": [],
  "is_ipex_available": [],
  "is_openvino_available": [],
  "is_optimum_version": [
    "operation",
    "reference_version"
  ],
  "is_optimum_intel_version": [
    "operation",
    "reference_version"
  ],
  "IMPORT_ERROR": [],
  "_MODEL_PROFILES": [],
  "_get_default_model_profile": [
    "model_name"
  ],
  "TGI_RESPONSE": {},
  "TGI_MESSAGE": {},
  "_lc_tool_call_to_hf_tool_call": [
    "tool_call"
  ],
  "_lc_invalid_tool_call_to_hf_tool_call": [
    "invalid_tool_call"
  ],
  "_convert_message_to_dict": [
    "message"
  ],
  "_convert_dict_to_message": [
    "_dict"
  ],
  "_is_huggingface_hub": [
    "llm"
  ],
  "_convert_chunk_to_message_chunk": [
    "chunk",
    "default_class"
  ],
  "_is_huggingface_textgen_inference": [
    "llm"
  ],
  "_is_huggingface_endpoint": [
    "llm"
  ],
  "_is_huggingface_pipeline": [
    "llm"
  ],
  "ChatHuggingFace": {
    "__init__": [
      "self"
    ],
    "_inherit_llm_properties": [
      "self"
    ],
    "validate_llm": [
      "self"
    ],
    "_set_model_profile": [
      "self"
    ],
    "from_model_id": [
      "cls",
      "model_id",
      "task",
      "backend"
    ],
    "_create_chat_result": [
      "self",
      "response"
    ],
    "_generate": [
      "self",
      "messages",
      "stop",
      "run_manager",
      "stream"
    ],
    "_agenerate": [
      "self",
      "messages",
      "stop",
      "run_manager",
      "stream"
    ],
    "_should_stream_usage": [
      "self"
    ],
    "_stream": [
      "self",
      "messages",
      "stop",
      "run_manager"
    ],
    "_astream": [
      "self",
      "messages",
      "stop",
      "run_manager"
    ],
    "_to_chat_prompt": [
      "self",
      "messages"
    ],
    "_to_chatml_format": [
      "self",
      "message"
    ],
    "_to_chat_result": [
      "llm_result"
    ],
    "_resolve_model_id": [
      "self"
    ],
    "bind_tools": [
      "self",
      "tools"
    ],
    "with_structured_output": [
      "self",
      "schema"
    ],
    "_create_message_dicts": [
      "self",
      "messages",
      "stop"
    ],
    "_default_params": [
      "self"
    ],
    "_llm_type": [
      "self"
    ]
  }
}