{
  "TTS": {
    "__init__": [
      "self",
      "model_name",
      "model_path",
      "config_path",
      "vocoder_path",
      "vocoder_config_path",
      "progress_bar",
      "gpu"
    ],
    "models": [
      "self"
    ],
    "is_multi_speaker": [
      "self"
    ],
    "is_multi_lingual": [
      "self"
    ],
    "speakers": [
      "self"
    ],
    "languages": [
      "self"
    ],
    "get_models_file_path": [],
    "list_models": [
      "self"
    ],
    "download_model_by_name": [
      "self",
      "model_name"
    ],
    "load_model_by_name": [
      "self",
      "model_name",
      "gpu"
    ],
    "load_vc_model_by_name": [
      "self",
      "model_name",
      "gpu"
    ],
    "load_tts_model_by_name": [
      "self",
      "model_name",
      "gpu"
    ],
    "load_tts_model_by_path": [
      "self",
      "model_path",
      "config_path",
      "vocoder_path",
      "vocoder_config",
      "gpu"
    ],
    "_check_arguments": [
      "self",
      "speaker",
      "language",
      "speaker_wav",
      "emotion",
      "speed"
    ],
    "tts": [
      "self",
      "text",
      "speaker",
      "language",
      "speaker_wav",
      "emotion",
      "speed",
      "split_sentences"
    ],
    "tts_to_file": [
      "self",
      "text",
      "speaker",
      "language",
      "speaker_wav",
      "emotion",
      "speed",
      "pipe_out",
      "file_path",
      "split_sentences"
    ],
    "voice_conversion": [
      "self",
      "source_wav",
      "target_wav"
    ],
    "voice_conversion_to_file": [
      "self",
      "source_wav",
      "target_wav",
      "file_path"
    ],
    "tts_with_vc": [
      "self",
      "text",
      "language",
      "speaker_wav",
      "speaker",
      "split_sentences"
    ],
    "tts_with_vc_to_file": [
      "self",
      "text",
      "language",
      "speaker_wav",
      "file_path",
      "speaker",
      "split_sentences"
    ]
  },
  "__version__": [],
  "BaseTrainerModel": {
    "init_from_config": [
      "config"
    ],
    "inference": [
      "self",
      "input",
      "aux_input"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "strict",
      "cache"
    ]
  },
  "WaveRNNDataset": {
    "__init__": [
      "self",
      "ap",
      "items",
      "seq_len",
      "hop_len",
      "pad",
      "mode",
      "mulaw",
      "is_training",
      "verbose",
      "return_segments"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "load_test_samples": [
      "self",
      "num_samples"
    ],
    "load_item": [
      "self",
      "index"
    ],
    "collate": [
      "self",
      "batch"
    ]
  },
  "WaveGradDataset": {
    "__init__": [
      "self",
      "ap",
      "items",
      "seq_len",
      "hop_len",
      "pad_short",
      "conv_pad",
      "is_training",
      "return_segments",
      "use_noise_augment",
      "use_cache",
      "verbose"
    ],
    "create_feature_cache": [
      "self"
    ],
    "find_wav_files": [
      "path"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "load_test_samples": [
      "self",
      "num_samples"
    ],
    "load_item": [
      "self",
      "idx"
    ],
    "collate_full_clips": [
      "batch"
    ]
  },
  "GANDataset": {
    "__init__": [
      "self",
      "ap",
      "items",
      "seq_len",
      "hop_len",
      "pad_short",
      "conv_pad",
      "return_pairs",
      "is_training",
      "return_segments",
      "use_noise_augment",
      "use_cache",
      "verbose"
    ],
    "create_feature_cache": [
      "self"
    ],
    "find_wav_files": [
      "path"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "_pad_short_samples": [
      "self",
      "audio",
      "mel"
    ],
    "shuffle_mapping": [
      "self"
    ],
    "load_item": [
      "self",
      "idx"
    ]
  },
  "setup_dataset": [
    "config",
    "ap",
    "is_eval",
    "data_items",
    "verbose"
  ],
  "preprocess_wav_files": [
    "out_path",
    "config",
    "ap"
  ],
  "find_wav_files": [
    "data_path",
    "file_ext"
  ],
  "find_feat_files": [
    "data_path"
  ],
  "load_wav_data": [
    "data_path",
    "eval_split_size",
    "file_ext"
  ],
  "load_wav_feat_data": [
    "data_path",
    "feat_path",
    "eval_split_size"
  ],
  "gaussian_loss": [
    "y_hat",
    "y",
    "log_std_min"
  ],
  "sample_from_gaussian": [
    "y_hat",
    "log_std_min",
    "scale_factor"
  ],
  "log_sum_exp": [
    "x"
  ],
  "discretized_mix_logistic_loss": [
    "y_hat",
    "y",
    "num_classes",
    "log_scale_min",
    "reduce"
  ],
  "sample_from_discretized_mix_logistic": [
    "y",
    "log_scale_min"
  ],
  "to_one_hot": [
    "tensor",
    "n",
    "fill_with"
  ],
  "interpolate_vocoder_input": [
    "scale_factor",
    "spec"
  ],
  "plot_results": [
    "y_hat",
    "y",
    "ap",
    "name_prefix"
  ],
  "STFTLoss": {
    "__init__": [
      "self",
      "n_fft",
      "hop_length",
      "win_length"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "MultiScaleSTFTLoss": {
    "__init__": [
      "self",
      "n_ffts",
      "hop_lengths",
      "win_lengths"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "L1SpecLoss": {
    "__init__": [
      "self",
      "sample_rate",
      "n_fft",
      "hop_length",
      "win_length",
      "mel_fmin",
      "mel_fmax",
      "n_mels",
      "use_mel"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "MultiScaleSubbandSTFTLoss": {
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "MSEGLoss": {
    "forward": [
      "self",
      "score_real"
    ]
  },
  "HingeGLoss": {
    "forward": [
      "self",
      "score_real"
    ]
  },
  "MSEDLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "score_fake",
      "score_real"
    ]
  },
  "HingeDLoss": {
    "forward": [
      "self",
      "score_fake",
      "score_real"
    ]
  },
  "MelganFeatureLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "fake_feats",
      "real_feats"
    ]
  },
  "_apply_G_adv_loss": [
    "scores_fake",
    "loss_func"
  ],
  "_apply_D_loss": [
    "scores_fake",
    "scores_real",
    "loss_func"
  ],
  "GeneratorLoss": {
    "__init__": [
      "self",
      "C"
    ],
    "forward": [
      "self",
      "y_hat",
      "y",
      "scores_fake",
      "feats_fake",
      "feats_real",
      "y_hat_sub",
      "y_sub"
    ]
  },
  "DiscriminatorLoss": {
    "__init__": [
      "self",
      "C"
    ],
    "forward": [
      "self",
      "scores_fake",
      "scores_real"
    ]
  },
  "WaveRNNLoss": {
    "__init__": [
      "self",
      "wave_rnn_mode"
    ],
    "forward": [
      "self",
      "y_hat",
      "y"
    ]
  },
  "ResStack": {
    "__init__": [
      "self",
      "kernel",
      "channel",
      "padding",
      "dilations"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "MRF": {
    "__init__": [
      "self",
      "kernels",
      "channel",
      "dilations"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "PQMF": {
    "__init__": [
      "self",
      "N",
      "taps",
      "cutoff",
      "beta"
    ],
    "forward": [
      "self",
      "x"
    ],
    "analysis": [
      "self",
      "x"
    ],
    "synthesis": [
      "self",
      "x"
    ]
  },
  "ResidualStack": {
    "__init__": [
      "self",
      "channels",
      "num_res_blocks",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "Conv1d": {
    "__init__": [
      "self"
    ]
  },
  "PositionalEncoding": {
    "__init__": [
      "self",
      "n_channels",
      "max_len"
    ],
    "forward": [
      "self",
      "x",
      "noise_level"
    ],
    "init_pe_matrix": [
      "self",
      "n_channels",
      "max_len",
      "x"
    ]
  },
  "FiLM": {
    "__init__": [
      "self",
      "input_size",
      "output_size"
    ],
    "forward": [
      "self",
      "x",
      "noise_scale"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ]
  },
  "shif_and_scale": [
    "x",
    "scale",
    "shift"
  ],
  "UBlock": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "factor",
      "dilation"
    ],
    "forward": [
      "self",
      "x",
      "shift",
      "scale"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ]
  },
  "DBlock": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "factor"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ]
  },
  "Stretch2d": {
    "__init__": [
      "self",
      "x_scale",
      "y_scale",
      "mode"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpsampleNetwork": {
    "__init__": [
      "self",
      "upsample_factors",
      "nonlinear_activation",
      "nonlinear_activation_params",
      "interpolate_mode",
      "freq_axis_kernel_size",
      "use_causal_conv"
    ],
    "forward": [
      "self",
      "c"
    ]
  },
  "ConvUpsample": {
    "__init__": [
      "self",
      "upsample_factors",
      "nonlinear_activation",
      "nonlinear_activation_params",
      "interpolate_mode",
      "freq_axis_kernel_size",
      "aux_channels",
      "aux_context_window",
      "use_causal_conv"
    ],
    "forward": [
      "self",
      "c"
    ]
  },
  "ResidualBlock": {
    "__init__": [
      "self",
      "kernel_size",
      "res_channels",
      "gate_channels",
      "skip_channels",
      "aux_channels",
      "dropout",
      "dilation",
      "bias",
      "use_causal_conv"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "KernelPredictor": {
    "__init__": [
      "self",
      "cond_channels",
      "conv_in_channels",
      "conv_out_channels",
      "conv_layers",
      "conv_kernel_size",
      "kpnet_hidden_channels",
      "kpnet_conv_size",
      "kpnet_dropout",
      "kpnet_nonlinear_activation",
      "kpnet_nonlinear_activation_params"
    ],
    "forward": [
      "self",
      "c"
    ]
  },
  "LVCBlock": {
    "__init__": [
      "self",
      "in_channels",
      "cond_channels",
      "upsample_ratio",
      "conv_layers",
      "conv_kernel_size",
      "cond_hop_length",
      "kpnet_hidden_channels",
      "kpnet_conv_size",
      "kpnet_dropout"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ],
    "location_variable_convolution": [
      "x",
      "kernel",
      "bias",
      "dilation",
      "hop_size"
    ]
  },
  "MelganConfig": {},
  "MultibandMelganConfig": {},
  "WavegradConfig": {},
  "WavernnConfig": {},
  "UnivnetConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "ParallelWaveganConfig": {},
  "configs_dir": [],
  "FullbandMelganConfig": {},
  "HifiganConfig": {},
  "BaseVocoderConfig": {},
  "BaseGANVocoderConfig": {
    "steps_to_start_discriminator": []
  },
  "GBlock": {
    "__init__": [
      "self",
      "in_channels",
      "cond_channels",
      "downsample_factor"
    ],
    "forward": [
      "self",
      "inputs",
      "conditions"
    ]
  },
  "ConditionalDiscriminator": {
    "__init__": [
      "self",
      "in_channels",
      "cond_channels",
      "downsample_factors",
      "out_channels"
    ],
    "forward": [
      "self",
      "inputs",
      "conditions"
    ]
  },
  "UnconditionalDiscriminator": {
    "__init__": [
      "self",
      "in_channels",
      "base_channels",
      "downsample_factors",
      "out_channels"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "RandomWindowDiscriminator": {
    "__init__": [
      "self",
      "cond_channels",
      "hop_length",
      "uncond_disc_donwsample_factors",
      "cond_disc_downsample_factors",
      "cond_disc_out_channels",
      "window_sizes"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "FullbandMelganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "proj_kernel",
      "base_channels",
      "upsample_factors",
      "res_kernel",
      "num_res_blocks"
    ],
    "inference": [
      "self",
      "cond_features"
    ]
  },
  "MelganDiscriminator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_sizes",
      "base_channels",
      "max_channels",
      "downsample_factors",
      "groups_denominator"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ParallelWaveganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "num_res_blocks",
      "stacks",
      "res_channels",
      "gate_channels",
      "skip_channels",
      "aux_channels",
      "dropout",
      "bias",
      "use_weight_norm",
      "upsample_factors",
      "inference_padding"
    ],
    "forward": [
      "self",
      "c"
    ],
    "inference": [
      "self",
      "c"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "_get_receptive_field_size": [
      "layers",
      "stacks",
      "kernel_size",
      "dilation"
    ],
    "receptive_field_size": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ]
  },
  "MelganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "proj_kernel",
      "base_channels",
      "upsample_factors",
      "res_kernel",
      "num_res_blocks"
    ],
    "forward": [
      "self",
      "c"
    ],
    "inference": [
      "self",
      "c"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ]
  },
  "LRELU_SLOPE": [],
  "get_padding": [
    "k",
    "d"
  ],
  "ResBlock1": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "ResBlock2": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "HifiganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "resblock_type",
      "resblock_dilation_sizes",
      "resblock_kernel_sizes",
      "upsample_kernel_sizes",
      "upsample_initial_channel",
      "upsample_factors",
      "inference_padding",
      "cond_channels",
      "conv_pre_weight_norm",
      "conv_post_weight_norm",
      "conv_post_bias"
    ],
    "forward": [
      "self",
      "x",
      "g"
    ],
    "inference": [
      "self",
      "c"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ]
  },
  "to_camel": [
    "text"
  ],
  "setup_model": [
    "config"
  ],
  "setup_generator": [
    "c"
  ],
  "setup_discriminator": [
    "c"
  ],
  "WavegradArgs": {},
  "Wavegrad": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "spectrogram",
      "noise_scale"
    ],
    "load_noise_schedule": [
      "self",
      "path"
    ],
    "inference": [
      "self",
      "x",
      "y_n"
    ],
    "compute_y_n": [
      "self",
      "y_0"
    ],
    "compute_noise_level": [
      "self",
      "beta"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "test": [
      "self",
      "assets",
      "test_loader",
      "outputs"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "get_criterion": [],
    "format_batch": [
      "batch"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus"
    ],
    "on_epoch_start": [
      "self",
      "trainer"
    ],
    "init_from_config": [
      "config"
    ]
  },
  "stream": [
    "string",
    "variables"
  ],
  "ResBlock": {
    "__init__": [
      "self",
      "dims"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MelResNet": {
    "__init__": [
      "self",
      "num_res_blocks",
      "in_dims",
      "compute_dims",
      "res_out_dims",
      "pad"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Upsample": {
    "__init__": [
      "self",
      "scale",
      "pad",
      "num_res_blocks",
      "feat_dims",
      "compute_dims",
      "res_out_dims",
      "use_aux_net"
    ],
    "forward": [
      "self",
      "m"
    ]
  },
  "WavernnArgs": {},
  "Wavernn": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "mels"
    ],
    "inference": [
      "self",
      "mels",
      "batched",
      "target",
      "overlap"
    ],
    "gen_display": [
      "self",
      "i",
      "seq_len",
      "b_size",
      "start"
    ],
    "fold_with_overlap": [
      "self",
      "x",
      "target",
      "overlap"
    ],
    "get_gru_cell": [
      "gru"
    ],
    "pad_tensor": [
      "x",
      "pad",
      "side"
    ],
    "xfade_and_unfold": [
      "y",
      "target",
      "overlap"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "test": [
      "self",
      "assets",
      "test_loader",
      "output"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "format_batch": [
      "batch"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus"
    ],
    "get_criterion": [
      "self"
    ],
    "init_from_config": [
      "config"
    ]
  },
  "MultibandMelganGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "proj_kernel",
      "base_channels",
      "upsample_factors",
      "res_kernel",
      "num_res_blocks"
    ],
    "pqmf_analysis": [
      "self",
      "x"
    ],
    "pqmf_synthesis": [
      "self",
      "x"
    ],
    "inference": [
      "self",
      "cond_features"
    ]
  },
  "MelganMultiscaleDiscriminator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "num_scales",
      "kernel_sizes",
      "base_channels",
      "max_channels",
      "downsample_factors",
      "pooling_kernel_size",
      "pooling_stride",
      "pooling_padding",
      "groups_denominator"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GAN": {
    "__init__": [
      "self",
      "config",
      "ap"
    ],
    "forward": [
      "self",
      "x"
    ],
    "inference": [
      "self",
      "x"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion",
      "optimizer_idx"
    ],
    "_log": [
      "self",
      "name",
      "ap",
      "batch",
      "outputs"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion",
      "optimizer_idx"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ],
    "on_train_step_start": [
      "self",
      "trainer"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "format_batch": [
      "batch"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus",
      "rank"
    ],
    "get_criterion": [
      "self"
    ],
    "init_from_config": [
      "config",
      "verbose"
    ]
  },
  "UnivnetGenerator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "cond_channels",
      "upsample_factors",
      "lvc_layers_each_block",
      "lvc_kernel_size",
      "kpnet_hidden_channels",
      "kpnet_conv_size",
      "dropout",
      "use_weight_norm"
    ],
    "forward": [
      "self",
      "c"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "_get_receptive_field_size": [
      "layers",
      "stacks",
      "kernel_size",
      "dilation"
    ],
    "receptive_field_size": [
      "self"
    ],
    "inference": [
      "self",
      "c"
    ]
  },
  "SpecDiscriminator": {
    "__init__": [
      "self",
      "fft_size",
      "hop_length",
      "win_length",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "y"
    ]
  },
  "MultiResSpecDiscriminator": {
    "__init__": [
      "self",
      "fft_sizes",
      "hop_sizes",
      "win_lengths",
      "window"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UnivnetDiscriminator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ParallelWaveganDiscriminator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "num_layers",
      "conv_channels",
      "dilation_factor",
      "nonlinear_activation",
      "nonlinear_activation_params",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "ResidualParallelWaveganDiscriminator": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "num_layers",
      "stacks",
      "res_channels",
      "gate_channels",
      "skip_channels",
      "dropout",
      "bias",
      "nonlinear_activation",
      "nonlinear_activation_params"
    ],
    "forward": [
      "self",
      "x"
    ],
    "apply_weight_norm": [
      "self"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "BaseVocoder": {
    "MODEL_TYPE": [],
    "__init__": [
      "self",
      "config"
    ],
    "_set_model_args": [
      "self",
      "config"
    ]
  },
  "DiscriminatorP": {
    "__init__": [
      "self",
      "period",
      "kernel_size",
      "stride",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiPeriodDiscriminator": {
    "__init__": [
      "self",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DiscriminatorS": {
    "__init__": [
      "self",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiScaleDiscriminator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HifiganDiscriminator": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "clear_gpu_cache": [],
  "XTTS_MODEL": [],
  "load_model": [
    "xtts_checkpoint",
    "xtts_config",
    "xtts_vocab"
  ],
  "run_tts": [
    "lang",
    "tts_text",
    "speaker_audio_file"
  ],
  "Logger": {
    "__init__": [
      "self",
      "filename"
    ],
    "write": [
      "self",
      "message"
    ],
    "flush": [
      "self"
    ],
    "isatty": [
      "self"
    ]
  },
  "read_logs": [],
  "train_gpt": [
    "language",
    "num_epochs",
    "batch_size",
    "grad_acumm",
    "train_csv",
    "eval_csv",
    "output_path",
    "max_audio_length"
  ],
  "audio_types": [],
  "list_audios": [
    "basePath",
    "contains"
  ],
  "list_files": [
    "basePath",
    "validExts",
    "contains"
  ],
  "format_audio_list": [
    "audio_files",
    "target_language",
    "out_path",
    "buffer",
    "eval_percentage",
    "speaker_name",
    "gradio_progress"
  ],
  "cml_tts": [
    "root_path",
    "meta_file",
    "ignored_speakers"
  ],
  "coqui": [
    "root_path",
    "meta_file",
    "ignored_speakers"
  ],
  "tweb": [
    "root_path",
    "meta_file"
  ],
  "mozilla": [
    "root_path",
    "meta_file"
  ],
  "mozilla_de": [
    "root_path",
    "meta_file"
  ],
  "mailabs": [
    "root_path",
    "meta_files",
    "ignored_speakers"
  ],
  "ljspeech": [
    "root_path",
    "meta_file"
  ],
  "ljspeech_test": [
    "root_path",
    "meta_file"
  ],
  "thorsten": [
    "root_path",
    "meta_file"
  ],
  "sam_accenture": [
    "root_path",
    "meta_file"
  ],
  "ruslan": [
    "root_path",
    "meta_file"
  ],
  "css10": [
    "root_path",
    "meta_file"
  ],
  "nancy": [
    "root_path",
    "meta_file"
  ],
  "common_voice": [
    "root_path",
    "meta_file",
    "ignored_speakers"
  ],
  "libri_tts": [
    "root_path",
    "meta_files",
    "ignored_speakers"
  ],
  "custom_turkish": [
    "root_path",
    "meta_file"
  ],
  "brspeech": [
    "root_path",
    "meta_file",
    "ignored_speakers"
  ],
  "vctk": [
    "root_path",
    "meta_files",
    "wavs_path",
    "mic",
    "ignored_speakers"
  ],
  "vctk_old": [
    "root_path",
    "meta_files",
    "wavs_path",
    "ignored_speakers"
  ],
  "synpaflex": [
    "root_path",
    "metafiles"
  ],
  "open_bible": [
    "root_path",
    "meta_files",
    "ignore_digits_sentences",
    "ignored_speakers"
  ],
  "mls": [
    "root_path",
    "meta_files",
    "ignored_speakers"
  ],
  "voxceleb2": [
    "root_path",
    "meta_file"
  ],
  "voxceleb1": [
    "root_path",
    "meta_file"
  ],
  "_voxcel_x": [
    "root_path",
    "meta_file",
    "voxcel_idx"
  ],
  "emotion": [
    "root_path",
    "meta_file",
    "ignored_speakers"
  ],
  "baker": [
    "root_path",
    "meta_file"
  ],
  "kokoro": [
    "root_path",
    "meta_file"
  ],
  "kss": [
    "root_path",
    "meta_file"
  ],
  "bel_tts_formatter": [
    "root_path",
    "meta_file"
  ],
  "split_dataset": [
    "items",
    "eval_split_max_size",
    "eval_split_size"
  ],
  "add_extra_keys": [
    "metadata",
    "language",
    "dataset_name"
  ],
  "load_tts_samples": [
    "datasets",
    "eval_split",
    "formatter",
    "eval_split_max_size",
    "eval_split_size"
  ],
  "load_attention_mask_meta_data": [
    "metafile_path"
  ],
  "_get_formatter_by_name": [
    "name"
  ],
  "find_unique_chars": [
    "data_samples",
    "verbose"
  ],
  "_parse_sample": [
    "item"
  ],
  "noise_augment_audio": [
    "wav"
  ],
  "string2filename": [
    "string"
  ],
  "TTSDataset": {
    "__init__": [
      "self",
      "outputs_per_step",
      "compute_linear_spec",
      "ap",
      "samples",
      "tokenizer",
      "compute_f0",
      "compute_energy",
      "f0_cache_path",
      "energy_cache_path",
      "return_wav",
      "batch_group_size",
      "min_text_len",
      "max_text_len",
      "min_audio_len",
      "max_audio_len",
      "phoneme_cache_path",
      "precompute_num_workers",
      "speaker_id_mapping",
      "d_vector_mapping",
      "language_id_mapping",
      "use_noise_augment",
      "start_by_longest",
      "verbose"
    ],
    "lengths": [
      "self"
    ],
    "samples": [
      "self",
      "new_samples"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "print_logs": [
      "self",
      "level"
    ],
    "load_wav": [
      "self",
      "filename"
    ],
    "get_phonemes": [
      "self",
      "idx",
      "text"
    ],
    "get_f0": [
      "self",
      "idx"
    ],
    "get_energy": [
      "self",
      "idx"
    ],
    "get_attn_mask": [
      "attn_file"
    ],
    "get_token_ids": [
      "self",
      "idx",
      "text"
    ],
    "load_data": [
      "self",
      "idx"
    ],
    "_compute_lengths": [
      "samples"
    ],
    "filter_by_length": [
      "lengths",
      "min_len",
      "max_len"
    ],
    "sort_by_length": [
      "samples"
    ],
    "create_buckets": [
      "samples",
      "batch_group_size"
    ],
    "_select_samples_by_idx": [
      "idxs",
      "samples"
    ],
    "preprocess_samples": [
      "self"
    ],
    "_sort_batch": [
      "batch",
      "text_lengths"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "PhonemeDataset": {
    "__init__": [
      "self",
      "samples",
      "tokenizer",
      "cache_path",
      "precompute_num_workers"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "compute_or_load": [
      "self",
      "file_name",
      "text",
      "language"
    ],
    "get_pad_id": [
      "self"
    ],
    "precompute": [
      "self",
      "num_workers"
    ],
    "collate_fn": [
      "self",
      "batch"
    ],
    "print_logs": [
      "self",
      "level"
    ]
  },
  "F0Dataset": {
    "__init__": [
      "self",
      "samples",
      "ap",
      "audio_config",
      "verbose",
      "cache_path",
      "precompute_num_workers",
      "normalize_f0"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "precompute": [
      "self",
      "num_workers"
    ],
    "get_pad_id": [
      "self"
    ],
    "create_pitch_file_path": [
      "file_name",
      "cache_path"
    ],
    "_compute_and_save_pitch": [
      "ap",
      "wav_file",
      "pitch_file"
    ],
    "compute_pitch_stats": [
      "pitch_vecs"
    ],
    "load_stats": [
      "self",
      "cache_path"
    ],
    "normalize": [
      "self",
      "pitch"
    ],
    "denormalize": [
      "self",
      "pitch"
    ],
    "compute_or_load": [
      "self",
      "wav_file",
      "audio_unique_name"
    ],
    "collate_fn": [
      "self",
      "batch"
    ],
    "print_logs": [
      "self",
      "level"
    ]
  },
  "EnergyDataset": {
    "__init__": [
      "self",
      "samples",
      "ap",
      "verbose",
      "cache_path",
      "precompute_num_workers",
      "normalize_energy"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__len__": [
      "self"
    ],
    "precompute": [
      "self",
      "num_workers"
    ],
    "get_pad_id": [
      "self"
    ],
    "create_energy_file_path": [
      "wav_file",
      "cache_path"
    ],
    "_compute_and_save_energy": [
      "ap",
      "wav_file",
      "energy_file"
    ],
    "compute_energy_stats": [
      "energy_vecs"
    ],
    "load_stats": [
      "self",
      "cache_path"
    ],
    "normalize": [
      "self",
      "energy"
    ],
    "denormalize": [
      "self",
      "energy"
    ],
    "compute_or_load": [
      "self",
      "wav_file",
      "audio_unique_name"
    ],
    "collate_fn": [
      "self",
      "batch"
    ],
    "print_logs": [
      "self",
      "level"
    ]
  },
  "_reduce": [
    "x",
    "reduction"
  ],
  "_validate_input": [
    "tensors",
    "dim_range",
    "data_range",
    "size_range"
  ],
  "gaussian_filter": [
    "kernel_size",
    "sigma"
  ],
  "ssim": [
    "x",
    "y",
    "kernel_size",
    "kernel_sigma",
    "data_range",
    "reduction",
    "full",
    "downsample",
    "k1",
    "k2"
  ],
  "SSIMLoss": {
    "__constants__": [],
    "__init__": [
      "self",
      "kernel_size",
      "kernel_sigma",
      "k1",
      "k2",
      "downsample",
      "reduction",
      "data_range"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "_ssim_per_channel": [
    "x",
    "y",
    "kernel",
    "k1",
    "k2"
  ],
  "_ssim_per_channel_complex": [
    "x",
    "y",
    "kernel",
    "k1",
    "k2"
  ],
  "plot_alignment": [
    "alignment",
    "info",
    "fig_size",
    "title",
    "output_fig",
    "plot_log"
  ],
  "plot_spectrogram": [
    "spectrogram",
    "ap",
    "fig_size",
    "output_fig"
  ],
  "plot_pitch": [
    "pitch",
    "spectrogram",
    "ap",
    "fig_size",
    "output_fig"
  ],
  "plot_avg_pitch": [
    "pitch",
    "chars",
    "fig_size",
    "output_fig"
  ],
  "plot_avg_energy": [
    "energy",
    "chars",
    "fig_size",
    "output_fig"
  ],
  "visualize": [
    "alignment",
    "postnet_output",
    "text",
    "hop_length",
    "CONFIG",
    "tokenizer",
    "stop_tokens",
    "decoder_output",
    "output_path",
    "figsize",
    "output_fig"
  ],
  "load_file": [
    "path"
  ],
  "save_file": [
    "obj",
    "path"
  ],
  "BaseIDManager": {
    "__init__": [
      "self",
      "id_file_path"
    ],
    "_load_json": [
      "json_file_path"
    ],
    "_save_json": [
      "json_file_path",
      "data"
    ],
    "set_ids_from_data": [
      "self",
      "items",
      "parse_key"
    ],
    "load_ids_from_file": [
      "self",
      "file_path"
    ],
    "save_ids_to_file": [
      "self",
      "file_path"
    ],
    "get_random_id": [
      "self"
    ],
    "parse_ids_from_data": [
      "items",
      "parse_key"
    ]
  },
  "EmbeddingManager": {
    "__init__": [
      "self",
      "embedding_file_path",
      "id_file_path",
      "encoder_model_path",
      "encoder_config_path",
      "use_cuda"
    ],
    "num_embeddings": [
      "self"
    ],
    "num_names": [
      "self"
    ],
    "embedding_dim": [
      "self"
    ],
    "embedding_names": [
      "self"
    ],
    "save_embeddings_to_file": [
      "self",
      "file_path"
    ],
    "read_embeddings_from_file": [
      "file_path"
    ],
    "load_embeddings_from_file": [
      "self",
      "file_path"
    ],
    "load_embeddings_from_list_of_files": [
      "self",
      "file_paths"
    ],
    "get_embedding_by_clip": [
      "self",
      "clip_idx"
    ],
    "get_embeddings_by_name": [
      "self",
      "idx"
    ],
    "get_embeddings_by_names": [
      "self"
    ],
    "get_mean_embedding": [
      "self",
      "idx",
      "num_samples",
      "randomize"
    ],
    "get_random_embedding": [
      "self"
    ],
    "get_clips": [
      "self"
    ],
    "init_encoder": [
      "self",
      "model_path",
      "config_path",
      "use_cuda"
    ],
    "compute_embedding_from_clip": [
      "self",
      "wav_file"
    ],
    "compute_embeddings": [
      "self",
      "feats"
    ]
  },
  "alignment_diagonal_score": [
    "alignments",
    "binary"
  ],
  "StandardScaler": {
    "__init__": [
      "self",
      "mean",
      "scale"
    ],
    "set_stats": [
      "self",
      "mean",
      "scale"
    ],
    "reset_stats": [
      "self"
    ],
    "transform": [
      "self",
      "X"
    ],
    "inverse_transform": [
      "self",
      "X"
    ]
  },
  "sequence_mask": [
    "sequence_length",
    "max_len"
  ],
  "segment": [
    "x",
    "segment_indices",
    "segment_size",
    "pad_short"
  ],
  "rand_segments": [
    "x",
    "x_lengths",
    "segment_size",
    "let_short_samples",
    "pad_short"
  ],
  "average_over_durations": [
    "values",
    "durs"
  ],
  "convert_pad_shape": [
    "pad_shape"
  ],
  "generate_path": [
    "duration",
    "mask"
  ],
  "maximum_path": [
    "value",
    "mask"
  ],
  "maximum_path_cython": [
    "value",
    "mask"
  ],
  "maximum_path_numpy": [
    "value",
    "mask",
    "max_neg_val"
  ],
  "beta_binomial_prior_distribution": [
    "phoneme_count",
    "mel_count",
    "scaling_factor"
  ],
  "compute_attn_prior": [
    "x_len",
    "y_len",
    "scaling_factor"
  ],
  "numpy_to_torch": [
    "np_array",
    "dtype",
    "cuda",
    "device"
  ],
  "compute_style_mel": [
    "style_wav",
    "ap",
    "cuda",
    "device"
  ],
  "run_model_torch": [
    "model",
    "inputs",
    "speaker_id",
    "style_mel",
    "style_text",
    "d_vector",
    "language_id"
  ],
  "trim_silence": [
    "wav",
    "ap"
  ],
  "inv_spectrogram": [
    "postnet_output",
    "ap",
    "CONFIG"
  ],
  "id_to_torch": [
    "aux_id",
    "cuda",
    "device"
  ],
  "embedding_to_torch": [
    "d_vector",
    "cuda",
    "device"
  ],
  "apply_griffin_lim": [
    "inputs",
    "input_lens",
    "CONFIG",
    "ap"
  ],
  "synthesis": [
    "model",
    "text",
    "CONFIG",
    "use_cuda",
    "speaker_id",
    "style_wav",
    "style_text",
    "use_griffin_lim",
    "do_trim_silence",
    "d_vector",
    "language_id"
  ],
  "transfer_voice": [
    "model",
    "CONFIG",
    "use_cuda",
    "reference_wav",
    "speaker_id",
    "d_vector",
    "reference_speaker_id",
    "reference_d_vector",
    "do_trim_silence",
    "use_griffin_lim"
  ],
  "SpeakerManager": {
    "__init__": [
      "self",
      "data_items",
      "d_vectors_file_path",
      "speaker_id_file_path",
      "encoder_model_path",
      "encoder_config_path",
      "use_cuda"
    ],
    "num_speakers": [
      "self"
    ],
    "speaker_names": [
      "self"
    ],
    "get_speakers": [
      "self"
    ],
    "init_from_config": [
      "config",
      "samples"
    ]
  },
  "_set_file_path": [
    "path"
  ],
  "load_speaker_mapping": [
    "out_path"
  ],
  "save_speaker_mapping": [
    "out_path",
    "speaker_mapping"
  ],
  "get_speaker_manager": [
    "c",
    "data",
    "restore_path",
    "out_path"
  ],
  "get_speaker_balancer_weights": [
    "items"
  ],
  "_pad_data": [
    "x",
    "length"
  ],
  "prepare_data": [
    "inputs"
  ],
  "_pad_tensor": [
    "x",
    "length"
  ],
  "prepare_tensor": [
    "inputs",
    "out_steps"
  ],
  "_pad_stop_target": [
    "x",
    "length",
    "pad_val"
  ],
  "prepare_stop_target": [
    "inputs",
    "out_steps"
  ],
  "pad_per_step": [
    "inputs",
    "pad_len"
  ],
  "get_length_balancer_weights": [
    "items",
    "num_buckets"
  ],
  "LanguageManager": {
    "__init__": [
      "self",
      "language_ids_file_path",
      "config"
    ],
    "num_languages": [
      "self"
    ],
    "language_names": [
      "self"
    ],
    "parse_language_ids_from_config": [
      "c"
    ],
    "set_language_ids_from_config": [
      "self",
      "c"
    ],
    "parse_ids_from_data": [
      "items",
      "parse_key"
    ],
    "set_ids_from_data": [
      "self",
      "items",
      "parse_key"
    ],
    "save_ids_to_file": [
      "self",
      "file_path"
    ],
    "init_from_config": [
      "config"
    ]
  },
  "get_language_balancer_weights": [
    "items"
  ],
  "rehash_fairseq_vits_checkpoint": [
    "checkpoint_file"
  ],
  "_whitespace_re": [],
  "expand_abbreviations": [
    "text",
    "lang"
  ],
  "lowercase": [
    "text"
  ],
  "collapse_whitespace": [
    "text"
  ],
  "convert_to_ascii": [
    "text"
  ],
  "remove_aux_symbols": [
    "text"
  ],
  "replace_symbols": [
    "text",
    "lang"
  ],
  "basic_cleaners": [
    "text"
  ],
  "transliteration_cleaners": [
    "text"
  ],
  "basic_german_cleaners": [
    "text"
  ],
  "basic_turkish_cleaners": [
    "text"
  ],
  "english_cleaners": [
    "text"
  ],
  "phoneme_cleaners": [
    "text"
  ],
  "french_cleaners": [
    "text"
  ],
  "portuguese_cleaners": [
    "text"
  ],
  "chinese_mandarin_cleaners": [
    "text"
  ],
  "multilingual_cleaners": [
    "text"
  ],
  "no_cleaners": [
    "text"
  ],
  "TTSTokenizer": {
    "__init__": [
      "self",
      "use_phonemes",
      "text_cleaner",
      "characters",
      "phonemizer",
      "add_blank",
      "use_eos_bos"
    ],
    "characters": [
      "self",
      "new_characters"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "token_ids"
    ],
    "text_to_ids": [
      "self",
      "text",
      "language"
    ],
    "ids_to_text": [
      "self",
      "id_sequence"
    ],
    "pad_with_bos_eos": [
      "self",
      "char_sequence"
    ],
    "intersperse_blank_char": [
      "self",
      "char_sequence",
      "use_blank_char"
    ],
    "print_logs": [
      "self",
      "level"
    ],
    "init_from_config": [
      "config",
      "characters"
    ]
  },
  "VALID_SYMBOLS": [],
  "CMUDict": {
    "__init__": [
      "self",
      "file_or_path",
      "keep_ambiguous"
    ],
    "__len__": [
      "self"
    ],
    "lookup": [
      "self",
      "word"
    ],
    "get_arpabet": [
      "word",
      "cmudict",
      "punctuation_symbols"
    ]
  },
  "_alt_re": [],
  "_parse_cmudict": [
    "file"
  ],
  "_get_pronunciation": [
    "s"
  ],
  "_DEF_PUNCS": [],
  "_PUNC_IDX": [],
  "PuncPosition": {
    "BEGIN": [],
    "END": [],
    "MIDDLE": []
  },
  "Punctuation": {
    "__init__": [
      "self",
      "puncs"
    ],
    "default_puncs": [],
    "puncs": [
      "self",
      "value"
    ],
    "strip": [
      "self",
      "text"
    ],
    "strip_to_restore": [
      "self",
      "text"
    ],
    "_strip_to_restore": [
      "self",
      "text"
    ],
    "restore": [
      "cls",
      "text",
      "puncs"
    ],
    "_restore": [
      "cls",
      "text",
      "puncs"
    ]
  },
  "parse_symbols": [],
  "_pad": [],
  "_eos": [],
  "_bos": [],
  "_blank": [],
  "_characters": [],
  "_punctuations": [],
  "_vowels": [],
  "_non_pulmonic_consonants": [],
  "_pulmonic_consonants": [],
  "_suprasegmentals": [],
  "_other_symbols": [],
  "_diacrilics": [],
  "_phonemes": [],
  "BaseVocabulary": {
    "__init__": [
      "self",
      "vocab",
      "pad",
      "blank",
      "bos",
      "eos"
    ],
    "pad_id": [
      "self"
    ],
    "blank_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "vocab": [
      "self",
      "vocab"
    ],
    "init_from_config": [
      "config"
    ],
    "to_config": [
      "self"
    ],
    "num_chars": [
      "self"
    ],
    "char_to_id": [
      "self",
      "char"
    ],
    "id_to_char": [
      "self",
      "idx"
    ]
  },
  "BaseCharacters": {
    "__init__": [
      "self",
      "characters",
      "punctuations",
      "pad",
      "eos",
      "bos",
      "blank",
      "is_unique",
      "is_sorted"
    ],
    "pad_id": [
      "self"
    ],
    "blank_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "bos_id": [
      "self"
    ],
    "characters": [
      "self",
      "characters"
    ],
    "punctuations": [
      "self",
      "punctuations"
    ],
    "pad": [
      "self",
      "pad"
    ],
    "eos": [
      "self",
      "eos"
    ],
    "bos": [
      "self",
      "bos"
    ],
    "blank": [
      "self",
      "blank"
    ],
    "vocab": [
      "self",
      "vocab"
    ],
    "num_chars": [
      "self"
    ],
    "_create_vocab": [
      "self"
    ],
    "char_to_id": [
      "self",
      "char"
    ],
    "id_to_char": [
      "self",
      "idx"
    ],
    "print_log": [
      "self",
      "level"
    ],
    "init_from_config": [
      "config"
    ],
    "to_config": [
      "self"
    ]
  },
  "IPAPhonemes": {
    "__init__": [
      "self",
      "characters",
      "punctuations",
      "pad",
      "eos",
      "bos",
      "blank",
      "is_unique",
      "is_sorted"
    ],
    "init_from_config": [
      "config"
    ]
  },
  "Graphemes": {
    "__init__": [
      "self",
      "characters",
      "punctuations",
      "pad",
      "eos",
      "bos",
      "blank",
      "is_unique",
      "is_sorted"
    ],
    "init_from_config": [
      "config"
    ]
  },
  "g2p": [],
  "korean_text_to_phonemes": [
    "text",
    "character"
  ],
  "etc_dictionary": [],
  "english_dictionary": [],
  "GRUUT_TRANS_TABLE": [],
  "Gruut": {
    "__init__": [
      "self",
      "language",
      "punctuations",
      "keep_puncs",
      "use_espeak_phonemes",
      "keep_stress"
    ],
    "name": [],
    "phonemize_gruut": [
      "self",
      "text",
      "separator",
      "tie"
    ],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "is_supported_language": [
      "self",
      "language"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "cls"
    ]
  },
  "BasePhonemizer": {
    "__init__": [
      "self",
      "language",
      "punctuations",
      "keep_puncs"
    ],
    "_init_language": [
      "self",
      "language"
    ],
    "language": [
      "self"
    ],
    "name": [],
    "is_available": [
      "cls"
    ],
    "version": [
      "cls"
    ],
    "supported_languages": [],
    "is_supported_language": [
      "self",
      "language"
    ],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "_phonemize_preprocess": [
      "self",
      "text"
    ],
    "_phonemize_postprocess": [
      "self",
      "phonemized",
      "punctuations"
    ],
    "phonemize": [
      "self",
      "text",
      "separator",
      "language"
    ],
    "print_logs": [
      "self",
      "level"
    ]
  },
  "_DEF_ZH_PUNCS": [],
  "ZH_CN_Phonemizer": {
    "language": [],
    "__init__": [
      "self",
      "punctuations",
      "keep_puncs"
    ],
    "name": [],
    "phonemize_zh_cn": [
      "text",
      "separator"
    ],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "self"
    ]
  },
  "BN_Phonemizer": {
    "language": [],
    "__init__": [
      "self",
      "punctuations",
      "keep_puncs"
    ],
    "name": [],
    "phonemize_bn": [
      "text",
      "separator"
    ],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "self"
    ]
  },
  "_DEF_JA_PUNCS": [],
  "_TRANS_TABLE": [],
  "trans": [
    "text"
  ],
  "JA_JP_Phonemizer": {
    "language": [],
    "__init__": [
      "self",
      "punctuations",
      "keep_puncs"
    ],
    "name": [],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "phonemize": [
      "self",
      "text",
      "separator",
      "language"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "self"
    ]
  },
  "PHONEMIZERS": [],
  "ESPEAK_LANGS": [],
  "GRUUT_LANGS": [],
  "_": [],
  "DEF_LANG_TO_PHONEMIZER": [],
  "_new_dict": [],
  "get_phonemizer_by_name": [
    "name"
  ],
  "_DEF_KO_PUNCS": [],
  "KO_KR_Phonemizer": {
    "language": [],
    "__init__": [
      "self",
      "punctuations",
      "keep_puncs"
    ],
    "name": [],
    "_phonemize": [
      "self",
      "text",
      "separator",
      "character"
    ],
    "phonemize": [
      "self",
      "text",
      "separator",
      "character",
      "language"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "self"
    ]
  },
  "MultiPhonemizer": {
    "lang_to_phonemizer": [],
    "__init__": [
      "self",
      "lang_to_phonemizer_name"
    ],
    "init_phonemizers": [
      "lang_to_phonemizer_name"
    ],
    "name": [],
    "phonemize": [
      "self",
      "text",
      "separator",
      "language"
    ],
    "supported_languages": [
      "self"
    ],
    "print_logs": [
      "self",
      "level"
    ]
  },
  "is_tool": [
    "name"
  ],
  "espeak_version_pattern": [],
  "get_espeak_version": [],
  "get_espeakng_version": [],
  "_espeak_exe": [
    "espeak_lib",
    "args",
    "sync"
  ],
  "ESpeak": {
    "_ESPEAK_LIB": [],
    "_ESPEAK_VER": [],
    "__init__": [
      "self",
      "language",
      "backend",
      "punctuations",
      "keep_puncs"
    ],
    "backend": [
      "self",
      "backend"
    ],
    "backend_version": [
      "self"
    ],
    "auto_set_espeak_lib": [
      "self"
    ],
    "name": [],
    "phonemize_espeak": [
      "self",
      "text",
      "separator",
      "tie"
    ],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "cls"
    ]
  },
  "_DEF_BE_PUNCS": [],
  "BEL_Phonemizer": {
    "language": [],
    "__init__": [
      "self",
      "punctuations",
      "keep_puncs"
    ],
    "name": [],
    "phonemize_be": [
      "text",
      "separator"
    ],
    "_phonemize": [
      "self",
      "text",
      "separator"
    ],
    "supported_languages": [],
    "version": [
      "self"
    ],
    "is_available": [
      "self"
    ]
  },
  "bnorm": [],
  "attribution_dict": [],
  "tag_text": [
    "text"
  ],
  "normalize": [
    "sen"
  ],
  "expand_full_attribution": [
    "text"
  ],
  "bangla_text_to_phonemes": [
    "text"
  ],
  "_CONVRULES": [],
  "_COLON_RX": [],
  "_REJECT_RX": [],
  "_makerulemap": [],
  "kata2phoneme": [
    "text"
  ],
  "_KATAKANA": [],
  "_HIRAGANA": [],
  "_HIRA2KATATRANS": [],
  "hira2kata": [
    "text"
  ],
  "_SYMBOL_TOKENS": [],
  "_NO_YOMI_TOKENS": [],
  "_TAGGER": [],
  "text2kata": [
    "text"
  ],
  "_ALPHASYMBOL_YOMI": [],
  "_NUMBER_WITH_SEPARATOR_RX": [],
  "_CURRENCY_MAP": [],
  "_CURRENCY_RX": [],
  "_NUMBER_RX": [],
  "japanese_convert_numbers_to_words": [
    "text"
  ],
  "japanese_convert_alpha_symbols_to_words": [
    "text"
  ],
  "japanese_text_to_phonemes": [
    "text"
  ],
  "finder": [],
  "init": [],
  "belarusian_text_to_phonemes": [
    "text"
  ],
  "abbreviations_fr": [],
  "_chinese_character_to_pinyin": [
    "text"
  ],
  "_chinese_pinyin_to_phoneme": [
    "pinyin"
  ],
  "chinese_text_to_phonemes": [
    "text",
    "seperator"
  ],
  "PINYIN_DICT": [],
  "_num2chinese": [
    "num",
    "big",
    "simp",
    "o",
    "twoalt"
  ],
  "_number_replace": [
    "match"
  ],
  "replace_numbers_to_characters_in_text": [
    "text"
  ],
  "_inflect": [],
  "_comma_number_re": [],
  "_decimal_number_re": [],
  "_currency_re": [],
  "_ordinal_re": [],
  "_number_re": [],
  "_remove_commas": [
    "m"
  ],
  "_expand_decimal_point": [
    "m"
  ],
  "__expand_currency": [
    "value",
    "inflection"
  ],
  "_expand_currency": [
    "m"
  ],
  "_expand_ordinal": [
    "m"
  ],
  "_expand_number": [
    "m"
  ],
  "normalize_numbers": [
    "text"
  ],
  "abbreviations_en": [],
  "_time_re": [],
  "_expand_num": [
    "n"
  ],
  "_expand_time_english": [
    "match"
  ],
  "expand_time_english": [
    "text"
  ],
  "L1LossMasked": {
    "__init__": [
      "self",
      "seq_len_norm"
    ],
    "forward": [
      "self",
      "x",
      "target",
      "length"
    ]
  },
  "MSELossMasked": {
    "__init__": [
      "self",
      "seq_len_norm"
    ],
    "forward": [
      "self",
      "x",
      "target",
      "length"
    ]
  },
  "sample_wise_min_max": [
    "x",
    "mask"
  ],
  "AttentionEntropyLoss": {
    "forward": [
      "self",
      "align"
    ]
  },
  "BCELossMasked": {
    "__init__": [
      "self",
      "pos_weight"
    ],
    "forward": [
      "self",
      "x",
      "target",
      "length"
    ]
  },
  "DifferentialSpectralLoss": {
    "__init__": [
      "self",
      "loss_func"
    ],
    "forward": [
      "self",
      "x",
      "target",
      "length"
    ]
  },
  "GuidedAttentionLoss": {
    "__init__": [
      "self",
      "sigma"
    ],
    "_make_ga_masks": [
      "self",
      "ilens",
      "olens"
    ],
    "forward": [
      "self",
      "att_ws",
      "ilens",
      "olens"
    ],
    "_make_ga_mask": [
      "ilen",
      "olen",
      "sigma"
    ],
    "_make_masks": [
      "ilens",
      "olens"
    ]
  },
  "Huber": {
    "forward": [
      "self",
      "x",
      "y",
      "length"
    ]
  },
  "ForwardSumLoss": {
    "__init__": [
      "self",
      "blank_logprob"
    ],
    "forward": [
      "self",
      "attn_logprob",
      "in_lens",
      "out_lens"
    ]
  },
  "TacotronLoss": {
    "__init__": [
      "self",
      "c",
      "ga_sigma"
    ],
    "forward": [
      "self",
      "postnet_output",
      "decoder_output",
      "mel_input",
      "linear_input",
      "stopnet_output",
      "stopnet_target",
      "stop_target_length",
      "capacitron_vae_outputs",
      "output_lens",
      "decoder_b_output",
      "alignments",
      "alignment_lens",
      "alignments_backwards",
      "input_lens"
    ]
  },
  "GlowTTSLoss": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "z",
      "means",
      "scales",
      "log_det",
      "y_lengths",
      "o_dur_log",
      "o_attn_dur",
      "x_lengths"
    ]
  },
  "mse_loss_custom": [
    "x",
    "y"
  ],
  "MDNLoss": {
    "forward": [
      "self",
      "logp",
      "text_lengths",
      "mel_lengths"
    ]
  },
  "AlignTTSLoss": {
    "__init__": [
      "self",
      "c"
    ],
    "forward": [
      "self",
      "logp",
      "decoder_output",
      "decoder_target",
      "decoder_output_lens",
      "dur_output",
      "dur_target",
      "input_lens",
      "phase"
    ]
  },
  "VitsGeneratorLoss": {
    "__init__": [
      "self",
      "c"
    ],
    "feature_loss": [
      "feats_real",
      "feats_generated"
    ],
    "generator_loss": [
      "scores_fake"
    ],
    "kl_loss": [
      "z_p",
      "logs_q",
      "m_p",
      "logs_p",
      "z_mask"
    ],
    "cosine_similarity_loss": [
      "gt_spk_emb",
      "syn_spk_emb"
    ],
    "forward": [
      "self",
      "mel_slice",
      "mel_slice_hat",
      "z_p",
      "logs_q",
      "m_p",
      "logs_p",
      "z_len",
      "scores_disc_fake",
      "feats_disc_fake",
      "feats_disc_real",
      "loss_duration",
      "use_speaker_encoder_as_loss",
      "gt_spk_emb",
      "syn_spk_emb"
    ]
  },
  "VitsDiscriminatorLoss": {
    "__init__": [
      "self",
      "c"
    ],
    "discriminator_loss": [
      "scores_real",
      "scores_fake"
    ],
    "forward": [
      "self",
      "scores_disc_real",
      "scores_disc_fake"
    ]
  },
  "ForwardTTSLoss": {
    "__init__": [
      "self",
      "c"
    ],
    "_binary_alignment_loss": [
      "alignment_hard",
      "alignment_soft"
    ],
    "forward": [
      "self",
      "decoder_output",
      "decoder_target",
      "decoder_output_lens",
      "dur_output",
      "dur_target",
      "pitch_output",
      "pitch_target",
      "energy_output",
      "energy_target",
      "input_lens",
      "alignment_logprob",
      "alignment_hard",
      "alignment_soft",
      "binary_loss_weight"
    ]
  },
  "TimeDepthSeparableConv": {
    "__init__": [
      "self",
      "in_channels",
      "hid_channels",
      "out_channels",
      "kernel_size",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TimeDepthSeparableConvBlock": {
    "__init__": [
      "self",
      "in_channels",
      "hid_channels",
      "out_channels",
      "num_layers",
      "kernel_size",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "ZeroTemporalPad": {
    "__init__": [
      "self",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1dBN": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "dilation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1dBNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "kernel_size",
      "dilation",
      "num_conv_blocks"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualConv1dBNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "kernel_size",
      "dilations",
      "num_res_blocks",
      "num_conv_blocks"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "fused_add_tanh_sigmoid_multiply": [
    "input_a",
    "input_b",
    "n_channels"
  ],
  "WN": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "num_layers",
      "c_in_channels",
      "dropout_p",
      "weight_norm"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "WNBlocks": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "num_blocks",
      "num_layers",
      "c_in_channels",
      "dropout_p",
      "weight_norm"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm2": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TemporalBatchNorm1d": {
    "__init__": [
      "self",
      "channels",
      "affine",
      "track_running_stats",
      "momentum"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ActNorm": {
    "__init__": [
      "self",
      "channels",
      "ddi"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse"
    ],
    "store_inverse": [
      "self"
    ],
    "set_ddi": [
      "self",
      "ddi"
    ],
    "initialize": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "GatedConvBlock": {
    "__init__": [
      "self",
      "in_out_channels",
      "kernel_size",
      "dropout_p",
      "num_layers"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "FFTransformer": {
    "__init__": [
      "self",
      "in_out_channels",
      "num_heads",
      "hidden_channels_ffn",
      "kernel_size_fft",
      "dropout_p"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask"
    ]
  },
  "FFTransformerBlock": {
    "__init__": [
      "self",
      "in_out_channels",
      "num_heads",
      "hidden_channels_ffn",
      "num_layers",
      "dropout_p"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "g"
    ]
  },
  "FFTDurationPredictor": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "num_heads",
      "num_layers",
      "dropout_p",
      "cond_channels"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "g"
    ]
  },
  "AlignmentNetwork": {
    "__init__": [
      "self",
      "in_query_channels",
      "in_key_channels",
      "attn_channels",
      "temperature"
    ],
    "init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "queries",
      "keys",
      "mask",
      "attn_prior"
    ]
  },
  "LocationLayer": {
    "__init__": [
      "self",
      "attention_dim",
      "attention_n_filters",
      "attention_kernel_size"
    ],
    "forward": [
      "self",
      "attention_cat"
    ]
  },
  "GravesAttention": {
    "COEF": [],
    "__init__": [
      "self",
      "query_dim",
      "K"
    ],
    "init_layers": [
      "self"
    ],
    "init_states": [
      "self",
      "inputs"
    ],
    "preprocess_inputs": [
      "self",
      "inputs"
    ],
    "forward": [
      "self",
      "query",
      "inputs",
      "processed_inputs",
      "mask"
    ]
  },
  "OriginalAttention": {
    "__init__": [
      "self",
      "query_dim",
      "embedding_dim",
      "attention_dim",
      "location_attention",
      "attention_location_n_filters",
      "attention_location_kernel_size",
      "windowing",
      "norm",
      "forward_attn",
      "trans_agent",
      "forward_attn_mask"
    ],
    "init_win_idx": [
      "self"
    ],
    "init_forward_attn": [
      "self",
      "inputs"
    ],
    "init_location_attention": [
      "self",
      "inputs"
    ],
    "init_states": [
      "self",
      "inputs"
    ],
    "preprocess_inputs": [
      "self",
      "inputs"
    ],
    "update_location_attention": [
      "self",
      "alignments"
    ],
    "get_location_attention": [
      "self",
      "query",
      "processed_inputs"
    ],
    "get_attention": [
      "self",
      "query",
      "processed_inputs"
    ],
    "apply_windowing": [
      "self",
      "attention",
      "inputs"
    ],
    "apply_forward_attention": [
      "self",
      "alignment"
    ],
    "forward": [
      "self",
      "query",
      "inputs",
      "processed_inputs",
      "mask"
    ]
  },
  "MonotonicDynamicConvolutionAttention": {
    "__init__": [
      "self",
      "query_dim",
      "embedding_dim",
      "attention_dim",
      "static_filter_dim",
      "static_kernel_size",
      "dynamic_filter_dim",
      "dynamic_kernel_size",
      "prior_filter_len",
      "alpha",
      "beta"
    ],
    "forward": [
      "self",
      "query",
      "inputs",
      "processed_inputs",
      "mask"
    ],
    "preprocess_inputs": [
      "self",
      "inputs"
    ],
    "init_states": [
      "self",
      "inputs"
    ]
  },
  "init_attn": [
    "attn_type",
    "query_dim",
    "embedding_dim",
    "attention_dim",
    "location_attention",
    "attention_location_n_filters",
    "attention_location_kernel_size",
    "windowing",
    "norm",
    "forward_attn",
    "trans_agent",
    "forward_attn_mask",
    "attn_K"
  ],
  "BatchNormConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "activation"
    ],
    "init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Highway": {
    "__init__": [
      "self",
      "in_features",
      "out_feature"
    ],
    "init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CBHG": {
    "__init__": [
      "self",
      "in_features",
      "K",
      "conv_bank_features",
      "conv_projections",
      "highway_features",
      "gru_features",
      "num_highways"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "EncoderCBHG": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Encoder": {
    "__init__": [
      "self",
      "in_features"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "PostCBHG": {
    "__init__": [
      "self",
      "mel_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "in_channels",
      "frame_channels",
      "r",
      "memory_size",
      "attn_type",
      "attn_windowing",
      "attn_norm",
      "prenet_type",
      "prenet_dropout",
      "forward_attn",
      "trans_agent",
      "forward_attn_mask",
      "location_attn",
      "attn_K",
      "separate_stopnet",
      "max_decoder_steps"
    ],
    "set_r": [
      "self",
      "new_r"
    ],
    "_reshape_memory": [
      "self",
      "memory"
    ],
    "_init_states": [
      "self",
      "inputs"
    ],
    "_parse_outputs": [
      "self",
      "outputs",
      "attentions",
      "stop_tokens"
    ],
    "decode": [
      "self",
      "inputs",
      "mask"
    ],
    "_update_memory_input": [
      "self",
      "new_memory"
    ],
    "forward": [
      "self",
      "inputs",
      "memory",
      "mask"
    ],
    "inference": [
      "self",
      "inputs"
    ]
  },
  "StopNet": {
    "__init__": [
      "self",
      "in_features"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "CapacitronVAE": {
    "__init__": [
      "self",
      "num_mel",
      "capacitron_VAE_embedding_dim",
      "encoder_output_dim",
      "reference_encoder_out_dim",
      "speaker_embedding_dim",
      "text_summary_embedding_dim"
    ],
    "forward": [
      "self",
      "reference_mel_info",
      "text_info",
      "speaker_embedding"
    ]
  },
  "ReferenceEncoder": {
    "__init__": [
      "self",
      "num_mel",
      "out_dim"
    ],
    "forward": [
      "self",
      "inputs",
      "input_lengths"
    ],
    "calculate_post_conv_height": [
      "height",
      "kernel_size",
      "stride",
      "pad",
      "n_convs"
    ]
  },
  "TextSummary": {
    "__init__": [
      "self",
      "embedding_dim",
      "encoder_output_dim"
    ],
    "forward": [
      "self",
      "inputs",
      "input_lengths"
    ]
  },
  "PostEncoderMLP": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size"
    ],
    "forward": [
      "self",
      "_input"
    ]
  },
  "ConvBNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Postnet": {
    "__init__": [
      "self",
      "in_out_channels",
      "num_convs"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Linear": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "init_gain"
    ],
    "_init_w": [
      "self",
      "init_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearBN": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "init_gain"
    ],
    "_init_w": [
      "self",
      "init_gain"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Prenet": {
    "__init__": [
      "self",
      "in_features",
      "prenet_type",
      "prenet_dropout",
      "dropout_at_inference",
      "out_features",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GST": {
    "__init__": [
      "self",
      "num_mel",
      "num_heads",
      "num_style_tokens",
      "gst_embedding_dim",
      "embedded_speaker_dim"
    ],
    "forward": [
      "self",
      "inputs",
      "speaker_embedding"
    ]
  },
  "StyleTokenLayer": {
    "__init__": [
      "self",
      "num_heads",
      "num_style_tokens",
      "gst_embedding_dim",
      "d_vector_dim"
    ],
    "forward": [
      "self",
      "inputs"
    ]
  },
  "MultiHeadAttention": {
    "__init__": [
      "self",
      "query_dim",
      "key_dim",
      "num_units",
      "num_heads"
    ],
    "forward": [
      "self",
      "query",
      "key"
    ]
  },
  "WaveNetDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "c_in_channels",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "RelativePositionTransformerDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "FFTransformerDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "ResidualConv1dBNDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "DurationPredictor": {
    "__init__": [
      "self",
      "hidden_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "RelativePositionTransformerEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "ResidualConv1dBNEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "params"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "setup_seed": [
    "seed"
  ],
  "StreamGenerationConfig": {
    "__init__": [
      "self"
    ]
  },
  "NewGenerationMixin": {
    "generate": [
      "self",
      "inputs",
      "generation_config",
      "logits_processor",
      "stopping_criteria",
      "prefix_allowed_tokens_fn",
      "synced_gpus",
      "seed"
    ],
    "sample_stream": [
      "self",
      "input_ids",
      "logits_processor",
      "stopping_criteria",
      "logits_warper",
      "max_length",
      "pad_token_id",
      "eos_token_id",
      "output_attentions",
      "output_hidden_states",
      "output_scores",
      "return_dict_in_generate",
      "synced_gpus"
    ]
  },
  "init_stream_support": [],
  "CHINESE_DIGIS": [],
  "BIG_CHINESE_DIGIS_SIMPLIFIED": [],
  "BIG_CHINESE_DIGIS_TRADITIONAL": [],
  "SMALLER_BIG_CHINESE_UNITS_SIMPLIFIED": [],
  "SMALLER_BIG_CHINESE_UNITS_TRADITIONAL": [],
  "LARGER_CHINESE_NUMERING_UNITS_SIMPLIFIED": [],
  "LARGER_CHINESE_NUMERING_UNITS_TRADITIONAL": [],
  "SMALLER_CHINESE_NUMERING_UNITS_SIMPLIFIED": [],
  "SMALLER_CHINESE_NUMERING_UNITS_TRADITIONAL": [],
  "ZERO_ALT": [],
  "ONE_ALT": [],
  "TWO_ALTS": [],
  "POSITIVE": [],
  "NEGATIVE": [],
  "POINT": [],
  "FILLER_CHARS": [],
  "ER_WHITELIST": [],
  "ER_WHITELIST_PATTERN": [],
  "NUMBERING_TYPES": [],
  "CURRENCY_NAMES": [],
  "CURRENCY_UNITS": [],
  "COM_QUANTIFIERS": [],
  "CN_PUNCS_STOP": [],
  "CN_PUNCS_NONSTOP": [],
  "CN_PUNCS": [],
  "PUNCS": [],
  "PUNCS_TRANSFORM": [],
  "QJ2BJ": [],
  "QJ2BJ_TRANSFORM": [],
  "CN_CHARS_COMMON": [],
  "CN_CHARS_EXT": [],
  "CN_CHARS": [],
  "IN_CH_CHARS": [],
  "EN_CHARS": [],
  "IN_EN_CHARS": [],
  "VALID_CHARS": [],
  "IN_VALID_CHARS": [],
  "ChineseChar": {
    "__init__": [
      "self",
      "simplified",
      "traditional"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ChineseNumberUnit": {
    "__init__": [
      "self",
      "power",
      "simplified",
      "traditional",
      "big_s",
      "big_t"
    ],
    "__str__": [
      "self"
    ],
    "create": [
      "cls",
      "index",
      "value",
      "numbering_type",
      "small_unit"
    ]
  },
  "ChineseNumberDigit": {
    "__init__": [
      "self",
      "value",
      "simplified",
      "traditional",
      "big_s",
      "big_t",
      "alt_s",
      "alt_t"
    ],
    "__str__": [
      "self"
    ],
    "create": [
      "cls",
      "i",
      "v"
    ]
  },
  "ChineseMath": {
    "__init__": [
      "self",
      "simplified",
      "traditional",
      "symbol",
      "expression"
    ]
  },
  "NumberSystem": {},
  "MathSymbol": {
    "__init__": [
      "self",
      "positive",
      "negative",
      "point"
    ],
    "__iter__": [
      "self"
    ]
  },
  "create_system": [
    "numbering_type"
  ],
  "chn2num": [
    "chinese_string",
    "numbering_type"
  ],
  "num2chn": [
    "number_string",
    "numbering_type",
    "big",
    "traditional",
    "alt_zero",
    "alt_one",
    "alt_two",
    "use_zeros",
    "use_units"
  ],
  "Cardinal": {
    "__init__": [
      "self",
      "cardinal",
      "chntext"
    ],
    "chntext2cardinal": [
      "self"
    ],
    "cardinal2chntext": [
      "self"
    ]
  },
  "Digit": {
    "__init__": [
      "self",
      "digit",
      "chntext"
    ],
    "digit2chntext": [
      "self"
    ]
  },
  "TelePhone": {
    "__init__": [
      "self",
      "telephone",
      "raw_chntext",
      "chntext"
    ],
    "telephone2chntext": [
      "self",
      "fixed"
    ]
  },
  "Fraction": {
    "__init__": [
      "self",
      "fraction",
      "chntext"
    ],
    "chntext2fraction": [
      "self"
    ],
    "fraction2chntext": [
      "self"
    ]
  },
  "Date": {
    "__init__": [
      "self",
      "date",
      "chntext"
    ],
    "date2chntext": [
      "self"
    ]
  },
  "Money": {
    "__init__": [
      "self",
      "money",
      "chntext"
    ],
    "money2chntext": [
      "self"
    ]
  },
  "Percentage": {
    "__init__": [
      "self",
      "percentage",
      "chntext"
    ],
    "chntext2percentage": [
      "self"
    ],
    "percentage2chntext": [
      "self"
    ]
  },
  "normalize_nsw": [
    "raw_text"
  ],
  "remove_erhua": [
    "text"
  ],
  "remove_space": [
    "text"
  ],
  "TextNorm": {
    "__init__": [
      "self",
      "to_banjiao",
      "to_upper",
      "to_lower",
      "remove_fillers",
      "remove_erhua",
      "check_chars",
      "remove_space",
      "cc_mode"
    ],
    "__call__": [
      "self",
      "text"
    ]
  },
  "null_position_embeddings": [
    "range",
    "dim"
  ],
  "LearnedPositionEmbeddings": {
    "__init__": [
      "self",
      "seq_len",
      "model_dim",
      "init",
      "relative"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_fixed_embedding": [
      "self",
      "ind",
      "dev"
    ]
  },
  "build_hf_gpt_transformer": [
    "layers",
    "model_dim",
    "heads",
    "max_mel_seq_len",
    "max_text_seq_len",
    "max_prompt_len",
    "checkpointing"
  ],
  "GPT": {
    "__init__": [
      "self",
      "start_text_token",
      "stop_text_token",
      "layers",
      "model_dim",
      "heads",
      "max_text_tokens",
      "max_mel_tokens",
      "max_prompt_tokens",
      "max_conditioning_inputs",
      "code_stride_len",
      "number_text_tokens",
      "num_audio_tokens",
      "start_audio_token",
      "stop_audio_token",
      "train_solo_embeddings",
      "checkpointing",
      "average_conditioning_embeddings",
      "label_smoothing",
      "use_perceiver_resampler",
      "perceiver_cond_length_compression"
    ],
    "get_grad_norm_parameter_groups": [
      "self"
    ],
    "init_gpt_for_inference": [
      "self",
      "kv_cache",
      "use_deepspeed"
    ],
    "set_inputs_and_targets": [
      "self",
      "input",
      "start_token",
      "stop_token"
    ],
    "set_mel_padding": [
      "self",
      "mel_input_tokens",
      "code_lengths"
    ],
    "get_logits": [
      "self",
      "first_inputs",
      "first_head",
      "second_inputs",
      "second_head",
      "prompt",
      "get_attns",
      "return_latent",
      "attn_mask_cond",
      "attn_mask_text",
      "attn_mask_mel"
    ],
    "get_conditioning": [
      "self",
      "speech_conditioning_input"
    ],
    "get_prompts": [
      "self",
      "prompt_codes"
    ],
    "get_style_emb": [
      "self",
      "cond_input",
      "return_latent"
    ],
    "forward": [
      "self",
      "text_inputs",
      "text_lengths",
      "audio_codes",
      "wav_lengths",
      "cond_mels",
      "cond_idxs",
      "cond_lens",
      "cond_latents",
      "return_attentions",
      "return_latent"
    ],
    "inference": [
      "self",
      "cond_latents",
      "text_inputs"
    ],
    "compute_embeddings": [
      "self",
      "cond_latents",
      "text_inputs"
    ],
    "generate": [
      "self",
      "cond_latents",
      "text_inputs"
    ],
    "get_generator": [
      "self",
      "fake_inputs"
    ]
  },
  "get_spacy_lang": [
    "lang"
  ],
  "split_sentence": [
    "text",
    "lang",
    "text_split_length"
  ],
  "_abbreviations": [],
  "expand_abbreviations_multilingual": [
    "text",
    "lang"
  ],
  "_symbols_multilingual": [],
  "expand_symbols_multilingual": [
    "text",
    "lang"
  ],
  "_dot_number_re": [],
  "_remove_dots": [
    "m"
  ],
  "expand_numbers_multilingual": [
    "text",
    "lang"
  ],
  "chinese_transliterate": [
    "text"
  ],
  "japanese_cleaners": [
    "text",
    "katsu"
  ],
  "korean_transliterate": [
    "text"
  ],
  "DEFAULT_VOCAB_FILE": [],
  "VoiceBpeTokenizer": {
    "__init__": [
      "self",
      "vocab_file"
    ],
    "katsu": [
      "self"
    ],
    "check_input_length": [
      "self",
      "txt",
      "lang"
    ],
    "preprocess_text": [
      "self",
      "txt",
      "lang"
    ],
    "encode": [
      "self",
      "txt",
      "lang"
    ],
    "decode": [
      "self",
      "seq"
    ],
    "__len__": [
      "self"
    ],
    "get_number_tokens": [
      "self"
    ]
  },
  "test_expand_numbers_multilingual": [],
  "test_abbreviations_multilingual": [],
  "test_symbols_multilingual": [],
  "GPT2InferenceModel": {
    "__init__": [
      "self",
      "config",
      "gpt",
      "pos_emb",
      "embeddings",
      "norm",
      "linear",
      "kv_cache"
    ],
    "store_prefix_emb": [
      "self",
      "prefix_emb"
    ],
    "prepare_inputs_for_generation": [
      "self",
      "input_ids",
      "past_key_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "past_key_values",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "head_mask",
      "inputs_embeds",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "labels",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict"
    ],
    "_reorder_cache": [
      "past",
      "beam_idx"
    ]
  },
  "GroupNorm32": {
    "forward": [
      "self",
      "x"
    ]
  },
  "conv_nd": [
    "dims"
  ],
  "normalization": [
    "channels"
  ],
  "zero_module": [
    "module"
  ],
  "QKVAttention": {
    "__init__": [
      "self",
      "n_heads"
    ],
    "forward": [
      "self",
      "qkv",
      "mask",
      "qk_bias"
    ]
  },
  "AttentionBlock": {
    "__init__": [
      "self",
      "channels",
      "num_heads",
      "num_head_channels",
      "out_channels",
      "do_activation"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "qk_bias"
    ]
  },
  "ConditioningEncoder": {
    "__init__": [
      "self",
      "spec_dim",
      "embedding_dim",
      "attn_blocks",
      "num_attn_heads"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "default": [
    "val",
    "d"
  ],
  "eval_decorator": [
    "fn"
  ],
  "dvae_wav_to_mel": [
    "wav",
    "mel_norms_file",
    "mel_norms",
    "device"
  ],
  "Quantize": {
    "__init__": [
      "self",
      "dim",
      "n_embed",
      "decay",
      "eps",
      "balancing_heuristic",
      "new_return_order"
    ],
    "forward": [
      "self",
      "input",
      "return_soft_codes"
    ],
    "embed_code": [
      "self",
      "embed_id"
    ]
  },
  "DiscretizationLoss": {
    "__init__": [
      "self",
      "discrete_bins",
      "dim",
      "expected_variance",
      "store_past"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpsampledConv": {
    "__init__": [
      "self",
      "conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DiscreteVAE": {
    "__init__": [
      "self",
      "positional_dims",
      "num_tokens",
      "codebook_dim",
      "num_layers",
      "num_resnet_blocks",
      "hidden_dim",
      "channels",
      "stride",
      "kernel_size",
      "use_transposed_convs",
      "encoder_norm",
      "activation",
      "smooth_l1_loss",
      "straight_through",
      "normalization",
      "record_codes",
      "discretization_loss_averaging_steps",
      "lr_quantizer_args"
    ],
    "norm": [
      "self",
      "images"
    ],
    "get_debug_values": [
      "self",
      "step",
      "__"
    ],
    "get_codebook_indices": [
      "self",
      "images"
    ],
    "decode": [
      "self",
      "img_seq"
    ],
    "infer": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "img"
    ],
    "log_codes": [
      "self",
      "codes"
    ]
  },
  "SELayer": {
    "__init__": [
      "self",
      "channel",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SEBasicBlock": {
    "expansion": [],
    "__init__": [
      "self",
      "inplanes",
      "planes",
      "stride",
      "downsample",
      "reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "set_init_dict": [
    "model_dict",
    "checkpoint_state",
    "c"
  ],
  "PreEmphasis": {
    "__init__": [
      "self",
      "coefficient"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ResNetSpeakerEncoder": {
    "__init__": [
      "self",
      "input_dim",
      "proj_dim",
      "layers",
      "num_filters",
      "encoder_type",
      "log_input",
      "use_torch_spec",
      "audio_config"
    ],
    "_init_layers": [
      "self"
    ],
    "create_layer": [
      "self",
      "block",
      "planes",
      "blocks",
      "stride"
    ],
    "new_parameter": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "l2_norm"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path",
      "eval",
      "use_cuda",
      "criterion",
      "cache"
    ]
  },
  "HifiDecoder": {
    "__init__": [
      "self",
      "input_sample_rate",
      "output_sample_rate",
      "output_hop_length",
      "ar_mel_length_compression",
      "decoder_input_dim",
      "resblock_type_decoder",
      "resblock_dilation_sizes_decoder",
      "resblock_kernel_sizes_decoder",
      "upsample_rates_decoder",
      "upsample_initial_channel_decoder",
      "upsample_kernel_sizes_decoder",
      "d_vector_dim",
      "cond_d_vector_in_each_upsampling_layer",
      "speaker_encoder_audio_config"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "latents",
      "g"
    ],
    "inference": [
      "self",
      "c",
      "g"
    ],
    "load_checkpoint": [
      "self",
      "checkpoint_path",
      "eval"
    ]
  },
  "exists": [
    "x"
  ],
  "once": [
    "fn"
  ],
  "print_once": [],
  "Attend": {
    "__init__": [
      "self",
      "dropout",
      "causal",
      "use_flash"
    ],
    "get_mask": [
      "self",
      "n",
      "device"
    ],
    "flash_attn": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "mask"
    ]
  },
  "Sequential": [],
  "RMSNorm": {
    "__init__": [
      "self",
      "dim",
      "scale",
      "dim_cond"
    ],
    "forward": [
      "self",
      "x",
      "cond"
    ]
  },
  "CausalConv1d": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GEGLU": {
    "forward": [
      "self",
      "x"
    ]
  },
  "FeedForward": [
    "dim",
    "mult",
    "causal_conv"
  ],
  "PerceiverResampler": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "mask"
    ]
  },
  "GPTTrainerConfig": {},
  "XttsAudioConfig": {},
  "GPTArgs": {},
  "callback_clearml_load_save": [
    "operation_type",
    "model_info"
  ],
  "GPTTrainer": {
    "__init__": [
      "self",
      "config"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "text_inputs",
      "text_lengths",
      "audio_codes",
      "wav_lengths",
      "cond_mels",
      "cond_idxs",
      "cond_lens"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "format_batch": [
      "self",
      "batch"
    ],
    "format_batch_on_device": [
      "self",
      "batch"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "on_train_epoch_start": [
      "self",
      "trainer"
    ],
    "on_init_end": [
      "self",
      "trainer"
    ],
    "inference": [
      "self",
      "x",
      "aux_input"
    ],
    "get_criterion": [],
    "get_sampler": [
      "self",
      "dataset",
      "num_gpus"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus",
      "rank"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "strict",
      "cache_storage",
      "target_protocol",
      "target_options"
    ],
    "init_from_config": [
      "config",
      "samples"
    ]
  },
  "key_samples_by_col": [
    "samples",
    "col"
  ],
  "get_prompt_slice": [
    "gt_path",
    "max_sample_length",
    "min_sample_length",
    "sample_rate",
    "is_eval"
  ],
  "XTTSDataset": {
    "__init__": [
      "self",
      "config",
      "samples",
      "tokenizer",
      "sample_rate",
      "is_eval"
    ],
    "check_eval_samples": [
      "self"
    ],
    "get_text": [
      "self",
      "text",
      "lang"
    ],
    "load_item": [
      "self",
      "sample"
    ],
    "__getitem__": [
      "self",
      "index"
    ],
    "__len__": [
      "self"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "NeuralHMM": {
    "__init__": [
      "self",
      "frame_channels",
      "ar_order",
      "deterministic_transition",
      "encoder_dim",
      "prenet_type",
      "prenet_dim",
      "prenet_n_layers",
      "prenet_dropout",
      "prenet_dropout_at_inference",
      "memory_rnn_dim",
      "outputnet_size",
      "flat_start_params",
      "std_floor",
      "use_grad_checkpointing"
    ],
    "forward": [
      "self",
      "inputs",
      "inputs_len",
      "mels",
      "mel_lens"
    ],
    "_mask_lengths": [
      "mel_lens",
      "log_c",
      "log_alpha_scaled"
    ],
    "_process_ar_timestep": [
      "self",
      "t",
      "ar_inputs",
      "h_memory",
      "c_memory"
    ],
    "_add_go_token": [
      "self",
      "mel_inputs"
    ],
    "_initialize_forward_algorithm_variables": [
      "mel_inputs",
      "N"
    ],
    "_init_lstm_states": [
      "batch_size",
      "hidden_state_dim",
      "device_tensor"
    ],
    "get_absorption_state_scaling_factor": [
      "self",
      "mels_len",
      "log_alpha_scaled",
      "inputs_len",
      "transition_vector"
    ],
    "get_mask_for_last_item": [
      "lengths",
      "device",
      "out_tensor"
    ],
    "inference": [
      "self",
      "inputs",
      "input_lens",
      "sampling_temp",
      "max_sampling_time",
      "duration_threshold"
    ],
    "sample": [
      "self",
      "inputs",
      "input_lens",
      "sampling_temp",
      "max_sampling_time",
      "duration_threshold"
    ],
    "_initialize_log_state_priors": [
      "text_embeddings"
    ]
  },
  "TransitionModel": {
    "forward": [
      "self",
      "log_alpha_scaled",
      "transition_vector",
      "inputs_len"
    ]
  },
  "EmissionModel": {
    "__init__": [
      "self"
    ],
    "sample": [
      "self",
      "means",
      "stds",
      "sampling_temp"
    ],
    "forward": [
      "self",
      "x_t",
      "means",
      "stds",
      "state_lengths"
    ]
  },
  "ParameterModel": {
    "__init__": [
      "self",
      "outputnet_size",
      "input_size",
      "output_size",
      "frame_channels",
      "flat_start_params"
    ],
    "flat_start_output_layer": [
      "self",
      "mean",
      "std",
      "transition_p"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Outputnet": {
    "__init__": [
      "self",
      "encoder_dim",
      "memory_rnn_dim",
      "frame_channels",
      "outputnet_size",
      "flat_start_params",
      "std_floor"
    ],
    "forward": [
      "self",
      "ar_mels",
      "inputs"
    ],
    "_floor_std": [
      "self",
      "std"
    ]
  },
  "OverflowUtils": {
    "get_data_parameters_for_flat_start": [
      "data_loader",
      "out_channels",
      "states_per_phone"
    ],
    "update_flat_start_transition": [
      "model",
      "transition_p"
    ],
    "log_clamped": [
      "x",
      "eps"
    ],
    "inverse_sigmod": [
      "x"
    ],
    "inverse_softplus": [
      "x"
    ],
    "logsumexp": [
      "x",
      "dim"
    ],
    "double_pad": [
      "list_of_different_shape_tensors"
    ]
  },
  "validate_numpy_array": [
    "value"
  ],
  "get_spec_from_most_probable_state": [
    "log_alpha_scaled",
    "means",
    "decoder"
  ],
  "plot_transition_probabilities_to_numpy": [
    "states",
    "transition_probabilities",
    "output_fig"
  ],
  "logger": [],
  "_md5": [
    "fname"
  ],
  "_download": [
    "from_s3_path",
    "to_local_path",
    "CACHE_DIR"
  ],
  "InferenceContext": {
    "__init__": [
      "self",
      "benchmark"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_traceback"
    ]
  },
  "inference_mode": [],
  "clear_cuda_cache": [],
  "_tokenize": [
    "tokenizer",
    "text"
  ],
  "_detokenize": [
    "tokenizer",
    "enc_text"
  ],
  "_normalize_whitespace": [
    "text"
  ],
  "get_voices": [
    "extra_voice_dirs"
  ],
  "load_npz": [
    "npz_file"
  ],
  "load_voice": [
    "model",
    "voice",
    "extra_voice_dirs"
  ],
  "zero_crossing_rate": [
    "audio",
    "frame_length",
    "hop_length"
  ],
  "compute_spectral_contrast": [
    "audio_data",
    "sample_rate",
    "n_bands",
    "fmin"
  ],
  "compute_average_bass_energy": [
    "audio_data",
    "sample_rate",
    "max_bass_freq"
  ],
  "generate_voice": [
    "audio",
    "model",
    "output_path"
  ],
  "generate_text_semantic": [
    "text",
    "model",
    "history_prompt",
    "temp",
    "top_k",
    "top_p",
    "silent",
    "min_eos_p",
    "max_gen_duration_s",
    "allow_early_stop",
    "base",
    "use_kv_caching"
  ],
  "_flatten_codebooks": [
    "arr",
    "offset_size"
  ],
  "generate_coarse": [
    "x_semantic",
    "model",
    "history_prompt",
    "temp",
    "top_k",
    "top_p",
    "silent",
    "max_coarse_history",
    "sliding_window_len",
    "base",
    "use_kv_caching"
  ],
  "generate_fine": [
    "x_coarse_gen",
    "model",
    "history_prompt",
    "temp",
    "silent",
    "base"
  ],
  "codec_decode": [
    "fine_tokens",
    "model"
  ],
  "CausalSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "past_kv",
      "use_cache"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "x",
      "past_kv",
      "use_cache"
    ]
  },
  "GPTConfig": {},
  "NonCausalSelfAttention": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FineBlock": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FineGPT": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pred_idx",
      "idx"
    ],
    "get_num_params": [
      "self",
      "non_embedding"
    ]
  },
  "FineGPTConfig": {},
  "HubertTokenizer": {
    "__init__": [
      "self",
      "hidden_size",
      "input_size",
      "output_size",
      "version"
    ],
    "forward": [
      "self",
      "x"
    ],
    "get_token": [
      "self",
      "x"
    ],
    "prepare_training": [
      "self"
    ],
    "train_step": [
      "self",
      "x_train",
      "y_train",
      "log_loss"
    ],
    "save": [
      "self",
      "path"
    ],
    "load_from_checkpoint": [
      "path",
      "map_location"
    ]
  },
  "Data": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "version"
    ],
    "load": [
      "string"
    ],
    "save": [
      "self"
    ]
  },
  "auto_train": [
    "data_path",
    "save_path",
    "load_model",
    "save_epochs"
  ],
  "round_down_nearest_multiple": [
    "num",
    "divisor"
  ],
  "curtail_to_multiple": [
    "t",
    "mult",
    "from_left"
  ],
  "CustomHubert": {
    "__init__": [
      "self",
      "checkpoint_path",
      "target_sample_hz",
      "seq_len_multiple_of",
      "output_layer",
      "device"
    ],
    "groups": [
      "self"
    ],
    "forward": [
      "self",
      "wav_input",
      "flatten",
      "input_sample_hz"
    ]
  },
  "HubertManager": {
    "make_sure_hubert_installed": [
      "download_url",
      "model_path"
    ],
    "make_sure_tokenizer_installed": [
      "model",
      "repo",
      "model_path"
    ]
  },
  "calc_same_padding": [
    "kernel_size"
  ],
  "Conformer": {
    "__init__": [
      "self",
      "dim",
      "n_layers",
      "n_heads",
      "speaker_embedding_dim",
      "p_dropout",
      "kernel_size_conv_mod",
      "lrelu_slope"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "speaker_embedding",
      "encoding"
    ]
  },
  "ConformerBlock": {
    "__init__": [
      "self",
      "d_model",
      "n_head",
      "d_k",
      "d_v",
      "kernel_size_conv_mod",
      "speaker_embedding_dim",
      "dropout",
      "lrelu_slope"
    ],
    "forward": [
      "self",
      "x",
      "speaker_embedding",
      "mask",
      "slf_attn_mask",
      "encoding"
    ]
  },
  "ConformerConvModule": {
    "__init__": [
      "self",
      "d_model",
      "expansion_factor",
      "kernel_size",
      "dropout",
      "lrelu_slope"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConformerMultiHeadedSelfAttention": {
    "__init__": [
      "self",
      "d_model",
      "num_heads",
      "dropout_p"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "mask",
      "encoding"
    ]
  },
  "RelativeMultiHeadAttention": {
    "__init__": [
      "self",
      "d_model",
      "num_heads"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_embedding",
      "mask"
    ],
    "_relative_shift": [
      "self",
      "pos_score"
    ]
  },
  "VariancePredictor": {
    "__init__": [
      "self",
      "channels_in",
      "channels",
      "channels_out",
      "kernel_size",
      "p_dropout",
      "lrelu_slope"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "ConvNorm": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "w_init_gain",
      "use_weight_norm"
    ],
    "forward": [
      "self",
      "signal",
      "mask"
    ]
  },
  "ConvLSTMLinear": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "n_layers",
      "n_channels",
      "kernel_size",
      "p_dropout",
      "lstm_type",
      "use_linear"
    ],
    "run_padded_sequence": [
      "self",
      "context",
      "lens"
    ],
    "run_unsorted_inputs": [
      "self",
      "fn",
      "context",
      "lens"
    ],
    "forward": [
      "self",
      "context",
      "lens"
    ]
  },
  "DepthWiseConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PointwiseConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "stride",
      "padding",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BSConv1d": {
    "__init__": [
      "self",
      "channels_in",
      "channels_out",
      "kernel_size",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BSConv2d": {
    "__init__": [
      "self",
      "channels_in",
      "channels_out",
      "kernel_size",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Conv1dGLU": {
    "__init__": [
      "self",
      "d_model",
      "kernel_size",
      "padding",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "x",
      "embeddings"
    ]
  },
  "ConvTransposed": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthwiseConvModule": {
    "__init__": [
      "self",
      "dim",
      "kernel_size",
      "expansion",
      "lrelu_slope"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AddCoords": {
    "__init__": [
      "self",
      "rank",
      "with_r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CoordConv1d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "with_r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CoordConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "with_r"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PhonemeProsodyPredictor": {
    "__init__": [
      "self",
      "hidden_size",
      "kernel_size",
      "dropout",
      "bottleneck_size",
      "lrelu_slope"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "AcousticModel": {
    "__init__": [
      "self",
      "args",
      "tokenizer",
      "speaker_manager"
    ],
    "init_multispeaker": [
      "self",
      "args"
    ],
    "_set_cond_input": [
      "aux_input"
    ],
    "get_aux_input": [
      "self",
      "aux_input"
    ],
    "_set_speaker_input": [
      "self",
      "aux_input"
    ],
    "_init_speaker_embedding": [
      "self"
    ],
    "_init_d_vector": [
      "self"
    ],
    "generate_attn": [
      "dr",
      "x_mask",
      "y_mask"
    ],
    "_expand_encoder_with_durations": [
      "self",
      "o_en",
      "dr",
      "x_mask",
      "y_lengths"
    ],
    "_forward_aligner": [
      "self",
      "x",
      "y",
      "x_mask",
      "y_mask",
      "attn_priors"
    ],
    "average_utterance_prosody": [
      "self",
      "u_prosody_pred",
      "src_mask"
    ],
    "forward": [
      "self",
      "tokens",
      "src_lens",
      "mels",
      "mel_lens",
      "pitches",
      "energies",
      "attn_priors",
      "use_ground_truth",
      "d_vectors",
      "speaker_idx"
    ],
    "inference": [
      "self",
      "tokens",
      "speaker_idx",
      "p_control",
      "d_control",
      "d_vectors",
      "pitch_transform",
      "energy_transform"
    ]
  },
  "PitchAdaptor": {
    "__init__": [
      "self",
      "n_input",
      "n_hidden",
      "n_out",
      "kernel_size",
      "emb_kernel_size",
      "p_dropout",
      "lrelu_slope"
    ],
    "get_pitch_embedding_train": [
      "self",
      "x",
      "target",
      "dr",
      "mask"
    ],
    "get_pitch_embedding": [
      "self",
      "x",
      "mask",
      "pitch_transform",
      "pitch_mean",
      "pitch_std"
    ]
  },
  "get_mask_from_lengths": [
    "lengths"
  ],
  "stride_lens": [
    "lens",
    "stride"
  ],
  "UtteranceLevelProsodyEncoder": {
    "__init__": [
      "self",
      "num_mels",
      "ref_enc_filters",
      "ref_enc_size",
      "ref_enc_strides",
      "ref_enc_gru_size",
      "dropout",
      "n_hidden",
      "bottleneck_size_u",
      "token_num"
    ],
    "forward": [
      "self",
      "mels",
      "mel_lens"
    ]
  },
  "PhonemeLevelProsodyEncoder": {
    "__init__": [
      "self",
      "num_mels",
      "ref_enc_filters",
      "ref_enc_size",
      "ref_enc_strides",
      "ref_enc_gru_size",
      "dropout",
      "n_hidden",
      "n_heads",
      "bottleneck_size_p"
    ],
    "forward": [
      "self",
      "x",
      "src_mask",
      "mels",
      "mel_lens",
      "encoding"
    ]
  },
  "EnergyAdaptor": {
    "__init__": [
      "self",
      "channels_in",
      "channels_hidden",
      "channels_out",
      "kernel_size",
      "dropout",
      "lrelu_slope",
      "emb_kernel_size"
    ],
    "get_energy_embedding_train": [
      "self",
      "x",
      "target",
      "dr",
      "mask"
    ],
    "get_energy_embedding": [
      "self",
      "x",
      "mask",
      "energy_transform"
    ]
  },
  "initialize_embeddings": [
    "shape"
  ],
  "positional_encoding": [
    "d_model",
    "length",
    "device"
  ],
  "BottleneckLayer": {
    "__init__": [
      "self",
      "in_dim",
      "reduction_factor",
      "norm",
      "non_linearity",
      "kernel_size",
      "use_partial_padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLUActivation": {
    "__init__": [
      "self",
      "slope"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StyleEmbedAttention": {
    "__init__": [
      "self",
      "query_dim",
      "key_dim",
      "num_units",
      "num_heads"
    ],
    "forward": [
      "self",
      "query",
      "key_soft"
    ]
  },
  "EmbeddingPadded": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx"
    ],
    "forward": [
      "self",
      "idx"
    ]
  },
  "EmbeddingProjBlock": {
    "__init__": [
      "self",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LinearNorm": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "STL": {
    "__init__": [
      "self",
      "n_hidden",
      "token_num"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "squeeze": [
    "x",
    "x_mask",
    "num_sqz"
  ],
  "unsqueeze": [
    "x",
    "x_mask",
    "num_sqz"
  ],
  "RelativePositionMultiHeadAttention": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "num_heads",
      "rel_attn_window_size",
      "heads_share",
      "dropout_p",
      "input_length",
      "proximal_bias",
      "proximal_init"
    ],
    "forward": [
      "self",
      "x",
      "c",
      "attn_mask"
    ],
    "attention": [
      "self",
      "query",
      "key",
      "value",
      "mask"
    ],
    "_matmul_with_relative_values": [
      "p_attn",
      "re"
    ],
    "_matmul_with_relative_keys": [
      "query",
      "re"
    ],
    "_get_relative_embeddings": [
      "self",
      "relative_embeddings",
      "length"
    ],
    "_relative_position_to_absolute_position": [
      "x"
    ],
    "_absolute_position_to_relative_position": [
      "x"
    ],
    "_attn_proximity_bias": [
      "length"
    ]
  },
  "FeedForwardNetwork": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "kernel_size",
      "dropout_p",
      "causal"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ],
    "_causal_padding": [
      "self",
      "x"
    ],
    "_same_padding": [
      "self",
      "x"
    ],
    "_pad_shape": [
      "padding"
    ]
  },
  "RelativePositionTransformer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "hidden_channels_ffn",
      "num_heads",
      "num_layers",
      "kernel_size",
      "dropout_p",
      "rel_attn_window_size",
      "input_length",
      "layer_norm_type"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "ResidualConv1dLayerNormBlock": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "out_channels",
      "kernel_size",
      "num_layers",
      "dropout_p"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "InvConvNear": {
    "__init__": [
      "self",
      "channels",
      "num_splits",
      "no_jacobian"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse"
    ],
    "store_inverse": [
      "self"
    ]
  },
  "CouplingBlock": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "num_layers",
      "c_in_channels",
      "dropout_p",
      "sigmoid_scale"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse",
      "g"
    ],
    "store_inverse": [
      "self"
    ]
  },
  "NoiseScheduleVP": {
    "__init__": [
      "self",
      "schedule",
      "betas",
      "alphas_cumprod",
      "continuous_beta_0",
      "continuous_beta_1",
      "dtype"
    ],
    "marginal_log_mean_coeff": [
      "self",
      "t"
    ],
    "marginal_alpha": [
      "self",
      "t"
    ],
    "marginal_std": [
      "self",
      "t"
    ],
    "marginal_lambda": [
      "self",
      "t"
    ],
    "inverse_lambda": [
      "self",
      "lamb"
    ]
  },
  "model_wrapper": [
    "model",
    "noise_schedule",
    "model_type",
    "model_kwargs",
    "guidance_type",
    "condition",
    "unconditional_condition",
    "guidance_scale",
    "classifier_fn",
    "classifier_kwargs"
  ],
  "DPM_Solver": {
    "__init__": [
      "self",
      "model_fn",
      "noise_schedule",
      "algorithm_type",
      "correcting_x0_fn",
      "correcting_xt_fn",
      "thresholding_max_val",
      "dynamic_thresholding_ratio"
    ],
    "dynamic_thresholding_fn": [
      "self",
      "x0",
      "t"
    ],
    "noise_prediction_fn": [
      "self",
      "x",
      "t"
    ],
    "data_prediction_fn": [
      "self",
      "x",
      "t"
    ],
    "model_fn": [
      "self",
      "x",
      "t"
    ],
    "get_time_steps": [
      "self",
      "skip_type",
      "t_T",
      "t_0",
      "N",
      "device"
    ],
    "get_orders_and_timesteps_for_singlestep_solver": [
      "self",
      "steps",
      "order",
      "skip_type",
      "t_T",
      "t_0",
      "device"
    ],
    "denoise_to_zero_fn": [
      "self",
      "x",
      "s"
    ],
    "dpm_solver_first_update": [
      "self",
      "x",
      "s",
      "t",
      "model_s",
      "return_intermediate"
    ],
    "singlestep_dpm_solver_second_update": [
      "self",
      "x",
      "s",
      "t",
      "r1",
      "model_s",
      "return_intermediate",
      "solver_type"
    ],
    "singlestep_dpm_solver_third_update": [
      "self",
      "x",
      "s",
      "t",
      "r1",
      "r2",
      "model_s",
      "model_s1",
      "return_intermediate",
      "solver_type"
    ],
    "multistep_dpm_solver_second_update": [
      "self",
      "x",
      "model_prev_list",
      "t_prev_list",
      "t",
      "solver_type"
    ],
    "multistep_dpm_solver_third_update": [
      "self",
      "x",
      "model_prev_list",
      "t_prev_list",
      "t",
      "solver_type"
    ],
    "singlestep_dpm_solver_update": [
      "self",
      "x",
      "s",
      "t",
      "order",
      "return_intermediate",
      "solver_type",
      "r1",
      "r2"
    ],
    "multistep_dpm_solver_update": [
      "self",
      "x",
      "model_prev_list",
      "t_prev_list",
      "t",
      "order",
      "solver_type"
    ],
    "dpm_solver_adaptive": [
      "self",
      "x",
      "order",
      "t_T",
      "t_0",
      "h_init",
      "atol",
      "rtol",
      "theta",
      "t_err",
      "solver_type"
    ],
    "add_noise": [
      "self",
      "x",
      "t",
      "noise"
    ],
    "inverse": [
      "self",
      "x",
      "steps",
      "t_start",
      "t_end",
      "order",
      "skip_type",
      "method",
      "lower_order_final",
      "denoise_to_zero",
      "solver_type",
      "atol",
      "rtol",
      "return_intermediate"
    ],
    "sample": [
      "self",
      "x",
      "steps",
      "t_start",
      "t_end",
      "order",
      "skip_type",
      "method",
      "lower_order_final",
      "denoise_to_zero",
      "solver_type",
      "atol",
      "rtol",
      "return_intermediate"
    ]
  },
  "interpolate_fn": [
    "x",
    "xp",
    "yp"
  ],
  "expand_dims": [
    "v",
    "dims"
  ],
  "QKVAttentionLegacy": {
    "__init__": [
      "self",
      "n_heads"
    ],
    "forward": [
      "self",
      "qkv",
      "mask",
      "rel_pos"
    ]
  },
  "Downsample": {
    "__init__": [
      "self",
      "channels",
      "use_conv",
      "out_channels",
      "factor",
      "ksize",
      "pad"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AudioMiniEncoder": {
    "__init__": [
      "self",
      "spec_dim",
      "embedding_dim",
      "base_channels",
      "depth",
      "resnet_blocks",
      "attn_blocks",
      "num_attn_heads",
      "dropout",
      "downsample_factor",
      "kernel_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DEFAULT_MEL_NORM_FILE": [],
  "TorchMelSpectrogram": {
    "__init__": [
      "self",
      "filter_length",
      "hop_length",
      "win_length",
      "n_mel_channels",
      "mel_fmin",
      "mel_fmax",
      "sampling_rate",
      "normalize",
      "mel_norm_file"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "CheckpointedLayer": {
    "__init__": [
      "self",
      "wrap"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CheckpointedXTransformerEncoder": {
    "__init__": [
      "self",
      "needs_permute",
      "exit_permute",
      "checkpoint"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TypicalLogitsWarper": {
    "__init__": [
      "self",
      "mass",
      "filter_value",
      "min_tokens_to_keep"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "max_alignment": [
    "s1",
    "s2",
    "skip_character",
    "record"
  ],
  "Wav2VecAlignment": {
    "__init__": [
      "self",
      "device"
    ],
    "align": [
      "self",
      "audio",
      "expected_text",
      "audio_sample_rate"
    ],
    "redact": [
      "self",
      "audio",
      "expected_text",
      "audio_sample_rate"
    ]
  },
  "is_latent": [
    "t"
  ],
  "is_sequence": [
    "t"
  ],
  "timestep_embedding": [
    "timesteps",
    "dim",
    "max_period"
  ],
  "TimestepBlock": {
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "TimestepEmbedSequential": {
    "forward": [
      "self",
      "x",
      "emb"
    ]
  },
  "DiffusionLayer": {
    "__init__": [
      "self",
      "model_channels",
      "dropout",
      "num_heads"
    ],
    "forward": [
      "self",
      "x",
      "time_emb"
    ]
  },
  "DiffusionTts": {
    "__init__": [
      "self",
      "model_channels",
      "num_layers",
      "in_channels",
      "in_latent_channels",
      "in_tokens",
      "out_channels",
      "dropout",
      "use_fp16",
      "num_heads",
      "layer_drop",
      "unconditioned_percentage"
    ],
    "get_grad_norm_parameter_groups": [
      "self"
    ],
    "get_conditioning": [
      "self",
      "conditioning_input"
    ],
    "timestep_independent": [
      "self",
      "aligned_conditioning",
      "conditioning_latent",
      "expected_seq_len",
      "return_code_pred"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "aligned_conditioning",
      "conditioning_latent",
      "precomputed_aligned_embeddings",
      "conditioning_free",
      "return_code_pred"
    ]
  },
  "DEFAULT_MODELS_DIR": [],
  "MODELS_DIR": [],
  "MODELS": [],
  "download_models": [
    "specific_models"
  ],
  "get_model_path": [
    "model_name",
    "models_dir"
  ],
  "AudioMiniEncoderWithClassifierHead": {
    "__init__": [
      "self",
      "classes",
      "distribute_zero_label"
    ],
    "forward": [
      "self",
      "x",
      "labels"
    ]
  },
  "fused_leaky_relu": [
    "input",
    "bias",
    "negative_slope",
    "scale"
  ],
  "EqualLinear": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "bias",
      "bias_init",
      "lr_mul"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "RandomLatentConverter": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "ref"
    ]
  },
  "DEFAULT_DIM_HEAD": [],
  "Intermediates": [],
  "LayerIntermediates": [],
  "cast_tuple": [
    "val",
    "depth"
  ],
  "always": {
    "__init__": [
      "self",
      "val"
    ],
    "__call__": [
      "self"
    ]
  },
  "not_equals": {
    "__init__": [
      "self",
      "val"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "equals": {
    "__init__": [
      "self",
      "val"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "max_neg_value": [
    "tensor"
  ],
  "l2norm": [
    "t"
  ],
  "init_zero_": [
    "layer"
  ],
  "pick_and_pop": [
    "keys",
    "d"
  ],
  "group_dict_by_key": [
    "cond",
    "d"
  ],
  "string_begins_with": [
    "prefix",
    "str"
  ],
  "group_by_key_prefix": [
    "prefix",
    "d"
  ],
  "groupby_prefix_and_trim": [
    "prefix",
    "d"
  ],
  "ReluSquared": {
    "forward": [
      "self",
      "x"
    ]
  },
  "AbsolutePositionalEmbedding": {
    "__init__": [
      "self",
      "dim",
      "max_seq_len"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FixedPositionalEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x",
      "seq_dim",
      "offset"
    ]
  },
  "RelativePositionBias": {
    "__init__": [
      "self",
      "scale",
      "causal",
      "num_buckets",
      "max_distance",
      "heads"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "causal",
      "num_buckets",
      "max_distance"
    ],
    "forward": [
      "self",
      "qk_dots"
    ]
  },
  "AlibiPositionalBias": {
    "__init__": [
      "self",
      "heads"
    ],
    "_get_slopes": [
      "heads"
    ],
    "forward": [
      "self",
      "qk_dots"
    ]
  },
  "LearnedAlibiPositionalBias": {
    "__init__": [
      "self",
      "heads",
      "bidirectional"
    ],
    "forward": [
      "self",
      "qk_dots"
    ]
  },
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "max_seq_len",
      "device"
    ]
  },
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb": [
    "t",
    "freqs"
  ],
  "Scale": {
    "__init__": [
      "self",
      "value",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Rezero": {
    "__init__": [
      "self",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ScaleNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RMSScaleShiftNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "norm_scale_shift_inp"
    ]
  },
  "Residual": {
    "__init__": [
      "self",
      "dim",
      "scale_residual"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "GRUGating": {
    "__init__": [
      "self",
      "dim",
      "scale_residual"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ]
  },
  "shift": [
    "t",
    "amount",
    "mask"
  ],
  "ShiftTokens": {
    "__init__": [
      "self",
      "shifts",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLU": {
    "__init__": [
      "self",
      "dim_in",
      "dim_out",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttentionLayers": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "heads",
      "causal",
      "cross_attend",
      "only_cross",
      "use_scalenorm",
      "use_rms_scaleshift_norm",
      "use_rmsnorm",
      "use_rezero",
      "alibi_pos_bias",
      "alibi_num_heads",
      "alibi_learned",
      "position_infused_attn",
      "rotary_pos_emb",
      "rotary_emb_dim",
      "custom_layers",
      "sandwich_coef",
      "par_ratio",
      "residual_attn",
      "cross_residual_attn",
      "macaron",
      "pre_norm",
      "gate_residual",
      "scale_residual",
      "shift_tokens",
      "sandwich_norm",
      "use_qk_norm_attn",
      "qk_norm_attn_seq_len",
      "zero_init_branch_output"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "full_context",
      "mask",
      "context_mask",
      "attn_mask",
      "mems",
      "return_hiddens",
      "norm_scale_shift_inp",
      "past_key_values",
      "expected_seq_len"
    ]
  },
  "CrossAttender": {
    "__init__": [
      "self"
    ]
  },
  "ViTransformerWrapper": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "img",
      "return_embeddings"
    ]
  },
  "TransformerWrapper": {
    "__init__": [
      "self"
    ],
    "init_": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "return_embeddings",
      "mask",
      "return_hiddens",
      "return_attn",
      "mems",
      "use_cache"
    ]
  },
  "ContinuousTransformerWrapper": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "return_embeddings",
      "mask",
      "return_attn",
      "mems",
      "use_cache"
    ]
  },
  "load_wav_to_torch": [
    "full_path"
  ],
  "check_audio": [
    "audio",
    "audiopath"
  ],
  "read_audio_file": [
    "audiopath"
  ],
  "load_required_audio": [
    "audiopath"
  ],
  "load_audio": [
    "audiopath",
    "sampling_rate"
  ],
  "TACOTRON_MEL_MAX": [],
  "TACOTRON_MEL_MIN": [],
  "denormalize_tacotron_mel": [
    "norm_mel"
  ],
  "normalize_tacotron_mel": [
    "mel"
  ],
  "dynamic_range_compression": [
    "x",
    "C",
    "clip_val"
  ],
  "dynamic_range_decompression": [
    "x",
    "C"
  ],
  "load_voices": [
    "voices",
    "extra_voice_dirs"
  ],
  "wav_to_univnet_mel": [
    "wav",
    "do_normalization",
    "device"
  ],
  "stable_softmax": [
    "t",
    "dim",
    "alpha"
  ],
  "route_args": [
    "router",
    "args",
    "depth"
  ],
  "SequentialSequence": {
    "__init__": [
      "self",
      "layers",
      "args_route",
      "layer_dropout"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DivideMax": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerScale": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "fn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PreNorm": {
    "__init__": [
      "self",
      "dim",
      "fn",
      "sandwich"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Transformer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_p": [
    "t"
  ],
  "MelEncoder": {
    "__init__": [
      "self",
      "channels",
      "mel_channels",
      "resblocks_per_reduction"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UnifiedVoice": {
    "__init__": [
      "self",
      "layers",
      "model_dim",
      "heads",
      "max_text_tokens",
      "max_mel_tokens",
      "max_conditioning_inputs",
      "mel_length_compression",
      "number_text_tokens",
      "start_text_token",
      "number_mel_codes",
      "start_mel_token",
      "stop_mel_token",
      "train_solo_embeddings",
      "use_mel_codes_as_input",
      "checkpointing",
      "types"
    ],
    "post_init_gpt2_config": [
      "self",
      "kv_cache"
    ],
    "build_aligned_inputs_and_targets": [
      "self",
      "input",
      "start_token",
      "stop_token"
    ],
    "set_mel_padding": [
      "self",
      "mel_input_tokens",
      "wav_lengths"
    ],
    "get_logits": [
      "self",
      "speech_conditioning_inputs",
      "first_inputs",
      "first_head",
      "second_inputs",
      "second_head",
      "get_attns",
      "return_latent"
    ],
    "get_conditioning": [
      "self",
      "speech_conditioning_input"
    ],
    "forward": [
      "self",
      "speech_conditioning_latent",
      "text_inputs",
      "text_lengths",
      "mel_codes",
      "wav_lengths",
      "types",
      "text_first",
      "raw_mels",
      "return_attentions",
      "return_latent",
      "clip_inputs"
    ],
    "inference_speech": [
      "self",
      "speech_conditioning_latent",
      "text_inputs",
      "input_tokens",
      "num_return_sequences",
      "max_generate_length",
      "typical_sampling",
      "typical_mass"
    ]
  },
  "MAX_WAV_VALUE": [],
  "UnivNetGenerator": {
    "__init__": [
      "self",
      "noise_dim",
      "channel_size",
      "dilations",
      "strides",
      "lReLU_slope",
      "kpnet_conv_size",
      "hop_length",
      "n_mel_channels"
    ],
    "forward": [
      "self",
      "c",
      "z"
    ],
    "eval": [
      "self",
      "inference"
    ],
    "remove_weight_norm": [
      "self"
    ],
    "inference": [
      "self",
      "c",
      "z"
    ]
  },
  "VocType": {
    "optionally_index": [
      "self",
      "model_dict"
    ]
  },
  "VocConf": {
    "Univnet": []
  },
  "masked_mean": [
    "t",
    "mask",
    "dim"
  ],
  "CLVP": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "text",
      "speech_tokens",
      "return_loss"
    ]
  },
  "SAMPLERS": [],
  "normal_kl": [
    "mean1",
    "logvar1",
    "mean2",
    "logvar2"
  ],
  "approx_standard_normal_cdf": [
    "x"
  ],
  "discretized_gaussian_log_likelihood": [
    "x"
  ],
  "mean_flat": [
    "tensor"
  ],
  "get_named_beta_schedule": [
    "schedule_name",
    "num_diffusion_timesteps"
  ],
  "betas_for_alpha_bar": [
    "num_diffusion_timesteps",
    "alpha_bar",
    "max_beta"
  ],
  "ModelMeanType": {
    "PREVIOUS_X": [],
    "START_X": [],
    "EPSILON": []
  },
  "ModelVarType": {
    "LEARNED": [],
    "FIXED_SMALL": [],
    "FIXED_LARGE": [],
    "LEARNED_RANGE": []
  },
  "LossType": {
    "MSE": [],
    "RESCALED_MSE": [],
    "KL": [],
    "RESCALED_KL": [],
    "is_vb": [
      "self"
    ]
  },
  "GaussianDiffusion": {
    "__init__": [
      "self"
    ],
    "q_mean_variance": [
      "self",
      "x_start",
      "t"
    ],
    "q_sample": [
      "self",
      "x_start",
      "t",
      "noise"
    ],
    "q_posterior_mean_variance": [
      "self",
      "x_start",
      "x_t",
      "t"
    ],
    "p_mean_variance": [
      "self",
      "model",
      "x",
      "t",
      "clip_denoised",
      "denoised_fn",
      "model_kwargs"
    ],
    "_predict_xstart_from_eps": [
      "self",
      "x_t",
      "t",
      "eps"
    ],
    "_predict_xstart_from_xprev": [
      "self",
      "x_t",
      "t",
      "xprev"
    ],
    "_predict_eps_from_xstart": [
      "self",
      "x_t",
      "t",
      "pred_xstart"
    ],
    "_scale_timesteps": [
      "self",
      "t"
    ],
    "condition_mean": [
      "self",
      "cond_fn",
      "p_mean_var",
      "x",
      "t",
      "model_kwargs"
    ],
    "condition_score": [
      "self",
      "cond_fn",
      "p_mean_var",
      "x",
      "t",
      "model_kwargs"
    ],
    "k_diffusion_sample_loop": [
      "self",
      "k_sampler",
      "pbar",
      "model",
      "shape",
      "noise",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "device",
      "model_kwargs",
      "progress"
    ],
    "sample_loop": [
      "self"
    ],
    "p_sample": [
      "self",
      "model",
      "x",
      "t",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "model_kwargs"
    ],
    "p_sample_loop": [
      "self",
      "model",
      "shape",
      "noise",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "model_kwargs",
      "device",
      "progress"
    ],
    "p_sample_loop_progressive": [
      "self",
      "model",
      "shape",
      "noise",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "model_kwargs",
      "device",
      "progress"
    ],
    "ddim_sample": [
      "self",
      "model",
      "x",
      "t",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "model_kwargs",
      "eta"
    ],
    "ddim_reverse_sample": [
      "self",
      "model",
      "x",
      "t",
      "clip_denoised",
      "denoised_fn",
      "model_kwargs",
      "eta"
    ],
    "ddim_sample_loop": [
      "self",
      "model",
      "shape",
      "noise",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "model_kwargs",
      "device",
      "progress",
      "eta"
    ],
    "ddim_sample_loop_progressive": [
      "self",
      "model",
      "shape",
      "noise",
      "clip_denoised",
      "denoised_fn",
      "cond_fn",
      "model_kwargs",
      "device",
      "progress",
      "eta"
    ],
    "_vb_terms_bpd": [
      "self",
      "model",
      "x_start",
      "x_t",
      "t",
      "clip_denoised",
      "model_kwargs"
    ],
    "training_losses": [
      "self",
      "model",
      "x_start",
      "t",
      "model_kwargs",
      "noise"
    ],
    "autoregressive_training_losses": [
      "self",
      "model",
      "x_start",
      "t",
      "model_output_keys",
      "gd_out_key",
      "model_kwargs",
      "noise"
    ],
    "_prior_bpd": [
      "self",
      "x_start"
    ],
    "calc_bpd_loop": [
      "self",
      "model",
      "x_start",
      "clip_denoised",
      "model_kwargs"
    ]
  },
  "SpacedDiffusion": {
    "__init__": [
      "self",
      "use_timesteps"
    ],
    "p_mean_variance": [
      "self",
      "model"
    ],
    "training_losses": [
      "self",
      "model"
    ],
    "autoregressive_training_losses": [
      "self",
      "model"
    ],
    "condition_mean": [
      "self",
      "cond_fn"
    ],
    "condition_score": [
      "self",
      "cond_fn"
    ],
    "_wrap_model": [
      "self",
      "model",
      "autoregressive"
    ],
    "_scale_timesteps": [
      "self",
      "t"
    ]
  },
  "space_timesteps": [
    "num_timesteps",
    "section_counts"
  ],
  "_WrappedModel": {
    "__init__": [
      "self",
      "model",
      "timestep_map",
      "rescale_timesteps",
      "original_num_steps"
    ],
    "__call__": [
      "self",
      "x",
      "ts"
    ]
  },
  "_WrappedAutoregressiveModel": {
    "__init__": [
      "self",
      "model",
      "timestep_map",
      "rescale_timesteps",
      "original_num_steps"
    ],
    "__call__": [
      "self",
      "x",
      "x0",
      "ts"
    ]
  },
  "_extract_into_tensor": [
    "arr",
    "timesteps",
    "broadcast_shape"
  ],
  "MDNBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DEFAULT_MIN_BIN_WIDTH": [],
  "DEFAULT_MIN_BIN_HEIGHT": [],
  "DEFAULT_MIN_DERIVATIVE": [],
  "piecewise_rational_quadratic_transform": [
    "inputs",
    "unnormalized_widths",
    "unnormalized_heights",
    "unnormalized_derivatives",
    "inverse",
    "tails",
    "tail_bound",
    "min_bin_width",
    "min_bin_height",
    "min_derivative"
  ],
  "searchsorted": [
    "bin_locations",
    "inputs",
    "eps"
  ],
  "unconstrained_rational_quadratic_spline": [
    "inputs",
    "unnormalized_widths",
    "unnormalized_heights",
    "unnormalized_derivatives",
    "inverse",
    "tails",
    "tail_bound",
    "min_bin_width",
    "min_bin_height",
    "min_derivative"
  ],
  "rational_quadratic_spline": [
    "inputs",
    "unnormalized_widths",
    "unnormalized_heights",
    "unnormalized_derivatives",
    "inverse",
    "left",
    "right",
    "bottom",
    "top",
    "min_bin_width",
    "min_bin_height",
    "min_derivative"
  ],
  "DilatedDepthSeparableConv": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "num_layers",
      "dropout_p"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "ElementwiseAffine": {
    "__init__": [
      "self",
      "channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse"
    ]
  },
  "ConvFlow": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "kernel_size",
      "num_layers",
      "num_bins",
      "tail_bound"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "StochasticDurationPredictor": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "kernel_size",
      "dropout_p",
      "num_flows",
      "cond_channels",
      "language_emb_dim"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "dr",
      "g",
      "lang_emb",
      "reverse",
      "noise_scale"
    ]
  },
  "init_weights": [
    "m",
    "mean",
    "std"
  ],
  "TextEncoder": {
    "__init__": [
      "self",
      "n_vocab",
      "out_channels",
      "hidden_channels",
      "hidden_channels_ffn",
      "num_heads",
      "num_layers",
      "kernel_size",
      "dropout_p",
      "language_emb_dim"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "lang_emb"
    ]
  },
  "ResidualCouplingBlock": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "num_layers",
      "dropout_p",
      "cond_channels",
      "mean_only"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "ResidualCouplingBlocks": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "num_layers",
      "num_flows",
      "cond_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "PosteriorEncoder": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "num_layers",
      "cond_channels"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "g"
    ]
  },
  "VitsDiscriminator": {
    "__init__": [
      "self",
      "periods",
      "use_spectral_norm"
    ],
    "forward": [
      "self",
      "x",
      "x_hat"
    ]
  },
  "FastSpeechConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "XttsConfig": {},
  "BarkConfig": {
    "REMOTE_BASE_URL": [],
    "__post_init__": [
      "self"
    ]
  },
  "SpeedySpeechConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "Tacotron2Config": {},
  "Fastspeech2Config": {
    "__post_init__": [
      "self"
    ]
  },
  "AlignTTSConfig": {},
  "FastPitchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "VitsConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "NeuralhmmTTSConfig": {
    "check_values": [
      "self"
    ]
  },
  "TortoiseConfig": {},
  "TacotronConfig": {
    "check_values": [
      "self"
    ]
  },
  "GlowTTSConfig": {},
  "OverflowConfig": {
    "check_values": [
      "self"
    ]
  },
  "DelightfulTTSConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GSTConfig": {
    "check_values": [
      "self"
    ]
  },
  "CapacitronVAEConfig": {
    "check_values": [
      "self"
    ]
  },
  "CharactersConfig": {},
  "BaseTTSConfig": {},
  "pad": [
    "input_ele",
    "max_len"
  ],
  "hann_window": [],
  "mel_basis": [],
  "weights_reset": [
    "m"
  ],
  "get_module_weights_sum": [
    "mdl"
  ],
  "_amp_to_db": [
    "x",
    "C",
    "clip_val"
  ],
  "_db_to_amp": [
    "x",
    "C"
  ],
  "amp_to_db": [
    "magnitudes"
  ],
  "db_to_amp": [
    "magnitudes"
  ],
  "_wav_to_spec": [
    "y",
    "n_fft",
    "hop_length",
    "win_length",
    "center"
  ],
  "wav_to_spec": [
    "y",
    "n_fft",
    "hop_length",
    "win_length",
    "center"
  ],
  "wav_to_energy": [
    "y",
    "n_fft",
    "hop_length",
    "win_length",
    "center"
  ],
  "name_mel_basis": [
    "spec",
    "n_fft",
    "fmax"
  ],
  "spec_to_mel": [
    "spec",
    "n_fft",
    "num_mels",
    "sample_rate",
    "fmin",
    "fmax"
  ],
  "wav_to_mel": [
    "y",
    "n_fft",
    "num_mels",
    "sample_rate",
    "hop_length",
    "win_length",
    "fmin",
    "fmax",
    "center"
  ],
  "get_attribute_balancer_weights": [
    "items",
    "attr_name",
    "multi_dict"
  ],
  "ForwardTTSE2eF0Dataset": {
    "__init__": [
      "self",
      "ap",
      "samples",
      "verbose",
      "cache_path",
      "precompute_num_workers",
      "normalize_f0"
    ],
    "_compute_and_save_pitch": [
      "self",
      "wav_file",
      "pitch_file"
    ],
    "compute_or_load": [
      "self",
      "wav_file",
      "audio_name"
    ]
  },
  "ForwardTTSE2eDataset": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "load_or_compute_attn_prior": [
      "self",
      "token_ids",
      "wav",
      "rel_wav_path"
    ],
    "lengths": [
      "self"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "VocoderConfig": {},
  "DelightfulTtsAudioConfig": {},
  "DelightfulTtsArgs": {
    "ref_enc_filters_reference_encoder": [],
    "ref_enc_strides_reference_encoder": [],
    "ref_enc_pad_reference_encoder": []
  },
  "DelightfulTTS": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "device": [
      "self"
    ],
    "energy_scaler": [
      "self"
    ],
    "length_scale": [
      "self",
      "value"
    ],
    "pitch_mean": [
      "self",
      "value"
    ],
    "pitch_std": [
      "self",
      "value"
    ],
    "mel_basis": [
      "self"
    ],
    "init_for_training": [
      "self"
    ],
    "init_multispeaker": [
      "self",
      "config"
    ],
    "_init_speaker_embedding": [
      "self"
    ],
    "_init_d_vector": [
      "self"
    ],
    "_freeze_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "spec_lengths",
      "spec",
      "waveform",
      "pitch",
      "energy",
      "attn_priors",
      "d_vectors",
      "speaker_idx"
    ],
    "inference": [
      "self",
      "x",
      "aux_input",
      "pitch_transform",
      "energy_transform"
    ],
    "inference_spec_decoder": [
      "self",
      "x",
      "aux_input"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion",
      "optimizer_idx"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion",
      "optimizer_idx"
    ],
    "_log": [
      "self",
      "batch",
      "outputs",
      "name_prefix"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "get_aux_input_from_test_sentences": [
      "self",
      "sentence_info"
    ],
    "plot_outputs": [
      "self",
      "text",
      "wav",
      "alignment",
      "outputs"
    ],
    "synthesize": [
      "self",
      "text",
      "speaker_id",
      "d_vector",
      "pitch_transform"
    ],
    "synthesize_with_gl": [
      "self",
      "text",
      "speaker_id",
      "d_vector"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "format_batch": [
      "self",
      "batch"
    ],
    "format_batch_on_device": [
      "self",
      "batch"
    ],
    "get_sampler": [
      "self",
      "config",
      "dataset",
      "num_gpus"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus",
      "rank"
    ],
    "get_criterion": [
      "self"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "on_epoch_end": [
      "self",
      "trainer"
    ],
    "init_from_config": [
      "config",
      "samples",
      "verbose"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval"
    ],
    "get_state_dict": [
      "self"
    ],
    "save": [
      "self",
      "config",
      "checkpoint_path"
    ],
    "on_train_step_start": [
      "self",
      "trainer"
    ]
  },
  "DelightfulTTSLoss": {
    "__init__": [
      "self",
      "config"
    ],
    "_binary_alignment_loss": [
      "alignment_hard",
      "alignment_soft"
    ],
    "feature_loss": [
      "feats_real",
      "feats_generated"
    ],
    "generator_loss": [
      "scores_fake"
    ],
    "forward": [
      "self",
      "mel_output",
      "mel_target",
      "mel_lens",
      "dur_output",
      "dur_target",
      "pitch_output",
      "pitch_target",
      "energy_output",
      "energy_target",
      "src_lens",
      "waveform",
      "waveform_hat",
      "p_prosody_ref",
      "p_prosody_pred",
      "u_prosody_ref",
      "u_prosody_pred",
      "aligner_logprob",
      "aligner_hard",
      "aligner_soft",
      "binary_loss_weight",
      "feats_fake",
      "feats_real",
      "scores_fake",
      "spec_slice",
      "spec_slice_hat",
      "skip_disc"
    ]
  },
  "pad_or_truncate": [
    "t",
    "length"
  ],
  "deterministic_state": [
    "seed"
  ],
  "load_discrete_vocoder_diffuser": [
    "trained_diffusion_steps",
    "desired_diffusion_steps",
    "cond_free",
    "cond_free_k",
    "sampler"
  ],
  "format_conditioning": [
    "clip",
    "cond_length",
    "device"
  ],
  "fix_autoregressive_output": [
    "codes",
    "stop_token",
    "complain"
  ],
  "do_spectrogram_diffusion": [
    "diffusion_model",
    "diffuser",
    "latents",
    "conditioning_latents",
    "temperature",
    "verbose"
  ],
  "classify_audio_clip": [
    "clip",
    "model_dir"
  ],
  "pick_best_batch_size_for_gpu": [],
  "TortoiseAudioConfig": {},
  "TortoiseArgs": {},
  "Tortoise": {
    "__init__": [
      "self",
      "config"
    ],
    "temporary_cuda": [
      "self",
      "model"
    ],
    "get_conditioning_latents": [
      "self",
      "voice_samples",
      "return_mels",
      "latent_averaging_mode",
      "original_tortoise"
    ],
    "get_random_conditioning_latents": [
      "self"
    ],
    "synthesize": [
      "self",
      "text",
      "config",
      "speaker_id",
      "voice_dirs"
    ],
    "inference_with_config": [
      "self",
      "text",
      "config"
    ],
    "inference": [
      "self",
      "text",
      "voice_samples",
      "conditioning_latents",
      "k",
      "verbose",
      "use_deterministic_seed",
      "return_deterministic_state",
      "latent_averaging_mode",
      "num_autoregressive_samples",
      "temperature",
      "length_penalty",
      "repetition_penalty",
      "top_p",
      "max_mel_tokens",
      "diffusion_iterations",
      "cond_free",
      "cond_free_k",
      "diffusion_temperature",
      "sampler",
      "half",
      "original_tortoise"
    ],
    "forward": [
      "self"
    ],
    "eval_step": [
      "self"
    ],
    "init_from_config": [
      "config"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_dir",
      "ar_checkpoint_path",
      "diff_checkpoint_path",
      "clvp_checkpoint_path",
      "vocoder_checkpoint_path",
      "eval",
      "strict"
    ],
    "train_step": [
      "self"
    ]
  },
  "BarkAudioConfig": {},
  "Bark": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "device": [
      "self"
    ],
    "load_bark_models": [
      "self"
    ],
    "train_step": [
      "self"
    ],
    "text_to_semantic": [
      "self",
      "text",
      "history_prompt",
      "temp",
      "base",
      "allow_early_stop"
    ],
    "semantic_to_waveform": [
      "self",
      "semantic_tokens",
      "history_prompt",
      "temp",
      "base"
    ],
    "generate_audio": [
      "self",
      "text",
      "history_prompt",
      "text_temp",
      "waveform_temp",
      "base",
      "allow_early_stop"
    ],
    "generate_voice": [
      "self",
      "audio",
      "speaker_id",
      "voice_dir"
    ],
    "_set_voice_dirs": [
      "self",
      "voice_dirs"
    ],
    "synthesize": [
      "self",
      "text",
      "config",
      "speaker_id",
      "voice_dirs"
    ],
    "eval_step": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "inference": [
      "self"
    ],
    "init_from_config": [
      "config"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_dir",
      "text_model_path",
      "coarse_model_path",
      "fine_model_path",
      "hubert_model_path",
      "hubert_tokenizer_path",
      "eval",
      "strict"
    ]
  },
  "BaseTacotron": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "_format_aux_input": [
      "aux_input"
    ],
    "_init_backward_decoder": [
      "self"
    ],
    "_init_coarse_decoder": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "inference": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ],
    "get_criterion": [
      "self"
    ],
    "init_from_config": [
      "config"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "compute_masks": [
      "self",
      "text_lengths",
      "mel_lengths"
    ],
    "_backward_pass": [
      "self",
      "mel_specs",
      "encoder_outputs",
      "mask"
    ],
    "_coarse_decoder_pass": [
      "self",
      "mel_specs",
      "encoder_outputs",
      "alignments",
      "input_mask"
    ],
    "compute_gst": [
      "self",
      "inputs",
      "style_input",
      "speaker_embedding"
    ],
    "compute_capacitron_VAE_embedding": [
      "self",
      "inputs",
      "reference_mel_info",
      "text_info",
      "speaker_embedding"
    ],
    "_add_speaker_embedding": [
      "outputs",
      "embedded_speakers"
    ],
    "_concat_speaker_embedding": [
      "outputs",
      "embedded_speakers"
    ],
    "on_epoch_start": [
      "self",
      "trainer"
    ]
  },
  "NeuralhmmTTS": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "update_mean_std": [
      "self",
      "statistics_dict"
    ],
    "preprocess_batch": [
      "self",
      "text",
      "text_len",
      "mels",
      "mel_len"
    ],
    "normalize": [
      "self",
      "x"
    ],
    "inverse_normalize": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "text",
      "text_len",
      "mels",
      "mel_len"
    ],
    "_training_stats": [
      "batch"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "_format_aux_input": [
      "self",
      "aux_input",
      "default_input_dict"
    ],
    "inference": [
      "self",
      "text",
      "aux_input"
    ],
    "get_criterion": [],
    "init_from_config": [
      "config",
      "samples",
      "verbose"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "strict",
      "cache"
    ],
    "on_init_start": [
      "self",
      "trainer"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ]
  },
  "NLLLoss": {
    "forward": [
      "self",
      "log_prob"
    ]
  },
  "Overflow": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "update_mean_std": [
      "self",
      "statistics_dict"
    ],
    "preprocess_batch": [
      "self",
      "text",
      "text_len",
      "mels",
      "mel_len"
    ],
    "normalize": [
      "self",
      "x"
    ],
    "inverse_normalize": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "text",
      "text_len",
      "mels",
      "mel_len"
    ],
    "_training_stats": [
      "batch"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "_format_aux_input": [
      "self",
      "aux_input",
      "default_input_dict"
    ],
    "inference": [
      "self",
      "text",
      "aux_input"
    ],
    "get_criterion": [],
    "init_from_config": [
      "config",
      "samples",
      "verbose"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "strict",
      "cache"
    ],
    "on_init_start": [
      "self",
      "trainer"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ]
  },
  "GlowTTS": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "init_multispeaker": [
      "self",
      "config"
    ],
    "compute_outputs": [
      "attn",
      "o_mean",
      "o_log_scale",
      "x_mask"
    ],
    "unlock_act_norm_layers": [
      "self"
    ],
    "lock_act_norm_layers": [
      "self"
    ],
    "_set_speaker_input": [
      "self",
      "aux_input"
    ],
    "_speaker_embedding": [
      "self",
      "aux_input"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "y",
      "y_lengths",
      "aux_input"
    ],
    "inference_with_MAS": [
      "self",
      "x",
      "x_lengths",
      "y",
      "y_lengths",
      "aux_input"
    ],
    "decoder_inference": [
      "self",
      "y",
      "y_lengths",
      "aux_input"
    ],
    "inference": [
      "self",
      "x",
      "aux_input"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "preprocess": [
      "self",
      "y",
      "y_lengths",
      "y_max_length",
      "attn"
    ],
    "store_inverse": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval"
    ],
    "get_criterion": [],
    "on_train_step_start": [
      "self",
      "trainer"
    ],
    "init_from_config": [
      "config",
      "samples",
      "verbose"
    ]
  },
  "Tacotron": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "forward": [
      "self",
      "text",
      "text_lengths",
      "mel_specs",
      "mel_lengths",
      "aux_input"
    ],
    "inference": [
      "self",
      "text_input",
      "aux_input"
    ],
    "before_backward_pass": [
      "self",
      "loss_dict",
      "optimizer"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "before_gradient_clipping": [
      "self"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "init_from_config": [
      "config",
      "samples"
    ]
  },
  "Tacotron2": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "shape_outputs": [
      "mel_outputs",
      "mel_outputs_postnet",
      "alignments"
    ],
    "forward": [
      "self",
      "text",
      "text_lengths",
      "mel_specs",
      "mel_lengths",
      "aux_input"
    ],
    "inference": [
      "self",
      "text",
      "aux_input"
    ],
    "before_backward_pass": [
      "self",
      "loss_dict",
      "optimizer"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "before_gradient_clipping": [
      "self"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "init_from_config": [
      "config",
      "samples"
    ]
  },
  "AlignTTSArgs": {},
  "AlignTTS": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "compute_log_probs": [
      "mu",
      "log_sigma",
      "y"
    ],
    "compute_align_path": [
      "self",
      "mu",
      "log_sigma",
      "y",
      "x_mask",
      "y_mask"
    ],
    "generate_attn": [
      "dr",
      "x_mask",
      "y_mask"
    ],
    "expand_encoder_outputs": [
      "self",
      "en",
      "dr",
      "x_mask",
      "y_mask"
    ],
    "format_durations": [
      "self",
      "o_dr_log",
      "x_mask"
    ],
    "_concat_speaker_embedding": [
      "o_en",
      "g"
    ],
    "_sum_speaker_embedding": [
      "self",
      "x",
      "g"
    ],
    "_forward_encoder": [
      "self",
      "x",
      "x_lengths",
      "g"
    ],
    "_forward_decoder": [
      "self",
      "o_en",
      "o_en_dp",
      "dr",
      "x_mask",
      "y_lengths",
      "g"
    ],
    "_forward_mdn": [
      "self",
      "o_en",
      "y",
      "y_lengths",
      "x_mask"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "y",
      "y_lengths",
      "aux_input",
      "phase"
    ],
    "inference": [
      "self",
      "x",
      "aux_input"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ],
    "get_criterion": [
      "self"
    ],
    "_set_phase": [
      "config",
      "global_step"
    ],
    "on_epoch_start": [
      "self",
      "trainer"
    ],
    "init_from_config": [
      "config",
      "samples"
    ]
  },
  "BaseTTS": {
    "MODEL_TYPE": [],
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager",
      "language_manager"
    ],
    "_set_model_args": [
      "self",
      "config"
    ],
    "init_multispeaker": [
      "self",
      "config",
      "data"
    ],
    "get_aux_input": [
      "self"
    ],
    "get_aux_input_from_test_sentences": [
      "self",
      "sentence_info"
    ],
    "format_batch": [
      "self",
      "batch"
    ],
    "get_sampler": [
      "self",
      "config",
      "dataset",
      "num_gpus"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus",
      "rank"
    ],
    "_get_test_aux_input": [
      "self"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "on_init_start": [
      "self",
      "trainer"
    ]
  },
  "BaseTTSE2E": {
    "_set_model_args": [
      "self",
      "config"
    ]
  },
  "wav_to_mel_cloning": [
    "wav",
    "mel_norms_file",
    "mel_norms",
    "device",
    "n_fft",
    "hop_length",
    "win_length",
    "power",
    "normalized",
    "sample_rate",
    "f_min",
    "f_max",
    "n_mels"
  ],
  "XttsArgs": {},
  "Xtts": {
    "__init__": [
      "self",
      "config"
    ],
    "init_models": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_gpt_cond_latents": [
      "self",
      "audio",
      "sr",
      "length",
      "chunk_length"
    ],
    "get_speaker_embedding": [
      "self",
      "audio",
      "sr"
    ],
    "get_conditioning_latents": [
      "self",
      "audio_path",
      "max_ref_length",
      "gpt_cond_len",
      "gpt_cond_chunk_len",
      "librosa_trim_db",
      "sound_norm_refs",
      "load_sr"
    ],
    "synthesize": [
      "self",
      "text",
      "config",
      "speaker_wav",
      "language",
      "speaker_id"
    ],
    "full_inference": [
      "self",
      "text",
      "ref_audio_path",
      "language",
      "temperature",
      "length_penalty",
      "repetition_penalty",
      "top_k",
      "top_p",
      "do_sample",
      "gpt_cond_len",
      "gpt_cond_chunk_len",
      "max_ref_len",
      "sound_norm_refs"
    ],
    "inference": [
      "self",
      "text",
      "language",
      "gpt_cond_latent",
      "speaker_embedding",
      "temperature",
      "length_penalty",
      "repetition_penalty",
      "top_k",
      "top_p",
      "do_sample",
      "num_beams",
      "speed",
      "enable_text_splitting"
    ],
    "handle_chunks": [
      "self",
      "wav_gen",
      "wav_gen_prev",
      "wav_overlap",
      "overlap_len"
    ],
    "inference_stream": [
      "self",
      "text",
      "language",
      "gpt_cond_latent",
      "speaker_embedding",
      "stream_chunk_size",
      "overlap_wav_len",
      "temperature",
      "length_penalty",
      "repetition_penalty",
      "top_k",
      "top_p",
      "do_sample",
      "speed",
      "enable_text_splitting"
    ],
    "forward": [
      "self"
    ],
    "eval_step": [
      "self"
    ],
    "init_from_config": [
      "config"
    ],
    "eval": [
      "self"
    ],
    "get_compatible_checkpoint_state_dict": [
      "self",
      "model_path"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_dir",
      "checkpoint_path",
      "vocab_path",
      "eval",
      "strict",
      "use_deepspeed",
      "speaker_file_path"
    ],
    "train_step": [
      "self"
    ]
  },
  "VitsAudioConfig": {},
  "VitsDataset": {
    "__init__": [
      "self",
      "model_args"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "lengths": [
      "self"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "VitsArgs": {},
  "Vits": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager",
      "language_manager"
    ],
    "device": [
      "self"
    ],
    "init_multispeaker": [
      "self",
      "config"
    ],
    "_init_speaker_embedding": [
      "self"
    ],
    "_init_d_vector": [
      "self"
    ],
    "init_multilingual": [
      "self",
      "config"
    ],
    "init_upsampling": [
      "self"
    ],
    "on_epoch_start": [
      "self",
      "trainer"
    ],
    "on_init_end": [
      "self",
      "trainer"
    ],
    "get_aux_input": [
      "self",
      "aux_input"
    ],
    "_freeze_layers": [
      "self"
    ],
    "_set_cond_input": [
      "aux_input"
    ],
    "_set_speaker_input": [
      "self",
      "aux_input"
    ],
    "forward_mas": [
      "self",
      "outputs",
      "z_p",
      "m_p",
      "logs_p",
      "x",
      "x_mask",
      "y_mask",
      "g",
      "lang_emb"
    ],
    "upsampling_z": [
      "self",
      "z",
      "slice_ids",
      "y_lengths",
      "y_mask"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "y",
      "y_lengths",
      "waveform",
      "aux_input"
    ],
    "_set_x_lengths": [
      "x",
      "aux_input"
    ],
    "inference": [
      "self",
      "x",
      "aux_input"
    ],
    "inference_voice_conversion": [
      "self",
      "reference_wav",
      "speaker_id",
      "d_vector",
      "reference_speaker_id",
      "reference_d_vector"
    ],
    "voice_conversion": [
      "self",
      "y",
      "y_lengths",
      "speaker_cond_src",
      "speaker_cond_tgt"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion",
      "optimizer_idx"
    ],
    "_log": [
      "self",
      "ap",
      "batch",
      "outputs",
      "name_prefix"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion",
      "optimizer_idx"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "get_aux_input_from_test_sentences": [
      "self",
      "sentence_info"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "test_log": [
      "self",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "format_batch": [
      "self",
      "batch"
    ],
    "format_batch_on_device": [
      "self",
      "batch"
    ],
    "get_sampler": [
      "self",
      "config",
      "dataset",
      "num_gpus",
      "is_eval"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus",
      "rank"
    ],
    "get_optimizer": [
      "self"
    ],
    "get_lr": [
      "self"
    ],
    "get_scheduler": [
      "self",
      "optimizer"
    ],
    "get_criterion": [
      "self"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "strict",
      "cache"
    ],
    "load_fairseq_checkpoint": [
      "self",
      "config",
      "checkpoint_dir",
      "eval",
      "strict"
    ],
    "init_from_config": [
      "config",
      "samples",
      "verbose"
    ],
    "export_onnx": [
      "self",
      "output_path",
      "verbose"
    ],
    "load_onnx": [
      "self",
      "model_path",
      "cuda"
    ],
    "inference_onnx": [
      "self",
      "x",
      "x_lengths",
      "speaker_id",
      "language_id"
    ]
  },
  "VitsCharacters": {
    "__init__": [
      "self",
      "graphemes",
      "punctuations",
      "pad",
      "ipa_characters"
    ],
    "_create_vocab": [
      "self"
    ],
    "init_from_config": [
      "config"
    ],
    "to_config": [
      "self"
    ]
  },
  "FairseqVocab": {
    "__init__": [
      "self",
      "vocab"
    ],
    "vocab": [
      "self",
      "vocab_file"
    ]
  },
  "ForwardTTSArgs": {},
  "ForwardTTS": {
    "__init__": [
      "self",
      "config",
      "ap",
      "tokenizer",
      "speaker_manager"
    ],
    "init_multispeaker": [
      "self",
      "config"
    ],
    "generate_attn": [
      "dr",
      "x_mask",
      "y_mask"
    ],
    "expand_encoder_outputs": [
      "self",
      "en",
      "dr",
      "x_mask",
      "y_mask"
    ],
    "format_durations": [
      "self",
      "o_dr_log",
      "x_mask"
    ],
    "_forward_encoder": [
      "self",
      "x",
      "x_mask",
      "g"
    ],
    "_forward_decoder": [
      "self",
      "o_en",
      "dr",
      "x_mask",
      "y_lengths",
      "g"
    ],
    "_forward_pitch_predictor": [
      "self",
      "o_en",
      "x_mask",
      "pitch",
      "dr"
    ],
    "_forward_energy_predictor": [
      "self",
      "o_en",
      "x_mask",
      "energy",
      "dr"
    ],
    "_forward_aligner": [
      "self",
      "x",
      "y",
      "x_mask",
      "y_mask"
    ],
    "_set_speaker_input": [
      "self",
      "aux_input"
    ],
    "forward": [
      "self",
      "x",
      "x_lengths",
      "y_lengths",
      "y",
      "dr",
      "pitch",
      "energy",
      "aux_input"
    ],
    "inference": [
      "self",
      "x",
      "aux_input"
    ],
    "train_step": [
      "self",
      "batch",
      "criterion"
    ],
    "_create_logs": [
      "self",
      "batch",
      "outputs",
      "ap"
    ],
    "train_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "eval_step": [
      "self",
      "batch",
      "criterion"
    ],
    "eval_log": [
      "self",
      "batch",
      "outputs",
      "logger",
      "assets",
      "steps"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "cache"
    ],
    "get_criterion": [
      "self"
    ],
    "on_train_step_start": [
      "self",
      "trainer"
    ],
    "init_from_config": [
      "config",
      "samples"
    ]
  },
  "read_json_with_comments": [
    "json_path"
  ],
  "register_config": [
    "model_name"
  ],
  "_process_model_name": [
    "config_dict"
  ],
  "load_config": [
    "config_path"
  ],
  "check_config_and_model_args": [
    "config",
    "arg_name",
    "value"
  ],
  "get_from_config_or_model_args": [
    "config",
    "arg_name"
  ],
  "get_from_config_or_model_args_with_default": [
    "config",
    "arg_name",
    "def_val"
  ],
  "BaseAudioConfig": {
    "check_values": [
      "self"
    ]
  },
  "BaseDatasetConfig": {
    "check_values": [
      "self"
    ]
  },
  "BaseTrainingConfig": {},
  "check_update": [
    "model",
    "grad_clip",
    "ignore_stopnet",
    "amp_opt_params"
  ],
  "gradual_training_scheduler": [
    "global_step",
    "config"
  ],
  "LICENSE_URLS": [],
  "ModelManager": {
    "tqdm_progress": [],
    "__init__": [
      "self",
      "models_file",
      "output_prefix",
      "progress_bar",
      "verbose"
    ],
    "read_models_file": [
      "self",
      "file_path"
    ],
    "_list_models": [
      "self",
      "model_type",
      "model_count"
    ],
    "_list_for_model_type": [
      "self",
      "model_type"
    ],
    "list_models": [
      "self"
    ],
    "model_info_by_idx": [
      "self",
      "model_query"
    ],
    "model_info_by_full_name": [
      "self",
      "model_query_name"
    ],
    "list_tts_models": [
      "self"
    ],
    "list_vocoder_models": [
      "self"
    ],
    "list_vc_models": [
      "self"
    ],
    "list_langs": [
      "self"
    ],
    "list_datasets": [
      "self"
    ],
    "print_model_license": [
      "model_item"
    ],
    "_download_github_model": [
      "self",
      "model_item",
      "output_path"
    ],
    "_download_hf_model": [
      "self",
      "model_item",
      "output_path"
    ],
    "download_fairseq_model": [
      "self",
      "model_name",
      "output_path"
    ],
    "set_model_url": [
      "model_item"
    ],
    "_set_model_item": [
      "self",
      "model_name"
    ],
    "ask_tos": [
      "model_full_path"
    ],
    "tos_agreed": [
      "model_item",
      "model_full_path"
    ],
    "create_dir_and_download_model": [
      "self",
      "model_name",
      "model_item",
      "output_path"
    ],
    "check_if_configs_are_equal": [
      "self",
      "model_name",
      "model_item",
      "output_path"
    ],
    "download_model": [
      "self",
      "model_name"
    ],
    "_find_files": [
      "output_path"
    ],
    "_find_speaker_encoder": [
      "output_path"
    ],
    "_update_paths": [
      "self",
      "output_path",
      "config_path"
    ],
    "_update_path": [
      "field_name",
      "new_path",
      "config_path"
    ],
    "_download_zip_file": [
      "file_url",
      "output_folder",
      "progress_bar"
    ],
    "_download_tar_file": [
      "file_url",
      "output_folder",
      "progress_bar"
    ],
    "_download_model_files": [
      "file_urls",
      "output_folder",
      "progress_bar"
    ],
    "_check_dict_key": [
      "my_dict",
      "key"
    ]
  },
  "TrainerCallback": {
    "on_init_start": [
      "trainer"
    ],
    "on_init_end": [
      "trainer"
    ],
    "on_epoch_start": [
      "trainer"
    ],
    "on_epoch_end": [
      "trainer"
    ],
    "on_train_step_start": [
      "trainer"
    ],
    "on_train_step_end": [
      "trainer"
    ],
    "on_keyboard_interrupt": [
      "trainer"
    ]
  },
  "read_audio": [
    "path"
  ],
  "resample_wav": [
    "wav",
    "sr",
    "new_sr"
  ],
  "map_timestamps_to_new_sr": [
    "vad_sr",
    "new_sr",
    "timestamps",
    "just_begging_end"
  ],
  "get_vad_model_and_utils": [
    "use_cuda",
    "use_onnx"
  ],
  "remove_silence": [
    "model_and_utils",
    "audio_path",
    "out_path",
    "vad_sample_rate",
    "trim_just_beginning_and_end",
    "use_cuda"
  ],
  "reduce_tensor": [
    "tensor",
    "num_gpus"
  ],
  "init_distributed": [
    "rank",
    "num_gpus",
    "group_name",
    "dist_backend",
    "dist_url"
  ],
  "RenamingUnpickler": {
    "find_class": [
      "self",
      "module",
      "name"
    ]
  },
  "AttrDict": {
    "__init__": [
      "self"
    ]
  },
  "load_fsspec": [
    "path",
    "map_location",
    "cache"
  ],
  "load_checkpoint": [
    "model",
    "checkpoint_path",
    "use_cuda",
    "eval",
    "cache"
  ],
  "CapacitronOptimizer": {
    "__init__": [
      "self",
      "config",
      "model_params"
    ],
    "first_step": [
      "self"
    ],
    "step": [
      "self"
    ],
    "zero_grad": [
      "self",
      "set_to_none"
    ],
    "load_state_dict": [
      "self",
      "state_dict"
    ],
    "state_dict": [
      "self"
    ],
    "split_model_parameters": [
      "model_params"
    ],
    "extract_optimizer_parameters": [
      "params"
    ]
  },
  "Synthesizer": {
    "__init__": [
      "self",
      "tts_checkpoint",
      "tts_config_path",
      "tts_speakers_file",
      "tts_languages_file",
      "vocoder_checkpoint",
      "vocoder_config",
      "encoder_checkpoint",
      "encoder_config",
      "vc_checkpoint",
      "vc_config",
      "model_dir",
      "voice_dir",
      "use_cuda"
    ],
    "_get_segmenter": [
      "lang"
    ],
    "_load_vc": [
      "self",
      "vc_checkpoint",
      "vc_config_path",
      "use_cuda"
    ],
    "_load_fairseq_from_dir": [
      "self",
      "model_dir",
      "use_cuda"
    ],
    "_load_tts_from_dir": [
      "self",
      "model_dir",
      "use_cuda"
    ],
    "_load_tts": [
      "self",
      "tts_checkpoint",
      "tts_config_path",
      "use_cuda"
    ],
    "_set_speaker_encoder_paths_from_tts_config": [
      "self"
    ],
    "_load_vocoder": [
      "self",
      "model_file",
      "model_config",
      "use_cuda"
    ],
    "split_into_sentences": [
      "self",
      "text"
    ],
    "save_wav": [
      "self",
      "wav",
      "path",
      "pipe_out"
    ],
    "voice_conversion": [
      "self",
      "source_wav",
      "target_wav"
    ],
    "tts": [
      "self",
      "text",
      "speaker_name",
      "language_name",
      "speaker_wav",
      "style_wav",
      "style_text",
      "reference_wav",
      "reference_speaker_name",
      "split_sentences"
    ]
  },
  "stream_url": [
    "url",
    "start_byte",
    "block_size",
    "progress_bar"
  ],
  "download_url": [
    "url",
    "download_folder",
    "filename",
    "hash_value",
    "hash_type",
    "progress_bar",
    "resume"
  ],
  "validate_file": [
    "file_obj",
    "hash_value",
    "hash_type"
  ],
  "extract_archive": [
    "from_path",
    "to_path",
    "overwrite"
  ],
  "download_kaggle_dataset": [
    "dataset_path",
    "dataset_name",
    "output_path"
  ],
  "download_ljspeech": [
    "path"
  ],
  "download_vctk": [
    "path",
    "use_kaggle"
  ],
  "download_tweb": [
    "path"
  ],
  "download_libri_tts": [
    "path",
    "subset"
  ],
  "download_thorsten_de": [
    "path"
  ],
  "download_mailabs": [
    "path",
    "language"
  ],
  "to_cuda": [
    "x"
  ],
  "get_cuda": [],
  "get_git_branch": [],
  "get_commit_hash": [],
  "get_experiment_folder_path": [
    "root_path",
    "model_name"
  ],
  "remove_experiment_folder": [
    "experiment_path"
  ],
  "count_parameters": [
    "model"
  ],
  "find_module": [
    "module_path",
    "module_name"
  ],
  "import_class": [
    "module_path"
  ],
  "get_import_path": [
    "obj"
  ],
  "get_user_data_dir": [
    "appname"
  ],
  "format_aux_input": [
    "def_args",
    "kwargs"
  ],
  "KeepAverage": {
    "__init__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "items": [
      "self"
    ],
    "add_value": [
      "self",
      "name",
      "init_val",
      "init_iter"
    ],
    "update_value": [
      "self",
      "name",
      "value",
      "weighted_avg"
    ],
    "add_values": [
      "self",
      "name_dict"
    ],
    "update_values": [
      "self",
      "value_dict"
    ]
  },
  "get_timestamp": [],
  "setup_logger": [
    "logger_name",
    "root",
    "phase",
    "level",
    "screen",
    "tofile"
  ],
  "RAdam": {
    "__init__": [
      "self",
      "params",
      "lr",
      "betas",
      "eps",
      "weight_decay",
      "degenerated_to_sgd"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "step": [
      "self",
      "closure"
    ]
  },
  "SubsetSampler": {
    "__init__": [
      "self",
      "indices"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "PerfectBatchSampler": {
    "__init__": [
      "self",
      "dataset_items",
      "classes",
      "batch_size",
      "num_classes_in_batch",
      "num_gpus",
      "shuffle",
      "drop_last",
      "label_key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "identity": [
    "x"
  ],
  "SortedSampler": {
    "__init__": [
      "self",
      "data",
      "sort_key"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "BucketBatchSampler": {
    "__init__": [
      "self",
      "sampler",
      "data",
      "batch_size",
      "drop_last",
      "sort_key",
      "bucket_size_multiplier"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "TorchSTFT": {
    "__init__": [
      "self",
      "n_fft",
      "hop_length",
      "win_length",
      "pad_wav",
      "window",
      "sample_rate",
      "mel_fmin",
      "mel_fmax",
      "n_mels",
      "use_mel",
      "do_amp_to_db",
      "spec_gain",
      "power",
      "use_htk",
      "mel_norm",
      "normalized"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "_build_mel_basis": [
      "self"
    ],
    "_amp_to_db": [
      "x",
      "spec_gain"
    ],
    "_db_to_amp": [
      "x",
      "spec_gain"
    ]
  },
  "build_mel_basis": [],
  "millisec_to_length": [],
  "_log": [
    "x",
    "base"
  ],
  "_exp": [
    "x",
    "base"
  ],
  "preemphasis": [],
  "deemphasis": [],
  "mel_to_spec": [],
  "spec_to_wav": [],
  "mel_to_wav": [],
  "stft": [],
  "istft": [],
  "griffin_lim": [],
  "compute_stft_paddings": [],
  "compute_f0": [],
  "compute_energy": [
    "y"
  ],
  "find_endpoint": [],
  "volume_norm": [],
  "rms_norm": [],
  "rms_volume_norm": [],
  "load_wav": [],
  "save_wav": [],
  "mulaw_encode": [],
  "mulaw_decode": [],
  "encode_16bits": [],
  "quantize": [],
  "dequantize": [],
  "AudioProcessor": {
    "__init__": [
      "self",
      "sample_rate",
      "resample",
      "num_mels",
      "log_func",
      "min_level_db",
      "frame_shift_ms",
      "frame_length_ms",
      "hop_length",
      "win_length",
      "ref_level_db",
      "fft_size",
      "power",
      "preemphasis",
      "signal_norm",
      "symmetric_norm",
      "max_norm",
      "mel_fmin",
      "mel_fmax",
      "pitch_fmax",
      "pitch_fmin",
      "spec_gain",
      "stft_pad_mode",
      "clip_norm",
      "griffin_lim_iters",
      "do_trim_silence",
      "trim_db",
      "do_sound_norm",
      "do_amp_to_db_linear",
      "do_amp_to_db_mel",
      "do_rms_norm",
      "db_level",
      "stats_path",
      "verbose"
    ],
    "init_from_config": [
      "config",
      "verbose"
    ],
    "normalize": [
      "self",
      "S"
    ],
    "denormalize": [
      "self",
      "S"
    ],
    "load_stats": [
      "self",
      "stats_path"
    ],
    "setup_scaler": [
      "self",
      "mel_mean",
      "mel_std",
      "linear_mean",
      "linear_std"
    ],
    "apply_preemphasis": [
      "self",
      "x"
    ],
    "apply_inv_preemphasis": [
      "self",
      "x"
    ],
    "spectrogram": [
      "self",
      "y"
    ],
    "melspectrogram": [
      "self",
      "y"
    ],
    "inv_spectrogram": [
      "self",
      "spectrogram"
    ],
    "inv_melspectrogram": [
      "self",
      "mel_spectrogram"
    ],
    "out_linear_to_mel": [
      "self",
      "linear_spec"
    ],
    "_griffin_lim": [
      "self",
      "S"
    ],
    "compute_f0": [
      "self",
      "x"
    ],
    "find_endpoint": [
      "self",
      "wav",
      "min_silence_sec"
    ],
    "trim_silence": [
      "self",
      "wav"
    ],
    "sound_norm": [
      "x"
    ],
    "rms_volume_norm": [
      "self",
      "x",
      "db_level"
    ],
    "load_wav": [
      "self",
      "filename",
      "sr"
    ],
    "save_wav": [
      "self",
      "wav",
      "path",
      "sr",
      "pipe_out"
    ],
    "get_duration": [
      "self",
      "filename"
    ]
  },
  "create_argparser": [],
  "args": [],
  "path": [],
  "manager": [],
  "model_path": [],
  "config_path": [],
  "speakers_file_path": [],
  "vocoder_path": [],
  "vocoder_config_path": [],
  "synthesizer": [],
  "use_multi_speaker": [],
  "speaker_manager": [],
  "use_multi_language": [],
  "language_manager": [],
  "use_gst": [],
  "app": [],
  "style_wav_uri_to_dict": [
    "style_wav"
  ],
  "index": [],
  "details": [],
  "lock": [],
  "tts": [],
  "mary_tts_api_locales": [],
  "mary_tts_api_voices": [],
  "mary_tts_api_process": [],
  "main": [],
  "FreeVCAudioConfig": {},
  "FreeVCArgs": {},
  "FreeVCConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "BaseVCConfig": {},
  "Generator": {
    "__init__": [
      "self",
      "initial_channel",
      "resblock",
      "resblock_kernel_sizes",
      "resblock_dilation_sizes",
      "upsample_rates",
      "upsample_initial_channel",
      "upsample_kernel_sizes",
      "gin_channels"
    ],
    "forward": [
      "self",
      "x",
      "g"
    ],
    "remove_weight_norm": [
      "self"
    ]
  },
  "SpeakerEncoder": {
    "__init__": [
      "self",
      "mel_n_channels",
      "model_num_layers",
      "model_hidden_size",
      "model_embedding_size"
    ],
    "forward": [
      "self",
      "mels"
    ],
    "compute_partial_slices": [
      "self",
      "total_frames",
      "partial_frames",
      "partial_hop"
    ],
    "embed_utterance": [
      "self",
      "mel",
      "partial_frames",
      "partial_hop"
    ]
  },
  "FreeVC": {
    "__init__": [
      "self",
      "config",
      "speaker_manager"
    ],
    "device": [
      "self"
    ],
    "load_pretrained_speaker_encoder": [
      "self"
    ],
    "init_multispeaker": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "c",
      "spec",
      "g",
      "mel",
      "c_lengths",
      "spec_lengths"
    ],
    "inference": [
      "self",
      "c",
      "g",
      "mel",
      "c_lengths"
    ],
    "extract_wavlm_features": [
      "self",
      "y"
    ],
    "load_audio": [
      "self",
      "wav"
    ],
    "voice_conversion": [
      "self",
      "src",
      "tgt"
    ],
    "eval_step": [],
    "init_from_config": [
      "config",
      "samples",
      "verbose"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "strict",
      "cache"
    ],
    "train_step": []
  },
  "BaseVC": {
    "MODEL_TYPE": [],
    "__init__": [
      "self",
      "config",
      "ap",
      "speaker_manager",
      "language_manager"
    ],
    "_set_model_args": [
      "self",
      "config"
    ],
    "init_multispeaker": [
      "self",
      "config",
      "data"
    ],
    "get_aux_input": [
      "self"
    ],
    "get_aux_input_from_test_sentences": [
      "self",
      "sentence_info"
    ],
    "format_batch": [
      "self",
      "batch"
    ],
    "get_sampler": [
      "self",
      "config",
      "dataset",
      "num_gpus"
    ],
    "get_data_loader": [
      "self",
      "config",
      "assets",
      "is_eval",
      "samples",
      "verbose",
      "num_gpus",
      "rank"
    ],
    "_get_test_aux_input": [
      "self"
    ],
    "test_run": [
      "self",
      "assets"
    ],
    "on_init_start": [
      "self",
      "trainer"
    ]
  },
  "dynamic_range_compression_torch": [
    "x",
    "C",
    "clip_val"
  ],
  "dynamic_range_decompression_torch": [
    "x",
    "C"
  ],
  "spectral_normalize_torch": [
    "magnitudes"
  ],
  "spectral_de_normalize_torch": [
    "magnitudes"
  ],
  "spectrogram_torch": [
    "y",
    "n_fft",
    "sampling_rate",
    "hop_size",
    "win_size",
    "center"
  ],
  "spec_to_mel_torch": [
    "spec",
    "n_fft",
    "num_mels",
    "sampling_rate",
    "fmin",
    "fmax"
  ],
  "mel_spectrogram_torch": [
    "y",
    "n_fft",
    "num_mels",
    "sampling_rate",
    "hop_size",
    "win_size",
    "fmin",
    "fmax",
    "center"
  ],
  "intersperse": [
    "lst",
    "item"
  ],
  "kl_divergence": [
    "m_p",
    "logs_p",
    "m_q",
    "logs_q"
  ],
  "rand_gumbel": [
    "shape"
  ],
  "rand_gumbel_like": [
    "x"
  ],
  "slice_segments": [
    "x",
    "ids_str",
    "segment_size"
  ],
  "rand_slice_segments": [
    "x",
    "x_lengths",
    "segment_size"
  ],
  "rand_spec_segments": [
    "x",
    "x_lengths",
    "segment_size"
  ],
  "get_timing_signal_1d": [
    "length",
    "channels",
    "min_timescale",
    "max_timescale"
  ],
  "add_timing_signal_1d": [
    "x",
    "min_timescale",
    "max_timescale"
  ],
  "cat_timing_signal_1d": [
    "x",
    "min_timescale",
    "max_timescale",
    "axis"
  ],
  "subsequent_mask": [
    "length"
  ],
  "shift_1d": [
    "x"
  ],
  "clip_grad_value_": [
    "parameters",
    "clip_value",
    "norm_type"
  ],
  "ConvReluNorm": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_channels",
      "out_channels",
      "kernel_size",
      "n_layers",
      "p_dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_mask"
    ]
  },
  "DDSConv": {
    "__init__": [
      "self",
      "channels",
      "kernel_size",
      "n_layers",
      "p_dropout"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g"
    ]
  },
  "Log": {
    "forward": [
      "self",
      "x",
      "x_mask",
      "reverse"
    ]
  },
  "Flip": {
    "forward": [
      "self",
      "x"
    ]
  },
  "ResidualCouplingLayer": {
    "__init__": [
      "self",
      "channels",
      "hidden_channels",
      "kernel_size",
      "dilation_rate",
      "n_layers",
      "p_dropout",
      "gin_channels",
      "mean_only"
    ],
    "forward": [
      "self",
      "x",
      "x_mask",
      "g",
      "reverse"
    ]
  },
  "int16_max": [],
  "preprocess_wav": [
    "fpath_or_wav",
    "source_sr"
  ],
  "wav_to_mel_spectrogram": [
    "wav"
  ],
  "normalize_volume": [
    "wav",
    "target_dBFS",
    "increase_only",
    "decrease_only"
  ],
  "mel_window_length": [],
  "mel_window_step": [],
  "mel_n_channels": [],
  "sampling_rate": [],
  "partials_n_frames": [],
  "vad_window_length": [],
  "vad_moving_average_width": [],
  "vad_max_silence_length": [],
  "audio_norm_target_dBFS": [],
  "model_hidden_size": [],
  "model_embedding_size": [],
  "model_num_layers": [],
  "compute_mask_indices": [
    "shape",
    "padding_mask",
    "mask_prob",
    "mask_length",
    "mask_type",
    "mask_other",
    "min_masks",
    "no_overlap",
    "min_space"
  ],
  "WavLMConfig": {
    "__init__": [
      "self",
      "cfg"
    ],
    "update": [
      "self",
      "cfg"
    ]
  },
  "WavLM": {
    "__init__": [
      "self",
      "cfg"
    ],
    "apply_mask": [
      "self",
      "x",
      "padding_mask"
    ],
    "forward_padding_mask": [
      "self",
      "features",
      "padding_mask"
    ],
    "extract_features": [
      "self",
      "source",
      "padding_mask",
      "mask",
      "ret_conv",
      "output_layer",
      "ret_layer_results"
    ]
  },
  "ConvFeatureExtractionModel": {
    "__init__": [
      "self",
      "conv_layers",
      "dropout",
      "mode",
      "conv_bias",
      "conv_type"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "TransformerEncoder": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "padding_mask",
      "streaming_mask",
      "layer"
    ],
    "extract_features": [
      "self",
      "x",
      "padding_mask",
      "streaming_mask",
      "tgt_layer"
    ]
  },
  "TransformerSentenceEncoderLayer": {
    "__init__": [
      "self",
      "embedding_dim",
      "ffn_embedding_dim",
      "num_attention_heads",
      "dropout",
      "attention_dropout",
      "activation_dropout",
      "activation_fn",
      "layer_norm_first",
      "has_relative_attention_bias",
      "num_buckets",
      "max_distance",
      "rescale_init",
      "gru_rel_pos"
    ],
    "forward": [
      "self",
      "x",
      "self_attn_mask",
      "self_attn_padding_mask",
      "need_weights",
      "pos_bias"
    ]
  },
  "model_uri": [],
  "get_wavlm": [
    "device"
  ],
  "TransposeLast": {
    "__init__": [
      "self",
      "deconstruct_idx"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Fp32LayerNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "Fp32GroupNorm": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "GradMultiply": {
    "forward": [
      "ctx",
      "x",
      "scale"
    ],
    "backward": [
      "ctx",
      "grad"
    ]
  },
  "SamePad": {
    "__init__": [
      "self",
      "kernel_size",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Swish": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLU_Linear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "glu_type",
      "bias_in_glu"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "gelu_accurate": [
    "x"
  ],
  "gelu": [
    "x"
  ],
  "get_activation_fn": [
    "activation"
  ],
  "init_bert_params": [
    "module"
  ],
  "quant_noise": [
    "module",
    "p",
    "block_size"
  ],
  "MultiheadAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "kdim",
      "vdim",
      "dropout",
      "bias",
      "add_bias_kv",
      "add_zero_attn",
      "self_attention",
      "encoder_decoder_attention",
      "q_noise",
      "qn_block_size",
      "has_relative_attention_bias",
      "num_buckets",
      "max_distance",
      "gru_rel_pos",
      "rescale_init"
    ],
    "reset_parameters": [
      "self"
    ],
    "_relative_positions_bucket": [
      "self",
      "relative_positions",
      "bidirectional"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "key_padding_mask",
      "incremental_state",
      "need_weights",
      "static_kv",
      "attn_mask",
      "before_softmax",
      "need_head_weights",
      "position_bias"
    ],
    "_append_prev_key_padding_mask": [
      "key_padding_mask",
      "prev_key_padding_mask",
      "batch_size",
      "src_len",
      "static_kv"
    ],
    "_get_input_buffer": [
      "self",
      "incremental_state"
    ],
    "_set_input_buffer": [
      "self",
      "incremental_state",
      "buffer"
    ],
    "apply_sparse_mask": [
      "self",
      "attn_weights",
      "tgt_len",
      "src_len",
      "bsz"
    ]
  },
  "adjust_path_and_remove_silence": [
    "audio_path"
  ],
  "preprocess_audios": [],
  "use_cuda": [],
  "num_gpus": [],
  "setup_loader": [
    "ap",
    "is_val",
    "verbose"
  ],
  "evaluation": [
    "model",
    "criterion",
    "data_loader",
    "global_step"
  ],
  "train": [
    "model",
    "optimizer",
    "scheduler",
    "criterion",
    "data_loader",
    "eval_data_loader",
    "global_step"
  ],
  "compute_embeddings": [
    "model_path",
    "config_path",
    "output_path",
    "old_speakers_file",
    "old_append",
    "config_dataset_path",
    "formatter_name",
    "dataset_name",
    "dataset_path",
    "meta_file_train",
    "meta_file_val",
    "disable_cuda",
    "no_eval"
  ],
  "TrainVocoderArgs": {},
  "resample_file": [
    "func_args"
  ],
  "resample_files": [
    "input_dir",
    "output_sr",
    "output_dir",
    "file_ext",
    "n_jobs"
  ],
  "TrainTTSArgs": {},
  "compute_encoder_accuracy": [
    "dataset_items",
    "encoder_manager"
  ],
  "system_info": [],
  "cuda_info": [],
  "package_info": [],
  "compute_phonemes": [
    "item"
  ],
  "set_filename": [
    "wav_path",
    "out_path"
  ],
  "format_data": [
    "data"
  ],
  "inference": [
    "model_name",
    "model",
    "ap",
    "text_input",
    "text_lengths",
    "mel_input",
    "mel_lengths",
    "speaker_ids",
    "d_vectors"
  ],
  "extract_spectrograms": [
    "data_loader",
    "model",
    "ap",
    "output_path",
    "quantize_bits",
    "save_audio",
    "debug",
    "metada_name"
  ],
  "description": [],
  "str2bool": [
    "v"
  ],
  "GE2ELoss": {
    "__init__": [
      "self",
      "init_w",
      "init_b",
      "loss_method"
    ],
    "calc_new_centroids": [
      "self",
      "dvecs",
      "centroids",
      "spkr",
      "utt"
    ],
    "calc_cosine_sim": [
      "self",
      "dvecs",
      "centroids"
    ],
    "embed_loss_softmax": [
      "self",
      "dvecs",
      "cos_sim_matrix"
    ],
    "embed_loss_contrast": [
      "self",
      "dvecs",
      "cos_sim_matrix"
    ],
    "forward": [
      "self",
      "x",
      "_label"
    ]
  },
  "AngleProtoLoss": {
    "__init__": [
      "self",
      "init_w",
      "init_b"
    ],
    "forward": [
      "self",
      "x",
      "_label"
    ]
  },
  "SoftmaxLoss": {
    "__init__": [
      "self",
      "embedding_dim",
      "n_speakers"
    ],
    "forward": [
      "self",
      "x",
      "label"
    ],
    "inference": [
      "self",
      "embedding"
    ]
  },
  "SoftmaxAngleProtoLoss": {
    "__init__": [
      "self",
      "embedding_dim",
      "n_speakers",
      "init_w",
      "init_b"
    ],
    "forward": [
      "self",
      "x",
      "label"
    ]
  },
  "EncoderDataset": {
    "__init__": [
      "self",
      "config",
      "ap",
      "meta_data",
      "voice_len",
      "num_classes_in_batch",
      "num_utter_per_class",
      "verbose",
      "augmentation_config",
      "use_torch_spec"
    ],
    "load_wav": [
      "self",
      "filename"
    ],
    "__parse_items": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "get_num_classes": [
      "self"
    ],
    "get_class_list": [
      "self"
    ],
    "set_classes": [
      "self",
      "classes"
    ],
    "get_map_classid_to_classname": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "collate_fn": [
      "self",
      "batch"
    ]
  },
  "TrainArgs": {},
  "getarguments": [],
  "process_args": [
    "args",
    "config"
  ],
  "init_arguments": [],
  "init_training": [
    "config"
  ],
  "colormap": [],
  "plot_embeddings": [
    "embeddings",
    "num_classes_in_batch"
  ],
  "SUBSETS": [],
  "MD5SUM": [],
  "USER": [],
  "speaker_id_dict": [],
  "download_and_extract": [
    "directory",
    "subset",
    "urls"
  ],
  "exec_cmd": [
    "cmd"
  ],
  "decode_aac_with_ffmpeg": [
    "aac_file",
    "wav_file"
  ],
  "convert_audio_and_make_label": [
    "input_dir",
    "subset",
    "output_dir",
    "output_file"
  ],
  "processor": [
    "directory",
    "subset",
    "force_process"
  ],
  "AugmentWAV": {
    "__init__": [
      "self",
      "ap",
      "augmentation_config"
    ],
    "create_augmentation_global_list": [
      "self"
    ],
    "additive_noise": [
      "self",
      "noise_type",
      "audio"
    ],
    "reverberate": [
      "self",
      "audio"
    ],
    "apply_one": [
      "self",
      "audio"
    ]
  },
  "setup_encoder_model": [
    "config"
  ],
  "EmotionEncoderConfig": {},
  "BaseEncoderConfig": {
    "check_values": [
      "self"
    ]
  },
  "SpeakerEncoderConfig": {},
  "LSTMWithProjection": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "proj_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LSTMWithoutProjection": {
    "__init__": [
      "self",
      "input_dim",
      "lstm_dim",
      "proj_dim",
      "num_lstm_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LSTMSpeakerEncoder": {
    "__init__": [
      "self",
      "input_dim",
      "proj_dim",
      "lstm_dim",
      "num_lstm_layers",
      "use_lstm_with_projection",
      "use_torch_spec",
      "audio_config"
    ],
    "_init_layers": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "l2_norm"
    ]
  },
  "BaseEncoder": {
    "__init__": [
      "self"
    ],
    "get_torch_mel_spectrogram_class": [
      "self",
      "audio_config"
    ],
    "inference": [
      "self",
      "x",
      "l2_norm"
    ],
    "compute_embedding": [
      "self",
      "x",
      "num_frames",
      "num_eval",
      "return_mean",
      "l2_norm"
    ],
    "get_criterion": [
      "self",
      "c",
      "num_classes"
    ],
    "load_checkpoint": [
      "self",
      "config",
      "checkpoint_path",
      "eval",
      "use_cuda",
      "criterion",
      "cache"
    ]
  }
}