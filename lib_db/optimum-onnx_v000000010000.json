{
  "logger": [],
  "ORTDiffusionPipeline": {
    "config_name": [],
    "task": [],
    "library": [],
    "auto_model_class": [],
    "__init__": [
      "self"
    ],
    "components": [
      "self"
    ],
    "to": [
      "self",
      "device"
    ],
    "from_pretrained": [
      "cls",
      "model_name_or_path",
      "export",
      "provider",
      "providers",
      "provider_options",
      "session_options",
      "use_io_binding"
    ],
    "save_pretrained": [
      "self",
      "save_directory",
      "push_to_hub"
    ]
  },
  "ORTModelMixin": {
    "__init__": [
      "self",
      "session",
      "parent",
      "use_io_binding"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ],
    "named_modules": [
      "self"
    ]
  },
  "ORTUnet": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "timestep",
      "encoder_hidden_states",
      "timestep_cond",
      "cross_attention_kwargs",
      "added_cond_kwargs",
      "return_dict"
    ]
  },
  "ORTTransformer": {
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "pooled_projections",
      "guidance",
      "txt_ids",
      "img_ids",
      "joint_attention_kwargs",
      "encoder_attention_mask",
      "attention_kwargs",
      "return_dict"
    ]
  },
  "ORTTextEncoder": {
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "ORTVaeEncoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "sample",
      "generator",
      "return_dict"
    ]
  },
  "ORTVaeDecoder": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "latent_sample",
      "generator",
      "return_dict"
    ]
  },
  "ORTVae": {
    "__init__": [
      "self",
      "encoder",
      "decoder"
    ],
    "decode": [
      "self"
    ],
    "encode": [
      "self"
    ],
    "config": [
      "self"
    ]
  },
  "ORT_PIPELINE_DOCSTRING": [],
  "ORTStableDiffusionPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": []
  },
  "ORTStableDiffusionImg2ImgPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": []
  },
  "ORTStableDiffusionInpaintPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": []
  },
  "ORTStableDiffusionXLPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": [],
    "_get_add_time_ids": [
      "self",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "dtype",
      "text_encoder_projection_dim"
    ]
  },
  "ORTStableDiffusionXLImg2ImgPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": [],
    "_get_add_time_ids": [
      "self",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "aesthetic_score",
      "negative_aesthetic_score",
      "negative_original_size",
      "negative_crops_coords_top_left",
      "negative_target_size",
      "dtype",
      "text_encoder_projection_dim"
    ]
  },
  "ORTStableDiffusionXLInpaintPipeline": {
    "main_input_name": [],
    "task": [],
    "auto_model_class": [],
    "_get_add_time_ids": [
      "self",
      "original_size",
      "crops_coords_top_left",
      "target_size",
      "aesthetic_score",
      "negative_aesthetic_score",
      "negative_original_size",
      "negative_crops_coords_top_left",
      "negative_target_size",
      "dtype",
      "text_encoder_projection_dim"
    ]
  },
  "ORTLatentConsistencyModelPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": []
  },
  "ORTLatentConsistencyModelImg2ImgPipeline": {
    "task": [],
    "main_input_name": [],
    "auto_model_class": []
  },
  "ORT_TEXT2IMAGE_PIPELINES_MAPPING": [],
  "ORT_IMAGE2IMAGE_PIPELINES_MAPPING": [],
  "ORT_INPAINT_PIPELINES_MAPPING": [],
  "SUPPORTED_ORT_PIPELINES_MAPPINGS": [],
  "ORTUnavailablePipeline": {
    "MIN_VERSION": [],
    "__init__": [
      "self"
    ]
  },
  "SUPPORTED_ORT_PIPELINES": [],
  "_get_ort_class": [
    "pipeline_class_name",
    "throw_error_if_not_exist"
  ],
  "_get_task_ort_class": [
    "mapping",
    "pipeline_class_name"
  ],
  "ORTPipelineForTask": {
    "config_name": [],
    "from_pretrained": [
      "cls",
      "pretrained_model_or_path"
    ]
  },
  "ORTPipelineForText2Image": {
    "config_name": [],
    "auto_model_class": [],
    "ort_pipelines_mapping": []
  },
  "ORTPipelineForImage2Image": {
    "config_name": [],
    "auto_model_class": [],
    "ort_pipelines_mapping": []
  },
  "ORTPipelineForInpainting": {
    "config_name": [],
    "auto_model_class": [],
    "ort_pipelines_mapping": []
  },
  "GENERIC_ORT_PIPELINES": [],
  "get_ort_model_class": [
    "task",
    "config",
    "model_id"
  ],
  "ort_infer_framework_load_model": [
    "model",
    "config",
    "task"
  ],
  "patch_pipelines_to_load_ort_model": [],
  "pipeline": [
    "task",
    "model",
    "config",
    "tokenizer",
    "feature_extractor",
    "image_processor",
    "processor",
    "revision",
    "use_fast",
    "token",
    "device",
    "trust_remote_code",
    "model_kwargs",
    "pipeline_class"
  ],
  "NON_EMPTY_TENSOR": [],
  "ORTSessionMixin": {
    "initialize_ort_attributes": [
      "self",
      "session",
      "use_io_binding"
    ],
    "model_path": [
      "self"
    ],
    "model_name": [
      "self"
    ],
    "providers": [
      "self"
    ],
    "provider": [
      "self"
    ],
    "provider_options": [
      "self"
    ],
    "provider_option": [
      "self"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "use_io_binding": [
      "self",
      "value"
    ],
    "to": [
      "self"
    ],
    "raise_on_numpy_input_io_binding": [
      "self",
      "use_torch"
    ],
    "_prepare_onnx_inputs": [
      "self",
      "use_torch",
      "model_inputs"
    ],
    "_prepare_onnx_outputs": [
      "self",
      "use_torch",
      "onnx_outputs"
    ],
    "_prepare_output_buffer": [
      "self",
      "output_name",
      "output_shape"
    ],
    "_output_shape_inference": [
      "self",
      "output_name",
      "known_axes_values"
    ],
    "_dynamic_axis_inference": [
      "self",
      "axis_name",
      "known_axes_values"
    ],
    "_prepare_io_binding": [
      "self",
      "model_inputs",
      "outputs_to_not_bind",
      "known_output_buffers",
      "known_output_shapes"
    ],
    "forward": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "save_session": [
      "self",
      "save_directory"
    ]
  },
  "ORTParentMixin": {
    "initialize_ort_attributes": [
      "self",
      "parts"
    ],
    "providers": [
      "self"
    ],
    "provider": [
      "self"
    ],
    "provider_options": [
      "self"
    ],
    "provider_option": [
      "self"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "use_io_binding": [
      "self",
      "value"
    ],
    "to": [
      "self"
    ]
  },
  "LOGGER": [],
  "ORTCalibrationDataReader": {
    "__slots__": [],
    "__init__": [
      "self",
      "dataset",
      "batch_size"
    ],
    "get_next": [
      "self"
    ]
  },
  "ORTQuantizer": {
    "__init__": [
      "self",
      "onnx_model_path",
      "config"
    ],
    "from_pretrained": [
      "cls",
      "model_or_path",
      "file_name"
    ],
    "fit": [
      "self",
      "dataset",
      "calibration_config",
      "onnx_augmented_model_name",
      "operators_to_quantize",
      "batch_size",
      "use_external_data_format",
      "use_gpu",
      "force_symmetric_range"
    ],
    "partial_fit": [
      "self",
      "dataset",
      "calibration_config",
      "onnx_augmented_model_name",
      "operators_to_quantize",
      "batch_size",
      "use_external_data_format",
      "use_gpu",
      "force_symmetric_range"
    ],
    "compute_ranges": [
      "self"
    ],
    "quantize": [
      "self",
      "quantization_config",
      "save_dir",
      "file_suffix",
      "calibration_tensors_range",
      "use_external_data_format",
      "preprocessor"
    ],
    "get_calibration_dataset": [
      "self",
      "dataset_name",
      "num_samples",
      "dataset_config_name",
      "dataset_split",
      "preprocess_function",
      "preprocess_batch",
      "seed",
      "token"
    ],
    "clean_calibration_dataset": [
      "self",
      "dataset"
    ]
  },
  "is_cupy_available": [],
  "ORTConfigManager": {
    "_conf": [],
    "get_model_ort_type": [
      "cls",
      "model_type"
    ],
    "check_supported_model": [
      "cls",
      "model_type"
    ],
    "check_optimization_supported_model": [
      "cls",
      "model_type",
      "optimization_config"
    ]
  },
  "generate_identified_filename": [
    "filename",
    "identifier"
  ],
  "get_device_for_provider": [
    "provider",
    "provider_options"
  ],
  "get_provider_for_device": [
    "device"
  ],
  "parse_device": [
    "device"
  ],
  "validate_provider_availability": [
    "provider"
  ],
  "prepare_providers_and_provider_options": [
    "provider",
    "providers",
    "provider_options"
  ],
  "check_io_binding": [
    "providers",
    "use_io_binding"
  ],
  "get_ordered_input_names": [
    "input_names",
    "func"
  ],
  "ORTQuantizableOperator": {
    "Gather": [],
    "Transpose": [],
    "EmbedLayerNormalizationQuant": [],
    "Conv": [],
    "MatMul": [],
    "Add": [],
    "Mul": [],
    "Relu": [],
    "Clip": [],
    "LeakyRelu": [],
    "Sigmoid": [],
    "MaxPool": [],
    "GlobalAveragePool": [],
    "Split": [],
    "Pad": [],
    "Reshape": [],
    "Squeeze": [],
    "Unsqueeze": [],
    "Resize": [],
    "AveragePool": [],
    "Concat": []
  },
  "evaluation_loop": [
    "model",
    "dataset",
    "label_names",
    "compute_metrics"
  ],
  "np_to_pt_generators": [
    "np_object",
    "device"
  ],
  "DummyWhisperModel": {
    "__init__": [
      "self"
    ]
  },
  "get_dtype_from_session": [
    "session"
  ],
  "ORTOptimizer": {
    "__init__": [
      "self",
      "onnx_model_path",
      "config",
      "from_ortmodel"
    ],
    "from_pretrained": [
      "cls",
      "model_or_path",
      "file_names"
    ],
    "optimize": [
      "self",
      "optimization_config",
      "save_dir",
      "file_suffix",
      "one_external_file"
    ],
    "get_fused_operators": [
      "onnx_model_path"
    ],
    "get_nodes_number_difference": [
      "onnx_model_path",
      "onnx_optimized_model_path"
    ],
    "get_operators_difference": [
      "onnx_model_path",
      "onnx_optimized_model_path"
    ]
  },
  "ONNX_MODEL_END_DOCSTRING": [],
  "SEQ2SEQ_ENCODER_INPUTS_DOCSTRING": [],
  "SPEECH_ENCODER_INPUTS_DOCSTRING": [],
  "MOONSHINE_ENCODER_INPUTS_DOCSTRING": [],
  "VISION_ENCODER_INPUTS_DOCSTRING": [],
  "PIX2STRUCT_INPUTS_DOCSTRING": [],
  "DECODER_INPUTS_DOCSTRING": [],
  "SEQ2SEQ_ONNX_MODEL_DOCSTRING": [],
  "SPEECH_SEQ2SEQ_ONNX_MODEL_DOCSTRING": [],
  "MOONSHINE_ONNX_MODEL_DOCSTRING": [],
  "VISION_ENCODER_DECODER_SEQ2SEQ_ONNX_MODEL_DOCSTRING": [],
  "PIX2STRUCT_ONNX_MODEL_DOCSTRING": [],
  "_TOKENIZER_FOR_DOC": [],
  "_PROCESSOR_FOR_DOC": [],
  "_IMAGE_PROCESSOR_FOR_DOC": [],
  "TRANSLATION_EXAMPLE": [],
  "AUTOMATIC_SPEECH_RECOGNITION_EXAMPLE": [],
  "IMAGE_TO_TEXT_EXAMPLE": [],
  "PIX2STRUCT_EXAMPLE": [],
  "ORTEncoder": {
    "main_input_name": [],
    "__init__": [
      "self",
      "config",
      "session",
      "use_io_binding"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask"
    ]
  },
  "ORTEncoderForSpeech": {
    "main_input_name": [],
    "forward": [
      "self",
      "input_features",
      "attention_mask"
    ]
  },
  "ORTEncoderForMoonshine": {
    "main_input_name": [],
    "forward": [
      "self",
      "input_values",
      "attention_mask"
    ]
  },
  "ORTEncoderForVision": {
    "main_input_name": [],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "ORTEncoderForPix2Struct": {
    "main_input_name": [],
    "forward": [
      "self",
      "flattened_patches",
      "attention_mask"
    ]
  },
  "ORTDecoderForSeq2Seq": {
    "main_input_name": [],
    "__init__": [
      "self",
      "config",
      "session",
      "use_io_binding"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "encoder_hidden_states",
      "encoder_attention_mask",
      "past_key_values",
      "cache_position",
      "use_cache"
    ]
  },
  "ORTModelForConditionalGeneration": {
    "_is_stateful": [],
    "_supports_cache_class": [],
    "_library_name": [],
    "_ort_encoder_class": [],
    "_ort_decoder_class": [],
    "__init__": [
      "self"
    ],
    "_save_pretrained": [
      "self",
      "save_directory"
    ],
    "_save_config": [
      "self",
      "save_directory"
    ],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token",
      "encoder_file_name",
      "decoder_file_name",
      "decoder_with_past_file_name",
      "provider",
      "providers",
      "provider_options",
      "session_options",
      "use_cache",
      "use_merged",
      "use_io_binding",
      "generation_config",
      "dtype",
      "model_save_dir"
    ],
    "_export": [
      "cls",
      "model_id",
      "config",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token",
      "use_merged",
      "use_cache"
    ],
    "get_encoder": [
      "self"
    ],
    "get_decoder": [
      "self"
    ],
    "_reorder_cache": [
      "past_key_values",
      "beam_idx"
    ],
    "prepare_inputs_for_generation": [
      "self"
    ],
    "_prepare_inputs_for_generation_legacy": [
      "self",
      "input_ids",
      "past_key_values"
    ],
    "can_use_cache": [
      "self"
    ],
    "use_merged": [
      "self"
    ],
    "use_cache": [
      "self"
    ],
    "_prepare_cache_for_generation": [
      "self"
    ]
  },
  "ORTModelForSeq2SeqLM": {
    "main_input_name": [],
    "auto_model_class": [],
    "_ort_encoder_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_outputs",
      "past_key_values",
      "token_type_ids",
      "cache_position",
      "use_cache"
    ]
  },
  "ORTModelForSpeechSeq2Seq": {
    "main_input_name": [],
    "auto_model_class": [],
    "_ort_encoder_class": [],
    "__init__": [
      "self"
    ],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config"
    ],
    "forward": [
      "self",
      "input_features",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_outputs",
      "past_key_values",
      "cache_position",
      "use_cache"
    ]
  },
  "ORTModelForWhisper": {
    "main_input_name": [],
    "auto_model_class": [],
    "__init__": [
      "self"
    ],
    "generate": [],
    "prepare_inputs_for_generation": [],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config"
    ]
  },
  "ORTModelForMoonshine": {
    "main_input_name": [],
    "auto_model_class": [],
    "_ort_encoder_class": [],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config"
    ],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_outputs",
      "past_key_values",
      "cache_position",
      "use_cache"
    ]
  },
  "ORTModelForVision2Seq": {
    "main_input_name": [],
    "auto_model_class": [],
    "_ort_encoder_class": [],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_outputs",
      "past_key_values",
      "cache_position",
      "use_cache"
    ]
  },
  "ORTModelForPix2Struct": {
    "main_input_name": [],
    "auto_model_class": [],
    "_ort_encoder_class": [],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config"
    ],
    "forward": [
      "self",
      "flattened_patches",
      "attention_mask",
      "decoder_input_ids",
      "decoder_attention_mask",
      "encoder_outputs",
      "past_key_values",
      "use_cache"
    ]
  },
  "_import_structure": [],
  "CAUSALLM_ONNX_MODEL_DOCSTRING": [],
  "TEXT_GENERATION_EXAMPLE": [],
  "ORTModelForCausalLM": {
    "auto_model_class": [],
    "main_input_name": [],
    "_supports_cache_class": [],
    "_is_stateful": [],
    "__init__": [
      "self"
    ],
    "use_cache": [
      "self"
    ],
    "use_merged": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "past_key_values",
      "position_ids",
      "use_cache"
    ],
    "prepare_inputs_for_generation": [
      "self"
    ],
    "_prepare_inputs_for_generation_legacy": [
      "self",
      "input_ids",
      "attention_mask",
      "past_key_values",
      "cache_position",
      "position_ids",
      "use_cache"
    ],
    "_reorder_cache": [
      "past_key_values",
      "beam_idx"
    ],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token",
      "file_name",
      "provider",
      "providers",
      "provider_options",
      "session_options",
      "use_cache",
      "use_io_binding",
      "generation_config",
      "dtype",
      "model_save_dir"
    ],
    "_export": [
      "cls",
      "model_id",
      "config",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token",
      "use_cache"
    ],
    "_save_config": [
      "self",
      "save_directory"
    ],
    "_prepare_cache_for_generation": [
      "self"
    ]
  },
  "_FEATURE_EXTRACTOR_FOR_DOC": [],
  "ONNX_TEXT_INPUTS_DOCSTRING": [],
  "ONNX_IMAGE_INPUTS_DOCSTRING": [],
  "ONNX_AUDIO_INPUTS_DOCSTRING": [],
  "ZeroShotImageClassificationOutput": {
    "to_tuple": [
      "self"
    ]
  },
  "ORTModel": {
    "model_type": [],
    "auto_model_class": [],
    "__init__": [
      "self"
    ],
    "_save_pretrained": [
      "self",
      "save_directory"
    ],
    "_cached_file": [
      "path_or_repo_id",
      "filename",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "token",
      "cache_dir"
    ],
    "_infer_file_path": [
      "pattern",
      "onnx_files",
      "standard_file_name",
      "target_file_name"
    ],
    "_from_pretrained": [
      "cls",
      "model_id",
      "config",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token",
      "file_name",
      "provider",
      "providers",
      "provider_options",
      "session_options",
      "use_io_binding",
      "dtype",
      "model_save_dir"
    ],
    "_export": [
      "cls",
      "model_id",
      "config",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token"
    ],
    "from_pretrained": [
      "cls",
      "model_id",
      "config",
      "export",
      "subfolder",
      "revision",
      "force_download",
      "local_files_only",
      "trust_remote_code",
      "cache_dir",
      "token",
      "provider",
      "providers",
      "provider_options",
      "session_options",
      "use_io_binding"
    ],
    "can_generate": [
      "self"
    ],
    "_warn_on_unhandled_inputs": [
      "self",
      "kwargs"
    ]
  },
  "FEATURE_EXTRACTION_EXAMPLE": [],
  "ORTModelForFeatureExtraction": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids",
      "position_ids",
      "pixel_values",
      "visual_embeds",
      "visual_attention_mask",
      "visual_token_type_ids",
      "input_features",
      "input_values"
    ]
  },
  "MASKED_LM_EXAMPLE": [],
  "ORTModelForMaskedLM": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "QUESTION_ANSWERING_EXAMPLE": [],
  "ORTModelForQuestionAnswering": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "SEQUENCE_CLASSIFICATION_EXAMPLE": [],
  "ORTModelForSequenceClassification": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "TOKEN_CLASSIFICATION_EXAMPLE": [],
  "ORTModelForTokenClassification": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "MULTIPLE_CHOICE_EXAMPLE": [],
  "ORTModelForMultipleChoice": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "token_type_ids"
    ]
  },
  "IMAGE_CLASSIFICATION_EXAMPLE": [],
  "ORTModelForImageClassification": {
    "auto_model_class": [],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "ORTModelForZeroShotImageClassification": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_ids",
      "pixel_values",
      "attention_mask"
    ]
  },
  "SEMANTIC_SEGMENTATION_EXAMPLE": [],
  "ORTModelForSemanticSegmentation": {
    "auto_model_class": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "AUDIO_CLASSIFICATION_EXAMPLE": [],
  "ORTModelForAudioClassification": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_values",
      "attention_mask",
      "input_features"
    ]
  },
  "CTC_EXAMPLE": [],
  "ORTModelForCTC": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_values",
      "input_features"
    ]
  },
  "AUDIO_XVECTOR_EXAMPLE": [],
  "ORTModelForAudioXVector": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_values"
    ]
  },
  "AUDIO_FRAME_CLASSIFICATION_EXAMPLE": [],
  "ORTModelForAudioFrameClassification": {
    "auto_model_class": [],
    "forward": [
      "self",
      "input_values"
    ]
  },
  "IMAGE_TO_IMAGE_EXAMPLE": [],
  "ORTModelForImageToImage": {
    "auto_model_class": [],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "CUSTOM_TASKS_EXAMPLE": [],
  "ORTModelForCustomTasks": {
    "forward": [
      "self"
    ]
  },
  "ORTStableDiffusion3Pipeline": {
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ORTStableDiffusion3Img2ImgPipeline": {
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ORTStableDiffusion3InpaintPipeline": {
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ORTFluxPipeline": {
    "__init__": [
      "self"
    ],
    "from_pretrained": [
      "cls"
    ]
  },
  "ONNX_WEIGHTS_NAME": [],
  "ONNX_ENCODER_NAME": [],
  "ONNX_DECODER_NAME": [],
  "ONNX_DECODER_WITH_PAST_NAME": [],
  "ONNX_DECODER_MERGED_NAME": [],
  "ENCODER_ONNX_FILE_PATTERN": [],
  "DECODER_ONNX_FILE_PATTERN": [],
  "DECODER_WITH_PAST_ONNX_FILE_PATTERN": [],
  "DECODER_MERGED_ONNX_FILE_PATTERN": [],
  "ONNX_FILE_PATTERN": [],
  "ORT_DEFAULT_CHANNEL_FOR_OPERATORS": [],
  "ORT_DEFAULT_OPS_DYNAMIC_QUANTIZATION": [],
  "ORT_DEFAULT_OPS_STATIC_QUANTIZATION_QDQ": [],
  "ORT_DEFAULT_OPS_STATIC_QUANTIZATION_QOPS": [],
  "CalibrationConfig": {
    "create_calibrator": [
      "self",
      "onnx_model_path",
      "operators_to_quantize",
      "use_external_data_format",
      "force_symmetric_range",
      "augmented_model_name"
    ]
  },
  "AutoCalibrationConfig": {
    "minmax": [
      "dataset",
      "moving_average",
      "averaging_constant"
    ],
    "entropy": [
      "dataset",
      "num_bins",
      "num_quantized_bins"
    ],
    "percentiles": [
      "dataset",
      "num_bins",
      "percentile"
    ]
  },
  "QuantizationConfig": {
    "__post_init__": [
      "self"
    ],
    "quantization_type_str": [
      "activations_dtype",
      "weights_dtype"
    ],
    "use_symmetric_calibration": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "ensure_valid_mode_or_raise": [
    "use_static_quantization",
    "mode"
  ],
  "ensure_valid_data_type_or_raise": [
    "use_static_quantization",
    "activations_dtype",
    "weights_dtype"
  ],
  "default_quantization_parameters": [
    "is_static",
    "format",
    "mode",
    "operators_to_quantize"
  ],
  "AutoQuantizationConfig": {
    "arm64": [
      "is_static",
      "use_symmetric_activations",
      "use_symmetric_weights",
      "per_channel",
      "nodes_to_quantize",
      "nodes_to_exclude",
      "operators_to_quantize"
    ],
    "avx2": [
      "is_static",
      "use_symmetric_activations",
      "use_symmetric_weights",
      "per_channel",
      "reduce_range",
      "nodes_to_quantize",
      "nodes_to_exclude",
      "operators_to_quantize"
    ],
    "avx512": [
      "is_static",
      "use_symmetric_activations",
      "use_symmetric_weights",
      "per_channel",
      "reduce_range",
      "nodes_to_quantize",
      "nodes_to_exclude",
      "operators_to_quantize"
    ],
    "avx512_vnni": [
      "is_static",
      "use_symmetric_activations",
      "use_symmetric_weights",
      "per_channel",
      "nodes_to_quantize",
      "nodes_to_exclude",
      "operators_to_quantize"
    ],
    "ppc64le": [
      "is_static",
      "use_symmetric_activations",
      "use_symmetric_weights",
      "per_channel",
      "nodes_to_quantize",
      "nodes_to_exclude",
      "operators_to_quantize"
    ],
    "tensorrt": [
      "per_channel",
      "nodes_to_quantize",
      "nodes_to_exclude",
      "operators_to_quantize"
    ]
  },
  "OptimizationConfig": {
    "create_fusion_options": [
      "self",
      "model_type"
    ]
  },
  "AutoOptimizationConfig": {
    "_LEVELS": [],
    "with_optimization_level": [
      "cls",
      "optimization_level",
      "for_gpu"
    ],
    "O1": [
      "cls",
      "for_gpu"
    ],
    "O2": [
      "cls",
      "for_gpu"
    ],
    "O3": [
      "cls",
      "for_gpu"
    ],
    "O4": [
      "cls",
      "for_gpu"
    ]
  },
  "ORTConfig": {
    "CONFIG_NAME": [],
    "FULL_CONFIGURATION_FILE": [],
    "__init__": [
      "self",
      "opset",
      "use_external_data_format",
      "one_external_file",
      "optimization",
      "quantization"
    ],
    "dataclass_to_dict": [
      "config"
    ],
    "to_dict": [
      "self"
    ]
  },
  "PreprocessorPass": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "graph",
      "model"
    ]
  },
  "QuantizationPreprocessor": {
    "__slots__": [],
    "__init__": [
      "self"
    ],
    "from_config": [
      "self",
      "config"
    ],
    "register_pass": [
      "self",
      "target"
    ],
    "collect": [
      "self",
      "model_or_path"
    ]
  },
  "__all__": [],
  "ExcludeNodeFollowedBy": {
    "__init__": [
      "self",
      "operator_type_to_exclude",
      "following_operator_type"
    ],
    "__call__": [
      "self",
      "_",
      "model"
    ]
  },
  "ExcludeNodeAfter": {
    "__init__": [
      "self",
      "parent_operator_type",
      "operator_type_to_exclude"
    ],
    "__call__": [
      "self",
      "graph",
      "model"
    ]
  },
  "ExcludeGeLUNodes": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "graph",
      "model"
    ]
  },
  "ExcludeLayerNormNodes": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "graph",
      "model"
    ]
  },
  "IncludeFullyConnectedNodes": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "graph",
      "model"
    ]
  },
  "ONNXRuntimeCommand": {
    "COMMAND": [],
    "SUBCOMMANDS": []
  },
  "parse_args_onnxruntime_quantize": [
    "parser"
  ],
  "ONNXRuntimeQuantizeCommand": {
    "parse_args": [
      "parser"
    ],
    "run": [
      "self"
    ]
  },
  "parse_args_onnxruntime_optimize": [
    "parser"
  ],
  "ONNXRuntimeOptimizeCommand": {
    "parse_args": [
      "parser"
    ],
    "run": [
      "self"
    ]
  },
  "REGISTER_COMMANDS": [],
  "parse_args_onnx": [
    "parser"
  ],
  "ONNXExportCommand": {
    "COMMAND": [],
    "parse_args": [
      "parser"
    ],
    "run": [
      "self"
    ]
  },
  "traceable_check_model_inputs": [
    "func"
  ],
  "GENERATE_DUMMY_DOCSTRING": [],
  "OnnxConfig": {
    "DEFAULT_ONNX_OPSET": [],
    "DEFAULT_VARIANT": [],
    "_MODEL_PATCHER": [],
    "_TASK_TO_COMMON_OUTPUTS": [],
    "__init__": [
      "self",
      "config",
      "task",
      "preprocessors",
      "int_dtype",
      "float_dtype"
    ],
    "variant": [
      "self",
      "value"
    ],
    "fix_dynamic_axes": [
      "self",
      "model_path",
      "device",
      "dtype",
      "input_shapes"
    ],
    "torch_to_onnx_input_map": [
      "self"
    ],
    "torch_to_onnx_output_map": [
      "self"
    ],
    "rename_ambiguous_inputs": [
      "self",
      "inputs"
    ],
    "ordered_inputs": [
      "self",
      "model"
    ],
    "flatten_output_collection_property": [
      "cls",
      "name",
      "field"
    ],
    "generate_dummy_inputs_for_validation": [
      "self",
      "reference_model_inputs",
      "onnx_input_names"
    ],
    "post_process_exported_models": [
      "self",
      "path",
      "models_and_onnx_configs",
      "onnx_files_subpaths"
    ],
    "patch_model_for_export": [
      "self",
      "model",
      "model_kwargs"
    ]
  },
  "OnnxConfigWithPast": {
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "use_past",
      "use_past_in_inputs",
      "preprocessors"
    ],
    "outputs": [
      "self"
    ],
    "values_override": [
      "self"
    ],
    "generate_dummy_inputs": [
      "self",
      "framework"
    ],
    "overwrite_shape_and_generate_input": [
      "self",
      "dummy_input_gen",
      "input_name",
      "framework",
      "input_shapes"
    ],
    "add_past_key_values": [
      "self",
      "inputs_or_outputs",
      "direction"
    ],
    "flatten_past_key_values": [
      "self",
      "flattened_output",
      "name",
      "idx",
      "t"
    ],
    "flatten_output_collection_property": [
      "self",
      "name",
      "field"
    ],
    "generate_dummy_inputs_for_validation": [
      "self",
      "reference_model_inputs",
      "onnx_input_names"
    ]
  },
  "ConfigBehavior": {
    "MONOLITH": [],
    "ENCODER": [],
    "DECODER": []
  },
  "OnnxSeq2SeqConfigWithPast": {
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "use_past",
      "use_past_in_inputs",
      "behavior",
      "preprocessors"
    ],
    "with_behavior": [
      "self",
      "behavior",
      "use_past",
      "use_past_in_inputs"
    ],
    "torch_to_onnx_input_map": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "add_past_key_values": [
      "self",
      "inputs_or_outputs",
      "direction"
    ],
    "flatten_past_key_values": [
      "self",
      "flattened_output",
      "name",
      "idx",
      "t"
    ],
    "post_process_exported_models": [
      "self",
      "path",
      "models_and_onnx_configs",
      "onnx_files_subpaths"
    ],
    "generate_dummy_inputs": [
      "self",
      "framework"
    ],
    "generate_dummy_inputs_for_validation": [
      "self",
      "reference_model_inputs",
      "onnx_input_names"
    ]
  },
  "MODEL_TYPES_REQUIRING_POSITION_IDS": [],
  "recursive_to_device": [
    "value",
    "device"
  ],
  "recursive_to_dtype": [
    "value",
    "dtype",
    "start_dtype"
  ],
  "PickableInferenceSession": {
    "__init__": [
      "self",
      "model_path",
      "sess_options",
      "providers"
    ],
    "run": [
      "self"
    ],
    "get_outputs": [
      "self"
    ],
    "get_inputs": [
      "self"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "values"
    ]
  },
  "_get_submodels_for_export_metaclip_2": [
    "model",
    "variant"
  ],
  "get_metaclip_2_models_for_export": [
    "model",
    "config"
  ],
  "get_sana_models_for_export": [
    "pipeline",
    "int_dtype",
    "float_dtype"
  ],
  "_get_submodels_and_onnx_configs": [
    "model",
    "task",
    "monolith",
    "custom_onnx_configs",
    "custom_architecture",
    "_variant",
    "library_name",
    "int_dtype",
    "float_dtype",
    "fn_get_submodels",
    "preprocessors",
    "model_kwargs"
  ],
  "DynamicAxisNameError": {},
  "validate_models_outputs": [
    "models_and_onnx_configs",
    "onnx_named_outputs",
    "output_dir",
    "atol",
    "onnx_files_subpaths",
    "input_shapes",
    "device",
    "use_subprocess",
    "model_kwargs"
  ],
  "validate_model_outputs": [
    "config",
    "reference_model",
    "onnx_model",
    "onnx_named_outputs",
    "atol",
    "input_shapes",
    "device",
    "use_subprocess",
    "model_kwargs"
  ],
  "_run_validation": [
    "config",
    "reference_model",
    "onnx_model",
    "onnx_named_outputs",
    "atol",
    "input_shapes",
    "device",
    "model_kwargs"
  ],
  "ValidationProcess": {
    "__init__": [
      "self",
      "config",
      "reference_model",
      "onnx_model",
      "onnx_named_outputs",
      "atol",
      "input_shapes",
      "device",
      "model_kwargs"
    ],
    "run": [
      "self"
    ],
    "exception": [
      "self"
    ]
  },
  "export_pytorch": [
    "model",
    "config",
    "opset",
    "output",
    "device",
    "input_shapes",
    "no_dynamic_axes",
    "do_constant_folding",
    "model_kwargs"
  ],
  "export_models": [
    "models_and_onnx_configs",
    "output_dir",
    "opset",
    "output_names",
    "device",
    "input_shapes",
    "disable_dynamic_axes_fix",
    "dtype",
    "no_dynamic_axes",
    "do_constant_folding",
    "model_kwargs"
  ],
  "export": [
    "model",
    "config",
    "output",
    "opset",
    "device",
    "input_shapes",
    "disable_dynamic_axes_fix",
    "dtype",
    "no_dynamic_axes",
    "do_constant_folding",
    "model_kwargs"
  ],
  "onnx_export_from_model": [
    "model",
    "output",
    "opset",
    "optimize",
    "monolith",
    "no_post_process",
    "atol",
    "do_validation",
    "model_kwargs",
    "custom_onnx_configs",
    "fn_get_submodels",
    "_variant",
    "preprocessors",
    "device",
    "no_dynamic_axes",
    "task",
    "use_subprocess",
    "do_constant_folding",
    "slim"
  ],
  "COMMON_TEXT_TASKS": [],
  "COMMON_TEXT_GENERATION_TASKS": [],
  "COMMON_TEXT2TEXT_GENERATION_TASKS": [],
  "register_tasks_manager_onnx": [],
  "BertOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "VisualBertOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "AlbertOnnxConfig": {},
  "ConvBertOnnxConfig": {},
  "ElectraOnnxConfig": {},
  "RoFormerOnnxConfig": {},
  "SqueezeBertOnnxConfig": {},
  "MobileBertOnnxConfig": {},
  "NystromformerOnnxConfig": {},
  "XLMOnnxConfig": {},
  "SplinterOnnxConfig": {},
  "RemBertOnnxConfig": {},
  "LongformerOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ]
  },
  "MegatronBertOnnxConfig": {},
  "DistilBertOnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "ModernBertOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "MPNetOnnxConfig": {},
  "RobertaOnnxConfig": {},
  "CamembertOnnxConfig": {},
  "FlaubertOnnxConfig": {},
  "IBertOnnxConfig": {},
  "XLMRobertaOnnxConfig": {},
  "DebertaOnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "MarkupLMOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ]
  },
  "DebertaV2OnnxConfig": {},
  "EsmOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "GPT2OnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "GPTJOnnxConfig": {},
  "CodeGenOnnxConfig": {},
  "ImageGPTOnnxConfig": {},
  "DecisionTransformerOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "GPTNeoOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "GPTNeoXOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "OPTOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "LlamaOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "NORMALIZED_CONFIG_CLASS": []
  },
  "ArceeOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "NORMALIZED_CONFIG_CLASS": []
  },
  "DeepSeekV3OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": []
  },
  "CohereOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "_MODEL_PATCHER": []
  },
  "GLMOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "HeliumOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "SmolLM3OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "StableLMOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "OlmoOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Olmo2OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Qwen2OnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Qwen3OnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Qwen3MoeOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": [],
    "_MODEL_PATCHER": []
  },
  "GemmaOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Gemma2OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Gemma3TextOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Gemma3OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "GPTOssOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "_MODEL_PATCHER": []
  },
  "NemotronOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "NORMALIZED_CONFIG_CLASS": []
  },
  "GraniteOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "PhiOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Phi3OnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": []
  },
  "InternLM2OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "MistralOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": []
  },
  "MPTOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "BloomOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "add_past_key_values": [
      "self",
      "inputs_or_outputs",
      "direction"
    ]
  },
  "GPTBigCodeOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "add_past_key_values": [
      "self",
      "inputs_or_outputs",
      "direction"
    ],
    "flatten_past_key_values": [
      "self",
      "flattened_output",
      "name",
      "idx",
      "t"
    ]
  },
  "FalconOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "T5OnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "NORMALIZED_CONFIG_CLASS": []
  },
  "MT5OnnxConfig": {},
  "LongT5OnnxConfig": {},
  "M2M100OnnxConfig": {
    "PAD_ATTENTION_MASK_TO_PAST": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "_create_dummy_input_generator_classes": [
      "self"
    ],
    "inputs_for_default_and_seq2seq_lm": [
      "self"
    ],
    "inputs_for_causal_lm": [
      "self"
    ],
    "inputs_for_other_tasks": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "flatten_past_key_values": [
      "self",
      "flattened_output",
      "name",
      "idx",
      "t"
    ]
  },
  "BartOnnxConfig": {},
  "MBartOnnxConfig": {},
  "BlenderbotOnnxConfig": {},
  "BlenderbotSmallOnnxConfig": {},
  "BigBirdOnnxConfig": {},
  "BigBirdPegasusOnnxConfig": {
    "_MODEL_PATCHER": []
  },
  "PegasusOnnxConfig": {},
  "MarianOnnxConfig": {},
  "ViTOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "VitPoseOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "_MODEL_PATCHER": [],
    "inputs": [
      "self"
    ]
  },
  "CvTOnnxConfig": {},
  "LevitOnnxConfig": {},
  "DeiTOnnxConfig": {},
  "BeitOnnxConfig": {},
  "ConvNextOnnxConfig": {},
  "ConvNextV2OnnxConfig": {},
  "HieraOnnxConfig": {},
  "PvtOnnxConfig": {},
  "VitMAEOnnxConfig": {},
  "VitMSNOnnxConfig": {},
  "Dinov2OnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": []
  },
  "MobileViTOnnxConfig": {},
  "RegNetOnnxConfig": {},
  "ResNetOnnxConfig": {},
  "DetrOnnxConfig": {
    "outputs": [
      "self"
    ]
  },
  "TableTransformerOnnxConfig": {},
  "YolosOnnxConfig": {},
  "SwinOnnxConfig": {},
  "SwinV2OnnxConfig": {},
  "Swin2srOnnxConfig": {
    "outputs": [
      "self"
    ]
  },
  "DptOnnxConfig": {},
  "GlpnOnnxConfig": {},
  "PoolFormerOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "SegformerOnnxConfig": {
    "outputs": [
      "self"
    ]
  },
  "MobileNetV1OnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "MobileNetV2OnnxConfig": {},
  "MaskFormerOnnxConfig": {
    "outputs": [
      "self"
    ],
    "torch_to_onnx_output_map": [
      "self"
    ]
  },
  "DonutSwinOnnxConfig": {},
  "TimmDefaultOnnxConfig": {
    "rename_ambiguous_inputs": [
      "self",
      "inputs"
    ],
    "torch_to_onnx_input_map": [
      "self"
    ]
  },
  "MgpstrOnnxConfig": {
    "_MODEL_PATCHER": [],
    "outputs": [
      "self"
    ]
  },
  "EfficientNetOnnxConfig": {
    "outputs": [
      "self"
    ]
  },
  "SentenceTransformersTransformerOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "_MODEL_PATCHER": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "CLIPNormalizedConfig": {
    "TEXT_CONFIG": [],
    "VISION_CONFIG": []
  },
  "CLIPVisionModelOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "_MODEL_PATCHER": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "CLIPOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "_MODEL_PATCHER": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "SentenceTransformersCLIPOnnxConfig": {
    "_MODEL_PATCHER": [],
    "outputs": [
      "self"
    ]
  },
  "CLIPTextWithProjectionOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "_MODEL_PATCHER": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "CLIPTextOnnxConfig": {
    "_MODEL_PATCHER": [],
    "outputs": [
      "self"
    ]
  },
  "MetaCLIP2OnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "MIN_TRANSFORMERS_VERSION": [],
    "VARIANTS": [],
    "DEFAULT_VARIANT": [],
    "_MODEL_PATCHER": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "variant",
      "vision_model",
      "preprocessors"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "SiglipNormalizedConfig": {},
  "ChineseCLIPOnnxConfig": {},
  "SiglipOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "SiglipTextWithProjectionOnnxConfig": {},
  "SiglipTextOnnxConfig": {},
  "SiglipVisionModelOnnxConfig": {},
  "UNetOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "torch_to_onnx_output_map": [
      "self"
    ],
    "generate_dummy_inputs": [
      "self",
      "framework"
    ],
    "ordered_inputs": [
      "self",
      "model"
    ]
  },
  "VaeEncoderOnnxConfig": {
    "ATOL_FOR_VALIDATION": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "VaeDecoderOnnxConfig": {
    "ATOL_FOR_VALIDATION": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "T5EncoderOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "SD3TransformerOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "torch_to_onnx_output_map": [
      "self"
    ]
  },
  "FluxTransformerOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "_MODEL_PATCHER": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "GroupViTOnnxConfig": {},
  "OwlViTOnnxConfig": {
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "preprocessors"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "OwlV2OnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "LayoutLMOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "LayoutLMv3OnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "LiltOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "Data2VecTextOnnxConfig": {},
  "Data2VecVisionOnnxConfig": {},
  "PerceiverOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "preprocessors"
    ],
    "inputs_name": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "generate_dummy_inputs": [
      "self",
      "framework"
    ]
  },
  "HubertOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "outputs": [
      "self"
    ]
  },
  "Data2VecAudioOnnxConfig": {},
  "Wav2Vec2OnnxConfig": {},
  "Wav2Vec2ConformerOnnxConfig": {},
  "SEWOnnxConfig": {},
  "SEWDOnnxConfig": {},
  "UniSpeechOnnxConfig": {},
  "UniSpeechSATOnnxConfig": {},
  "WavLMOnnxConfig": {},
  "MCTCTOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "ASTOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ]
  },
  "MoonshineOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "_MODEL_PATCHER": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "WhisperOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "MusicgenOnnxConfig": {
    "VARIANTS": [],
    "DEFAULT_VARIANT": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "_MODEL_PATCHER": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "use_past",
      "use_past_in_inputs",
      "behavior",
      "preprocessors",
      "model_part",
      "variant"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "overwrite_shape_and_generate_input": [
      "self",
      "dummy_input_gen",
      "input_name",
      "framework",
      "input_shapes"
    ]
  },
  "SpeechT5OnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "VARIANTS": [],
    "DEFAULT_VARIANT": [],
    "_MODEL_PATCHER": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "use_past",
      "use_past_in_inputs",
      "behavior",
      "preprocessors",
      "is_postnet_and_vocoder"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "overwrite_shape_and_generate_input": [
      "self",
      "dummy_input_gen",
      "input_name",
      "framework",
      "input_shapes"
    ]
  },
  "VitsOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "Speech2TextOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "TrOCROnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "VisionEncoderDecoderOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "SamOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "VARIANTS": [],
    "DEFAULT_VARIANT": [],
    "_MODEL_PATCHER": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "variant",
      "vision_encoder",
      "preprocessors"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "Pix2StructNormalizedConfig": {
    "ENCODER_NUM_LAYERS": [],
    "DECODER_NUM_LAYERS": [],
    "ENCODER_NUM_ATTENTION_HEADS": [],
    "DECODER_NUM_ATTENTION_HEADS": [],
    "HIDDEN_SIZE": [],
    "VOCAB_SIZE": []
  },
  "Pix2StructOnnxConfig": {
    "PAD_ATTENTION_MASK_TO_PAST": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "__init__": [
      "self"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "_create_dummy_input_generator_classes": [
      "self"
    ],
    "overwrite_shape_and_generate_input": [
      "self",
      "dummy_input_gen",
      "input_name",
      "framework",
      "input_shapes"
    ]
  },
  "EncoderDecoderOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": []
  },
  "PatchTSTOnnxConfig": {
    "NORMALIZED_CONFIG_CLASS": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "PatchTSMixerOnnxConfig": {},
  "RTDetrOnnxConfig": {
    "inputs": [
      "self"
    ],
    "_create_dummy_input_generator_classes": [
      "self"
    ]
  },
  "RTDetrV2OnnxConfig": {},
  "ColPaliOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "VARIANTS": [],
    "DEFAULT_VARIANT": [],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "generate_dummy_inputs": [
      "self",
      "framework"
    ]
  },
  "DFineOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "Gemma2TextEncoderOnnxConfig": {
    "MIN_TRANSFORMERS_VERSION": []
  },
  "SanaTransformerOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "NORMALIZED_CONFIG_CLASS": [],
    "inputs": [
      "self"
    ]
  },
  "DcaeEncoderOnnxConfig": {
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "DcaeDecoderOnnxConfig": {
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ]
  },
  "TextEncoderOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": []
  },
  "TextDecoderOnnxConfig": {
    "PAD_ATTENTION_MASK_TO_PAST": [],
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "DUMMY_PKV_GENERATOR_CLASS": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "use_past",
      "use_past_in_inputs",
      "preprocessors"
    ],
    "inputs": [
      "self"
    ],
    "outputs": [
      "self"
    ],
    "post_process_exported_models": [
      "self",
      "path",
      "models_and_onnx_configs",
      "onnx_files_subpaths"
    ]
  },
  "TextDecoderWithPositionIdsOnnxConfig": {
    "inputs": [
      "self"
    ]
  },
  "TextSeq2SeqOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ],
    "_create_dummy_input_generator_classes": [
      "self"
    ]
  },
  "VisionOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": []
  },
  "TextAndVisionOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": []
  },
  "AudioOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ]
  },
  "AudioToTextOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "inputs": [
      "self"
    ]
  },
  "EncoderDecoderBaseOnnxConfig": {
    "DUMMY_INPUT_GENERATOR_CLASSES": [],
    "__init__": [
      "self",
      "config",
      "task",
      "int_dtype",
      "float_dtype",
      "use_past",
      "use_past_in_inputs",
      "behavior",
      "preprocessors"
    ],
    "inputs": [
      "self"
    ],
    "add_past_key_values": [
      "self",
      "inputs_or_outputs",
      "direction"
    ],
    "flatten_past_key_values": [
      "self",
      "flattened_output",
      "name",
      "idx",
      "t"
    ],
    "flatten_output_collection_property": [
      "self",
      "name",
      "field"
    ],
    "generate_dummy_inputs_for_validation": [
      "self",
      "reference_model_inputs",
      "onnx_input_names"
    ],
    "post_process_exported_models": [
      "self",
      "path",
      "models_and_onnx_configs",
      "onnx_files_subpaths"
    ]
  },
  "GPTBigCodeDummyPastKeyValuesGenerator": {
    "__init__": [
      "self",
      "task",
      "normalized_config"
    ],
    "generate": [
      "self",
      "input_name",
      "framework",
      "int_dtype",
      "float_dtype"
    ]
  },
  "DummyMoonshineAudioInputGenerator": {
    "SUPPORTED_INPUT_NAMES": [],
    "generate": [
      "self",
      "input_name",
      "framework",
      "int_dtype",
      "float_dtype"
    ]
  },
  "DummySanaTransforemerTextInputGenerator": {
    "SUPPORTED_INPUT_NAMES": [],
    "generate": [
      "self",
      "input_name",
      "framework",
      "int_dtype",
      "float_dtype"
    ]
  },
  "__ior_": [
    "g",
    "self",
    "other"
  ],
  "patch_everywhere": [
    "attribute_name",
    "patch",
    "module_name_prefix"
  ],
  "override_arguments": [
    "args",
    "kwargs",
    "forward_signature",
    "model_kwargs"
  ],
  "preprocess_encoder_outputs": [
    "encoder_outputs"
  ],
  "preprocess_past_key_values": [
    "past_key_values"
  ],
  "postprocess_past_key_values": [
    "past_key_values",
    "output_names"
  ],
  "PatchingSpec": {},
  "onnx_compatible_unfold": [
    "input_tensor",
    "dimension",
    "size",
    "step"
  ],
  "onnx_compatible_repeat_interleave": [
    "input_tensor",
    "repeats",
    "dim",
    "output_size"
  ],
  "onnx_compatible_linalg_norm": [
    "x",
    "ord",
    "dim",
    "keepdim"
  ],
  "onnx_compatible_rms_norm": [
    "input",
    "normalized_shape",
    "weight",
    "eps"
  ],
  "find_packed_sequence_indices_patched": [
    "position_ids"
  ],
  "sdpa_mask_without_vmap": [
    "batch_size",
    "cache_position",
    "kv_length",
    "kv_offset",
    "mask_function",
    "attention_mask",
    "local_size",
    "allow_is_causal_skip"
  ],
  "eager_mask_without_vmap": [],
  "original_triu": [],
  "original_tril": [],
  "onnx_compatible_tril": [
    "input_tensor"
  ],
  "onnx_compatible_triu": [
    "input_tensor"
  ],
  "original_scaled_dot_product_attention": [],
  "traceable_scaled_dot_product_attention": [
    "query",
    "key",
    "value",
    "attn_mask",
    "dropout_p",
    "is_causal"
  ],
  "noop_bfloat16_casting": [
    "self"
  ],
  "original_movedim": [],
  "onnx_compatible_movedim": [
    "self",
    "dim1",
    "dim2"
  ],
  "patched_dynamic_layer_update": [
    "self",
    "key_states",
    "value_states",
    "cache_kwargs"
  ],
  "UNSUPPORTED_OPS_PATCHING_SPEC": [],
  "ModelPatcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ],
    "patch_ops": [
      "self"
    ],
    "restore_ops": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "__call__": [
      "self"
    ]
  },
  "BigBirdPegasusModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "MgpstrModelPatcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "SAMModelPatcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "patched_speecht5_prenet_forward": [
    "self",
    "input_values",
    "speaker_embeddings"
  ],
  "SpeechT5ModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "SentenceTransformersTransformerPatcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "SentenceTransformersCLIPPatcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "triu_onnx": [
    "x",
    "diagonal"
  ],
  "patched_build_delay_pattern_mask": [
    "self",
    "input_ids",
    "pad_token_id",
    "max_length"
  ],
  "MusicgenModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "MetaCLIP2Patcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "CLIPModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "VitPoseModelPatcher": {
    "__init__": [
      "self",
      "config",
      "model",
      "model_kwargs"
    ]
  },
  "qwen3_moe_forward_patched": [
    "self",
    "hidden_states"
  ],
  "Qwen3MoeModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "_get_feat_extract_output_lengths_patched": [
    "self",
    "input_lengths"
  ],
  "MoonshineModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "patched_apply_rotary_emb": [
    "x",
    "freqs_cis",
    "use_real",
    "use_real_unbind_dim",
    "sequence_dim"
  ],
  "FluxTransformerModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "patched_cohere_rotary_forward": [
    "self",
    "x",
    "position_ids"
  ],
  "CohereModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "gpt_oss_forward": [
    "self",
    "hidden_states",
    "router_indices",
    "routing_weights"
  ],
  "GptOssModelPatcher": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "EXTERNAL_DATA_FORMAT_SIZE_LIMIT": [],
  "UNPICKABLE_ARCHS": [],
  "SDPA_ARCHS_ONNX_EXPORT_NOT_SUPPORTED": [],
  "TraceableCache": {
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "key_states",
      "value_states",
      "layer_idx",
      "cache_kwargs"
    ],
    "get_seq_length": [
      "self",
      "layer_idx"
    ],
    "get_max_length": [
      "self"
    ],
    "get_max_cache_shape": [
      "self"
    ],
    "get_usable_length": [
      "self",
      "new_seq_length",
      "layer_idx"
    ],
    "reorder_cache": [
      "self",
      "beam_idx"
    ],
    "seen_tokens": [
      "self"
    ]
  },
  "main_export": [
    "model_name_or_path",
    "output",
    "task",
    "opset",
    "device",
    "dtype",
    "optimize",
    "monolith",
    "no_post_process",
    "framework",
    "atol",
    "pad_token_id",
    "subfolder",
    "revision",
    "force_download",
    "local_files_only",
    "trust_remote_code",
    "cache_dir",
    "token",
    "do_validation",
    "model_kwargs",
    "custom_onnx_configs",
    "fn_get_submodels",
    "use_subprocess",
    "_variant",
    "library_name",
    "no_dynamic_axes",
    "do_constant_folding",
    "slim"
  ],
  "main": [],
  "__version__": [],
  "_get_onnx_external_constants": [
    "model"
  ],
  "_get_onnx_external_data_tensors": [
    "model"
  ],
  "_get_external_data_paths": [
    "src_paths",
    "dst_paths"
  ],
  "_get_model_external_data_paths": [
    "model_path"
  ],
  "check_model_uses_external_data": [
    "model"
  ],
  "has_onnx_input": [
    "model",
    "input_name"
  ],
  "remove_duplicate_weights": [
    "model",
    "inplace"
  ],
  "remove_duplicate_weights_from_tied_info": [
    "onnx_model",
    "torch_model",
    "tied_params",
    "save_path"
  ],
  "replace_atenops_to_gather": [
    "model"
  ],
  "check_and_save_model": [
    "model",
    "save_path"
  ],
  "merge_decoders": [
    "decoder",
    "decoder_with_past",
    "graph_name",
    "producer_name",
    "save_path",
    "strict"
  ],
  "cast_slice_nodes_inputs_to_int32": [
    "model"
  ],
  "_find_duplicate_initializers": [
    "models"
  ],
  "_create_name_sharing_dict": [
    "duplicate_weights",
    "suffix"
  ],
  "_replace_input_names": [
    "models",
    "name_sharing_dict"
  ],
  "_remove_redundant_initializers": [
    "models",
    "name_sharing_dict"
  ],
  "_infer_output_shape": [
    "output"
  ],
  "_unify_onnx_outputs": [
    "model1",
    "model2",
    "strict"
  ],
  "_get_all_inputs": [
    "model_list"
  ],
  "_get_onnx_opset": [
    "model"
  ],
  "_deduplicated_cross_model_initializers": [
    "models",
    "suffix"
  ],
  "cast_int64_tensorproto_to_int32": [
    "initializer",
    "cast"
  ],
  "_get_weights_to_tie": [
    "tied_params",
    "torch_model"
  ],
  "_find_matching_initializers": [
    "tied_params_with_op",
    "model",
    "initializer_name_to_idx"
  ],
  "_deduplicate_gather_matmul": [
    "model",
    "tied_groups_to_tie",
    "tied_groups_map",
    "initializer_name_to_idx"
  ]
}