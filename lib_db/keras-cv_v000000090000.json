{
  "__dir__": [],
  "__all__": [],
  "MIN_VERSION": [],
  "check_tf_version": [],
  "__version__": [],
  "version": [],
  "maybe_register_serializable": [
    "symbol",
    "package"
  ],
  "CENTER_XYZ_DXDYDZ_PHI": {
    "X": [],
    "Y": [],
    "Z": [],
    "DX": [],
    "DY": [],
    "DZ": [],
    "PHI": [],
    "CLASS": []
  },
  "keras_cv_custom_ops": [],
  "iou_3d": [
    "y_true",
    "y_pred"
  ],
  "IoULoss": {
    "__init__": [
      "self",
      "bounding_box_format",
      "mode",
      "axis"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "l1": [
    "y_true",
    "y_pred",
    "sigma"
  ],
  "CenterNetBoxLoss": {
    "__init__": [
      "self",
      "num_heading_bins",
      "anchor_size"
    ],
    "heading_regression_loss": [
      "self",
      "heading_true",
      "heading_pred"
    ],
    "regression_loss": [
      "self",
      "y_true",
      "y_pred"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "FocalLoss": {
    "__init__": [
      "self",
      "alpha",
      "gamma",
      "from_logits",
      "label_smoothing"
    ],
    "_smooth_labels": [
      "self",
      "y_true"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "BinaryPenaltyReducedFocalCrossEntropy": {
    "__init__": [
      "self",
      "alpha",
      "beta",
      "from_logits",
      "positive_threshold",
      "positive_weight",
      "negative_weight",
      "reduction",
      "name"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "SmoothL1Loss": {
    "__init__": [
      "self",
      "l1_cutoff"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "CIoULoss": {
    "__init__": [
      "self",
      "bounding_box_format",
      "eps"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "LARGE_NUM": [],
  "l2_normalize": [
    "x",
    "axis"
  ],
  "SimCLRLoss": {
    "__init__": [
      "self",
      "temperature"
    ],
    "call": [
      "self",
      "projections_1",
      "projections_2"
    ],
    "get_config": [
      "self"
    ]
  },
  "GIoULoss": {
    "__init__": [
      "self",
      "bounding_box_format",
      "axis"
    ],
    "_compute_enclosure": [
      "self",
      "boxes1",
      "boxes2"
    ],
    "_compute_giou": [
      "self",
      "boxes1",
      "boxes2"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred",
      "sample_weight"
    ],
    "get_config": [
      "self"
    ]
  },
  "TestCase": {
    "assertAllClose": [
      "self",
      "x1",
      "x2",
      "atol",
      "rtol",
      "msg"
    ],
    "assertAllEqual": [
      "self",
      "x1",
      "x2",
      "msg"
    ],
    "assertAllGreaterEqual": [
      "self",
      "x1",
      "x2"
    ],
    "assertAllLessEqual": [
      "self",
      "x1",
      "x2"
    ]
  },
  "convert_to_numpy": [
    "x"
  ],
  "HidePrints": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "_box_concat": [
    "boxes"
  ],
  "METRIC_NAMES": [],
  "METRIC_MAPPING": [],
  "BoxCOCOMetrics": {
    "__init__": [
      "self",
      "bounding_box_format",
      "evaluate_freq",
      "name"
    ],
    "__new__": [
      "cls"
    ],
    "name_prefix": [
      "self"
    ],
    "update_state": [
      "self",
      "y_true",
      "y_pred",
      "sample_weight"
    ],
    "reset_state": [
      "self"
    ],
    "result": [
      "self",
      "force"
    ],
    "_compute_result": [
      "self"
    ]
  },
  "compute_pycocotools_metric": [
    "y_true",
    "y_pred",
    "bounding_box_format"
  ],
  "PyCOCOWrapper": {
    "__init__": [
      "self",
      "gt_dataset"
    ],
    "loadRes": [
      "self",
      "predictions"
    ]
  },
  "_yxyx_to_xywh": [
    "boxes"
  ],
  "_convert_predictions_to_coco_annotations": [
    "predictions"
  ],
  "_convert_groundtruths_to_coco_dataset": [
    "groundtruths",
    "label_map"
  ],
  "_concat_numpy": [
    "groundtruths",
    "predictions"
  ],
  "compute_pycoco_metrics": [
    "groundtruths",
    "predictions"
  ],
  "ContrastiveTrainer": {
    "__init__": [
      "self",
      "encoder",
      "augmenter",
      "projector",
      "probe"
    ],
    "compile": [
      "self",
      "encoder_loss",
      "encoder_optimizer",
      "encoder_metrics",
      "probe_optimizer",
      "probe_loss",
      "probe_metrics"
    ],
    "metrics": [
      "self"
    ],
    "fit": [
      "self",
      "x",
      "y",
      "sample_weight",
      "batch_size"
    ],
    "run_augmenters": [
      "self",
      "x",
      "y"
    ],
    "train_step": [
      "self",
      "data"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "linear_probe": [
      "num_classes"
    ]
  },
  "SimCLRTrainer": {
    "__init__": [
      "self",
      "encoder",
      "augmenter",
      "projection_width"
    ]
  },
  "SimCLRAugmenter": {
    "__init__": [
      "self",
      "value_range",
      "height",
      "width",
      "crop_area_factor",
      "aspect_ratio_factor",
      "grayscale_rate",
      "color_jitter_rate",
      "brightness_factor",
      "contrast_factor",
      "saturation_factor",
      "hue_factor"
    ]
  },
  "XY": {
    "X": [],
    "Y": [],
    "CLASS": [],
    "CONFIDENCE": []
  },
  "REL_XY": {
    "X": [],
    "Y": [],
    "CLASS": [],
    "CONFIDENCE": []
  },
  "H_AXIS": [],
  "W_AXIS": [],
  "filter_out_of_image": [
    "keypoints",
    "image"
  ],
  "_RequiresImagesException": {},
  "_rel_xy_to_xy": [
    "keypoints",
    "images"
  ],
  "_xy_to_rel_xy": [
    "keypoints",
    "images"
  ],
  "_xy_noop": [
    "keypoints",
    "images"
  ],
  "TO_XY_CONVERTERS": [],
  "FROM_XY_CONVERTERS": [],
  "convert_format": [
    "keypoints",
    "source",
    "target",
    "images",
    "dtype"
  ],
  "_format_inputs": [
    "keypoints",
    "images"
  ],
  "_format_outputs": [
    "result",
    "squeeze_axis"
  ],
  "PointTensors": {},
  "LabelTensors": {},
  "_generate_frames": [
    "segments",
    "transformer"
  ],
  "load": [
    "tfrecord_path",
    "transformer",
    "output_signature"
  ],
  "WOD_FRAME_OUTPUT_SIGNATURE": [],
  "_MAX_NUM_NON_TOP_LIDAR_POINTS": [],
  "_decode_range_images": [
    "frame"
  ],
  "_get_range_image_top_pose": [
    "frame"
  ],
  "_get_point_top_lidar": [
    "range_image",
    "frame"
  ],
  "_get_lidar_calibration": [
    "frame",
    "name"
  ],
  "_downsample": [
    "point",
    "n"
  ],
  "_get_point_lidar": [
    "ris",
    "frame",
    "max_num_points"
  ],
  "_get_point": [
    "frame",
    "max_num_lidar_points"
  ],
  "_get_point_label_box": [
    "frame"
  ],
  "_get_box_class_per_point": [
    "box",
    "box_class",
    "point_xyz"
  ],
  "_get_point_label": [
    "frame",
    "point_xyz"
  ],
  "_point_vehicle_to_global": [
    "point_vehicle_xyz",
    "sdc_pose"
  ],
  "_point_global_to_vehicle": [
    "point_xyz",
    "sdc_pose"
  ],
  "_box_3d_vehicle_to_global": [
    "box_3d",
    "sdc_pose"
  ],
  "_box_3d_global_to_vehicle": [
    "box_3d",
    "sdc_pose"
  ],
  "build_tensors_from_wod_frame": [
    "frame"
  ],
  "pad_or_trim_tensors": [
    "frame",
    "max_num_point",
    "max_num_label_box"
  ],
  "transform_to_vehicle_frame": [
    "frame"
  ],
  "convert_to_center_pillar_inputs": [
    "frame"
  ],
  "build_tensors_for_augmentation": [
    "frame"
  ],
  "curry_map_function": [
    "bounding_box_format"
  ],
  "VOC_URL": [],
  "SBD_URL": [],
  "CLASSES": [],
  "CLASS_TO_INDEX": [],
  "VOC_PNG_COLOR_VALUE": [],
  "VOC_PNG_COLOR_MAPPING": [],
  "_maybe_populate_voc_color_mapping": [],
  "_download_data_file": [
    "data_url",
    "extracted_dir",
    "local_dir_path",
    "override_extract"
  ],
  "_parse_annotation_data": [
    "annotation_file_path"
  ],
  "_get_image_ids": [
    "data_dir",
    "split"
  ],
  "_get_sbd_image_ids": [
    "data_dir",
    "split"
  ],
  "_parse_single_image": [
    "image_file_path"
  ],
  "_parse_single_sbd_image": [
    "image_file_path"
  ],
  "_build_metadata": [
    "data_dir",
    "image_ids"
  ],
  "_build_sbd_metadata": [
    "data_dir",
    "image_ids"
  ],
  "_decode_png_mask": [
    "mask"
  ],
  "_load_images": [
    "example"
  ],
  "_load_sbd_images": [
    "image_file_path",
    "seg_cls_file_path",
    "seg_obj_file_path"
  ],
  "_build_dataset_from_metadata": [
    "metadata"
  ],
  "_build_sbd_dataset_from_metadata": [
    "metadata"
  ],
  "_load_voc": [
    "split",
    "data_dir"
  ],
  "_load_sbd": [
    "split",
    "data_dir"
  ],
  "parse_imagenet_example": [
    "img_size",
    "crop_to_aspect_ratio"
  ],
  "XYXY": {
    "LEFT": [],
    "TOP": [],
    "RIGHT": [],
    "BOTTOM": []
  },
  "REL_XYXY": {
    "LEFT": [],
    "TOP": [],
    "RIGHT": [],
    "BOTTOM": []
  },
  "CENTER_XYWH": {
    "X": [],
    "Y": [],
    "WIDTH": [],
    "HEIGHT": []
  },
  "XYWH": {
    "X": [],
    "Y": [],
    "WIDTH": [],
    "HEIGHT": []
  },
  "REL_XYWH": {
    "X": [],
    "Y": [],
    "WIDTH": [],
    "HEIGHT": []
  },
  "YXYX": {
    "TOP": [],
    "LEFT": [],
    "BOTTOM": [],
    "RIGHT": []
  },
  "REL_YXYX": {
    "TOP": [],
    "LEFT": [],
    "BOTTOM": [],
    "RIGHT": []
  },
  "mask_invalid_detections": [
    "bounding_boxes",
    "output_ragged"
  ],
  "validate_format": [
    "bounding_boxes",
    "variable_name"
  ],
  "ensure_tensor": [
    "boxes",
    "dtype"
  ],
  "is_relative": [
    "bounding_box_format"
  ],
  "as_relative": [
    "bounding_box_format"
  ],
  "_relative_area": [
    "boxes",
    "bounding_box_format"
  ],
  "clip_to_image": [
    "bounding_boxes",
    "bounding_box_format",
    "images",
    "image_shape"
  ],
  "_clip_boxes": [
    "boxes",
    "box_format",
    "image_shape"
  ],
  "to_ragged": [
    "bounding_boxes",
    "sentinel",
    "dtype"
  ],
  "RequiresImagesException": {},
  "ALL_AXES": [],
  "_encode_box_to_deltas": [
    "anchors",
    "boxes",
    "anchor_format",
    "box_format",
    "variance",
    "image_shape"
  ],
  "_decode_deltas_to_boxes": [
    "anchors",
    "boxes_delta",
    "anchor_format",
    "box_format",
    "variance",
    "image_shape"
  ],
  "_center_yxhw_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_center_xywh_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xywh_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_center_yxhw": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_rel_xywh_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_no_op": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_xywh": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_rel_xywh": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_center_xywh": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_rel_xyxy_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_rel_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_yxyx_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_rel_yxyx_to_xyxy": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_yxyx": [
    "boxes",
    "images",
    "image_shape"
  ],
  "_xyxy_to_rel_yxyx": [
    "boxes",
    "images",
    "image_shape"
  ],
  "TO_XYXY_CONVERTERS": [],
  "FROM_XYXY_CONVERTERS": [],
  "_validate_image_shape": [
    "image_shape"
  ],
  "_image_shape": [
    "images",
    "image_shape",
    "boxes"
  ],
  "_compute_area": [
    "box"
  ],
  "_compute_intersection": [
    "boxes1",
    "boxes2"
  ],
  "compute_iou": [
    "boxes1",
    "boxes2",
    "bounding_box_format",
    "use_masking",
    "mask_val",
    "images",
    "image_shape"
  ],
  "compute_ciou": [
    "boxes1",
    "boxes2",
    "bounding_box_format"
  ],
  "_box_shape": [
    "batched",
    "boxes_shape",
    "max_boxes"
  ],
  "_classes_shape": [
    "batched",
    "classes_shape",
    "max_boxes"
  ],
  "to_dense": [
    "bounding_boxes",
    "max_boxes",
    "default_value"
  ],
  "KAGGLE_PREFIX": [],
  "GS_PREFIX": [],
  "get_file": [
    "preset",
    "path"
  ],
  "recursive_pop": [
    "config",
    "key"
  ],
  "save_to_preset": [
    "layer",
    "preset",
    "save_weights",
    "config_filename",
    "weights_filename"
  ],
  "load_from_preset": [
    "preset",
    "load_weights",
    "input_shape",
    "config_file",
    "config_overrides"
  ],
  "check_preset_class": [
    "preset",
    "classes",
    "config_file"
  ],
  "legacy_load_weights": [
    "layer",
    "weights_path"
  ],
  "to_numpy": [
    "x"
  ],
  "exhaustive_compare": [
    "obj1",
    "obj2"
  ],
  "config_equals": [
    "config1",
    "config2"
  ],
  "classproperty": {
    "__get__": [
      "self",
      "_",
      "owner_cls"
    ]
  },
  "format_docstring": [],
  "scale_loss_for_distribution": [
    "loss_value"
  ],
  "convert_inputs_to_tf_dataset": [
    "x",
    "y",
    "sample_weight",
    "batch_size"
  ],
  "get_feature_extractor": [
    "model",
    "layer_names",
    "output_keys"
  ],
  "_target_gather": [
    "targets",
    "indices",
    "mask",
    "mask_val"
  ],
  "normalize_tuple": [
    "value",
    "n",
    "name",
    "allow_zero"
  ],
  "_TF_INTERPOLATION_METHODS": [],
  "get_interpolation": [
    "interpolation"
  ],
  "transform_value_range": [
    "images",
    "original_range",
    "target_range",
    "dtype"
  ],
  "_unwrap_value_range": [
    "value_range",
    "dtype"
  ],
  "blend": [
    "image1",
    "image2",
    "factor"
  ],
  "parse_factor": [
    "param",
    "min_value",
    "max_value",
    "param_name",
    "seed"
  ],
  "random_inversion": [
    "random_generator"
  ],
  "batch_random_inversion": [
    "random_generator",
    "batch_size"
  ],
  "get_rotation_matrix": [
    "angles",
    "image_height",
    "image_width",
    "name"
  ],
  "get_translation_matrix": [
    "translations",
    "name"
  ],
  "transform": [
    "images",
    "transforms",
    "fill_mode",
    "fill_value",
    "interpolation",
    "output_shape",
    "name"
  ],
  "check_fill_mode_and_interpolation": [
    "fill_mode",
    "interpolation"
  ],
  "TF_VERSION_FOR_ABI_COMPATIBILITY": [],
  "abi_warning_already_raised": [],
  "get_project_root": [],
  "get_path_to_datafile": [
    "path"
  ],
  "LazySO": {
    "__init__": [
      "self",
      "relative_path"
    ],
    "ops": [
      "self"
    ],
    "display_warning_if_incompatible": [
      "self"
    ]
  },
  "abi_is_compatible": [],
  "_axis_mask": [
    "starts",
    "ends",
    "mask_len"
  ],
  "corners_to_mask": [
    "bounding_boxes",
    "mask_shape"
  ],
  "fill_rectangle": [
    "images",
    "centers_x",
    "centers_y",
    "widths",
    "heights",
    "fill_values"
  ],
  "assert_cv2_installed": [
    "symbol_name"
  ],
  "assert_matplotlib_installed": [
    "symbol_name"
  ],
  "assert_waymo_open_dataset_installed": [
    "symbol_name"
  ],
  "assert_pycocotools_installed": [
    "symbol_name"
  ],
  "WaymoEvaluationCallback": {
    "__init__": [
      "self",
      "validation_data",
      "config"
    ],
    "_get_default_config": [
      "self"
    ],
    "on_epoch_end": [
      "self",
      "epoch",
      "logs"
    ],
    "_eval_dataset": [
      "self",
      "dataset"
    ]
  },
  "PyCOCOCallback": {
    "__init__": [
      "self",
      "validation_data",
      "bounding_box_format",
      "cache"
    ],
    "on_epoch_end": [
      "self",
      "epoch",
      "logs"
    ]
  },
  "PatchingAndEmbedding": {
    "__init__": [
      "self",
      "project_dim",
      "patch_size",
      "padding"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "images",
      "interpolate",
      "interpolate_width",
      "interpolate_height",
      "patch_size"
    ],
    "__interpolate_positional_embeddings": [
      "self",
      "embedding",
      "height",
      "width",
      "patch_size"
    ],
    "get_config": [
      "self"
    ]
  },
  "SpatialPyramidPooling": {
    "__init__": [
      "self",
      "dilation_rates",
      "num_channels",
      "activation",
      "dropout"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "get_config": [
      "self"
    ]
  },
  "BN_AXIS": [],
  "CONV_KERNEL_INITIALIZER": [],
  "MBConvBlock": {
    "__init__": [
      "self",
      "input_filters",
      "output_filters",
      "expand_ratio",
      "kernel_size",
      "strides",
      "se_ratio",
      "bn_momentum",
      "activation",
      "survival_probability"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "Augmenter": {
    "__init__": [
      "self",
      "layers"
    ],
    "__call__": [
      "self",
      "inputs"
    ]
  },
  "SegFormerMultiheadAttention": {
    "__init__": [
      "self",
      "project_dim",
      "num_heads",
      "sr_ratio"
    ],
    "call": [
      "self",
      "x"
    ]
  },
  "OverlappingPatchingAndEmbedding": {
    "__init__": [
      "self",
      "project_dim",
      "patch_size",
      "stride"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "FeaturePyramid": {
    "__init__": [
      "self",
      "min_level",
      "max_level",
      "num_channels",
      "lateral_layers",
      "output_layers"
    ],
    "_validate_user_layers": [
      "self",
      "user_input",
      "param_name"
    ],
    "call": [
      "self",
      "features"
    ],
    "build_feature_pyramid": [
      "self",
      "input_features"
    ],
    "get_config": [
      "self"
    ]
  },
  "TransformerEncoder": {
    "__init__": [
      "self",
      "project_dim",
      "num_heads",
      "mlp_dim",
      "mlp_dropout",
      "attention_dropout",
      "activation",
      "layer_norm_epsilon"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config",
      "custom_objects"
    ]
  },
  "FusedMBConvBlock": {
    "__init__": [
      "self",
      "input_filters",
      "output_filters",
      "expand_ratio",
      "kernel_size",
      "strides",
      "se_ratio",
      "bn_momentum",
      "activation",
      "survival_probability"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "hidden_dim",
      "output_dim",
      "num_layers",
      "activation"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "AddRelativePositionalEmbedding": {
    "__init__": [
      "self",
      "input_size",
      "key_dim"
    ],
    "_get_rel_pos": [
      "self",
      "query_size",
      "key_size",
      "rel_pos"
    ],
    "call": [
      "self",
      "attention_map",
      "queries",
      "query_size",
      "key_size"
    ],
    "get_config": [
      "self"
    ]
  },
  "MultiHeadAttentionWithRelativePE": {
    "__init__": [
      "self",
      "num_heads",
      "key_dim",
      "use_bias",
      "use_rel_pos",
      "input_size"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "WindowPartitioning": {
    "__init__": [
      "self",
      "window_size"
    ],
    "partition": [
      "self",
      "x"
    ],
    "unpartition": [
      "self",
      "windows",
      "HW_padded",
      "HW"
    ],
    "get_config": [
      "self"
    ]
  },
  "WindowedTransformerEncoder": {
    "__init__": [
      "self",
      "project_dim",
      "mlp_dim",
      "num_heads",
      "use_bias",
      "use_rel_pos",
      "window_size",
      "input_size",
      "activation",
      "layer_norm_epsilon"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "ViTDetPatchingAndEmbedding": {
    "__init__": [
      "self",
      "kernel_size",
      "strides",
      "embed_dim"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "AddPositionalEmbedding": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "embed_dim"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_confg": [
      "self"
    ]
  },
  "HierarchicalTransformerEncoder": {
    "__init__": [
      "self",
      "project_dim",
      "num_heads",
      "sr_ratio",
      "drop_prob",
      "layer_norm_epsilon"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "POINT_CLOUDS": [],
  "BOUNDING_BOXES": [],
  "OBJECT_POINT_CLOUDS": [],
  "OBJECT_BOUNDING_BOXES": [],
  "ADDITIONAL_POINT_CLOUDS": [],
  "ADDITIONAL_BOUNDING_BOXES": [],
  "BOX_LABEL_INDEX": [],
  "POINTCLOUD_LABEL_INDEX": [],
  "POINTCLOUD_FEATURE_INDEX": [],
  "BaseAugmentationLayer3D": {
    "__init__": [
      "self",
      "seed"
    ],
    "auto_vectorize": [
      "self",
      "auto_vectorize"
    ],
    "_map_fn": [
      "self"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds",
      "bounding_boxes"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ]
  },
  "convert_to_model_format": [
    "inputs"
  ],
  "convert_from_model_format": [
    "inputs"
  ],
  "RandomDropBox": {
    "__init__": [
      "self",
      "max_drop_bounding_boxes",
      "label_index"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds",
      "bounding_boxes"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "GroupPointsByBoundingBoxes": {
    "__init__": [
      "self",
      "label_index",
      "min_points_per_bounding_boxes",
      "max_points_per_bounding_boxes"
    ],
    "get_config": [
      "self"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes"
    ],
    "augment_point_clouds_bounding_boxes_v2": [
      "self",
      "point_clouds",
      "bounding_boxes"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "GlobalRandomRotation": {
    "__init__": [
      "self",
      "max_rotation_angle_x",
      "max_rotation_angle_y",
      "max_rotation_angle_z"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "GlobalRandomTranslation": {
    "__init__": [
      "self",
      "x_stddev",
      "y_stddev",
      "z_stddev"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "RandomCopyPaste": {
    "__init__": [
      "self",
      "label_index",
      "min_paste_bounding_boxes",
      "max_paste_bounding_boxes"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "object_point_clouds",
      "object_bounding_boxes"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "SwapBackground": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "additional_point_clouds",
      "additional_bounding_boxes"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ],
    "_augment": [
      "self",
      "inputs"
    ]
  },
  "GlobalRandomFlip": {
    "__init__": [
      "self",
      "flip_x",
      "flip_y",
      "flip_z"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "GlobalRandomDroppingPoints": {
    "__init__": [
      "self",
      "drop_rate",
      "exclude_classes"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "GlobalRandomScaling": {
    "__init__": [
      "self",
      "x_factor",
      "y_factor",
      "z_factor",
      "preserve_aspect_ratio"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "FrustumRandomDroppingPoints": {
    "__init__": [
      "self",
      "r_distance",
      "theta_width",
      "phi_width",
      "drop_rate",
      "exclude_classes"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "FrustumRandomPointFeatureNoise": {
    "__init__": [
      "self",
      "r_distance",
      "theta_width",
      "phi_width",
      "max_noise_level",
      "exclude_classes"
    ],
    "get_config": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "point_clouds"
    ],
    "augment_point_clouds_bounding_boxes": [
      "self",
      "point_clouds",
      "bounding_boxes",
      "transformation"
    ]
  },
  "decode_bin_heading": [
    "predictions",
    "num_bin"
  ],
  "decode_bin_box": [
    "pd",
    "num_head_bin",
    "anchor_size"
  ],
  "HeatmapDecoder": {
    "__init__": [
      "self",
      "class_id",
      "num_head_bin",
      "anchor_size",
      "max_pool_size",
      "max_num_box",
      "heatmap_threshold",
      "voxel_size",
      "spatial_size"
    ],
    "call": [
      "self",
      "prediction"
    ],
    "get_config": [
      "self"
    ]
  },
  "EPSILON": [],
  "compute_feature_map_ref_xyz": [
    "voxel_size",
    "spatial_size",
    "global_xyz"
  ],
  "compute_voxel_spatial_size": [
    "spatial_size",
    "voxel_size"
  ],
  "compute_voxel_origin": [
    "spatial_size",
    "voxel_size"
  ],
  "point_to_voxel_coord": [
    "point_xyz",
    "voxel_size",
    "dtype"
  ],
  "voxel_coord_to_point": [
    "voxel_coord",
    "voxel_size",
    "dtype"
  ],
  "get_yaw_rotation": [
    "yaw",
    "name"
  ],
  "inv_loc": [
    "rot",
    "loc"
  ],
  "_has_rank": [
    "tensor",
    "expected_rank"
  ],
  "_pad_or_trim_to": [
    "x",
    "shape",
    "pad_val",
    "pad_after_contents"
  ],
  "INF_VOXEL_SIZE": [],
  "_meshgrid": [
    "max_radius_in_voxels",
    "voxel_size"
  ],
  "compute_heatmap": [
    "box_3d",
    "box_mask",
    "voxel_size",
    "max_radius"
  ],
  "scatter_to_dense_heatmap": [
    "point_xyz",
    "point_mask",
    "point_box_id",
    "heatmap",
    "voxel_size",
    "spatial_size"
  ],
  "decode_tensor": [
    "t",
    "dims"
  ],
  "compute_top_k_heatmap_idx": [
    "heatmap",
    "k"
  ],
  "CenterNetLabelEncoder": {
    "__init__": [
      "self",
      "voxel_size",
      "max_radius",
      "spatial_size",
      "num_classes",
      "top_k_heatmap"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "VOXEL_FEATURE_MIN": [],
  "compute_point_voxel_id": [
    "point_voxel_xyz",
    "voxel_spatial_size"
  ],
  "PointToVoxel": {
    "__init__": [
      "self",
      "voxel_size",
      "spatial_size"
    ],
    "call": [
      "self",
      "point_xyz",
      "point_mask"
    ]
  },
  "DynamicVoxelization": {
    "__init__": [
      "self",
      "voxel_size",
      "spatial_size"
    ],
    "call": [
      "self",
      "point_xyz",
      "point_feature",
      "point_mask",
      "training"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ]
  },
  "SqueezeAndExcite2D": {
    "__init__": [
      "self",
      "filters",
      "bottleneck_filters",
      "squeeze_activation",
      "excite_activation"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "DropPath": {
    "__init__": [
      "self",
      "rate",
      "seed"
    ],
    "call": [
      "self",
      "x",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "StochasticDepth": {
    "__init__": [
      "self",
      "rate"
    ],
    "call": [
      "self",
      "x",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "DropBlock2D": {
    "__init__": [
      "self",
      "rate",
      "block_size",
      "seed"
    ],
    "call": [
      "self",
      "x",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "Solarization": {
    "__init__": [
      "self",
      "value_range",
      "addition_factor",
      "threshold_factor",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomCropAndResize": {
    "__init__": [
      "self",
      "target_size",
      "crop_area_factor",
      "aspect_ratio_factor",
      "interpolation",
      "bounding_box_format",
      "seed"
    ],
    "get_random_transformation": [
      "self",
      "image",
      "label",
      "bounding_box"
    ],
    "compute_image_signature": [
      "self",
      "images"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_target": [
      "self",
      "target"
    ],
    "_transform_bounding_boxes": [
      "bounding_boxes",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformation",
      "image"
    ],
    "_resize": [
      "self",
      "image"
    ],
    "_check_class_arguments": [
      "self",
      "target_size",
      "crop_area_factor",
      "aspect_ratio_factor"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "_crop_and_resize": [
      "self",
      "image",
      "transformation",
      "method"
    ]
  },
  "CutMix": {
    "__init__": [
      "self",
      "alpha",
      "seed"
    ],
    "_sample_from_beta": [
      "self",
      "alpha",
      "beta",
      "shape"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "_cutmix": [
      "self",
      "images"
    ],
    "_update_labels": [
      "self",
      "labels",
      "lambda_sample",
      "permutation_order"
    ],
    "_update_segmentation_masks": [
      "self",
      "segmentation_masks",
      "permutation_order",
      "random_center_height",
      "random_center_width",
      "cut_width",
      "cut_height"
    ],
    "_validate_inputs": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "Posterization": {
    "__init__": [
      "self",
      "value_range",
      "bits"
    ],
    "augment_image": [
      "self",
      "image"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_posterize": [
      "self",
      "image"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "MixUp": {
    "__init__": [
      "self",
      "alpha",
      "seed"
    ],
    "_sample_from_beta": [
      "self",
      "alpha",
      "beta",
      "shape"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "_mixup": [
      "self",
      "images"
    ],
    "_update_labels": [
      "self",
      "labels",
      "lambda_sample",
      "permutation_order"
    ],
    "_update_bounding_boxes": [
      "self",
      "bounding_boxes",
      "permutation_order"
    ],
    "_update_segmentation_masks": [
      "self",
      "segmentation_masks",
      "lambda_sample",
      "permutation_order"
    ],
    "_validate_inputs": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomCrop": {
    "__init__": [
      "self",
      "height",
      "width",
      "seed",
      "bounding_box_format"
    ],
    "compute_ragged_image_signature": [
      "self",
      "images"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "raw_images"
    ],
    "_get_image_shape": [
      "self",
      "images"
    ],
    "_crop_images": [
      "self",
      "images",
      "transformations"
    ],
    "_resize_images": [
      "self",
      "images"
    ],
    "_crop_bounding_boxes": [
      "self",
      "images",
      "boxes",
      "transformation"
    ],
    "_resize_bounding_boxes": [
      "self",
      "images",
      "boxes"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomJpegQuality": {
    "__init__": [
      "self",
      "factor",
      "seed"
    ],
    "get_random_transformation": [
      "self"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomContrast": {
    "__init__": [
      "self",
      "value_range",
      "factor",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomShear": {
    "__init__": [
      "self",
      "x_factor",
      "y_factor",
      "interpolation",
      "fill_mode",
      "fill_value",
      "bounding_box_format",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "_build_shear_x_transform_matrix": [
      "shear_x"
    ],
    "_build_shear_y_transform_matrix": [
      "shear_y"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "images"
    ],
    "_format_transform": [
      "transform"
    ],
    "get_config": [
      "self"
    ]
  },
  "ChannelShuffle": {
    "__init__": [
      "self",
      "groups",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomTranslation": {
    "__init__": [
      "self",
      "height_factor",
      "width_factor",
      "fill_mode",
      "interpolation",
      "seed",
      "fill_value",
      "bounding_box_format"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "images"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "_center_crop": [
    "mask",
    "width",
    "height"
  ],
  "GridMask": {
    "__init__": [
      "self",
      "ratio_factor",
      "rotation_factor",
      "fill_mode",
      "fill_value",
      "seed"
    ],
    "_check_parameter_values": [
      "self"
    ],
    "get_random_transformation": [
      "self",
      "image",
      "label",
      "bounding_boxes"
    ],
    "_compute_grid_mask": [
      "self",
      "input_shape",
      "ratio"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomSharpness": {
    "__init__": [
      "self",
      "factor",
      "value_range",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomGaussianBlur": {
    "__init__": [
      "self",
      "kernel_size",
      "factor"
    ],
    "get_random_transformation": [
      "self"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "get_kernel": [
      "factor",
      "filter_size"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomChannelShift": {
    "__init__": [
      "self",
      "value_range",
      "factor",
      "channels",
      "seed"
    ],
    "get_random_transformation": [
      "self",
      "image",
      "label",
      "bounding_boxes"
    ],
    "_get_shift": [
      "self"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "IMAGES": [],
  "LABELS": [],
  "TARGETS": [],
  "KEYPOINTS": [],
  "SEGMENTATION_MASKS": [],
  "IS_DICT": [],
  "USE_TARGETS": [],
  "BaseImageAugmentationLayer": {
    "__init__": [
      "self",
      "seed"
    ],
    "force_output_ragged_images": [
      "self",
      "force_output_ragged_images"
    ],
    "force_output_dense_images": [
      "self",
      "force_output_dense_images"
    ],
    "auto_vectorize": [
      "self",
      "auto_vectorize"
    ],
    "compute_image_signature": [
      "self",
      "images"
    ],
    "_compute_bounding_box_signature": [
      "self",
      "bounding_boxes"
    ],
    "_compute_keypoints_signature": [
      "self",
      "keypoints"
    ],
    "_compute_target_signature": [
      "self",
      "targets"
    ],
    "_compute_output_signature": [
      "self",
      "inputs"
    ],
    "_any_ragged": [
      "inputs"
    ],
    "_map_fn": [
      "self",
      "func",
      "inputs"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_target": [
      "self",
      "target",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformation"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "get_random_transformation": [
      "self",
      "image",
      "label",
      "bounding_boxes",
      "keypoints",
      "segmentation_mask"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_format_inputs": [
      "self",
      "inputs"
    ],
    "_format_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "_format_output": [
      "self",
      "output",
      "metadata"
    ],
    "_ensure_inputs_are_compute_dtype": [
      "self",
      "inputs"
    ]
  },
  "Grayscale": {
    "__init__": [
      "self",
      "output_channels"
    ],
    "_check_input_params": [
      "self",
      "output_channels"
    ],
    "compute_ragged_image_signature": [
      "self",
      "images"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "get_config": [
      "self"
    ]
  },
  "JitteredResize": {
    "__init__": [
      "self",
      "target_size",
      "scale_factor",
      "crop_size",
      "bounding_box_format",
      "interpolation",
      "seed"
    ],
    "compute_ragged_image_signature": [
      "self",
      "images"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size",
      "images"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations",
      "resize_method"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "raw_images"
    ],
    "_get_image_shape": [
      "self",
      "images"
    ],
    "resize_and_crop_single_image": [
      "self",
      "inputs",
      "resize_method"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "FourierMix": {
    "__init__": [
      "self",
      "alpha",
      "decay_power",
      "seed"
    ],
    "_sample_from_beta": [
      "self",
      "alpha",
      "beta",
      "shape"
    ],
    "_fftfreq": [
      "signal_size",
      "sample_spacing"
    ],
    "_apply_fftfreq": [
      "self",
      "h",
      "w"
    ],
    "_get_spectrum": [
      "self",
      "freqs",
      "decay_power",
      "channel",
      "h",
      "w"
    ],
    "_sample_mask_from_transform": [
      "self",
      "decay",
      "shape",
      "ch"
    ],
    "_binarise_mask": [
      "self",
      "mask",
      "lam",
      "in_shape"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "_fourier_mix": [
      "self",
      "images"
    ],
    "_update_labels": [
      "self",
      "labels",
      "lambda_sample",
      "permutation_order"
    ],
    "_update_segmentation_masks": [
      "self",
      "segmentation_masks",
      "masks",
      "permutation_order"
    ],
    "get_config": [
      "self"
    ]
  },
  "AugMix": {
    "__init__": [
      "self",
      "value_range",
      "severity",
      "num_chains",
      "chain_depth",
      "alpha",
      "seed"
    ],
    "_sample_from_dirichlet": [
      "self",
      "alpha"
    ],
    "_sample_from_beta": [
      "self",
      "alpha",
      "beta"
    ],
    "_sample_depth": [
      "self"
    ],
    "_loop_on_depth": [
      "self",
      "depth_level",
      "image_aug"
    ],
    "_loop_on_width": [
      "self",
      "image",
      "chain_mixing_weights",
      "curr_chain",
      "result"
    ],
    "_auto_contrast": [
      "self",
      "image"
    ],
    "_equalize": [
      "self",
      "image"
    ],
    "_posterize": [
      "self",
      "image"
    ],
    "_rotate": [
      "self",
      "image"
    ],
    "_solarize": [
      "self",
      "image"
    ],
    "_shear_x": [
      "self",
      "image"
    ],
    "_shear_y": [
      "self",
      "image"
    ],
    "_format_random_shear_transform": [
      "transform"
    ],
    "_translate_x": [
      "self",
      "image"
    ],
    "_translate_y": [
      "self",
      "image"
    ],
    "_apply_op": [
      "self",
      "image",
      "op_index"
    ],
    "get_random_transformation": [
      "self",
      "image",
      "label",
      "bounding_boxes",
      "keypoints",
      "segmentation_mask"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_masks",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomHue": {
    "__init__": [
      "self",
      "factor",
      "value_range",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "Equalization": {
    "__init__": [
      "self",
      "value_range",
      "bins"
    ],
    "equalize_channel": [
      "self",
      "images",
      "channel_index"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_targets": [
      "self",
      "targets",
      "transformations"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomColorDegeneration": {
    "__init__": [
      "self",
      "factor",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_targets": [
      "self",
      "targets",
      "transformations"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomColorJitter": {
    "__init__": [
      "self",
      "value_range",
      "brightness_factor",
      "contrast_factor",
      "saturation_factor",
      "hue_factor",
      "seed"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomBrightness": {
    "__init__": [
      "self",
      "factor",
      "value_range",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomApply": {
    "__init__": [
      "self",
      "layer",
      "rate",
      "batchwise",
      "auto_vectorize",
      "seed"
    ],
    "_should_augment": [
      "self"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomSaturation": {
    "__init__": [
      "self",
      "factor",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformation"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomChoice": {
    "__init__": [
      "self",
      "layers",
      "auto_vectorize",
      "batchwise",
      "seed"
    ],
    "_curry_call_layer": [
      "self",
      "inputs",
      "layer"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "RepeatedAugmentation": {
    "__init__": [
      "self",
      "augmenters",
      "shuffle"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "shuffle_outputs": [
      "self",
      "result"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomZoom": {
    "__init__": [
      "self",
      "height_factor",
      "width_factor",
      "fill_mode",
      "interpolation",
      "seed",
      "fill_value"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "get_zoom_matrix": [
      "self",
      "zooms",
      "image_height",
      "image_width",
      "name"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomRotation": {
    "__init__": [
      "self",
      "factor",
      "fill_mode",
      "interpolation",
      "seed",
      "fill_value",
      "bounding_box_format",
      "segmentation_classes"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "raw_images"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "_rotate_images": [
      "self",
      "images",
      "transformations"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomAspectRatio": {
    "__init__": [
      "self",
      "factor",
      "interpolation",
      "bounding_box_format",
      "seed"
    ],
    "get_random_transformation": [
      "self"
    ],
    "compute_image_signature": [
      "self",
      "images"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformation",
      "image"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "supported_keys": [],
  "Resizing": {
    "__init__": [
      "self",
      "height",
      "width",
      "interpolation",
      "crop_to_aspect_ratio",
      "pad_to_aspect_ratio",
      "bounding_box_format"
    ],
    "compute_image_signature": [
      "self",
      "images"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "_resize_with_distortion": [
      "self",
      "inputs"
    ],
    "_resize_with_pad": [
      "self",
      "inputs"
    ],
    "_resize_with_crop": [
      "self",
      "inputs"
    ],
    "_check_inputs": [
      "self",
      "inputs"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "Mosaic": {
    "__init__": [
      "self",
      "offset",
      "bounding_box_format",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations",
      "resize_method"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations",
      "images"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "images"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "_validate_inputs": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RandomAugmentationPipeline": {
    "__init__": [
      "self",
      "layers",
      "augmentations_per_image",
      "rate",
      "auto_vectorize",
      "seed"
    ],
    "_augment": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "Rescaling": {
    "__init__": [
      "self",
      "scale",
      "offset"
    ],
    "augment_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_label": [
      "self",
      "label",
      "transformation"
    ],
    "augment_segmentation_mask": [
      "self",
      "segmentation_mask",
      "transformation"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomCutout": {
    "__init__": [
      "self",
      "height_factor",
      "width_factor",
      "fill_mode",
      "fill_value",
      "seed"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size",
      "images"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_targets": [
      "self",
      "targets",
      "transformations"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "_get_image_shape": [
      "self",
      "images"
    ],
    "_compute_rectangle_position": [
      "self",
      "inputs"
    ],
    "_compute_rectangle_size": [
      "self",
      "inputs"
    ],
    "_compute_rectangle_fill": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "BATCHED": [],
  "VectorizedBaseImageAugmentationLayer": {
    "__init__": [
      "self",
      "seed"
    ],
    "force_output_dense_images": [
      "self",
      "force_output_dense_images"
    ],
    "force_output_dense_segmentation_masks": [
      "self",
      "force_output_dense_segmentation_masks"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "compute_ragged_image_signature": [
      "self",
      "images"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_targets": [
      "self",
      "targets",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size",
      "images",
      "labels",
      "bounding_boxes",
      "keypoints",
      "segmentation_masks"
    ],
    "_unwrap_ragged_image_call": [
      "self",
      "inputs"
    ],
    "_batch_augment": [
      "self",
      "inputs"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "_format_inputs": [
      "self",
      "inputs"
    ],
    "_format_output": [
      "self",
      "output",
      "metadata"
    ],
    "_ensure_inputs_are_compute_dtype": [
      "self",
      "inputs"
    ],
    "_format_bounding_boxes": [
      "self",
      "bounding_boxes"
    ]
  },
  "HORIZONTAL": [],
  "VERTICAL": [],
  "HORIZONTAL_AND_VERTICAL": [],
  "RandomFlip": {
    "__init__": [
      "self",
      "mode",
      "rate",
      "seed",
      "bounding_box_format"
    ],
    "get_random_transformation_batch": [
      "self",
      "batch_size"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes",
      "transformations",
      "raw_images"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "_flip_images": [
      "self",
      "images",
      "transformations"
    ],
    "_flip_boxes_horizontal": [
      "self",
      "boxes"
    ],
    "_flip_boxes_vertical": [
      "self",
      "boxes"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "AutoContrast": {
    "__init__": [
      "self",
      "value_range"
    ],
    "augment_images": [
      "self",
      "images",
      "transformations"
    ],
    "augment_bounding_boxes": [
      "self",
      "bounding_boxes"
    ],
    "augment_labels": [
      "self",
      "labels",
      "transformations"
    ],
    "augment_segmentation_masks": [
      "self",
      "segmentation_masks",
      "transformations"
    ],
    "augment_keypoints": [
      "self",
      "keypoints",
      "transformations"
    ],
    "augment_targets": [
      "self",
      "targets",
      "transformations"
    ],
    "augment_ragged_image": [
      "self",
      "image",
      "transformation"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandAugment": {
    "__init__": [
      "self",
      "value_range",
      "augmentations_per_image",
      "magnitude",
      "magnitude_stddev",
      "rate",
      "geometric",
      "seed"
    ],
    "_augment": [
      "self",
      "sample"
    ],
    "get_standard_policy": [
      "value_range",
      "magnitude",
      "magnitude_stddev",
      "geometric",
      "seed"
    ],
    "get_config": [
      "self"
    ]
  },
  "auto_contrast_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "equalize_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "solarize_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "color_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "contrast_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "brightness_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "shear_x_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "shear_y_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "translate_x_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "translate_y_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "POLICY_PAIRS": [],
  "create_rand_augment_policy": [
    "magnitude",
    "magnitude_stddev"
  ],
  "ROIPooler": {
    "__init__": [
      "self",
      "bounding_box_format",
      "target_size",
      "image_shape"
    ],
    "call": [
      "self",
      "feature_map",
      "rois"
    ],
    "_pool_single_sample": [
      "self",
      "args"
    ],
    "get_config": [
      "self"
    ]
  },
  "ROIGenerator": {
    "__init__": [
      "self",
      "bounding_box_format",
      "pre_nms_topk_train",
      "nms_score_threshold_train",
      "nms_iou_threshold_train",
      "post_nms_topk_train",
      "pre_nms_topk_test",
      "nms_score_threshold_test",
      "nms_iou_threshold_test",
      "post_nms_topk_test"
    ],
    "call": [
      "self",
      "multi_level_boxes",
      "multi_level_scores",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "MultiClassNonMaxSuppression": {
    "__init__": [
      "self",
      "bounding_box_format",
      "from_logits",
      "iou_threshold",
      "confidence_threshold",
      "max_detections",
      "max_detections_per_class"
    ],
    "call": [
      "self",
      "box_prediction",
      "class_prediction",
      "images",
      "image_shape"
    ],
    "get_config": [
      "self"
    ]
  },
  "AnchorGenerator": {
    "__init__": [
      "self",
      "bounding_box_format",
      "sizes",
      "scales",
      "aspect_ratios",
      "strides",
      "clip_boxes"
    ],
    "_format_sizes_and_strides": [
      "sizes",
      "strides"
    ],
    "_ensure_param_is_levels_dict": [
      "param",
      "param_name"
    ],
    "_match_param_structure_to_sizes": [
      "params",
      "sizes"
    ],
    "__call__": [
      "self",
      "image",
      "image_shape"
    ]
  },
  "_SingleAnchorGenerator": {
    "__init__": [
      "self",
      "bounding_box_format",
      "sizes",
      "scales",
      "aspect_ratios",
      "stride",
      "clip_boxes",
      "dtype"
    ],
    "__call__": [
      "self",
      "image_size"
    ]
  },
  "balanced_sample": [
    "positive_matches",
    "negative_matches",
    "num_samples",
    "positive_fraction"
  ],
  "_ROISampler": {
    "__init__": [
      "self",
      "bounding_box_format",
      "roi_matcher",
      "positive_fraction",
      "background_class",
      "num_sampled_rois",
      "append_gt_boxes"
    ],
    "call": [
      "self",
      "rois",
      "gt_boxes",
      "gt_classes"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config",
      "custom_objects"
    ]
  },
  "_feature_bilinear_interpolation": [
    "features",
    "kernel_y",
    "kernel_x"
  ],
  "_compute_grid_positions": [
    "boxes",
    "boundaries",
    "output_size",
    "sample_offset"
  ],
  "multilevel_crop_and_resize": [
    "features",
    "boxes",
    "output_size",
    "sample_offset"
  ],
  "_ROIAligner": {
    "__init__": [
      "self",
      "bounding_box_format",
      "target_size",
      "sample_offset"
    ],
    "call": [
      "self",
      "features",
      "boxes",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "BoxMatcher": {
    "__init__": [
      "self",
      "thresholds",
      "match_values",
      "force_match_for_each_col"
    ],
    "call": [
      "self",
      "similarity_matrix"
    ],
    "_set_values_using_indicator": [
      "self",
      "x",
      "indicator",
      "val"
    ],
    "get_config": [
      "self"
    ]
  },
  "_RpnLabelEncoder": {
    "__init__": [
      "self",
      "anchor_format",
      "ground_truth_box_format",
      "positive_threshold",
      "negative_threshold",
      "samples_per_image",
      "positive_fraction",
      "box_variance"
    ],
    "call": [
      "self",
      "anchors_dict",
      "gt_boxes",
      "gt_classes"
    ],
    "unpack_targets": [
      "self",
      "targets",
      "anchors_dict"
    ],
    "get_config": [
      "self"
    ]
  },
  "NonMaxSuppression": {
    "__init__": [
      "self",
      "bounding_box_format",
      "from_logits",
      "iou_threshold",
      "confidence_threshold",
      "max_detections"
    ],
    "call": [
      "self",
      "box_prediction",
      "class_prediction",
      "images",
      "image_shape"
    ],
    "get_config": [
      "self"
    ]
  },
  "non_max_suppression": [
    "boxes",
    "scores",
    "max_output_size",
    "iou_threshold",
    "score_threshold",
    "tile_size"
  ],
  "_bbox_overlap": [
    "boxes_a",
    "boxes_b"
  ],
  "_self_suppression": [
    "iou",
    "_",
    "iou_sum",
    "iou_threshold"
  ],
  "_cross_suppression": [
    "boxes",
    "box_slice",
    "iou_threshold",
    "inner_idx",
    "tile_size"
  ],
  "_suppression_loop_body": [
    "boxes",
    "iou_threshold",
    "output_size",
    "idx",
    "tile_size"
  ],
  "custom_ops": [],
  "within_box3d_index": [
    "points",
    "boxes"
  ],
  "group_points_by_boxes": [
    "points",
    "boxes"
  ],
  "is_within_any_box3d_v2": [
    "points",
    "boxes",
    "keepdims"
  ],
  "is_within_any_box3d_v3": [
    "points",
    "boxes",
    "keepdims"
  ],
  "get_rank": [
    "tensor"
  ],
  "wrap_angle_radians": [
    "angle_radians",
    "min_val",
    "max_val"
  ],
  "_get_3d_rotation_matrix": [
    "yaw",
    "roll",
    "pitch"
  ],
  "_center_xyzWHD_to_corner_xyz": [
    "boxes"
  ],
  "_get_shape": [
    "tensor"
  ],
  "_is_on_lefthand_side": [
    "points",
    "v1",
    "v2"
  ],
  "_box_area": [
    "boxes"
  ],
  "is_within_box2d": [
    "points",
    "boxes"
  ],
  "is_within_any_box3d": [
    "points",
    "boxes",
    "keepdims"
  ],
  "is_within_box3d": [
    "points",
    "boxes"
  ],
  "coordinate_transform": [
    "points",
    "pose"
  ],
  "spherical_coordinate_transform": [
    "points"
  ],
  "within_a_frustum": [
    "points",
    "center",
    "r_distance",
    "theta_width",
    "phi_width"
  ],
  "assert_tf_keras": [
    "src"
  ],
  "supports_ragged": [],
  "detect_if_tensorflow_uses_keras_3": [],
  "_USE_KERAS_3": [],
  "keras_3": [],
  "backend": [],
  "smart_resize": [
    "x",
    "size",
    "interpolation"
  ],
  "_ORIGINAL_OPS": [],
  "_ORIGINAL_SUPPORTS_RAGGED": [],
  "_IN_TF_DATA_SCOPE": [],
  "tf_data": [
    "function"
  ],
  "TFDataScope": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "exc_tb"
    ]
  },
  "_make_default_seed": [],
  "SeedGenerator": {
    "__new__": [
      "cls",
      "seed"
    ],
    "__init__": [
      "self",
      "seed"
    ],
    "next": [
      "self",
      "ordered"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "_draw_seed": [
    "seed"
  ],
  "normal": [
    "shape",
    "mean",
    "stddev",
    "dtype",
    "seed"
  ],
  "uniform": [
    "shape",
    "minval",
    "maxval",
    "dtype",
    "seed"
  ],
  "shuffle": [
    "x",
    "axis",
    "seed"
  ],
  "categorical": [
    "logits",
    "num_samples",
    "dtype",
    "seed"
  ],
  "_KERAS_CORE_ALIASES": [],
  "Task": {
    "__init__": [
      "self"
    ],
    "__dir__": [
      "self"
    ],
    "backbone": [
      "self",
      "value"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "presets_without_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ],
    "from_preset": [
      "cls",
      "preset",
      "load_weights",
      "input_shape"
    ],
    "layers": [
      "self"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__init_subclass__": [
      "cls"
    ]
  },
  "get_tensor_input_name": [
    "tensor"
  ],
  "parse_model_inputs": [
    "input_shape",
    "input_tensor"
  ],
  "correct_pad_downsample": [
    "inputs",
    "kernel_size"
  ],
  "CLIPTextEncoder": {
    "__init__": [
      "self",
      "transformer_width",
      "transformer_layers",
      "transformer_heads",
      "vocab_size",
      "embed_dim",
      "context_length"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs",
      "attention_mask"
    ],
    "get_config": [
      "self"
    ]
  },
  "SPECIAL_WHITESPACES": [],
  "SPLIT_PATTERN_1": [],
  "SPLIT_PATTERN_2": [],
  "split_strings_for_bpe": [
    "inputs",
    "unsplittable_tokens"
  ],
  "create_alts_for_unsplittable_tokens": [
    "unsplittable_tokens"
  ],
  "remove_strings_from_inputs": [
    "tensor",
    "string_to_remove"
  ],
  "CLIPTokenizer": {
    "__init__": [
      "self"
    ],
    "_bpe_merge_and_update_cache": [
      "self",
      "tokens"
    ],
    "tokenize": [
      "self",
      "inputs"
    ]
  },
  "_decode_strings_to_utf8": [
    "inputs"
  ],
  "tensor_to_list": [
    "inputs"
  ],
  "convert_to_backend_tensor_or_python_list": [
    "x"
  ],
  "convert_inputs_to_list_of_tensor_segments": [
    "x"
  ],
  "CLIPHead": {
    "__init__": [
      "self"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "image_embeddings",
      "text_embeddings"
    ]
  },
  "CLIP": {
    "__init__": [
      "self",
      "embed_dim",
      "image_resolution",
      "vision_layers",
      "vision_width",
      "vision_patch_size",
      "context_length",
      "vocab_size",
      "transformer_width",
      "transformer_heads",
      "transformer_layers"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "get_config": [
      "self"
    ]
  },
  "CLIPPatchingAndEmbedding": {
    "__init__": [
      "self",
      "width",
      "patch_size",
      "input_resolution",
      "output_dim"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "CLIPImageEncoder": {
    "__init__": [
      "self",
      "input_resolution",
      "patch_size",
      "width",
      "num_layers",
      "heads",
      "output_dim"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "image"
    ],
    "get_config": [
      "self"
    ]
  },
  "CLIPProcessor": {
    "__init__": [
      "self",
      "vocabulary",
      "merges"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "_process_texts": [
      "self",
      "texts",
      "context_length"
    ],
    "call": [
      "self",
      "texts",
      "context_length"
    ],
    "get_build_config": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "get_config": [
      "self"
    ]
  },
  "clip_presets": [],
  "QuickGELU": {
    "__init__": [
      "self"
    ],
    "call": [
      "self",
      "x"
    ]
  },
  "ResidualAttention": {
    "__init__": [
      "self",
      "proj_dim",
      "num_heads",
      "num_hidden_layers"
    ],
    "attention": [
      "self",
      "x",
      "causal_attention_mask",
      "attention_mask"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x",
      "causal_attention_mask",
      "attention_mask"
    ],
    "compute_output_shape": [
      "self",
      "inputs_shape"
    ],
    "get_config": [
      "self"
    ]
  },
  "CLIPEncoder": {
    "__init__": [
      "self",
      "width",
      "num_layers",
      "heads"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x",
      "causal_attention_mask",
      "attention_mask"
    ],
    "get_config": [
      "self"
    ]
  },
  "CLIPAttention": {
    "__init__": [
      "self",
      "proj_dim",
      "num_heads",
      "num_hidden_layers",
      "dropout"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "_transpose_for_scores": [
      "self",
      "tensor",
      "batch_size"
    ],
    "call": [
      "self",
      "x",
      "attention_mask",
      "output_attentions",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "test_backbone_presets": [],
  "backbone_presets_no_weights": [],
  "backbone_presets_with_weights": [],
  "backbone_presets": [],
  "Backbone": {
    "__init__": [
      "self"
    ],
    "__dir__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "presets_without_weights": [
      "cls"
    ],
    "from_preset": [
      "cls",
      "preset",
      "load_weights"
    ],
    "__init_subclass__": [
      "cls"
    ],
    "pyramid_level_inputs": [
      "self",
      "value"
    ]
  },
  "BN_EPSILON": [],
  "ResNetV2Backbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "apply_basic_block": [
    "x",
    "filters",
    "kernel_size",
    "stride",
    "dilation",
    "conv_shortcut",
    "name"
  ],
  "apply_block": [
    "x",
    "filters",
    "kernel_size",
    "stride",
    "dilation",
    "conv_shortcut",
    "name"
  ],
  "apply_stack": [
    "x",
    "filters",
    "blocks",
    "stride",
    "dilations",
    "name",
    "block_type",
    "first_shortcut"
  ],
  "ALIAS_DOCSTRING": [],
  "ResNet18V2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet34V2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet50V2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet101V2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet152V2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ViTDetBBackbone": {
    "__new__": [
      "cls"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ViTDetLBackbone": {
    "__new__": [
      "cls"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ViTDetHBackbone": {
    "__new__": [
      "cls"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ViTDetBackbone": {
    "__init__": [
      "self"
    ],
    "pyramid_level_inputs": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "CSPDarkNetTinyBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "CSPDarkNetSBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "CSPDarkNetMBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "CSPDarkNetLBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "CSPDarkNetXLBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "DarknetConvBlock": [
    "filters",
    "kernel_size",
    "strides",
    "use_bias",
    "activation",
    "name"
  ],
  "ResidualBlocks": [
    "filters",
    "num_blocks",
    "name"
  ],
  "SpatialPyramidPoolingBottleneck": [
    "filters",
    "hidden_filters",
    "kernel_sizes",
    "activation",
    "name"
  ],
  "DarknetConvBlockDepthwise": [
    "filters",
    "kernel_size",
    "strides",
    "activation",
    "name"
  ],
  "CrossStagePartial": {
    "__init__": [
      "self",
      "filters",
      "num_bottlenecks",
      "residual",
      "use_depthwise",
      "activation"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "Focus": [
    "name"
  ],
  "CSPDarkNetBackbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B0Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B1Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B3Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B4Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B5Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B6Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1B7Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV1Backbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ]
  },
  "conv_kernel_initializer": [
    "scale"
  ],
  "round_filters": [
    "filters",
    "width_coefficient",
    "divisor"
  ],
  "round_repeats": [
    "repeats",
    "depth_coefficient"
  ],
  "apply_efficientnet_block": [
    "inputs",
    "filters_in",
    "filters_out",
    "kernel_size",
    "strides",
    "activation",
    "expand_ratio",
    "se_ratio",
    "dropout_rate",
    "name"
  ],
  "MiTBackbone": {
    "__init__": [
      "self",
      "include_rescaling",
      "depths",
      "input_shape",
      "input_tensor",
      "embedding_dims"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MiTB0Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MiTB1Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MiTB2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MiTB3Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MiTB4Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MiTB5Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetLiteB0Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetLiteB1Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetLiteB2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetLiteB3Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetLiteB4Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetLiteBackbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ]
  },
  "apply_efficient_net_lite_block": [
    "inputs",
    "activation",
    "dropout_rate",
    "name",
    "filters_in",
    "filters_out",
    "kernel_size",
    "strides",
    "expand_ratio"
  ],
  "VideoSwinTBackbone": {
    "__new__": [
      "cls",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "include_rescaling"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "VideoSwinSBackbone": {
    "__new__": [
      "cls",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "include_rescaling"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "VideoSwinBBackbone": {
    "__new__": [
      "cls",
      "embed_dim",
      "depths",
      "num_heads",
      "window_size",
      "include_rescaling"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "VideoSwinBackbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "pyramid_level_inputs": [
      "self"
    ]
  },
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_reverse": [
    "windows",
    "window_size",
    "batch_size",
    "depth",
    "height",
    "width"
  ],
  "get_window_size": [
    "x_size",
    "window_size",
    "shift_size"
  ],
  "compute_mask": [
    "depth",
    "height",
    "width",
    "window_size",
    "shift_size"
  ],
  "VideoSwinPatchingAndEmbedding": {
    "__init__": [
      "self",
      "patch_size",
      "embed_dim",
      "norm_layer"
    ],
    "__compute_padding": [
      "self",
      "dim",
      "patch_size"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "VideoSwinPatchMerging": {
    "__init__": [
      "self",
      "input_dim",
      "norm_layer"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "get_config": [
      "self"
    ]
  },
  "VideoSwinWindowAttention": {
    "__init__": [
      "self",
      "input_dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop_rate",
      "proj_drop_rate"
    ],
    "get_relative_position_index": [
      "self",
      "window_depth",
      "window_height",
      "window_width"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x",
      "mask",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "VideoSwinBasicLayer": {
    "__init__": [
      "self",
      "input_dim",
      "depth",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "norm_layer",
      "downsampling_layer"
    ],
    "__compute_dim_padded": [
      "self",
      "input_dim",
      "window_dim_size"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "VideoSwinTransformerBlock": {
    "__init__": [
      "self",
      "input_dim",
      "num_heads",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop_rate",
      "attn_drop_rate",
      "drop_path_rate",
      "activation",
      "norm_layer"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "first_forward": [
      "self",
      "x",
      "mask_matrix",
      "training"
    ],
    "second_forward": [
      "self",
      "x",
      "training"
    ],
    "call": [
      "self",
      "x",
      "mask_matrix",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "EfficientNetV2SBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2MBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2LBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2B0Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2B1Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2B2Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2B3Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "EfficientNetV2Backbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "get_conv_constructor": [
    "conv_type"
  ],
  "VGG16Backbone": {
    "__init__": [
      "self",
      "include_rescaling",
      "include_top",
      "input_tensor",
      "num_classes",
      "input_shape",
      "pooling",
      "classifier_activation",
      "name"
    ],
    "get_config": [
      "self"
    ]
  },
  "apply_vgg_block": [
    "x",
    "num_layers",
    "filters",
    "kernel_size",
    "activation",
    "padding",
    "max_pool",
    "name"
  ],
  "DenseNetBackbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "apply_dense_block": [
    "x",
    "num_repeats",
    "growth_rate",
    "name"
  ],
  "apply_transition_block": [
    "x",
    "compression_ratio",
    "name"
  ],
  "apply_conv_block": [
    "x",
    "growth_rate",
    "name"
  ],
  "DenseNet121Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "DenseNet169Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "DenseNet201Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "CHANNEL_AXIS": [],
  "BN_MOMENTUM": [],
  "MobileNetV3Backbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "HardSigmoidActivation": {
    "__init__": [
      "self"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "adjust_channels": [
    "x",
    "divisor",
    "min_value"
  ],
  "apply_hard_sigmoid": [
    "x"
  ],
  "apply_hard_swish": [
    "x"
  ],
  "apply_inverted_res_block": [
    "x",
    "expansion",
    "filters",
    "kernel_size",
    "stride",
    "se_ratio",
    "activation",
    "expansion_index"
  ],
  "MobileNetV3SmallBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MobileNetV3LargeBackbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNetBackbone": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet18Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet34Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet50Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet101Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "ResNet152Backbone": {
    "__new__": [
      "cls",
      "include_rescaling",
      "input_shape",
      "input_tensor"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "MultiHeadCenterPillar": {
    "__init__": [
      "self",
      "backbone",
      "voxel_net",
      "multiclass_head",
      "prediction_decoder"
    ],
    "compile": [
      "self",
      "heatmap_loss",
      "box_loss"
    ],
    "compute_loss": [
      "self",
      "x",
      "y",
      "y_pred",
      "sample_weight"
    ],
    "predict_step": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "MultiClassDetectionHead": {
    "__init__": [
      "self",
      "num_classes",
      "num_head_bin",
      "name"
    ],
    "call": [
      "self",
      "feature",
      "training"
    ]
  },
  "MultiClassHeatmapDecoder": {
    "__init__": [
      "self",
      "num_classes",
      "num_head_bin",
      "anchor_size",
      "max_pool_size",
      "max_num_box",
      "heatmap_threshold",
      "voxel_size",
      "spatial_size"
    ],
    "call": [
      "self",
      "predictions"
    ]
  },
  "CenterPillarBackbone": {
    "__init__": [
      "self",
      "stackwise_down_blocks",
      "stackwise_down_filters",
      "stackwise_up_filters",
      "input_shape"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ]
  },
  "Block": [
    "filters",
    "downsample"
  ],
  "SkipBlock": [
    "filters"
  ],
  "DownSampleBlock": [
    "filters",
    "num_blocks"
  ],
  "UpSampleBlock": [
    "filters"
  ],
  "parse_weights": [
    "weights",
    "include_top",
    "model_type"
  ],
  "BASE_PATH": [],
  "ALIASES": [],
  "WEIGHTS_CONFIG": [],
  "MODEL_CONFIGS": [],
  "BASE_DOCSTRING": [],
  "apply_mlp_block": [
    "x",
    "mlp_dim",
    "name"
  ],
  "apply_mixer_block": [
    "x",
    "tokens_mlp_dim",
    "channels_mlp_dim",
    "name"
  ],
  "MLPMixer": {
    "__init__": [
      "self",
      "input_shape",
      "patch_size",
      "num_blocks",
      "hidden_dim",
      "tokens_mlp_dim",
      "channels_mlp_dim",
      "include_rescaling",
      "include_top",
      "num_classes",
      "input_tensor",
      "weights",
      "pooling",
      "classifier_activation",
      "name"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "MLPMixerB16": [
    "input_shape"
  ],
  "MLPMixerB32": [
    "input_shape"
  ],
  "MLPMixerL16": [
    "input_shape"
  ],
  "LayerScale": {
    "__init__": [
      "self",
      "init_values",
      "projection_dim"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "x"
    ],
    "get_config": [
      "self"
    ]
  },
  "apply_head": [
    "x",
    "num_classes",
    "activation",
    "name"
  ],
  "ConvNeXt": {
    "__init__": [
      "self",
      "include_rescaling",
      "include_top",
      "depths",
      "projection_dims",
      "drop_path_rate",
      "layer_scale_init_value",
      "weights",
      "input_shape",
      "input_tensor",
      "pooling",
      "num_classes",
      "classifier_activation",
      "name"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "ConvNeXtTiny": [],
  "ConvNeXtSmall": [],
  "ConvNeXtBase": [],
  "ConvNeXtLarge": [],
  "ConvNeXtXLarge": [],
  "DarkNet": {
    "__init__": [
      "self",
      "blocks",
      "include_rescaling",
      "include_top",
      "num_classes",
      "weights",
      "input_shape",
      "input_tensor",
      "pooling",
      "classifier_activation",
      "name"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "DarkNet21": [],
  "DarkNet53": [],
  "as_backbone": [
    "self",
    "min_level",
    "max_level"
  ],
  "VGG19": {
    "__init__": [
      "self",
      "include_rescaling",
      "include_top",
      "input_tensor",
      "num_classes",
      "weights",
      "input_shape",
      "pooling",
      "classifier_activation",
      "name"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "apply_conv2d_bn": [
    "x",
    "filters",
    "kernel_size",
    "strides",
    "use_bias",
    "groups",
    "padding",
    "kernel_initializer",
    "batch_norm",
    "activation",
    "name"
  ],
  "apply_stem": [
    "x",
    "name"
  ],
  "apply_x_block": [
    "inputs",
    "filters_in",
    "filters_out",
    "group_width",
    "stride",
    "name"
  ],
  "apply_y_block": [
    "inputs",
    "filters_in",
    "filters_out",
    "group_width",
    "stride",
    "squeeze_excite_ratio",
    "name"
  ],
  "apply_z_block": [
    "inputs",
    "filters_in",
    "filters_out",
    "group_width",
    "stride",
    "squeeze_excite_ratio",
    "bottleneck_ratio",
    "name"
  ],
  "apply_stage": [
    "x",
    "block_type",
    "depth",
    "group_width",
    "filters_in",
    "filters_out",
    "name"
  ],
  "RegNet": {
    "__init__": [
      "self",
      "depths",
      "widths",
      "group_width",
      "block_type",
      "include_rescaling",
      "include_top",
      "num_classes",
      "model_name",
      "weights",
      "input_tensor",
      "input_shape",
      "pooling",
      "classifier_activation"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "RegNetX002": [],
  "RegNetX004": [],
  "RegNetX006": [],
  "RegNetX008": [],
  "RegNetX016": [],
  "RegNetX032": [],
  "RegNetX040": [],
  "RegNetX064": [],
  "RegNetX080": [],
  "RegNetX120": [],
  "RegNetX160": [],
  "RegNetX320": [],
  "RegNetY002": [],
  "RegNetY004": [],
  "RegNetY006": [],
  "RegNetY008": [],
  "RegNetY016": [],
  "RegNetY032": [],
  "RegNetY040": [],
  "RegNetY064": [],
  "RegNetY080": [],
  "RegNetY120": [],
  "RegNetY160": [],
  "RegNetY320": [],
  "VGG16": {
    "__init__": [
      "self",
      "include_rescaling",
      "include_top",
      "input_tensor",
      "num_classes",
      "weights",
      "input_shape",
      "pooling",
      "classifier_activation",
      "name"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "apply_conv_mixer_layer": [
    "x",
    "dim",
    "kernel_size"
  ],
  "apply_patch_embed": [
    "x",
    "dim",
    "patch_size"
  ],
  "ConvMixer": {
    "__init__": [
      "self",
      "dim",
      "depth",
      "patch_size",
      "kernel_size",
      "include_top",
      "include_rescaling",
      "name",
      "weights",
      "input_shape",
      "input_tensor",
      "pooling",
      "num_classes",
      "classifier_activation"
    ],
    "get_config": [
      "self"
    ]
  },
  "ConvMixer_1536_20": [
    "include_rescaling",
    "include_top",
    "num_classes",
    "weights",
    "input_shape",
    "input_tensor",
    "pooling",
    "classifier_activation",
    "name"
  ],
  "ConvMixer_1536_24": [
    "include_rescaling",
    "include_top",
    "num_classes",
    "weights",
    "input_shape",
    "input_tensor",
    "pooling",
    "classifier_activation",
    "name"
  ],
  "ConvMixer_768_32": [
    "include_rescaling",
    "include_top",
    "num_classes",
    "weights",
    "input_shape",
    "input_tensor",
    "pooling",
    "classifier_activation",
    "name"
  ],
  "ConvMixer_1024_16": [
    "include_rescaling",
    "include_top",
    "num_classes",
    "weights",
    "input_shape",
    "input_tensor",
    "pooling",
    "classifier_activation",
    "name"
  ],
  "ConvMixer_512_16": [
    "include_rescaling",
    "include_top",
    "num_classes",
    "weights",
    "input_shape",
    "input_tensor",
    "pooling",
    "classifier_activation",
    "name"
  ],
  "ViT": {
    "__init__": [
      "self",
      "include_rescaling",
      "include_top",
      "weights",
      "input_shape",
      "input_tensor",
      "pooling",
      "num_classes",
      "patch_size",
      "transformer_layer_num",
      "num_heads",
      "mlp_dropout",
      "attention_dropout",
      "activation",
      "project_dim",
      "mlp_dim",
      "classifier_activation"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "ViTTiny16": [],
  "ViTS16": [],
  "ViTB16": [],
  "ViTL16": [],
  "ViTH16": [],
  "ViTTiny32": [],
  "ViTS32": [],
  "ViTB32": [],
  "ViTL32": [],
  "ViTH32": [],
  "BOX_VARIANCE": [],
  "RPNHead": {
    "__init__": [
      "self",
      "num_anchors_per_location"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "feature_map",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "RCNNHead": {
    "__init__": [
      "self",
      "num_classes",
      "conv_dims",
      "fc_dims"
    ],
    "call": [
      "self",
      "feature_map",
      "training"
    ],
    "get_config": [
      "self"
    ]
  },
  "FasterRCNN": {
    "__init__": [
      "self",
      "num_classes",
      "bounding_box_format",
      "backbone",
      "anchor_generator",
      "label_encoder",
      "rcnn_head",
      "prediction_decoder"
    ],
    "_call_rpn": [
      "self",
      "images",
      "anchors",
      "training"
    ],
    "_call_rcnn": [
      "self",
      "rois",
      "feature_map",
      "training"
    ],
    "call": [
      "self",
      "images",
      "training"
    ],
    "compile": [
      "self",
      "box_loss",
      "classification_loss",
      "rpn_box_loss",
      "rpn_classification_loss",
      "weight_decay",
      "loss"
    ],
    "compute_loss": [
      "self",
      "images",
      "boxes",
      "classes",
      "training"
    ],
    "train_step": [
      "self",
      "data"
    ],
    "test_step": [
      "self",
      "data"
    ],
    "make_predict_function": [
      "self",
      "force"
    ],
    "prediction_decoder": [
      "self",
      "prediction_decoder"
    ],
    "decode_predictions": [
      "self",
      "predictions",
      "images"
    ],
    "get_config": [
      "self"
    ]
  },
  "_validate_and_get_loss": [
    "loss",
    "loss_name"
  ],
  "ImageClassifier": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "pooling",
      "activation"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "classifier_presets": [],
  "VideoClassifier": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "pooling",
      "activation"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "SegFormerB0": {
    "__new__": [
      "cls",
      "num_classes"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "SegFormerB1": {
    "__new__": [
      "cls",
      "num_classes"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "SegFormerB2": {
    "__new__": [
      "cls",
      "num_classes"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "SegFormerB3": {
    "__new__": [
      "cls",
      "num_classes"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "SegFormerB4": {
    "__new__": [
      "cls",
      "num_classes"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "SegFormerB5": {
    "__new__": [
      "cls",
      "num_classes"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "SegFormer": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "projection_filters"
    ],
    "get_config": [
      "self"
    ],
    "from_preset": [
      "cls",
      "preset",
      "num_classes",
      "load_weights",
      "input_shape"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "presets_no_weights": [],
  "presets_with_weights": [],
  "presets": [],
  "deeplab_v3_plus_presets": [],
  "DeepLabV3Plus": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "projection_filters",
      "spatial_pyramid_pooling",
      "segmentation_head"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "TwoWayTransformer": {
    "__init__": [
      "self"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "image_embedding",
      "image_pe",
      "point_embedding"
    ],
    "get_config": [
      "self"
    ]
  },
  "MultiHeadAttentionWithDownsampling": {
    "__init__": [
      "self",
      "num_heads",
      "key_dim",
      "downsample_rate"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "__separate_heads": [
      "self",
      "x"
    ],
    "__recombine_heads": [
      "self",
      "x"
    ],
    "call": [
      "self",
      "query",
      "value",
      "key"
    ],
    "get_config": [
      "self"
    ]
  },
  "TwoWayMultiHeadAttention": {
    "__init__": [
      "self",
      "num_heads",
      "key_dim",
      "mlp_dim",
      "skip_first_layer_pe",
      "attention_downsample_rate",
      "activation"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "queries",
      "keys",
      "query_pe",
      "key_pe"
    ],
    "get_config": [
      "self"
    ]
  },
  "RandomFrequencyPositionalEmbeddings": {
    "__init__": [
      "self",
      "num_positional_features",
      "scale"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "__positional_encodings": [
      "self",
      "coords"
    ],
    "call": [
      "self",
      "size"
    ],
    "encode_image": [
      "self",
      "size"
    ],
    "encode_coordinates": [
      "self",
      "coords_input",
      "image_size"
    ],
    "get_config": [
      "self"
    ]
  },
  "SegmentAnythingModel": {
    "__init__": [
      "self"
    ],
    "predict_step": [
      "self"
    ],
    "fit": [
      "self"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "_add_placeholder_prompts": [
    "inputs"
  ],
  "sam_presets": [],
  "SAMPromptEncoder": {
    "__init__": [
      "self"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "__embed_points": [
      "self",
      "points",
      "labels"
    ],
    "__embed_box": [
      "self",
      "box"
    ],
    "__embed_mask": [
      "self",
      "mask"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "get_config": [
      "self"
    ]
  },
  "SAMMaskDecoder": {
    "__init__": [
      "self"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs"
    ],
    "_predict_masks": [
      "self",
      "image_embeddings",
      "image_pe",
      "sparse_prompt_embeddings",
      "dense_prompt_embeddings"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "basnet_presets": [],
  "BASNet": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "input_shape",
      "input_tensor",
      "include_rescaling",
      "projection_filters",
      "prediction_heads",
      "refinement_head"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "presets_without_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "convolution_block": [
    "x_input",
    "filters",
    "dilation"
  ],
  "get_resnet_block": [
    "_resnet",
    "block_num"
  ],
  "basnet_predict": [
    "x_input",
    "backbone",
    "filters",
    "segmentation_heads"
  ],
  "basnet_rrm": [
    "base_model",
    "filters",
    "segmentation_head"
  ],
  "ResnetBlock": {
    "__init__": [
      "self",
      "output_dim"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "bytes_to_unicode": [],
  "get_pairs": [
    "word"
  ],
  "basic_clean": [
    "text"
  ],
  "whitespace_clean": [
    "text"
  ],
  "SimpleTokenizer": {
    "__init__": [
      "self",
      "bpe_path"
    ],
    "_create_encoder": [
      "self",
      "vocab"
    ],
    "_create_decoder": [
      "self",
      "encoder"
    ],
    "_create_pat": [
      "self"
    ],
    "end_of_text": [
      "self"
    ],
    "start_of_text": [
      "self"
    ],
    "add_tokens": [
      "self",
      "tokens"
    ],
    "bpe": [
      "self",
      "token"
    ],
    "encode": [
      "self",
      "text"
    ],
    "decode": [
      "self",
      "tokens"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "img_height",
      "img_width",
      "name",
      "download_weights"
    ]
  },
  "DiffusionModel": {
    "__init__": [
      "self",
      "img_height",
      "img_width",
      "max_text_length",
      "name",
      "download_weights"
    ]
  },
  "DiffusionModelV2": {
    "__init__": [
      "self",
      "img_height",
      "img_width",
      "max_text_length",
      "name",
      "download_weights"
    ]
  },
  "ResBlock": {
    "__init__": [
      "self",
      "output_dim"
    ],
    "build": [
      "self",
      "input_shape"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "SpatialTransformer": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "fully_connected"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "BasicTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "head_size"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "CrossAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size"
    ],
    "call": [
      "self",
      "inputs",
      "context"
    ]
  },
  "Upsample": {
    "__init__": [
      "self",
      "channels"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "GEGLU": {
    "__init__": [
      "self",
      "output_dim"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "td_dot": [
    "a",
    "b"
  ],
  "NoiseScheduler": {
    "__init__": [
      "self",
      "train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "variance_type",
      "clip_sample"
    ],
    "_get_variance": [
      "self",
      "timestep",
      "predicted_variance"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "predict_epsilon"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "TextEncoder": {
    "__init__": [
      "self",
      "max_length",
      "vocab_size",
      "name",
      "download_weights"
    ]
  },
  "TextEncoderV2": {
    "__init__": [
      "self",
      "max_length",
      "vocab_size",
      "name",
      "download_weights"
    ]
  },
  "quick_gelu": [
    "x"
  ],
  "CLIPEmbedding": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "max_length"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "CLIPEncoderLayer": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "activation"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "MAX_PROMPT_LENGTH": [],
  "StableDiffusionBase": {
    "__init__": [
      "self",
      "img_height",
      "img_width",
      "jit_compile"
    ],
    "text_to_image": [
      "self",
      "prompt",
      "negative_prompt",
      "batch_size",
      "num_steps",
      "unconditional_guidance_scale",
      "seed"
    ],
    "encode_text": [
      "self",
      "prompt"
    ],
    "generate_image": [
      "self",
      "encoded_text",
      "negative_prompt",
      "batch_size",
      "num_steps",
      "unconditional_guidance_scale",
      "diffusion_noise",
      "seed"
    ],
    "_get_unconditional_context": [
      "self"
    ],
    "_expand_tensor": [
      "self",
      "text_embedding",
      "batch_size"
    ],
    "image_encoder": [
      "self"
    ],
    "text_encoder": [
      "self"
    ],
    "diffusion_model": [
      "self"
    ],
    "decoder": [
      "self"
    ],
    "tokenizer": [
      "self"
    ],
    "_get_timestep_embedding": [
      "self",
      "timestep",
      "batch_size",
      "dim",
      "max_period"
    ],
    "_get_initial_alphas": [
      "self",
      "timesteps"
    ],
    "_get_initial_diffusion_noise": [
      "self",
      "batch_size",
      "seed"
    ],
    "_get_pos_ids": []
  },
  "StableDiffusion": {
    "__init__": [
      "self",
      "img_height",
      "img_width",
      "jit_compile"
    ],
    "text_encoder": [
      "self"
    ],
    "diffusion_model": [
      "self"
    ]
  },
  "StableDiffusionV2": {
    "__init__": [
      "self",
      "img_height",
      "img_width",
      "jit_compile"
    ],
    "text_encoder": [
      "self"
    ],
    "diffusion_model": [
      "self"
    ]
  },
  "_UNCONDITIONAL_TOKENS": [],
  "_ALPHAS_CUMPROD": [],
  "ImageEncoder": {
    "__init__": [
      "self",
      "download_weights"
    ]
  },
  "PaddedConv2D": {
    "__init__": [
      "self",
      "filters",
      "kernel_size",
      "padding",
      "strides"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "AttentionBlock": {
    "__init__": [
      "self",
      "output_dim"
    ],
    "call": [
      "self",
      "inputs"
    ]
  },
  "_minimum_control_deps": [
    "outputs"
  ],
  "make_predict_function": [
    "model",
    "force"
  ],
  "unpack_input": [
    "data"
  ],
  "_get_tensor_types": [],
  "train_validation_split": [
    "arrays",
    "validation_split"
  ],
  "yolo_v8_detector_presets": [],
  "apply_spatial_pyramid_pooling_fast": [
    "inputs",
    "pool_size",
    "activation",
    "name"
  ],
  "YOLOV8Backbone": {
    "__init__": [
      "self",
      "stackwise_channels",
      "stackwise_depth",
      "include_rescaling",
      "activation",
      "input_shape",
      "input_tensor"
    ],
    "get_config": [
      "self"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ]
  },
  "BATCH_NORM_EPSILON": [],
  "BATCH_NORM_MOMENTUM": [],
  "apply_conv_bn": [
    "inputs",
    "output_channel",
    "kernel_size",
    "strides",
    "activation",
    "name"
  ],
  "apply_csp_block": [
    "inputs",
    "channels",
    "depth",
    "shortcut",
    "expansion",
    "activation",
    "name"
  ],
  "is_anchor_center_within_box": [
    "anchors",
    "gt_bboxes"
  ],
  "YOLOV8LabelEncoder": {
    "__init__": [
      "self",
      "num_classes",
      "max_anchor_matches",
      "alpha",
      "beta",
      "epsilon"
    ],
    "assign": [
      "self",
      "scores",
      "decode_bboxes",
      "anchors",
      "gt_labels",
      "gt_bboxes",
      "gt_mask"
    ],
    "call": [
      "self",
      "scores",
      "decode_bboxes",
      "anchors",
      "gt_labels",
      "gt_bboxes",
      "gt_mask"
    ],
    "count_params": [
      "self"
    ],
    "get_config": [
      "self"
    ]
  },
  "BOX_REGRESSION_CHANNELS": [],
  "get_anchors": [
    "image_shape",
    "strides",
    "base_anchors"
  ],
  "apply_path_aggregation_fpn": [
    "features",
    "depth",
    "name"
  ],
  "apply_yolo_v8_head": [
    "inputs",
    "num_classes",
    "name"
  ],
  "decode_regression_to_boxes": [
    "preds"
  ],
  "dist2bbox": [
    "distance",
    "anchor_points"
  ],
  "YOLOV8Detector": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "bounding_box_format",
      "fpn_depth",
      "label_encoder",
      "prediction_decoder"
    ],
    "compile": [
      "self",
      "box_loss",
      "classification_loss",
      "box_loss_weight",
      "classification_loss_weight",
      "metrics"
    ],
    "train_step": [
      "self"
    ],
    "test_step": [
      "self"
    ],
    "compute_loss": [
      "self",
      "x",
      "y",
      "y_pred",
      "sample_weight"
    ],
    "decode_predictions": [
      "self",
      "pred",
      "images"
    ],
    "predict_step": [
      "self"
    ],
    "prediction_decoder": [
      "self",
      "prediction_decoder"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "retinanet_presets": [],
  "RetinaNetLabelEncoder": {
    "__init__": [
      "self",
      "bounding_box_format",
      "anchor_generator",
      "positive_threshold",
      "negative_threshold",
      "box_variance",
      "background_class",
      "ignore_class"
    ],
    "_encode_sample": [
      "self",
      "box_labels",
      "anchor_boxes",
      "image_shape"
    ],
    "call": [
      "self",
      "images",
      "box_labels"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "MatchedBoxesMetric": {
    "load_own_variables": [
      "self",
      "store"
    ]
  },
  "RetinaNet": {
    "__init__": [
      "self",
      "backbone",
      "num_classes",
      "bounding_box_format",
      "anchor_generator",
      "label_encoder",
      "prediction_decoder",
      "feature_pyramid",
      "classification_head",
      "box_head"
    ],
    "predict_step": [
      "self"
    ],
    "prediction_decoder": [
      "self",
      "prediction_decoder"
    ],
    "default_anchor_generator": [
      "bounding_box_format"
    ],
    "decode_predictions": [
      "self",
      "predictions",
      "images"
    ],
    "compile": [
      "self",
      "box_loss",
      "classification_loss",
      "loss",
      "metrics"
    ],
    "compute_loss": [
      "self",
      "x",
      "y",
      "y_pred",
      "sample_weight"
    ],
    "train_step": [
      "self"
    ],
    "test_step": [
      "self"
    ],
    "compute_metrics": [
      "self",
      "x",
      "y",
      "y_pred",
      "sample_weight"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "presets": [
      "cls"
    ],
    "presets_with_weights": [
      "cls"
    ],
    "backbone_presets": [
      "cls"
    ]
  },
  "_parse_box_loss": [
    "loss"
  ],
  "_parse_classification_loss": [
    "loss"
  ],
  "PredictionHead": {
    "__init__": [
      "self",
      "output_filters",
      "bias_initializer",
      "num_conv_layers"
    ],
    "call": [
      "self",
      "x",
      "training"
    ],
    "compute_output_shape": [
      "self",
      "input_shape"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "build": [
      "self",
      "input_shape"
    ]
  },
  "BinaryCrossentropy": {
    "__init__": [
      "self",
      "from_logits",
      "label_smoothing",
      "axis"
    ],
    "call": [
      "self",
      "y_true",
      "y_pred"
    ],
    "get_config": [
      "self"
    ]
  },
  "YoloXHead": {
    "__init__": [
      "self",
      "num_classes",
      "bias_initializer",
      "width_multiplier",
      "num_level",
      "activation",
      "use_depthwise"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ]
  },
  "YoloXPredictionDecoder": {
    "__init__": [
      "self",
      "bounding_box_format",
      "num_classes",
      "suppression_layer"
    ],
    "call": [
      "self",
      "images",
      "predictions"
    ]
  },
  "YoloXLabelEncoder": {
    "__init__": [
      "self"
    ],
    "call": [
      "self",
      "images",
      "box_labels"
    ]
  },
  "YoloXPAFPN": {
    "__init__": [
      "self",
      "depth_multiplier",
      "width_multiplier",
      "in_channels",
      "use_depthwise",
      "activation"
    ],
    "call": [
      "self",
      "inputs",
      "training"
    ]
  },
  "FactorSampler": {
    "__call__": [
      "self",
      "shape",
      "dtype"
    ],
    "get_config": [
      "self"
    ]
  },
  "NormalFactorSampler": {
    "__init__": [
      "self",
      "mean",
      "stddev",
      "min_value",
      "max_value",
      "seed"
    ],
    "__call__": [
      "self",
      "shape",
      "dtype"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "UniformFactorSampler": {
    "__init__": [
      "self",
      "lower",
      "upper",
      "seed"
    ],
    "__call__": [
      "self",
      "shape",
      "dtype"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "ConstantFactorSampler": {
    "__init__": [
      "self",
      "value"
    ],
    "__call__": [
      "self",
      "shape",
      "dtype"
    ],
    "get_config": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ]
  },
  "draw_bounding_boxes": [
    "images",
    "bounding_boxes",
    "color",
    "bounding_box_format",
    "line_thickness",
    "text_thickness",
    "font_scale",
    "class_mapping"
  ],
  "_find_text_location": [
    "x",
    "y",
    "font_scale",
    "line_thickness",
    "outline_factor"
  ],
  "reshape_masks": [
    "segmentation_masks"
  ],
  "transform_segmentation_masks": [
    "segmentation_masks",
    "num_classes",
    "value_range"
  ],
  "plot_segmentation_mask_gallery": [
    "images",
    "value_range",
    "num_classes",
    "y_true",
    "y_pred",
    "rows",
    "cols"
  ],
  "_extract_image_batch": [
    "images",
    "num_images",
    "batch_size"
  ],
  "plot_image_gallery": [
    "images",
    "value_range",
    "scale",
    "rows",
    "cols",
    "path",
    "show",
    "transparent",
    "dpi",
    "legend_handles"
  ],
  "plot_bounding_box_gallery": [
    "images",
    "value_range",
    "bounding_box_format",
    "y_true",
    "y_pred",
    "true_color",
    "pred_color",
    "line_thickness",
    "font_scale",
    "text_thickness",
    "class_mapping",
    "ground_truth_mapping",
    "prediction_mapping",
    "legend",
    "legend_handles",
    "rows",
    "cols"
  ]
}