{
  "_get_redis_kwargs": [],
  "_get_redis_url_kwargs": [
    "client"
  ],
  "_get_redis_cluster_kwargs": [
    "client"
  ],
  "_get_redis_env_kwarg_mapping": [],
  "_redis_kwargs_from_environment": [],
  "_generate_gcp_iam_access_token": [
    "service_account"
  ],
  "create_gcp_iam_redis_connect_func": [
    "service_account",
    "ssl_ca_certs"
  ],
  "get_redis_url_from_environment": [],
  "_get_redis_client_logic": [],
  "init_redis_cluster": [
    "redis_kwargs"
  ],
  "_init_redis_sentinel": [
    "redis_kwargs"
  ],
  "_init_async_redis_sentinel": [
    "redis_kwargs"
  ],
  "get_redis_client": [],
  "get_redis_async_client": [
    "connection_pool"
  ],
  "get_redis_connection_pool": [],
  "_pretty_print_redis_config": [
    "redis_kwargs"
  ],
  "_CachingHandlerResponse": [],
  "_LLMCachingHandler": [],
  "_CustomGuardrail": [],
  "_CustomLogger": [],
  "_get_cached_custom_logger": [],
  "_get_cached_custom_guardrail": [],
  "_get_cached_caching_handler_response": [],
  "_get_cached_llm_caching_handler": [],
  "_audio_utils_module": [],
  "_get_cached_audio_utils": [],
  "claude_json_str": [],
  "sentry_sdk_instance": [],
  "capture_exception": [],
  "add_breadcrumb": [],
  "posthog": [],
  "slack_app": [],
  "alerts_channel": [],
  "heliconeLogger": [],
  "athinaLogger": [],
  "promptLayerLogger": [],
  "langsmithLogger": [],
  "logfireLogger": [],
  "weightsBiasesLogger": [],
  "customLogger": [],
  "langFuseLogger": [],
  "openMeterLogger": [],
  "lagoLogger": [],
  "dataDogLogger": [],
  "prometheusLogger": [],
  "dynamoLogger": [],
  "s3Logger": [],
  "greenscaleLogger": [],
  "lunaryLogger": [],
  "aispendLogger": [],
  "supabaseClient": [],
  "user_logger_fn": [],
  "last_fetched_at": [],
  "last_fetched_at_keys": [],
  "print_verbose": [
    "print_statement",
    "logger_only",
    "log_level"
  ],
  "custom_llm_setup": [],
  "_add_custom_logger_callback_to_specific_event": [
    "callback",
    "logging_event"
  ],
  "_custom_logger_class_exists_in_success_callbacks": [
    "callback_class"
  ],
  "_custom_logger_class_exists_in_failure_callbacks": [
    "callback_class"
  ],
  "get_request_guardrails": [
    "kwargs"
  ],
  "get_applied_guardrails": [
    "kwargs"
  ],
  "load_credentials_from_list": [
    "kwargs"
  ],
  "get_dynamic_callbacks": [
    "dynamic_callbacks"
  ],
  "_is_gemini_model": [
    "model",
    "custom_llm_provider"
  ],
  "_remove_thought_signature_from_id": [
    "tool_call_id",
    "separator"
  ],
  "_process_assistant_message_tool_calls": [
    "msg_copy",
    "thought_signature_separator"
  ],
  "_process_tool_message_id": [
    "msg_copy",
    "thought_signature_separator"
  ],
  "_remove_thought_signatures_from_messages": [
    "messages",
    "thought_signature_separator"
  ],
  "function_setup": [
    "original_function",
    "rules_obj",
    "start_time"
  ],
  "_client_async_logging_helper": [
    "logging_obj",
    "result",
    "start_time",
    "end_time",
    "is_completion_with_fallbacks"
  ],
  "_get_wrapper_num_retries": [
    "kwargs",
    "exception"
  ],
  "_get_wrapper_timeout": [
    "kwargs",
    "exception"
  ],
  "check_coroutine": [
    "value"
  ],
  "async_pre_call_deployment_hook": [
    "kwargs",
    "call_type"
  ],
  "async_post_call_success_deployment_hook": [
    "request_data",
    "response",
    "call_type"
  ],
  "post_call_processing": [
    "original_response",
    "model",
    "optional_params",
    "original_function",
    "rules_obj"
  ],
  "client": [
    "original_function"
  ],
  "_is_async_request": [
    "kwargs",
    "is_pass_through"
  ],
  "_STREAMING_CALL_TYPES": [],
  "_is_streaming_request": [
    "kwargs",
    "call_type"
  ],
  "_select_tokenizer": [
    "model",
    "custom_tokenizer"
  ],
  "_select_tokenizer_helper": [
    "model"
  ],
  "_return_openai_tokenizer": [
    "model"
  ],
  "_return_huggingface_tokenizer": [
    "model"
  ],
  "encode": [
    "model",
    "text",
    "custom_tokenizer"
  ],
  "decode": [
    "model",
    "tokens",
    "custom_tokenizer"
  ],
  "create_pretrained_tokenizer": [
    "identifier",
    "revision",
    "auth_token"
  ],
  "create_tokenizer": [
    "json"
  ],
  "token_counter": [
    "model",
    "custom_tokenizer",
    "text",
    "messages",
    "count_response_tokens",
    "tools",
    "tool_choice",
    "use_default_image_token_count",
    "default_token_count"
  ],
  "supports_httpx_timeout": [
    "custom_llm_provider"
  ],
  "supports_system_messages": [
    "model",
    "custom_llm_provider"
  ],
  "supports_web_search": [
    "model",
    "custom_llm_provider"
  ],
  "supports_url_context": [
    "model",
    "custom_llm_provider"
  ],
  "supports_native_streaming": [
    "model",
    "custom_llm_provider"
  ],
  "supports_response_schema": [
    "model",
    "custom_llm_provider"
  ],
  "supports_parallel_function_calling": [
    "model",
    "custom_llm_provider"
  ],
  "supports_function_calling": [
    "model",
    "custom_llm_provider"
  ],
  "supports_tool_choice": [
    "model",
    "custom_llm_provider"
  ],
  "_supports_provider_info_factory": [
    "model",
    "custom_llm_provider",
    "key"
  ],
  "_supports_factory": [
    "model",
    "custom_llm_provider",
    "key"
  ],
  "supports_audio_input": [
    "model",
    "custom_llm_provider"
  ],
  "supports_pdf_input": [
    "model",
    "custom_llm_provider"
  ],
  "supports_audio_output": [
    "model",
    "custom_llm_provider"
  ],
  "supports_prompt_caching": [
    "model",
    "custom_llm_provider"
  ],
  "supports_computer_use": [
    "model",
    "custom_llm_provider"
  ],
  "supports_vision": [
    "model",
    "custom_llm_provider"
  ],
  "supports_reasoning": [
    "model",
    "custom_llm_provider"
  ],
  "get_supported_regions": [
    "model",
    "custom_llm_provider"
  ],
  "supports_embedding_image_input": [
    "model",
    "custom_llm_provider"
  ],
  "_update_dictionary": [
    "existing_dict",
    "new_dict"
  ],
  "_convert_stringified_numbers": [
    "value"
  ],
  "register_model": [
    "model_cost"
  ],
  "_should_drop_param": [
    "k",
    "additional_drop_params"
  ],
  "_get_non_default_params": [
    "passed_params",
    "default_params",
    "additional_drop_params"
  ],
  "get_optional_params_transcription": [
    "model",
    "custom_llm_provider",
    "language",
    "prompt",
    "response_format",
    "temperature",
    "timestamp_granularities",
    "drop_params"
  ],
  "_map_openai_size_to_vertex_ai_aspect_ratio": [
    "size"
  ],
  "get_optional_params_image_gen": [
    "model",
    "n",
    "quality",
    "response_format",
    "size",
    "style",
    "user",
    "custom_llm_provider",
    "additional_drop_params",
    "provider_config",
    "drop_params"
  ],
  "get_optional_params_embeddings": [
    "model",
    "user",
    "encoding_format",
    "dimensions",
    "custom_llm_provider",
    "drop_params",
    "additional_drop_params"
  ],
  "_remove_additional_properties": [
    "schema"
  ],
  "_remove_strict_from_schema": [
    "schema"
  ],
  "_remove_json_schema_refs": [
    "schema",
    "max_depth"
  ],
  "_remove_unsupported_params": [
    "non_default_params",
    "supported_openai_params"
  ],
  "filter_out_litellm_params": [
    "kwargs"
  ],
  "PreProcessNonDefaultParams": {
    "base_pre_process_non_default_params": [
      "passed_params",
      "special_params",
      "custom_llm_provider",
      "additional_drop_params",
      "default_param_values",
      "additional_endpoint_specific_params"
    ],
    "embedding_pre_process_non_default_params": [
      "passed_params",
      "special_params",
      "custom_llm_provider",
      "additional_drop_params",
      "model",
      "remove_sensitive_keys",
      "add_provider_specific_params"
    ]
  },
  "pre_process_non_default_params": [
    "passed_params",
    "special_params",
    "custom_llm_provider",
    "additional_drop_params",
    "model",
    "remove_sensitive_keys",
    "add_provider_specific_params",
    "provider_config"
  ],
  "remove_sensitive_keys_from_dict": [
    "d"
  ],
  "pre_process_optional_params": [
    "passed_params",
    "non_default_params",
    "custom_llm_provider"
  ],
  "get_optional_params": [
    "model",
    "functions",
    "function_call",
    "temperature",
    "top_p",
    "n",
    "stream",
    "stream_options",
    "stop",
    "max_tokens",
    "max_completion_tokens",
    "modalities",
    "prediction",
    "audio",
    "presence_penalty",
    "frequency_penalty",
    "logit_bias",
    "user",
    "custom_llm_provider",
    "response_format",
    "seed",
    "tools",
    "tool_choice",
    "max_retries",
    "logprobs",
    "top_logprobs",
    "extra_headers",
    "api_version",
    "parallel_tool_calls",
    "drop_params",
    "allowed_openai_params",
    "reasoning_effort",
    "verbosity",
    "additional_drop_params",
    "messages",
    "thinking",
    "web_search_options",
    "safety_identifier"
  ],
  "add_provider_specific_params_to_optional_params": [
    "optional_params",
    "passed_params",
    "custom_llm_provider",
    "openai_params",
    "additional_drop_params"
  ],
  "_apply_openai_param_overrides": [
    "optional_params",
    "non_default_params",
    "allowed_openai_params"
  ],
  "get_non_default_params": [
    "passed_params"
  ],
  "calculate_max_parallel_requests": [
    "max_parallel_requests",
    "rpm",
    "tpm",
    "default_max_parallel_requests"
  ],
  "_get_order_filtered_deployments": [
    "healthy_deployments"
  ],
  "_get_model_region": [
    "custom_llm_provider",
    "litellm_params"
  ],
  "_infer_model_region": [
    "litellm_params"
  ],
  "_is_region_eu": [
    "litellm_params"
  ],
  "_is_region_us": [
    "litellm_params"
  ],
  "is_region_allowed": [
    "litellm_params",
    "allowed_model_region"
  ],
  "get_model_region": [
    "litellm_params",
    "mode"
  ],
  "get_first_chars_messages": [
    "kwargs"
  ],
  "_count_characters": [
    "text"
  ],
  "get_response_string": [
    "response_obj"
  ],
  "get_api_key": [
    "llm_provider",
    "dynamic_api_key"
  ],
  "get_utc_datetime": [],
  "get_max_tokens": [
    "model"
  ],
  "_strip_stable_vertex_version": [
    "model_name"
  ],
  "_get_base_bedrock_model": [
    "model_name"
  ],
  "_strip_openai_finetune_model_name": [
    "model_name"
  ],
  "_strip_model_name": [
    "model",
    "custom_llm_provider"
  ],
  "_invalidate_model_cost_lowercase_map": [],
  "_rebuild_model_cost_lowercase_map": [],
  "_handle_stale_map_entry_rebuild": [
    "potential_key_lower"
  ],
  "_handle_new_key_with_scan": [
    "potential_key_lower"
  ],
  "_get_model_cost_key": [
    "potential_key"
  ],
  "_get_model_info_from_model_cost": [
    "key"
  ],
  "_check_provider_match": [
    "model_info",
    "custom_llm_provider"
  ],
  "PotentialModelNamesAndCustomLLMProvider": {},
  "_get_potential_model_names": [
    "model",
    "custom_llm_provider"
  ],
  "_get_max_position_embeddings": [
    "model_name"
  ],
  "_cached_get_model_info_helper": [
    "model",
    "custom_llm_provider"
  ],
  "get_provider_info": [
    "model",
    "custom_llm_provider"
  ],
  "_is_potential_model_name_in_model_cost": [
    "potential_model_names"
  ],
  "_get_model_info_helper": [
    "model",
    "custom_llm_provider"
  ],
  "get_model_info": [
    "model",
    "custom_llm_provider"
  ],
  "json_schema_type": [
    "python_type_name"
  ],
  "function_to_dict": [
    "input_function"
  ],
  "modify_url": [
    "original_url",
    "new_path"
  ],
  "load_test_model": [
    "model",
    "custom_llm_provider",
    "api_base",
    "prompt",
    "num_calls",
    "force_timeout"
  ],
  "get_provider_fields": [
    "custom_llm_provider"
  ],
  "create_proxy_transport_and_mounts": [],
  "validate_environment": [
    "model",
    "api_key",
    "api_base",
    "api_version"
  ],
  "acreate": [],
  "prompt_token_calculator": [
    "model",
    "messages"
  ],
  "valid_model": [
    "model"
  ],
  "check_valid_key": [
    "model",
    "api_key"
  ],
  "_should_retry": [
    "status_code"
  ],
  "_get_retry_after_from_exception_header": [
    "response_headers"
  ],
  "_calculate_retry_after": [
    "remaining_retries",
    "max_retries",
    "response_headers",
    "min_timeout"
  ],
  "register_prompt_template": [
    "model",
    "roles",
    "initial_prompt_value",
    "final_prompt_value",
    "tokenizer_config"
  ],
  "TextCompletionStreamWrapper": {
    "__init__": [
      "self",
      "completion_stream",
      "model",
      "stream_options",
      "custom_llm_provider"
    ],
    "__iter__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "convert_to_text_completion_object": [
      "self",
      "chunk"
    ],
    "__next__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "mock_completion_streaming_obj": [
    "model_response",
    "mock_response",
    "model",
    "n"
  ],
  "async_mock_completion_streaming_obj": [
    "model_response",
    "mock_response",
    "model",
    "n"
  ],
  "read_config_args": [
    "config_path"
  ],
  "process_system_message": [
    "system_message",
    "max_tokens",
    "model"
  ],
  "process_messages": [
    "messages",
    "max_tokens",
    "model"
  ],
  "attempt_message_addition": [
    "final_messages",
    "message",
    "available_tokens",
    "max_tokens",
    "model"
  ],
  "can_add_message": [
    "message",
    "messages",
    "max_tokens",
    "model"
  ],
  "get_token_count": [
    "messages",
    "model"
  ],
  "shorten_message_to_fit_limit": [
    "message",
    "tokens_needed",
    "model",
    "raise_error_on_max_limit"
  ],
  "trim_messages": [
    "messages",
    "model",
    "trim_ratio",
    "return_response_tokens",
    "max_tokens"
  ],
  "AvailableModelsCache": {
    "__init__": [
      "self",
      "ttl_seconds",
      "max_size"
    ],
    "_get_env_hash": [
      "self"
    ],
    "_check_env_changed": [
      "self"
    ],
    "_get_cache_key": [
      "self",
      "custom_llm_provider",
      "litellm_params"
    ],
    "get_cached_model_info": [
      "self",
      "custom_llm_provider",
      "litellm_params"
    ],
    "set_cached_model_info": [
      "self",
      "custom_llm_provider",
      "litellm_params",
      "available_models"
    ]
  },
  "_model_cache": [],
  "_infer_valid_provider_from_env_vars": [
    "custom_llm_provider"
  ],
  "_get_valid_models_from_provider_api": [
    "provider_config",
    "custom_llm_provider",
    "litellm_params"
  ],
  "get_valid_models": [
    "check_provider_endpoint",
    "custom_llm_provider",
    "litellm_params",
    "api_key",
    "api_base"
  ],
  "print_args_passed_to_litellm": [
    "original_function",
    "args",
    "kwargs"
  ],
  "get_logging_id": [
    "start_time",
    "response_obj"
  ],
  "_get_base_model_from_metadata": [
    "model_call_details"
  ],
  "ModelResponseIterator": {
    "__init__": [
      "self",
      "model_response",
      "convert_to_delta"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "ModelResponseListIterator": {
    "__init__": [
      "self",
      "model_responses",
      "delay"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "CustomModelResponseIterator": {
    "__init__": [
      "self"
    ]
  },
  "is_cached_message": [
    "message"
  ],
  "is_base64_encoded": [
    "s"
  ],
  "get_base64_str": [
    "s"
  ],
  "has_tool_call_blocks": [
    "messages"
  ],
  "any_assistant_message_has_thinking_blocks": [
    "messages"
  ],
  "last_assistant_with_tool_calls_has_no_thinking_blocks": [
    "messages"
  ],
  "add_dummy_tool": [
    "custom_llm_provider"
  ],
  "convert_to_dict": [
    "message"
  ],
  "convert_list_message_to_dict": [
    "messages"
  ],
  "validate_and_fix_openai_messages": [
    "messages"
  ],
  "validate_and_fix_openai_tools": [
    "tools"
  ],
  "cleanup_none_field_in_message": [
    "message"
  ],
  "validate_chat_completion_user_messages": [
    "messages"
  ],
  "validate_chat_completion_tool_choice": [
    "tool_choice"
  ],
  "validate_openai_optional_params": [
    "stop"
  ],
  "ProviderConfigManager": {
    "_build_provider_config_map": [],
    "_get_azure_config": [
      "model"
    ],
    "_get_azure_ai_config": [
      "model"
    ],
    "_get_vertex_ai_config": [
      "model"
    ],
    "_get_bedrock_config": [
      "model"
    ],
    "_get_cohere_config": [
      "model"
    ],
    "_get_langgraph_config": [],
    "get_provider_chat_config": [
      "model",
      "provider"
    ],
    "get_provider_embedding_config": [
      "model",
      "provider"
    ],
    "get_provider_rerank_config": [
      "model",
      "provider",
      "api_base",
      "present_version_params"
    ],
    "get_provider_anthropic_messages_config": [
      "model",
      "provider"
    ],
    "get_provider_audio_transcription_config": [
      "model",
      "provider"
    ],
    "get_provider_responses_api_config": [
      "provider",
      "model"
    ],
    "get_provider_skills_api_config": [
      "provider"
    ],
    "get_provider_evals_api_config": [
      "provider"
    ],
    "get_provider_text_completion_config": [
      "model",
      "provider"
    ],
    "get_provider_model_info": [
      "model",
      "provider"
    ],
    "get_provider_passthrough_config": [
      "model",
      "provider"
    ],
    "get_provider_image_variation_config": [
      "model",
      "provider"
    ],
    "get_provider_files_config": [
      "model",
      "provider"
    ],
    "get_provider_batches_config": [
      "model",
      "provider"
    ],
    "get_provider_vector_store_config": [
      "provider"
    ],
    "get_provider_vector_stores_config": [
      "provider",
      "api_type"
    ],
    "get_provider_vector_store_files_config": [
      "provider"
    ],
    "get_provider_image_generation_config": [
      "model",
      "provider"
    ],
    "get_provider_video_config": [
      "model",
      "provider"
    ],
    "get_provider_container_config": [
      "provider"
    ],
    "get_provider_realtime_config": [
      "model",
      "provider"
    ],
    "get_provider_image_edit_config": [
      "model",
      "provider"
    ],
    "get_provider_ocr_config": [
      "model",
      "provider"
    ],
    "get_provider_search_config": [
      "provider"
    ],
    "get_provider_text_to_speech_config": [
      "model",
      "provider"
    ],
    "get_provider_google_genai_generate_content_config": [
      "model",
      "provider"
    ]
  },
  "get_end_user_id_for_cost_tracking": [
    "litellm_params",
    "service_type"
  ],
  "should_use_cohere_v1_client": [
    "api_base",
    "present_version_params"
  ],
  "is_prompt_caching_valid_prompt": [
    "model",
    "messages",
    "tools",
    "custom_llm_provider"
  ],
  "extract_duration_from_srt_or_vtt": [
    "srt_or_vtt_content"
  ],
  "_add_path_to_api_base": [
    "api_base",
    "ending_path"
  ],
  "get_standard_openai_params": [
    "params"
  ],
  "get_non_default_completion_params": [
    "kwargs"
  ],
  "get_non_default_transcription_params": [
    "kwargs"
  ],
  "add_openai_metadata": [
    "metadata"
  ],
  "get_requester_metadata": [
    "metadata"
  ],
  "return_raw_request": [
    "endpoint",
    "kwargs"
  ],
  "jsonify_tools": [
    "tools"
  ],
  "get_empty_usage": [],
  "should_run_mock_completion": [
    "mock_response",
    "mock_tool_calls",
    "mock_timeout"
  ],
  "__getattr__": [
    "name"
  ],
  "_A2A_CALL_TYPES": [],
  "_VIDEO_CALL_TYPES": [],
  "_SPEECH_CALL_TYPES": [],
  "_TRANSCRIPTION_CALL_TYPES": [],
  "_RERANK_CALL_TYPES": [],
  "_SEARCH_CALL_TYPES": [],
  "_AREALTIME_CALL_TYPE": [],
  "_MCP_CALL_TYPE": [],
  "_cost_per_token_custom_pricing_helper": [
    "prompt_tokens",
    "completion_tokens",
    "response_time_ms",
    "custom_cost_per_token",
    "custom_cost_per_second"
  ],
  "_get_additional_costs": [
    "model",
    "custom_llm_provider",
    "prompt_tokens",
    "completion_tokens"
  ],
  "_transcription_usage_has_token_details": [
    "usage_block"
  ],
  "cost_per_token": [
    "model",
    "prompt_tokens",
    "completion_tokens",
    "response_time_ms",
    "custom_llm_provider",
    "region_name",
    "prompt_characters",
    "completion_characters",
    "cache_creation_input_tokens",
    "cache_read_input_tokens",
    "custom_cost_per_token",
    "custom_cost_per_second",
    "number_of_queries",
    "usage_object",
    "rerank_billed_units",
    "call_type",
    "audio_transcription_file_duration",
    "service_tier",
    "response"
  ],
  "get_replicate_completion_pricing": [
    "completion_response",
    "total_time"
  ],
  "has_hidden_params": [
    "obj"
  ],
  "_get_provider_for_cost_calc": [
    "model",
    "custom_llm_provider"
  ],
  "_select_model_name_for_cost_calc": [
    "model",
    "completion_response",
    "base_model",
    "custom_pricing",
    "custom_llm_provider",
    "router_model_id"
  ],
  "_model_contains_known_llm_provider": [
    "model"
  ],
  "_get_response_model": [
    "completion_response"
  ],
  "_get_usage_object": [
    "completion_response"
  ],
  "_is_known_usage_objects": [
    "usage_obj"
  ],
  "_infer_call_type": [
    "call_type",
    "completion_response"
  ],
  "_apply_cost_discount": [
    "base_cost",
    "custom_llm_provider"
  ],
  "_apply_cost_margin": [
    "base_cost",
    "custom_llm_provider"
  ],
  "_store_cost_breakdown_in_logging_obj": [
    "litellm_logging_obj",
    "prompt_tokens_cost_usd_dollar",
    "completion_tokens_cost_usd_dollar",
    "cost_for_built_in_tools_cost_usd_dollar",
    "total_cost_usd_dollar",
    "additional_costs",
    "original_cost",
    "discount_percent",
    "discount_amount",
    "margin_percent",
    "margin_fixed_amount",
    "margin_total_amount"
  ],
  "completion_cost": [
    "completion_response",
    "model",
    "prompt",
    "messages",
    "completion",
    "total_time",
    "call_type",
    "custom_llm_provider",
    "region_name",
    "size",
    "quality",
    "n",
    "custom_cost_per_token",
    "custom_cost_per_second",
    "optional_params",
    "custom_pricing",
    "base_model",
    "standard_built_in_tools_params",
    "litellm_model_name",
    "router_model_id",
    "litellm_logging_obj",
    "service_tier"
  ],
  "get_response_cost_from_hidden_params": [
    "hidden_params"
  ],
  "response_cost_calculator": [
    "response_object",
    "model",
    "custom_llm_provider",
    "call_type",
    "optional_params",
    "cache_hit",
    "base_model",
    "custom_pricing",
    "prompt",
    "standard_built_in_tools_params",
    "litellm_model_name",
    "router_model_id",
    "litellm_logging_obj",
    "service_tier"
  ],
  "ocr_cost": [
    "model",
    "custom_llm_provider",
    "response"
  ],
  "vector_store_search_cost": [
    "model",
    "custom_llm_provider",
    "response"
  ],
  "rerank_cost": [
    "model",
    "custom_llm_provider",
    "billed_units"
  ],
  "transcription_cost": [
    "model",
    "custom_llm_provider",
    "duration"
  ],
  "default_image_cost_calculator": [
    "model",
    "custom_llm_provider",
    "quality",
    "n",
    "size",
    "optional_params"
  ],
  "default_video_cost_calculator": [
    "model",
    "duration_seconds",
    "custom_llm_provider"
  ],
  "batch_cost_calculator": [
    "usage",
    "model",
    "custom_llm_provider",
    "model_info"
  ],
  "BaseTokenUsageProcessor": {
    "combine_usage_objects": [
      "usage_objects"
    ]
  },
  "RealtimeAPITokenUsageProcessor": {
    "collect_usage_from_realtime_stream_results": [
      "results"
    ],
    "collect_and_combine_usage_from_realtime_stream_results": [
      "results"
    ],
    "create_logging_realtime_object": [
      "usage",
      "results"
    ]
  },
  "handle_realtime_stream_cost_calculation": [
    "results",
    "combined_usage_object",
    "custom_llm_provider",
    "litellm_model_name"
  ],
  "uuid": [],
  "uuid4": [],
  "BudgetManager": {
    "__init__": [
      "self",
      "project_name",
      "client_type",
      "api_base",
      "headers"
    ],
    "print_verbose": [
      "self",
      "print_statement"
    ],
    "load_data": [
      "self"
    ],
    "create_budget": [
      "self",
      "total_budget",
      "user",
      "duration",
      "created_at"
    ],
    "projected_cost": [
      "self",
      "model",
      "messages",
      "user"
    ],
    "get_total_budget": [
      "self",
      "user"
    ],
    "update_cost": [
      "self",
      "user",
      "completion_obj",
      "model",
      "input_text",
      "output_text"
    ],
    "get_current_cost": [
      "self",
      "user"
    ],
    "get_model_cost": [
      "self",
      "user"
    ],
    "is_valid_user": [
      "self",
      "user"
    ],
    "get_users": [
      "self"
    ],
    "reset_cost": [
      "self",
      "user"
    ],
    "reset_on_duration": [
      "self",
      "user"
    ],
    "update_budget_all_users": [
      "self"
    ],
    "_save_data_thread": [
      "self"
    ],
    "save_data": [
      "self"
    ]
  },
  "ServiceLogging": {
    "__init__": [
      "self",
      "mock_testing"
    ],
    "service_success_hook": [
      "self",
      "service",
      "duration",
      "call_type",
      "parent_otel_span",
      "start_time",
      "end_time"
    ],
    "service_failure_hook": [
      "self",
      "service",
      "duration",
      "error",
      "call_type"
    ],
    "async_service_success_hook": [
      "self",
      "service",
      "call_type",
      "duration",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "init_prometheus_services_logger_if_none": [
      "self"
    ],
    "init_datadog_logger_if_none": [
      "self"
    ],
    "init_otel_logger_if_none": [
      "self"
    ],
    "async_service_failure_hook": [
      "self",
      "service",
      "duration",
      "error",
      "call_type",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "DEFAULT_HEALTH_CHECK_PROMPT": [],
  "AZURE_DEFAULT_RESPONSES_API_VERSION": [],
  "ROUTER_MAX_FALLBACKS": [],
  "DEFAULT_BATCH_SIZE": [],
  "DEFAULT_FLUSH_INTERVAL_SECONDS": [],
  "DEFAULT_S3_FLUSH_INTERVAL_SECONDS": [],
  "DEFAULT_S3_BATCH_SIZE": [],
  "DEFAULT_SQS_FLUSH_INTERVAL_SECONDS": [],
  "DEFAULT_NUM_WORKERS_LITELLM_PROXY": [],
  "DYNAMIC_RATE_LIMIT_ERROR_THRESHOLD_PER_MINUTE": [],
  "DEFAULT_SQS_BATCH_SIZE": [],
  "SQS_SEND_MESSAGE_ACTION": [],
  "SQS_API_VERSION": [],
  "DEFAULT_MAX_RETRIES": [],
  "DEFAULT_MAX_RECURSE_DEPTH": [],
  "DEFAULT_MAX_RECURSE_DEPTH_SENSITIVE_DATA_MASKER": [],
  "DEFAULT_FAILURE_THRESHOLD_PERCENT": [],
  "DEFAULT_MAX_TOKENS": [],
  "DEFAULT_ALLOWED_FAILS": [],
  "DEFAULT_REDIS_SYNC_INTERVAL": [],
  "DEFAULT_COOLDOWN_TIME_SECONDS": [],
  "DEFAULT_REPLICATE_POLLING_RETRIES": [],
  "DEFAULT_REPLICATE_POLLING_DELAY_SECONDS": [],
  "DEFAULT_IMAGE_TOKEN_COUNT": [],
  "MAX_BASE64_LENGTH_FOR_LOGGING": [],
  "LITELLM_DETAILED_TIMING": [],
  "MODEL_COST_MAP_MIN_MODEL_COUNT": [],
  "MODEL_COST_MAP_MAX_SHRINK_RATIO": [],
  "DEFAULT_IMAGE_WIDTH": [],
  "DEFAULT_IMAGE_HEIGHT": [],
  "MAX_IMAGE_URL_DOWNLOAD_SIZE_MB": [],
  "MAX_SIZE_PER_ITEM_IN_MEMORY_CACHE_IN_KB": [],
  "SINGLE_DEPLOYMENT_TRAFFIC_FAILURE_THRESHOLD": [],
  "DEFAULT_FAILURE_THRESHOLD_MINIMUM_REQUESTS": [],
  "DEFAULT_REASONING_EFFORT_DISABLE_THINKING_BUDGET": [],
  "DEFAULT_MCP_SEMANTIC_FILTER_EMBEDDING_MODEL": [],
  "DEFAULT_MCP_SEMANTIC_FILTER_TOP_K": [],
  "DEFAULT_MCP_SEMANTIC_FILTER_SIMILARITY_THRESHOLD": [],
  "MAX_MCP_SEMANTIC_FILTER_TOOLS_HEADER_LENGTH": [],
  "DEFAULT_SEMANTIC_GUARD_EMBEDDING_MODEL": [],
  "DEFAULT_SEMANTIC_GUARD_SIMILARITY_THRESHOLD": [],
  "MCP_OAUTH2_TOKEN_EXPIRY_BUFFER_SECONDS": [],
  "MCP_OAUTH2_TOKEN_CACHE_MAX_SIZE": [],
  "MCP_OAUTH2_TOKEN_CACHE_DEFAULT_TTL": [],
  "MCP_NPM_CACHE_DIR": [],
  "MCP_OAUTH2_TOKEN_CACHE_MIN_TTL": [],
  "LITELLM_UI_ALLOW_HEADERS": [],
  "DEFAULT_REASONING_EFFORT_MINIMAL_THINKING_BUDGET_GEMINI_2_5_FLASH": [],
  "DEFAULT_REASONING_EFFORT_MINIMAL_THINKING_BUDGET_GEMINI_2_5_PRO": [],
  "DEFAULT_REASONING_EFFORT_MINIMAL_THINKING_BUDGET_GEMINI_2_5_FLASH_LITE": [],
  "MAX_CALLBACKS": [],
  "DEFAULT_REASONING_EFFORT_MINIMAL_THINKING_BUDGET": [],
  "XAI_API_BASE": [],
  "DEFAULT_REASONING_EFFORT_LOW_THINKING_BUDGET": [],
  "DEFAULT_REASONING_EFFORT_MEDIUM_THINKING_BUDGET": [],
  "DEFAULT_REASONING_EFFORT_HIGH_THINKING_BUDGET": [],
  "MAX_TOKEN_TRIMMING_ATTEMPTS": [],
  "RUNWAYML_DEFAULT_API_VERSION": [],
  "RUNWAYML_POLLING_TIMEOUT": [],
  "_DEFAULT_TTL_FOR_HTTPX_CLIENTS": [],
  "AIOHTTP_CONNECTOR_LIMIT": [],
  "AIOHTTP_CONNECTOR_LIMIT_PER_HOST": [],
  "AIOHTTP_KEEPALIVE_TIMEOUT": [],
  "AIOHTTP_TTL_DNS_CACHE": [],
  "AIOHTTP_NEEDS_CLEANUP_CLOSED": [],
  "_max_size_env": [],
  "REALTIME_WEBSOCKET_MAX_MESSAGE_SIZE_BYTES": [],
  "DEFAULT_SSL_CIPHERS": [],
  "REDIS_UPDATE_BUFFER_KEY": [],
  "REDIS_DAILY_SPEND_UPDATE_BUFFER_KEY": [],
  "REDIS_DAILY_TEAM_SPEND_UPDATE_BUFFER_KEY": [],
  "REDIS_DAILY_ORG_SPEND_UPDATE_BUFFER_KEY": [],
  "REDIS_DAILY_END_USER_SPEND_UPDATE_BUFFER_KEY": [],
  "REDIS_DAILY_AGENT_SPEND_UPDATE_BUFFER_KEY": [],
  "REDIS_DAILY_TAG_SPEND_UPDATE_BUFFER_KEY": [],
  "MAX_REDIS_BUFFER_DEQUEUE_COUNT": [],
  "MAX_SIZE_IN_MEMORY_QUEUE": [],
  "LITELLM_ASYNCIO_QUEUE_MAXSIZE": [],
  "MAX_IN_MEMORY_QUEUE_FLUSH_COUNT": [],
  "MINIMUM_PROMPT_CACHE_TOKEN_COUNT": [],
  "DEFAULT_TRIM_RATIO": [],
  "HOURS_IN_A_DAY": [],
  "DAYS_IN_A_WEEK": [],
  "DAYS_IN_A_MONTH": [],
  "DAYS_IN_A_YEAR": [],
  "REPLICATE_MODEL_NAME_WITH_ID_LENGTH": [],
  "FUNCTION_DEFINITION_TOKEN_COUNT": [],
  "SYSTEM_MESSAGE_TOKEN_COUNT": [],
  "TOOL_CHOICE_OBJECT_TOKEN_COUNT": [],
  "DEFAULT_MOCK_RESPONSE_PROMPT_TOKEN_COUNT": [],
  "DEFAULT_MOCK_RESPONSE_COMPLETION_TOKEN_COUNT": [],
  "MAX_SHORT_SIDE_FOR_IMAGE_HIGH_RES": [],
  "MAX_LONG_SIDE_FOR_IMAGE_HIGH_RES": [],
  "MAX_TILE_WIDTH": [],
  "MAX_TILE_HEIGHT": [],
  "OPENAI_FILE_SEARCH_COST_PER_1K_CALLS": [],
  "AZURE_FILE_SEARCH_COST_PER_GB_PER_DAY": [],
  "AZURE_COMPUTER_USE_INPUT_COST_PER_1K_TOKENS": [],
  "AZURE_COMPUTER_USE_OUTPUT_COST_PER_1K_TOKENS": [],
  "AZURE_VECTOR_STORE_COST_PER_GB_PER_DAY": [],
  "MIN_NON_ZERO_TEMPERATURE": [],
  "REPEATED_STREAMING_CHUNK_LIMIT": [],
  "DEFAULT_MAX_LRU_CACHE_SIZE": [],
  "_REALTIME_BODY_CACHE_SIZE": [],
  "INITIAL_RETRY_DELAY": [],
  "MAX_RETRY_DELAY": [],
  "JITTER": [],
  "DEFAULT_IN_MEMORY_TTL": [],
  "DEFAULT_MAX_REDIS_BATCH_CACHE_SIZE": [],
  "DEFAULT_POLLING_INTERVAL": [],
  "AZURE_OPERATION_POLLING_TIMEOUT": [],
  "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION": [],
  "AZURE_DOCUMENT_INTELLIGENCE_DEFAULT_DPI": [],
  "REDIS_SOCKET_TIMEOUT": [],
  "REDIS_CONNECTION_POOL_TIMEOUT": [],
  "DEFAULT_REDIS_MAJOR_VERSION": [],
  "NON_LLM_CONNECTION_TIMEOUT": [],
  "MAX_EXCEPTION_MESSAGE_LENGTH": [],
  "MAX_STRING_LENGTH_PROMPT_IN_DB": [],
  "BEDROCK_MAX_POLICY_SIZE": [],
  "BEDROCK_MIN_THINKING_BUDGET_TOKENS": [],
  "REPLICATE_POLLING_DELAY_SECONDS": [],
  "DEFAULT_ANTHROPIC_CHAT_MAX_TOKENS": [],
  "TOGETHER_AI_4_B": [],
  "TOGETHER_AI_8_B": [],
  "TOGETHER_AI_21_B": [],
  "TOGETHER_AI_41_B": [],
  "TOGETHER_AI_80_B": [],
  "TOGETHER_AI_110_B": [],
  "TOGETHER_AI_EMBEDDING_150_M": [],
  "TOGETHER_AI_EMBEDDING_350_M": [],
  "QDRANT_SCALAR_QUANTILE": [],
  "QDRANT_VECTOR_SIZE": [],
  "CACHED_STREAMING_CHUNK_DELAY": [],
  "AUDIO_SPEECH_CHUNK_SIZE": [],
  "DEFAULT_MAX_TOKENS_FOR_TRITON": [],
  "DEFAULT_REPLICATE_GPU_PRICE_PER_SECOND": [],
  "FIREWORKS_AI_56_B_MOE": [],
  "FIREWORKS_AI_176_B_MOE": [],
  "FIREWORKS_AI_4_B": [],
  "FIREWORKS_AI_16_B": [],
  "FIREWORKS_AI_80_B": [],
  "REDACTED_BY_LITELM_STRING": [],
  "MAX_LANGFUSE_INITIALIZED_CLIENTS": [],
  "LOGGING_WORKER_CONCURRENCY": [],
  "LOGGING_WORKER_MAX_QUEUE_SIZE": [],
  "LOGGING_WORKER_MAX_TIME_PER_COROUTINE": [],
  "LOGGING_WORKER_CLEAR_PERCENTAGE": [],
  "MAX_ITERATIONS_TO_CLEAR_QUEUE": [],
  "MAX_TIME_TO_CLEAR_QUEUE": [],
  "LOGGING_WORKER_AGGRESSIVE_CLEAR_COOLDOWN_SECONDS": [],
  "DD_TRACER_STREAMING_CHUNK_YIELD_RESOURCE": [],
  "EMAIL_BUDGET_ALERT_TTL": [],
  "EMAIL_BUDGET_ALERT_MAX_SPEND_ALERT_PERCENTAGE": [],
  "ANTHROPIC_TOKEN_COUNTING_BETA_VERSION": [],
  "ANTHROPIC_SKILLS_API_BETA_VERSION": [],
  "ANTHROPIC_WEB_SEARCH_TOOL_MAX_USES": [],
  "LITELLM_WEB_SEARCH_TOOL_NAME": [],
  "DEFAULT_IMAGE_ENDPOINT_MODEL": [],
  "DEFAULT_VIDEO_ENDPOINT_MODEL": [],
  "DEFAULT_GOOGLE_VIDEO_DURATION_SECONDS": [],
  "DEFAULT_DATAFORSEO_LOCATION_CODE": [],
  "LITELLM_CHAT_PROVIDERS": [],
  "LITELLM_EMBEDDING_PROVIDERS_SUPPORTING_INPUT_ARRAY_OF_TOKENS": [],
  "OPENAI_CHAT_COMPLETION_PARAMS": [],
  "OPENAI_TRANSCRIPTION_PARAMS": [],
  "OPENAI_EMBEDDING_PARAMS": [],
  "DEFAULT_EMBEDDING_PARAM_VALUES": [],
  "DEFAULT_CHAT_COMPLETION_PARAM_VALUES": [],
  "empower_models": [],
  "BEDROCK_INVOKE_PROVIDERS_LITERAL": [],
  "BEDROCK_EMBEDDING_PROVIDERS_LITERAL": [],
  "BEDROCK_CONVERSE_MODELS": [],
  "known_tokenizer_config": [],
  "OPENAI_FINISH_REASONS": [],
  "HUMANLOOP_PROMPT_CACHE_TTL_SECONDS": [],
  "RESPONSE_FORMAT_TOOL_NAME": [],
  "AZURE_STORAGE_MSFT_VERSION": [],
  "PROMETHEUS_BUDGET_METRICS_REFRESH_INTERVAL_MINUTES": [],
  "CLOUDZERO_EXPORT_INTERVAL_MINUTES": [],
  "MCP_TOOL_NAME_PREFIX": [],
  "MAXIMUM_TRACEBACK_LINES_TO_LOG": [],
  "X_LITELLM_DISABLE_CALLBACKS": [],
  "LITELLM_METADATA_FIELD": [],
  "OLD_LITELLM_METADATA_FIELD": [],
  "LITELLM_TRUNCATED_PAYLOAD_FIELD": [],
  "STANDARD_CUSTOMER_ID_HEADERS": [],
  "MAX_SPENDLOG_ROWS_TO_QUERY": [],
  "DEFAULT_SOFT_BUDGET": [],
  "RATE_LIMIT_ERROR_MESSAGE_FOR_VIRTUAL_KEY": [],
  "PYTHON_GC_THRESHOLD": [],
  "BEDROCK_AGENT_RUNTIME_PASS_THROUGH_ROUTES": [],
  "ALLOWED_VERTEX_AI_PASSTHROUGH_HEADERS": [],
  "PASS_THROUGH_HEADER_PREFIX": [],
  "BASE_MCP_ROUTE": [],
  "BATCH_STATUS_POLL_INTERVAL_SECONDS": [],
  "BATCH_STATUS_POLL_MAX_ATTEMPTS": [],
  "HEALTH_CHECK_TIMEOUT_SECONDS": [],
  "LITTELM_INTERNAL_HEALTH_SERVICE_ACCOUNT_NAME": [],
  "LITTELM_CLI_SERVICE_ACCOUNT_NAME": [],
  "LITELLM_INTERNAL_JOBS_SERVICE_ACCOUNT_NAME": [],
  "LITELLM_KEY_ROTATION_ENABLED": [],
  "LITELLM_KEY_ROTATION_CHECK_INTERVAL_SECONDS": [],
  "UI_SESSION_TOKEN_TEAM_ID": [],
  "LITELLM_PROXY_ADMIN_NAME": [],
  "LITELLM_CLI_SOURCE_IDENTIFIER": [],
  "LITELLM_CLI_SESSION_TOKEN_PREFIX": [],
  "CLI_SSO_SESSION_CACHE_KEY_PREFIX": [],
  "CLI_JWT_TOKEN_NAME": [],
  "CLI_JWT_EXPIRATION_HOURS": [],
  "DB_SPEND_UPDATE_JOB_NAME": [],
  "PROMETHEUS_EMIT_BUDGET_METRICS_JOB_NAME": [],
  "CLOUDZERO_EXPORT_USAGE_DATA_JOB_NAME": [],
  "CLOUDZERO_MAX_FETCHED_DATA_RECORDS": [],
  "SPEND_LOG_CLEANUP_JOB_NAME": [],
  "SPEND_LOG_RUN_LOOPS": [],
  "SPEND_LOG_CLEANUP_BATCH_SIZE": [],
  "SPEND_LOG_QUEUE_SIZE_THRESHOLD": [],
  "SPEND_LOG_QUEUE_POLL_INTERVAL": [],
  "DEFAULT_CRON_JOB_LOCK_TTL_SECONDS": [],
  "PROXY_BUDGET_RESCHEDULER_MIN_TIME": [],
  "PROXY_BATCH_POLLING_INTERVAL": [],
  "PROXY_BUDGET_RESCHEDULER_MAX_TIME": [],
  "PROXY_BATCH_WRITE_AT": [],
  "APSCHEDULER_COALESCE": [],
  "APSCHEDULER_MISFIRE_GRACE_TIME": [],
  "APSCHEDULER_MAX_INSTANCES": [],
  "APSCHEDULER_REPLACE_EXISTING": [],
  "DEFAULT_HEALTH_CHECK_INTERVAL": [],
  "DEFAULT_SHARED_HEALTH_CHECK_TTL": [],
  "DEFAULT_SHARED_HEALTH_CHECK_LOCK_TTL": [],
  "PROMETHEUS_FALLBACK_STATS_SEND_TIME_HOURS": [],
  "DEFAULT_MODEL_CREATED_AT_TIME": [],
  "DEFAULT_SLACK_ALERTING_THRESHOLD": [],
  "MAX_TEAM_LIST_LIMIT": [],
  "MAX_POLICY_ESTIMATE_IMPACT_ROWS": [],
  "DEFAULT_PROMPT_INJECTION_SIMILARITY_THRESHOLD": [],
  "LENGTH_OF_LITELLM_GENERATED_KEY": [],
  "SECRET_MANAGER_REFRESH_INTERVAL": [],
  "LITELLM_SETTINGS_SAFE_DB_OVERRIDES": [],
  "SPECIAL_LITELLM_AUTH_TOKEN": [],
  "DEFAULT_MANAGEMENT_OBJECT_IN_MEMORY_CACHE_TTL": [],
  "DEFAULT_ACCESS_GROUP_CACHE_TTL": [],
  "SENTRY_DENYLIST": [],
  "SENTRY_PII_DENYLIST": [],
  "COROUTINE_CHECKER_MAX_SIZE_IN_MEMORY": [],
  "DEFAULT_CHUNK_SIZE": [],
  "DEFAULT_CHUNK_OVERLAP": [],
  "S3_VECTORS_DEFAULT_DIMENSION": [],
  "S3_VECTORS_DEFAULT_DISTANCE_METRIC": [],
  "S3_VECTORS_DEFAULT_NON_FILTERABLE_METADATA_KEYS": [],
  "MICROSOFT_USER_EMAIL_ATTRIBUTE": [],
  "MICROSOFT_USER_DISPLAY_NAME_ATTRIBUTE": [],
  "MICROSOFT_USER_ID_ATTRIBUTE": [],
  "MICROSOFT_USER_FIRST_NAME_ATTRIBUTE": [],
  "MICROSOFT_USER_LAST_NAME_ATTRIBUTE": [],
  "MAX_PAYLOAD_SIZE_FOR_DEBUG_LOG": [],
  "MAX_COMPETITOR_NAMES": [],
  "COMPETITOR_LLM_TEMPERATURE": [],
  "DEFAULT_COMPETITOR_DISCOVERY_MODEL": [],
  "COST_CALCULATOR_NAMES": [],
  "LITELLM_LOGGING_NAMES": [],
  "UTILS_NAMES": [],
  "TOKEN_COUNTER_NAMES": [],
  "LLM_CLIENT_CACHE_NAMES": [],
  "BEDROCK_TYPES_NAMES": [],
  "TYPES_UTILS_NAMES": [],
  "CACHING_NAMES": [],
  "HTTP_HANDLER_NAMES": [],
  "DOTPROMPT_NAMES": [],
  "LLM_CONFIG_NAMES": [],
  "TYPES_NAMES": [],
  "LLM_PROVIDER_LOGIC_NAMES": [],
  "UTILS_MODULE_NAMES": [],
  "_UTILS_IMPORT_MAP": [],
  "_COST_CALCULATOR_IMPORT_MAP": [],
  "_TYPES_UTILS_IMPORT_MAP": [],
  "_TOKEN_COUNTER_IMPORT_MAP": [],
  "_BEDROCK_TYPES_IMPORT_MAP": [],
  "_CACHING_IMPORT_MAP": [],
  "_LITELLM_LOGGING_IMPORT_MAP": [],
  "_DOTPROMPT_IMPORT_MAP": [],
  "_TYPES_IMPORT_MAP": [],
  "_LLM_PROVIDER_LOGIC_IMPORT_MAP": [],
  "_LLM_CONFIGS_IMPORT_MAP": [],
  "_UTILS_MODULE_IMPORT_MAP": [],
  "__all__": [],
  "GetAnthropicBetaHeadersConfig": {
    "load_local_beta_headers_config": [],
    "_check_is_valid_dict": [
      "fetched_config"
    ],
    "validate_beta_headers_config": [
      "cls",
      "fetched_config"
    ],
    "fetch_remote_beta_headers_config": [
      "url",
      "timeout"
    ]
  },
  "get_beta_headers_config": [
    "url"
  ],
  "_load_beta_headers_config": [],
  "reload_beta_headers_config": [],
  "get_provider_name": [
    "provider"
  ],
  "filter_and_transform_beta_headers": [
    "beta_headers",
    "provider"
  ],
  "is_beta_header_supported": [
    "beta_header",
    "provider"
  ],
  "get_provider_beta_header": [
    "anthropic_beta_header",
    "provider"
  ],
  "update_headers_with_filtered_beta": [
    "headers",
    "provider"
  ],
  "get_unsupported_headers": [
    "provider"
  ],
  "SchedulerCacheKeys": {
    "queue": [],
    "default_in_memory_ttl": []
  },
  "FlowItem": {},
  "Scheduler": {
    "__init__": [
      "self",
      "polling_interval",
      "redis_cache"
    ],
    "add_request": [
      "self",
      "request"
    ],
    "poll": [
      "self",
      "id",
      "model_name",
      "health_deployments"
    ],
    "remove_request": [
      "self",
      "request_id",
      "model_name"
    ],
    "peek": [
      "self",
      "id",
      "model_name",
      "health_deployments"
    ],
    "get_queue_status": [
      "self"
    ],
    "get_queue": [
      "self",
      "model_name"
    ],
    "save_queue": [
      "self",
      "queue",
      "model_name"
    ]
  },
  "openai_chat_completions": [],
  "openai_text_completions": [],
  "openai_audio_transcriptions": [],
  "openai_image_variations": [],
  "groq_chat_completions": [],
  "sap_gen_ai_hub_chat_completions": [],
  "sap_gen_ai_hub_emb": [],
  "azure_ai_embedding": [],
  "anthropic_chat_completions": [],
  "azure_anthropic_chat_completions": [],
  "azure_chat_completions": [],
  "azure_o1_chat_completions": [],
  "azure_text_completions": [],
  "azure_audio_transcriptions": [],
  "huggingface_embed": [],
  "predibase_chat_completions": [],
  "codestral_text_completions": [],
  "bedrock_converse_chat_completion": [],
  "bedrock_embedding": [],
  "bedrock_image_generation": [],
  "bedrock_image_edit": [],
  "vertex_chat_completion": [],
  "vertex_embedding": [],
  "vertex_multimodal_embedding": [],
  "vertex_image_generation": [],
  "google_batch_embeddings": [],
  "vertex_partner_models_chat_completion": [],
  "vertex_gemma_chat_completion": [],
  "vertex_model_garden_chat_completion": [],
  "sagemaker_llm": [],
  "watsonx_chat_completion": [],
  "openai_like_embedding": [],
  "openai_like_chat_completion": [],
  "databricks_embedding": [],
  "base_llm_http_handler": [],
  "base_llm_aiohttp_handler": [],
  "sagemaker_chat_completion": [],
  "bytez_transformation": [],
  "heroku_transformation": [],
  "oci_transformation": [],
  "ovhcloud_transformation": [],
  "lemonade_transformation": [],
  "MOCK_RESPONSE_TYPE": [],
  "LiteLLM": {
    "__init__": [
      "self"
    ]
  },
  "Chat": {
    "__init__": [
      "self",
      "params",
      "router_obj"
    ]
  },
  "Completions": {
    "__init__": [
      "self",
      "params",
      "router_obj"
    ],
    "create": [
      "self",
      "messages",
      "model"
    ]
  },
  "AsyncCompletions": {
    "__init__": [
      "self",
      "params",
      "router_obj"
    ],
    "create": [
      "self",
      "messages",
      "model"
    ]
  },
  "acompletion": [
    "model",
    "messages",
    "functions",
    "function_call",
    "timeout",
    "temperature",
    "top_p",
    "n",
    "stream",
    "stream_options",
    "stop",
    "max_tokens",
    "max_completion_tokens",
    "modalities",
    "prediction",
    "audio",
    "presence_penalty",
    "frequency_penalty",
    "logit_bias",
    "user",
    "response_format",
    "seed",
    "tools",
    "tool_choice",
    "parallel_tool_calls",
    "logprobs",
    "top_logprobs",
    "deployment_id",
    "reasoning_effort",
    "verbosity",
    "safety_identifier",
    "service_tier",
    "base_url",
    "api_version",
    "api_key",
    "model_list",
    "extra_headers",
    "thinking",
    "web_search_options",
    "shared_session"
  ],
  "_async_streaming": [
    "response",
    "model",
    "custom_llm_provider",
    "args"
  ],
  "_handle_mock_potential_exceptions": [
    "mock_response",
    "model",
    "custom_llm_provider"
  ],
  "_handle_mock_timeout": [
    "mock_timeout",
    "timeout",
    "model"
  ],
  "_handle_mock_timeout_async": [
    "mock_timeout",
    "timeout",
    "model"
  ],
  "_sleep_for_timeout": [
    "timeout"
  ],
  "_sleep_for_timeout_async": [
    "timeout"
  ],
  "mock_completion": [
    "model",
    "messages",
    "stream",
    "n",
    "mock_response",
    "mock_tool_calls",
    "mock_timeout",
    "logging",
    "custom_llm_provider",
    "timeout"
  ],
  "responses_api_bridge_check": [
    "model",
    "custom_llm_provider",
    "web_search_options"
  ],
  "_should_allow_input_examples": [
    "custom_llm_provider",
    "model"
  ],
  "_drop_input_examples_from_tool": [
    "tool"
  ],
  "_drop_input_examples_from_tools": [
    "tools"
  ],
  "completion": [
    "model",
    "messages",
    "timeout",
    "temperature",
    "top_p",
    "n",
    "stream",
    "stream_options",
    "stop",
    "max_completion_tokens",
    "max_tokens",
    "modalities",
    "prediction",
    "audio",
    "presence_penalty",
    "frequency_penalty",
    "logit_bias",
    "user",
    "reasoning_effort",
    "verbosity",
    "response_format",
    "seed",
    "tools",
    "tool_choice",
    "logprobs",
    "top_logprobs",
    "parallel_tool_calls",
    "web_search_options",
    "deployment_id",
    "extra_headers",
    "safety_identifier",
    "service_tier",
    "functions",
    "function_call",
    "base_url",
    "api_version",
    "api_key",
    "model_list",
    "thinking",
    "shared_session"
  ],
  "completion_with_retries": [],
  "acompletion_with_retries": [],
  "responses_with_retries": [],
  "aresponses_with_retries": [],
  "aembedding": [],
  "embedding": [
    "model",
    "input",
    "dimensions",
    "encoding_format",
    "timeout",
    "api_base",
    "api_version",
    "api_key",
    "api_type",
    "caching",
    "user",
    "custom_llm_provider",
    "litellm_call_id",
    "logger_fn"
  ],
  "atext_completion": [],
  "text_completion": [
    "prompt",
    "model",
    "best_of",
    "echo",
    "frequency_penalty",
    "logit_bias",
    "logprobs",
    "max_tokens",
    "n",
    "presence_penalty",
    "stop",
    "stream",
    "stream_options",
    "suffix",
    "temperature",
    "top_p",
    "user",
    "api_base",
    "api_version",
    "api_key",
    "model_list",
    "custom_llm_provider"
  ],
  "aadapter_completion": [],
  "aadapter_generate_content": [],
  "adapter_completion": [],
  "moderation": [
    "input",
    "model",
    "api_key"
  ],
  "amoderation": [
    "input",
    "model",
    "api_key",
    "custom_llm_provider"
  ],
  "atranscription": [],
  "transcription": [
    "model",
    "file",
    "language",
    "prompt",
    "response_format",
    "timestamp_granularities",
    "temperature",
    "user",
    "timeout",
    "api_key",
    "api_base",
    "api_version",
    "max_retries",
    "custom_llm_provider"
  ],
  "aspeech": [],
  "speech": [
    "model",
    "input",
    "voice",
    "api_key",
    "api_base",
    "api_version",
    "organization",
    "project",
    "max_retries",
    "metadata",
    "timeout",
    "response_format",
    "speed",
    "instructions",
    "client",
    "headers",
    "custom_llm_provider",
    "aspeech"
  ],
  "ahealth_check": [
    "model_params",
    "mode",
    "prompt",
    "input"
  ],
  "config_completion": [],
  "stream_chunk_builder_text_completion": [
    "chunks",
    "messages"
  ],
  "stream_chunk_builder": [
    "chunks",
    "messages",
    "start_time",
    "end_time",
    "logging_obj"
  ],
  "_get_encoding": [],
  "_get_minimal_error_response": [],
  "AuthenticationError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NotFoundError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BadRequestError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries",
      "body"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ImageFetchError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries",
      "body"
    ]
  },
  "UnprocessableEntityError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "Timeout": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "litellm_debug_info",
      "max_retries",
      "num_retries",
      "headers",
      "exception_status_code"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PermissionDeniedError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RateLimitError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ContextWindowExceededError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "response",
      "litellm_debug_info"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RejectedRequestError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "request_data",
      "litellm_debug_info"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ContentPolicyViolationError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "response",
      "litellm_debug_info",
      "provider_specific_fields",
      "body"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "_transform_error_to_string": [
      "self"
    ]
  },
  "ServiceUnavailableError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BadGatewayError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "InternalServerError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "APIError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "llm_provider",
      "model",
      "request",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "APIConnectionError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "request",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "APIResponseValidationError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "JSONSchemaValidationError": {
    "__init__": [
      "self",
      "model",
      "llm_provider",
      "raw_response",
      "schema"
    ]
  },
  "OpenAIError": {
    "__init__": [
      "self",
      "original_exception"
    ]
  },
  "UnsupportedParamsError": {
    "__init__": [
      "self",
      "message",
      "llm_provider",
      "model",
      "status_code",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ]
  },
  "LITELLM_EXCEPTION_TYPES": [],
  "BudgetExceededError": {
    "__init__": [
      "self",
      "current_cost",
      "max_budget",
      "message"
    ]
  },
  "InvalidRequestError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider"
    ]
  },
  "MockException": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "llm_provider",
      "model",
      "request",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ]
  },
  "LiteLLMUnknownProvider": {
    "__init__": [
      "self",
      "model",
      "custom_llm_provider"
    ],
    "__str__": [
      "self"
    ]
  },
  "GuardrailRaisedException": {
    "__init__": [
      "self",
      "guardrail_name",
      "message",
      "should_wrap_with_default_message"
    ]
  },
  "BlockedPiiEntityError": {
    "__init__": [
      "self",
      "entity_type",
      "guardrail_name"
    ]
  },
  "MidStreamFallbackError": {
    "__init__": [
      "self",
      "message",
      "model",
      "llm_provider",
      "original_exception",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries",
      "generated_content",
      "is_pre_first_chunk"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "GuardrailInterventionNormalStringError": {
    "__init__": [
      "self",
      "message"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "RoutingArgs": {
    "ttl": []
  },
  "Router": {
    "tenacity": [],
    "__init__": [
      "self",
      "model_list",
      "assistants_config",
      "search_tools",
      "guardrail_list",
      "redis_url",
      "redis_host",
      "redis_port",
      "redis_password",
      "redis_db",
      "cache_responses",
      "cache_kwargs",
      "caching_groups",
      "client_ttl",
      "polling_interval",
      "default_priority",
      "num_retries",
      "max_fallbacks",
      "timeout",
      "stream_timeout",
      "default_litellm_params",
      "default_max_parallel_requests",
      "set_verbose",
      "debug_level",
      "default_fallbacks",
      "fallbacks",
      "context_window_fallbacks",
      "content_policy_fallbacks",
      "model_group_alias",
      "enable_pre_call_checks",
      "enable_tag_filtering",
      "tag_filtering_match_any",
      "retry_after",
      "retry_policy",
      "model_group_retry_policy",
      "allowed_fails",
      "allowed_fails_policy",
      "cooldown_time",
      "disable_cooldowns",
      "routing_strategy",
      "optional_pre_call_checks",
      "routing_strategy_args",
      "provider_budget_config",
      "alerting_config",
      "router_general_settings",
      "deployment_affinity_ttl_seconds",
      "ignore_invalid_deployments"
    ],
    "get_valid_args": [],
    "apply_default_settings": [
      "self"
    ],
    "discard": [
      "self"
    ],
    "_create_redis_cache": [
      "cache_config"
    ],
    "_update_redis_cache": [
      "self",
      "cache"
    ],
    "routing_strategy_init": [
      "self",
      "routing_strategy",
      "routing_strategy_args"
    ],
    "initialize_assistants_endpoint": [
      "self"
    ],
    "_initialize_core_endpoints": [
      "self"
    ],
    "_initialize_vector_store_endpoints": [
      "self"
    ],
    "_initialize_vector_store_file_endpoints": [
      "self"
    ],
    "_initialize_google_genai_endpoints": [
      "self"
    ],
    "_initialize_ocr_search_endpoints": [
      "self"
    ],
    "_initialize_video_endpoints": [
      "self"
    ],
    "_initialize_container_endpoints": [
      "self"
    ],
    "_initialize_skills_endpoints": [
      "self"
    ],
    "_initialize_interactions_endpoints": [
      "self"
    ],
    "_initialize_specialized_endpoints": [
      "self"
    ],
    "initialize_router_endpoints": [
      "self"
    ],
    "validate_fallbacks": [
      "self",
      "fallback_param"
    ],
    "add_optional_pre_call_checks": [
      "self",
      "optional_pre_call_checks"
    ],
    "print_deployment": [
      "self",
      "deployment"
    ],
    "completion": [
      "self",
      "model",
      "messages"
    ],
    "_completion": [
      "self",
      "model",
      "messages"
    ],
    "_get_silent_experiment_kwargs": [
      "self"
    ],
    "_silent_experiment_completion": [
      "self",
      "silent_model",
      "messages"
    ],
    "acompletion": [
      "self",
      "model",
      "messages",
      "stream"
    ],
    "_acompletion_streaming_iterator": [
      "self",
      "model_response",
      "messages",
      "initial_kwargs"
    ],
    "_silent_experiment_acompletion": [
      "self",
      "silent_model",
      "messages"
    ],
    "_acompletion": [
      "self",
      "model",
      "messages"
    ],
    "_update_kwargs_before_fallbacks": [
      "self",
      "model",
      "kwargs",
      "metadata_variable_name"
    ],
    "_set_deployment_num_retries_on_exception": [
      "self",
      "exception",
      "deployment"
    ],
    "_update_kwargs_with_default_litellm_params": [
      "self",
      "kwargs",
      "metadata_variable_name"
    ],
    "_handle_clientside_credential": [
      "self",
      "deployment",
      "kwargs",
      "function_name"
    ],
    "_merge_tools_from_deployment": [
      "deployment",
      "kwargs"
    ],
    "_update_kwargs_with_deployment": [
      "self",
      "deployment",
      "kwargs",
      "function_name"
    ],
    "_get_async_openai_model_client": [
      "self",
      "deployment",
      "kwargs"
    ],
    "_get_stream_timeout": [
      "self",
      "kwargs",
      "data"
    ],
    "_get_non_stream_timeout": [
      "self",
      "kwargs",
      "data"
    ],
    "_get_timeout": [
      "self",
      "kwargs",
      "data"
    ],
    "abatch_completion": [
      "self",
      "models",
      "messages"
    ],
    "abatch_completion_one_model_multiple_requests": [
      "self",
      "model",
      "messages"
    ],
    "abatch_completion_fastest_response": [
      "self",
      "model",
      "messages",
      "stream"
    ],
    "schedule_acompletion": [
      "self",
      "model",
      "messages",
      "priority",
      "stream"
    ],
    "_schedule_factory": [
      "self",
      "model",
      "priority",
      "original_function",
      "args",
      "kwargs"
    ],
    "_is_prompt_management_model": [
      "self",
      "model"
    ],
    "_prompt_management_factory": [
      "self",
      "model",
      "messages",
      "kwargs"
    ],
    "image_generation": [
      "self",
      "prompt",
      "model"
    ],
    "_image_generation": [
      "self",
      "prompt",
      "model"
    ],
    "aimage_generation": [
      "self",
      "prompt",
      "model"
    ],
    "_aimage_generation": [
      "self",
      "prompt",
      "model"
    ],
    "atranscription": [
      "self",
      "file",
      "model"
    ],
    "_atranscription": [
      "self",
      "file",
      "model"
    ],
    "aspeech": [
      "self",
      "model",
      "input",
      "voice"
    ],
    "arerank": [
      "self",
      "model"
    ],
    "_arerank": [
      "self",
      "model"
    ],
    "text_completion": [
      "self",
      "model",
      "prompt",
      "is_retry",
      "is_fallback",
      "is_async"
    ],
    "atext_completion": [
      "self",
      "model",
      "prompt",
      "is_retry",
      "is_fallback",
      "is_async"
    ],
    "_atext_completion": [
      "self",
      "model",
      "prompt"
    ],
    "aadapter_completion": [
      "self",
      "adapter_id",
      "model",
      "is_retry",
      "is_fallback",
      "is_async"
    ],
    "_aadapter_completion": [
      "self",
      "adapter_id",
      "model"
    ],
    "_asearch_with_fallbacks": [
      "self",
      "original_function"
    ],
    "_asearch_with_fallbacks_helper": [
      "self",
      "model",
      "original_generic_function"
    ],
    "aguardrail": [
      "self",
      "guardrail_name",
      "original_function"
    ],
    "_aguardrail_helper": [
      "self",
      "model",
      "original_generic_function"
    ],
    "get_available_guardrail": [
      "self",
      "guardrail_name"
    ],
    "_ageneric_api_call_with_fallbacks": [
      "self",
      "model",
      "original_function"
    ],
    "_add_deployment_model_to_endpoint_for_llm_passthrough_route": [
      "self",
      "kwargs",
      "model",
      "model_name"
    ],
    "_ageneric_api_call_with_fallbacks_helper": [
      "self",
      "model",
      "original_generic_function"
    ],
    "_generic_api_call_with_fallbacks": [
      "self",
      "model",
      "original_function"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "is_async"
    ],
    "_embedding": [
      "self",
      "input",
      "model"
    ],
    "aembedding": [
      "self",
      "model",
      "input",
      "is_async"
    ],
    "_aembedding": [
      "self",
      "input",
      "model"
    ],
    "acreate_file": [
      "self",
      "model"
    ],
    "_acreate_file": [
      "self",
      "model"
    ],
    "avector_store_create": [
      "self",
      "model"
    ],
    "_override_vector_store_methods_for_router": [
      "self"
    ],
    "acreate_batch": [
      "self",
      "model"
    ],
    "_acreate_batch": [
      "self",
      "model"
    ],
    "aretrieve_batch": [
      "self",
      "model"
    ],
    "acancel_batch": [
      "self",
      "model"
    ],
    "_acancel_batch": [
      "self",
      "model"
    ],
    "alist_batches": [
      "self",
      "model"
    ],
    "_pass_through_moderation_endpoint_factory": [
      "self",
      "original_function",
      "custom_llm_provider"
    ],
    "factory_function": [
      "self",
      "original_function",
      "call_type"
    ],
    "_init_vector_store_api_endpoints": [
      "self",
      "original_function",
      "custom_llm_provider"
    ],
    "_init_containers_api_endpoints": [
      "self",
      "original_function",
      "custom_llm_provider"
    ],
    "_init_responses_api_endpoints": [
      "self",
      "original_function"
    ],
    "_init_interactions_api_endpoints": [
      "self",
      "original_function",
      "custom_llm_provider"
    ],
    "_pass_through_assistants_endpoint_factory": [
      "self",
      "original_function",
      "custom_llm_provider",
      "client"
    ],
    "async_function_with_fallbacks_common_utils": [
      "self",
      "e",
      "disable_fallbacks",
      "fallbacks",
      "context_window_fallbacks",
      "content_policy_fallbacks",
      "model_group",
      "args",
      "kwargs"
    ],
    "async_function_with_fallbacks": [
      "self"
    ],
    "_handle_mock_testing_fallbacks": [
      "self",
      "kwargs",
      "model_group",
      "fallbacks",
      "context_window_fallbacks",
      "content_policy_fallbacks"
    ],
    "async_function_with_retries": [
      "self"
    ],
    "make_call": [
      "self",
      "original_function"
    ],
    "_handle_mock_testing_rate_limit_error": [
      "self",
      "kwargs",
      "model_group"
    ],
    "should_retry_this_error": [
      "self",
      "error",
      "healthy_deployments",
      "all_deployments",
      "context_window_fallbacks",
      "content_policy_fallbacks",
      "regular_fallbacks"
    ],
    "function_with_fallbacks": [
      "self"
    ],
    "_get_fallback_model_group_from_fallbacks": [
      "self",
      "fallbacks",
      "model_group"
    ],
    "_get_first_default_fallback": [
      "self"
    ],
    "_time_to_sleep_before_retry": [
      "self",
      "e",
      "remaining_retries",
      "num_retries",
      "healthy_deployments",
      "all_deployments"
    ],
    "deployment_callback_on_success": [
      "self",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time"
    ],
    "sync_deployment_callback_on_success": [
      "self",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time"
    ],
    "deployment_callback_on_failure": [
      "self",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time"
    ],
    "async_deployment_callback_on_failure": [
      "self",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time"
    ],
    "_get_metadata_variable_name_from_kwargs": [
      "self",
      "kwargs"
    ],
    "log_retry": [
      "self",
      "kwargs",
      "e"
    ],
    "_update_usage": [
      "self",
      "deployment_id",
      "parent_otel_span"
    ],
    "_has_default_fallbacks": [
      "self"
    ],
    "_should_raise_content_policy_error": [
      "self",
      "model",
      "response",
      "kwargs"
    ],
    "_get_healthy_deployments": [
      "self",
      "model",
      "parent_otel_span"
    ],
    "_async_get_healthy_deployments": [
      "self",
      "model",
      "parent_otel_span"
    ],
    "routing_strategy_pre_call_checks": [
      "self",
      "deployment"
    ],
    "async_routing_strategy_pre_call_checks": [
      "self",
      "deployment",
      "parent_otel_span",
      "logging_obj"
    ],
    "async_callback_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "parent_otel_span",
      "request_kwargs",
      "logging_obj"
    ],
    "_generate_model_id": [
      "self",
      "model_group",
      "litellm_params"
    ],
    "_create_deployment": [
      "self",
      "deployment_info",
      "_model_name",
      "_litellm_params",
      "_model_info"
    ],
    "_is_auto_router_deployment": [
      "self",
      "litellm_params"
    ],
    "init_auto_router_deployment": [
      "self",
      "deployment"
    ],
    "_is_complexity_router_deployment": [
      "self",
      "litellm_params"
    ],
    "init_complexity_router_deployment": [
      "self",
      "deployment"
    ],
    "deployment_is_active_for_environment": [
      "self",
      "deployment"
    ],
    "set_model_list": [
      "self",
      "model_list"
    ],
    "_add_deployment": [
      "self",
      "deployment"
    ],
    "_initialize_deployment_for_pass_through": [
      "self",
      "deployment",
      "custom_llm_provider",
      "model"
    ],
    "add_deployment": [
      "self",
      "deployment"
    ],
    "_update_deployment_indices_after_removal": [
      "self",
      "model_id",
      "removal_idx"
    ],
    "_add_model_to_list_and_index_map": [
      "self",
      "model",
      "model_id"
    ],
    "upsert_deployment": [
      "self",
      "deployment"
    ],
    "delete_deployment": [
      "self",
      "id"
    ],
    "get_deployment": [
      "self",
      "model_id"
    ],
    "get_deployment_credentials": [
      "self",
      "model_id"
    ],
    "get_deployment_by_model_group_name": [
      "self",
      "model_group_name"
    ],
    "get_deployment_credentials_with_provider": [
      "self",
      "model_id"
    ],
    "get_router_model_info": [
      "self",
      "deployment",
      "received_model_name",
      "id"
    ],
    "get_model_info": [
      "self",
      "id"
    ],
    "get_model_group": [
      "self",
      "id"
    ],
    "get_deployment_model_info": [
      "self",
      "model_id",
      "model_name"
    ],
    "_set_model_group_info": [
      "self",
      "model_group",
      "user_facing_model_group_name"
    ],
    "get_model_group_info": [
      "self",
      "model_group"
    ],
    "get_model_group_usage": [
      "self",
      "model_group"
    ],
    "_cached_get_model_group_info": [
      "self",
      "model_group"
    ],
    "get_remaining_model_group_usage": [
      "self",
      "model_group"
    ],
    "set_response_headers": [
      "self",
      "response",
      "model_group"
    ],
    "_build_model_name_index": [
      "self",
      "model_list"
    ],
    "_build_model_id_to_deployment_index_map": [
      "self",
      "model_list"
    ],
    "get_model_ids": [
      "self",
      "model_name",
      "exclude_team_models"
    ],
    "has_model_id": [
      "self",
      "candidate_id"
    ],
    "resolve_model_name_from_model_id": [
      "self",
      "model_id"
    ],
    "map_team_model": [
      "self",
      "team_model_name",
      "team_id"
    ],
    "should_include_deployment": [
      "self",
      "model_name",
      "model",
      "team_id"
    ],
    "_get_all_deployments": [
      "self",
      "model_name",
      "model_alias",
      "team_id"
    ],
    "get_model_names": [
      "self",
      "team_id"
    ],
    "_get_team_specific_model": [
      "self",
      "deployment",
      "team_id"
    ],
    "_is_team_specific_model": [
      "self",
      "model_info"
    ],
    "get_model_list_from_model_alias": [
      "self",
      "model_name"
    ],
    "get_model_list": [
      "self",
      "model_name",
      "team_id"
    ],
    "_invalidate_access_groups_cache": [
      "self"
    ],
    "get_model_access_groups": [
      "self",
      "model_name",
      "model_access_group",
      "team_id"
    ],
    "_is_model_access_group_for_wildcard_route": [
      "self",
      "model_access_group"
    ],
    "get_settings": [
      "self"
    ],
    "update_settings": [
      "self"
    ],
    "_get_client": [
      "self",
      "deployment",
      "kwargs",
      "client_type"
    ],
    "_pre_call_checks": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs"
    ],
    "_get_model_from_alias": [
      "self",
      "model"
    ],
    "_get_deployment_by_litellm_model": [
      "self",
      "model"
    ],
    "_common_checks_available_deployment": [
      "self",
      "model",
      "messages",
      "input",
      "specific_deployment",
      "request_kwargs"
    ],
    "async_get_healthy_deployments": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment",
      "parent_otel_span"
    ],
    "async_get_available_deployment": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment"
    ],
    "async_get_available_deployment_for_pass_through": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment"
    ],
    "async_pre_routing_hook": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment"
    ],
    "get_available_deployment": [
      "self",
      "model",
      "messages",
      "input",
      "specific_deployment",
      "request_kwargs"
    ],
    "get_available_deployment_for_pass_through": [
      "self",
      "model",
      "messages",
      "input",
      "specific_deployment",
      "request_kwargs"
    ],
    "_filter_cooldown_deployments": [
      "self",
      "healthy_deployments",
      "cooldown_deployments"
    ],
    "_filter_pass_through_deployments": [
      "self",
      "healthy_deployments"
    ],
    "_track_deployment_metrics": [
      "self",
      "deployment",
      "parent_otel_span",
      "response"
    ],
    "get_num_retries_from_retry_policy": [
      "self",
      "exception",
      "model_group"
    ],
    "get_allowed_fails_from_policy": [
      "self",
      "exception"
    ],
    "_initialize_alerting": [
      "self"
    ],
    "set_custom_routing_strategy": [
      "self",
      "CustomRoutingStrategy"
    ],
    "flush_cache": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "timeout": [
    "timeout_duration",
    "exception_to_raise"
  ],
  "_LoopWrapper": {
    "__init__": [
      "self"
    ],
    "run": [
      "self"
    ],
    "stop_loop": [
      "self"
    ]
  },
  "set_verbose": [],
  "json_logs": [],
  "log_level": [],
  "handler": [],
  "_try_parse_json_message": [
    "message"
  ],
  "_try_parse_embedded_python_dict": [
    "message"
  ],
  "_get_standard_record_attrs": [],
  "_STANDARD_RECORD_ATTRS": [],
  "JsonFormatter": {
    "__init__": [
      "self"
    ],
    "formatTime": [
      "self",
      "record",
      "datefmt"
    ],
    "format": [
      "self",
      "record"
    ]
  },
  "_setup_json_exception_handlers": [
    "formatter"
  ],
  "verbose_proxy_logger": [],
  "verbose_router_logger": [],
  "verbose_logger": [],
  "_suppress_loggers": [],
  "ALL_LOGGERS": [],
  "_get_loggers_to_initialize": [],
  "_initialize_loggers_with_handler": [
    "handler"
  ],
  "_get_uvicorn_json_log_config": [],
  "_turn_on_json": [],
  "_turn_on_debug": [],
  "_disable_debugging": [],
  "_enable_debugging": [],
  "_is_debugging_on": [],
  "litellm_mode": [],
  "CALLBACK_TYPES": [],
  "_custom_logger_compatible_callbacks_literal": [],
  "store_audit_logs": [],
  "telemetry": [],
  "drop_params": [],
  "modify_params": [],
  "retry": [],
  "AZURE_DEFAULT_API_VERSION": [],
  "WATSONX_DEFAULT_API_VERSION": [],
  "_current_cost": [],
  "suppress_debug_info": [],
  "model_cost": [],
  "check_provider_endpoint": [],
  "MyLocal": {
    "__init__": [
      "self"
    ]
  },
  "_thread_context": [],
  "identify": [
    "event_details"
  ],
  "headers": [],
  "organization": [],
  "project": [],
  "config_path": [],
  "is_bedrock_pricing_only_model": [
    "key"
  ],
  "is_openai_finetune_model": [
    "key"
  ],
  "add_known_models": [],
  "azure_llms": [],
  "azure_embedding_models": [],
  "petals_models": [],
  "ollama_models": [],
  "maritalk_models": [],
  "model_list": [],
  "model_list_set": [],
  "all_embedding_models": [],
  "openai_image_generation_models": [],
  "openai_video_generation_models": [],
  "vertexAITextEmbeddingConfig": [],
  "set_global_bitbucket_config": [
    "config"
  ],
  "set_global_gitlab_config": [
    "config"
  ],
  "_async_client_cleanup_registered": [],
  "_get_litellm_globals": [],
  "_get_utils_globals": [],
  "_get_default_encoding": [],
  "_get_modified_max_tokens": [],
  "_get_token_counter_new": [],
  "_get_lazy_import_registry": [],
  "_generic_lazy_import": [
    "name",
    "import_map",
    "category"
  ],
  "_lazy_import_utils": [
    "name"
  ],
  "_lazy_import_cost_calculator": [
    "name"
  ],
  "_lazy_import_token_counter": [
    "name"
  ],
  "_lazy_import_bedrock_types": [
    "name"
  ],
  "_lazy_import_types_utils": [
    "name"
  ],
  "_lazy_import_caching": [
    "name"
  ],
  "_lazy_import_dotprompt": [
    "name"
  ],
  "_lazy_import_types": [
    "name"
  ],
  "_lazy_import_llm_configs": [
    "name"
  ],
  "_lazy_import_litellm_logging": [
    "name"
  ],
  "_lazy_import_llm_provider_logic": [
    "name"
  ],
  "_lazy_import_utils_module": [
    "name"
  ],
  "_lazy_import_llm_client_cache": [
    "name"
  ],
  "_lazy_import_http_handlers": [
    "name"
  ],
  "calculate_batch_cost_and_usage": [
    "file_content_dictionary",
    "custom_llm_provider",
    "model_name",
    "model_info"
  ],
  "_handle_completed_batch": [
    "batch",
    "custom_llm_provider",
    "model_name",
    "litellm_params"
  ],
  "_get_batch_models_from_file_content": [
    "file_content_dictionary",
    "model_name"
  ],
  "_batch_cost_calculator": [
    "file_content_dictionary",
    "custom_llm_provider",
    "model_name",
    "model_info"
  ],
  "calculate_vertex_ai_batch_cost_and_usage": [
    "vertex_ai_batch_responses",
    "model_name"
  ],
  "_get_batch_output_file_content_as_dictionary": [
    "batch",
    "custom_llm_provider",
    "litellm_params"
  ],
  "_extract_file_access_credentials": [
    "litellm_params"
  ],
  "_get_file_content_as_dictionary": [
    "file_content"
  ],
  "_get_batch_job_cost_from_file_content": [
    "file_content_dictionary",
    "custom_llm_provider",
    "model_info"
  ],
  "_get_batch_job_total_usage_from_file_content": [
    "file_content_dictionary",
    "custom_llm_provider",
    "model_name"
  ],
  "_get_batch_job_input_file_usage": [
    "file_content_dictionary",
    "custom_llm_provider",
    "model_name"
  ],
  "_get_batch_job_usage_from_response_body": [
    "response_body"
  ],
  "_get_response_from_batch_job_output_file": [
    "batch_job_output_file"
  ],
  "_batch_response_was_successful": [
    "batch_job_output_file"
  ],
  "openai_batches_instance": [],
  "azure_batches_instance": [],
  "vertex_ai_batches_instance": [],
  "anthropic_batches_instance": [],
  "_resolve_timeout": [
    "optional_params",
    "kwargs",
    "custom_llm_provider",
    "default_timeout"
  ],
  "acreate_batch": [
    "completion_window",
    "endpoint",
    "input_file_id",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "create_batch": [
    "completion_window",
    "endpoint",
    "input_file_id",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "aretrieve_batch": [
    "batch_id",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "_handle_retrieve_batch_providers_without_provider_config": [
    "batch_id",
    "optional_params",
    "timeout",
    "litellm_params",
    "_retrieve_batch_request",
    "_is_async",
    "custom_llm_provider",
    "logging_obj"
  ],
  "retrieve_batch": [
    "batch_id",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "alist_batches": [
    "after",
    "limit",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "list_batches": [
    "after",
    "limit",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "acancel_batch": [
    "batch_id",
    "model",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "cancel_batch": [
    "batch_id",
    "model",
    "custom_llm_provider",
    "metadata",
    "extra_headers",
    "extra_body"
  ],
  "_handle_async_invoke_status": [
    "batch_id",
    "aws_region_name",
    "logging_obj"
  ],
  "batch_completion": [
    "model",
    "messages",
    "functions",
    "function_call",
    "temperature",
    "top_p",
    "n",
    "stream",
    "stop",
    "max_tokens",
    "presence_penalty",
    "frequency_penalty",
    "logit_bias",
    "user",
    "deployment_id",
    "request_timeout",
    "timeout",
    "max_workers"
  ],
  "batch_completion_models": [],
  "batch_completion_models_all_responses": [],
  "A2ARequestUtils": {
    "extract_text_from_message": [
      "message"
    ],
    "extract_text_from_response": [
      "response_dict"
    ],
    "get_input_message_from_request": [
      "request"
    ],
    "count_tokens": [
      "text"
    ],
    "calculate_usage_from_request_response": [
      "request",
      "response_dict"
    ]
  },
  "extract_text_from_a2a_message": [
    "message"
  ],
  "extract_text_from_a2a_response": [
    "response_dict"
  ],
  "A2ACostCalculator": {
    "calculate_a2a_cost": [
      "litellm_logging_obj"
    ],
    "_calculate_token_based_cost": [
      "model_call_details",
      "input_cost_per_token",
      "output_cost_per_token"
    ]
  },
  "is_localhost_or_internal_url": [
    "url"
  ],
  "fix_agent_card_url": [
    "agent_card",
    "base_url"
  ],
  "LiteLLMA2ACardResolver": {
    "get_agent_card": [
      "self",
      "relative_card_path",
      "http_kwargs"
    ]
  },
  "A2A_SDK_AVAILABLE": [],
  "A2AExceptionCheckers": {
    "is_connection_error": [
      "error_str"
    ],
    "is_localhost_url": [
      "url"
    ],
    "is_agent_card_error": [
      "error_str"
    ]
  },
  "map_a2a_exception": [
    "original_exception",
    "card_url",
    "api_base",
    "model"
  ],
  "handle_a2a_localhost_retry": [
    "error",
    "agent_card",
    "a2a_client",
    "is_streaming"
  ],
  "A2AStreamingIterator": {
    "__init__": [
      "self",
      "stream",
      "request",
      "logging_obj",
      "agent_name"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "_collect_text_from_chunk": [
      "self",
      "chunk"
    ],
    "_is_completed_chunk": [
      "self",
      "chunk"
    ],
    "_handle_stream_complete": [
      "self"
    ],
    "_build_logging_result": [
      "self",
      "usage"
    ]
  },
  "A2ACardResolver": [],
  "_set_usage_on_logging_obj": [
    "kwargs",
    "prompt_tokens",
    "completion_tokens"
  ],
  "_set_agent_id_on_logging_obj": [
    "kwargs",
    "agent_id"
  ],
  "_get_a2a_model_info": [
    "a2a_client",
    "kwargs"
  ],
  "asend_message": [
    "a2a_client",
    "request",
    "api_base",
    "litellm_params",
    "agent_id"
  ],
  "send_message": [
    "a2a_client",
    "request"
  ],
  "_build_streaming_logging_obj": [
    "request",
    "agent_name",
    "agent_id",
    "litellm_params",
    "metadata",
    "proxy_server_request"
  ],
  "asend_message_streaming": [
    "a2a_client",
    "request",
    "api_base",
    "litellm_params",
    "agent_id",
    "metadata",
    "proxy_server_request"
  ],
  "create_a2a_client": [
    "base_url",
    "timeout",
    "extra_headers"
  ],
  "aget_agent_card": [
    "base_url",
    "timeout",
    "extra_headers"
  ],
  "A2AError": {
    "__init__": [
      "self",
      "message",
      "status_code",
      "llm_provider",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ],
    "__str__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "A2AConnectionError": {
    "__init__": [
      "self",
      "message",
      "url",
      "model",
      "response",
      "litellm_debug_info",
      "max_retries",
      "num_retries"
    ]
  },
  "A2AAgentCardError": {
    "__init__": [
      "self",
      "message",
      "url",
      "model",
      "response",
      "litellm_debug_info"
    ]
  },
  "A2ALocalhostURLError": {
    "__init__": [
      "self",
      "localhost_url",
      "base_url",
      "original_error",
      "model"
    ]
  },
  "A2AClient": {
    "__init__": [
      "self",
      "base_url",
      "timeout",
      "extra_headers"
    ],
    "_get_client": [
      "self"
    ],
    "get_agent_card": [
      "self"
    ],
    "send_message": [
      "self",
      "request"
    ],
    "send_message_streaming": [
      "self",
      "request"
    ]
  },
  "A2AStreamingContext": {
    "__init__": [
      "self",
      "request_id",
      "input_message"
    ]
  },
  "A2ACompletionBridgeTransformation": {
    "a2a_message_to_openai_messages": [
      "a2a_message"
    ],
    "openai_response_to_a2a_response": [
      "response",
      "request_id"
    ],
    "_get_timestamp": [],
    "create_task_event": [
      "ctx"
    ],
    "create_status_update_event": [
      "ctx",
      "state",
      "final",
      "message_text"
    ],
    "create_artifact_update_event": [
      "ctx",
      "text"
    ],
    "openai_chunk_to_a2a_chunk": [
      "chunk",
      "request_id",
      "is_final"
    ]
  },
  "A2ACompletionBridgeHandler": {
    "handle_non_streaming": [
      "request_id",
      "params",
      "litellm_params",
      "api_base"
    ],
    "handle_streaming": [
      "request_id",
      "params",
      "litellm_params",
      "api_base"
    ]
  },
  "handle_a2a_completion": [
    "request_id",
    "params",
    "litellm_params",
    "api_base"
  ],
  "handle_a2a_completion_streaming": [
    "request_id",
    "params",
    "litellm_params",
    "api_base"
  ],
  "A2AProviderConfigManager": {
    "get_provider_config": [
      "custom_llm_provider"
    ]
  },
  "BaseA2AProviderConfig": {
    "handle_non_streaming": [
      "self",
      "request_id",
      "params",
      "api_base"
    ],
    "handle_streaming": [
      "self",
      "request_id",
      "params",
      "api_base"
    ]
  },
  "PydanticAITransformation": {
    "_remove_none_values": [
      "obj"
    ],
    "_params_to_dict": [
      "params"
    ],
    "_poll_for_completion": [
      "client",
      "endpoint",
      "task_id",
      "request_id",
      "max_attempts",
      "poll_interval"
    ],
    "_send_and_poll_raw": [
      "api_base",
      "request_id",
      "params",
      "timeout"
    ],
    "send_non_streaming_request": [
      "api_base",
      "request_id",
      "params",
      "timeout"
    ],
    "send_and_get_raw_response": [
      "api_base",
      "request_id",
      "params",
      "timeout"
    ],
    "_transform_to_a2a_response": [
      "response_data",
      "request_id"
    ],
    "_extract_response_text": [
      "response_data"
    ],
    "fake_streaming_from_response": [
      "response_data",
      "request_id",
      "chunk_size",
      "delay_ms"
    ]
  },
  "PydanticAIHandler": {
    "handle_non_streaming": [
      "request_id",
      "params",
      "api_base",
      "timeout"
    ],
    "handle_streaming": [
      "request_id",
      "params",
      "api_base",
      "timeout",
      "chunk_size",
      "delay_ms"
    ]
  },
  "PydanticAIProviderConfig": {
    "handle_non_streaming": [
      "self",
      "request_id",
      "params",
      "api_base"
    ],
    "handle_streaming": [
      "self",
      "request_id",
      "params",
      "api_base"
    ]
  },
  "LiteLLMResponsesTransformationHandler": {
    "__init__": [
      "self"
    ],
    "_handle_raw_dict_response_item": [
      "self",
      "item",
      "index"
    ],
    "convert_chat_completion_messages_to_responses_api": [
      "self",
      "messages"
    ],
    "_map_optional_params_to_responses_api_request": [
      "self",
      "optional_params",
      "responses_api_request"
    ],
    "_build_sanitized_litellm_params": [
      "self",
      "litellm_params"
    ],
    "_merge_responses_api_request_into_request_data": [
      "self",
      "request_data",
      "responses_api_request",
      "instructions"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers",
      "litellm_logging_obj",
      "client"
    ],
    "_convert_response_output_to_choices": [
      "output_items",
      "handle_raw_dict_callback"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "_convert_content_str_to_input_text": [
      "self",
      "content",
      "role"
    ],
    "_convert_content_to_responses_format_image": [
      "self",
      "content",
      "role"
    ],
    "_convert_content_to_responses_format": [
      "self",
      "content",
      "role"
    ],
    "_convert_tools_to_responses_format": [
      "self",
      "tools"
    ],
    "_extract_extra_body_params": [
      "self",
      "optional_params"
    ],
    "_map_reasoning_effort": [
      "self",
      "reasoning_effort"
    ],
    "_add_web_search_tool": [
      "self",
      "responses_api_request",
      "web_search_options"
    ],
    "_transform_response_format_to_text_format": [
      "self",
      "response_format"
    ],
    "_convert_annotations_to_chat_format": [
      "annotations"
    ],
    "_map_responses_status_to_finish_reason": [
      "self",
      "status"
    ]
  },
  "OpenAiResponsesToChatCompletionStreamIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "_handle_string_chunk": [
      "self",
      "str_line"
    ],
    "translate_responses_chunk_to_openai_stream": [
      "parsed_chunk"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "ResponsesToCompletionBridgeHandlerInputKwargs": {},
  "ResponsesToCompletionBridgeHandler": {
    "__init__": [
      "self"
    ],
    "_resolve_stream_flag": [
      "optional_params",
      "litellm_params"
    ],
    "_coerce_response_object": [
      "response_obj",
      "hidden_params"
    ],
    "_collect_response_from_stream": [
      "self",
      "stream_iter"
    ],
    "_collect_response_from_stream_async": [
      "self",
      "stream_iter"
    ],
    "validate_input_kwargs": [
      "self",
      "kwargs"
    ],
    "completion": [
      "self"
    ],
    "acompletion": [
      "self"
    ]
  },
  "responses_api_bridge": [],
  "FileType": {
    "AAC": [],
    "CSV": [],
    "DOC": [],
    "DOCX": [],
    "FLAC": [],
    "FLV": [],
    "GIF": [],
    "GOOGLE_DOC": [],
    "GOOGLE_DRAWINGS": [],
    "GOOGLE_SHEETS": [],
    "GOOGLE_SLIDES": [],
    "HEIC": [],
    "HEIF": [],
    "HTML": [],
    "JPEG": [],
    "JSON": [],
    "M4A": [],
    "M4V": [],
    "MOV": [],
    "MP3": [],
    "MP4": [],
    "MPEG": [],
    "MPEGPS": [],
    "MPG": [],
    "MPA": [],
    "MPGA": [],
    "OGG": [],
    "OPUS": [],
    "PDF": [],
    "PCM": [],
    "PNG": [],
    "PPT": [],
    "PPTX": [],
    "RTF": [],
    "THREE_GPP": [],
    "TXT": [],
    "WAV": [],
    "WEBM": [],
    "WEBP": [],
    "WMV": [],
    "XLS": [],
    "XLSX": []
  },
  "get_file_extension_from_mime_type": [
    "mime_type"
  ],
  "get_file_type_from_extension": [
    "extension"
  ],
  "get_file_extension_for_file_type": [
    "file_type"
  ],
  "get_file_mime_type_for_file_type": [
    "file_type"
  ],
  "get_file_mime_type_from_extension": [
    "extension"
  ],
  "IMAGE_FILE_TYPES": [],
  "is_image_file_type": [
    "file_type"
  ],
  "VIDEO_FILE_TYPES": [],
  "is_video_file_type": [
    "file_type"
  ],
  "AUDIO_FILE_TYPES": [],
  "is_audio_file_type": [
    "file_type"
  ],
  "TEXT_FILE_TYPES": [],
  "is_text_file_type": [
    "file_type"
  ],
  "is_gemini_1_5_accepted_file_type": [
    "file_type"
  ],
  "TwoStepFileUploadRequest": {},
  "TwoStepFileUploadConfig": {},
  "TagBase": {},
  "TagConfig": {},
  "TagNewRequest": {},
  "TagUpdateRequest": {},
  "TagDeleteRequest": {},
  "TagInfoRequest": {},
  "LiteLLM_DailyTagSpendTable": {},
  "_generate_id": [],
  "SafeAttributeModel": {
    "__delattr__": [
      "self",
      "name"
    ]
  },
  "LiteLLMCommonStrings": {
    "redacted_by_litellm": [],
    "llm_provider_not_provided": []
  },
  "SupportedCacheControls": [],
  "CostPerToken": {},
  "ProviderField": {},
  "ProviderSpecificModelInfo": {},
  "SearchContextCostPerQuery": {},
  "AgenticLoopParams": {},
  "ModelInfoBase": {},
  "ModelInfo": {},
  "GenericStreamingChunk": {},
  "CallTypes": {
    "embedding": [],
    "aembedding": [],
    "completion": [],
    "acompletion": [],
    "atext_completion": [],
    "text_completion": [],
    "image_generation": [],
    "aimage_generation": [],
    "image_edit": [],
    "aimage_edit": [],
    "moderation": [],
    "amoderation": [],
    "atranscription": [],
    "transcription": [],
    "aspeech": [],
    "speech": [],
    "rerank": [],
    "arerank": [],
    "search": [],
    "asearch": [],
    "arealtime": [],
    "create_batch": [],
    "acreate_batch": [],
    "aretrieve_batch": [],
    "retrieve_batch": [],
    "acancel_batch": [],
    "cancel_batch": [],
    "pass_through": [],
    "anthropic_messages": [],
    "get_assistants": [],
    "aget_assistants": [],
    "create_assistants": [],
    "acreate_assistants": [],
    "delete_assistant": [],
    "adelete_assistant": [],
    "acreate_thread": [],
    "create_thread": [],
    "aget_thread": [],
    "get_thread": [],
    "a_add_message": [],
    "add_message": [],
    "aget_messages": [],
    "get_messages": [],
    "arun_thread": [],
    "run_thread": [],
    "arun_thread_stream": [],
    "run_thread_stream": [],
    "afile_retrieve": [],
    "file_retrieve": [],
    "afile_delete": [],
    "file_delete": [],
    "afile_list": [],
    "file_list": [],
    "acreate_file": [],
    "create_file": [],
    "afile_content": [],
    "file_content": [],
    "create_fine_tuning_job": [],
    "acreate_fine_tuning_job": [],
    "create_video": [],
    "acreate_video": [],
    "avideo_retrieve": [],
    "video_retrieve": [],
    "avideo_content": [],
    "video_content": [],
    "video_remix": [],
    "avideo_remix": [],
    "video_list": [],
    "avideo_list": [],
    "video_retrieve_job": [],
    "avideo_retrieve_job": [],
    "video_delete": [],
    "avideo_delete": [],
    "vector_store_file_create": [],
    "avector_store_file_create": [],
    "vector_store_file_list": [],
    "avector_store_file_list": [],
    "vector_store_file_retrieve": [],
    "avector_store_file_retrieve": [],
    "vector_store_file_content": [],
    "avector_store_file_content": [],
    "vector_store_file_update": [],
    "avector_store_file_update": [],
    "vector_store_file_delete": [],
    "avector_store_file_delete": [],
    "vector_store_create": [],
    "avector_store_create": [],
    "vector_store_search": [],
    "avector_store_search": [],
    "create_container": [],
    "acreate_container": [],
    "list_containers": [],
    "alist_containers": [],
    "retrieve_container": [],
    "aretrieve_container": [],
    "delete_container": [],
    "adelete_container": [],
    "list_container_files": [],
    "alist_container_files": [],
    "upload_container_file": [],
    "aupload_container_file": [],
    "acancel_fine_tuning_job": [],
    "cancel_fine_tuning_job": [],
    "alist_fine_tuning_jobs": [],
    "list_fine_tuning_jobs": [],
    "aretrieve_fine_tuning_job": [],
    "retrieve_fine_tuning_job": [],
    "responses": [],
    "aresponses": [],
    "alist_input_items": [],
    "llm_passthrough_route": [],
    "allm_passthrough_route": [],
    "generate_content": [],
    "agenerate_content": [],
    "generate_content_stream": [],
    "agenerate_content_stream": [],
    "ocr": [],
    "aocr": [],
    "call_mcp_tool": [],
    "list_mcp_tools": [],
    "asend_message": [],
    "send_message": [],
    "acreate_skill": []
  },
  "CallTypesLiteral": [],
  "API_ROUTE_TO_CALL_TYPES": [],
  "PassthroughCallTypes": {
    "passthrough_image_generation": []
  },
  "TopLogprob": {},
  "ChatCompletionTokenLogprob": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "ChoiceLogprobs": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "FunctionCall": {},
  "Function": {
    "__init__": [
      "self",
      "arguments",
      "name"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "ChatCompletionDeltaToolCall": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "ChatCompletionMessageToolCall": {
    "__init__": [
      "self",
      "function",
      "id",
      "type"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "ChatCompletionAudioResponse": {
    "__init__": [
      "self",
      "data",
      "expires_at",
      "transcript",
      "id"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "add_provider_specific_fields": [
    "object",
    "provider_specific_fields"
  ],
  "Message": {
    "__init__": [
      "self",
      "content",
      "role",
      "function_call",
      "tool_calls",
      "audio",
      "images",
      "provider_specific_fields",
      "reasoning_content",
      "thinking_blocks",
      "annotations"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ]
  },
  "Delta": {
    "__init__": [
      "self",
      "content",
      "role",
      "function_call",
      "tool_calls",
      "audio",
      "images",
      "reasoning_content",
      "thinking_blocks",
      "annotations"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "Choices": {
    "__init__": [
      "self",
      "finish_reason",
      "index",
      "message",
      "logprobs",
      "enhancements",
      "provider_specific_fields"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "CompletionTokensDetailsWrapper": {},
  "CacheCreationTokenDetails": {},
  "PromptTokensDetailsWrapper": {
    "__init__": [
      "self"
    ]
  },
  "ServerToolUse": {},
  "Usage": {
    "__init__": [
      "self",
      "prompt_tokens",
      "completion_tokens",
      "total_tokens",
      "reasoning_tokens",
      "prompt_tokens_details",
      "completion_tokens_details",
      "server_tool_use",
      "cost"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "StreamingChoices": {
    "__init__": [
      "self",
      "finish_reason",
      "index",
      "delta",
      "logprobs",
      "enhancements"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "StreamingChatCompletionChunk": {
    "__init__": [
      "self"
    ]
  },
  "ModelResponseBase": {
    "model_dump": [
      "self"
    ]
  },
  "ModelResponseStream": {
    "__init__": [
      "self",
      "choices",
      "id",
      "created",
      "provider_specific_fields"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "ModelResponse": {
    "__init__": [
      "self",
      "id",
      "choices",
      "created",
      "model",
      "object",
      "system_fingerprint",
      "usage",
      "stream",
      "stream_options",
      "response_ms",
      "hidden_params",
      "_response_headers"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "Embedding": {
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "EmbeddingResponse": {
    "__init__": [
      "self",
      "model",
      "usage",
      "response_ms",
      "data",
      "hidden_params",
      "_response_headers"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ]
  },
  "Logprobs": {},
  "TextChoices": {
    "__init__": [
      "self",
      "finish_reason",
      "index",
      "text",
      "logprobs"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ]
  },
  "TextCompletionResponse": {
    "__init__": [
      "self",
      "id",
      "choices",
      "created",
      "model",
      "usage",
      "stream",
      "response_ms",
      "object"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "ImageObject": {
    "__init__": [
      "self",
      "b64_json",
      "url",
      "revised_prompt",
      "provider_specific_fields"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ]
  },
  "ImageUsageInputTokensDetails": {},
  "ImageUsage": {},
  "ImageResponse": {
    "model_config": [],
    "__init__": [
      "self",
      "created",
      "data",
      "response_ms",
      "usage",
      "hidden_params"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ]
  },
  "TranscriptionUsageDurationObject": {},
  "TranscriptionUsageInputTokenDetailsObject": {},
  "TranscriptionUsageTokensObject": {},
  "TranscriptionResponse": {
    "__init__": [
      "self",
      "text"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ]
  },
  "GenericImageParsingChunk": {},
  "ResponseFormatChunk": {},
  "LoggedLiteLLMParams": {},
  "AdapterCompletionStreamWrapper": {
    "__init__": [
      "self",
      "completion_stream"
    ],
    "__iter__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "StandardLoggingUserAPIKeyMetadata": {},
  "StandardLoggingMCPToolCall": {},
  "StandardLoggingVectorStoreRequest": {},
  "StandardBuiltInToolsParams": {},
  "StandardLoggingPromptManagementMetadata": {},
  "StandardLoggingMetadata": {},
  "StandardLoggingAdditionalHeaders": {},
  "StandardLoggingHiddenParams": {},
  "StandardLoggingModelInformation": {},
  "StandardLoggingModelCostFailureDebugInformation": {},
  "StandardLoggingPayloadErrorInformation": {},
  "GuardrailMode": {},
  "GuardrailStatus": [],
  "StandardLoggingGuardrailInformation": {},
  "GuardrailTracingDetail": {},
  "StandardLoggingPayloadStatus": [],
  "CachingDetails": {},
  "CostBreakdown": {},
  "StandardLoggingPayloadStatusFields": {},
  "StandardLoggingPayload": {},
  "CustomStreamingDecoder": {
    "aiter_bytes": [
      "self",
      "iterator"
    ],
    "iter_bytes": [
      "self",
      "iterator"
    ]
  },
  "StandardPassThroughResponseObject": {},
  "OPENAI_RESPONSE_HEADERS": [],
  "StandardCallbackDynamicParams": {},
  "CustomPricingLiteLLMParams": {},
  "all_litellm_params": [],
  "KeyGenerationConfig": {},
  "TeamUIKeyGenerationConfig": {},
  "PersonalUIKeyGenerationConfig": {},
  "StandardKeyGenerationConfig": {},
  "BudgetConfig": {
    "__init__": [
      "self"
    ]
  },
  "GenericBudgetConfigType": [],
  "LlmProviders": {
    "OPENAI": [],
    "CHATGPT": [],
    "OPENAI_LIKE": [],
    "JINA_AI": [],
    "XAI": [],
    "ZAI": [],
    "CUSTOM_OPENAI": [],
    "TEXT_COMPLETION_OPENAI": [],
    "COHERE": [],
    "COHERE_CHAT": [],
    "CLARIFAI": [],
    "ANTHROPIC": [],
    "ANTHROPIC_TEXT": [],
    "BYTEZ": [],
    "REPLICATE": [],
    "RUNWAYML": [],
    "AWS_POLLY": [],
    "HUGGINGFACE": [],
    "TOGETHER_AI": [],
    "OPENROUTER": [],
    "DATAROBOT": [],
    "VERTEX_AI": [],
    "VERTEX_AI_BETA": [],
    "GEMINI": [],
    "AI21": [],
    "BASETEN": [],
    "AZURE": [],
    "AZURE_TEXT": [],
    "AZURE_AI": [],
    "SAGEMAKER": [],
    "SAGEMAKER_CHAT": [],
    "BEDROCK": [],
    "VLLM": [],
    "NLP_CLOUD": [],
    "PETALS": [],
    "OOBABOOGA": [],
    "OLLAMA": [],
    "OLLAMA_CHAT": [],
    "DEEPINFRA": [],
    "PERPLEXITY": [],
    "MISTRAL": [],
    "MILVUS": [],
    "GROQ": [],
    "A2A": [],
    "GIGACHAT": [],
    "NVIDIA_NIM": [],
    "CEREBRAS": [],
    "AI21_CHAT": [],
    "VOLCENGINE": [],
    "CODESTRAL": [],
    "TEXT_COMPLETION_CODESTRAL": [],
    "DASHSCOPE": [],
    "MOONSHOT": [],
    "PUBLICAI": [],
    "V0": [],
    "MORPH": [],
    "LAMBDA_AI": [],
    "DEEPSEEK": [],
    "SAMBANOVA": [],
    "MARITALK": [],
    "VOYAGE": [],
    "CLOUDFLARE": [],
    "XINFERENCE": [],
    "FIREWORKS_AI": [],
    "FRIENDLIAI": [],
    "FEATHERLESS_AI": [],
    "WATSONX": [],
    "WATSONX_TEXT": [],
    "TRITON": [],
    "PREDIBASE": [],
    "DATABRICKS": [],
    "EMPOWER": [],
    "GITHUB": [],
    "RAGFLOW": [],
    "COMPACTIFAI": [],
    "DOCKER_MODEL_RUNNER": [],
    "CUSTOM": [],
    "LITELLM_PROXY": [],
    "HOSTED_VLLM": [],
    "LLAMAFILE": [],
    "LM_STUDIO": [],
    "GALADRIEL": [],
    "NEBIUS": [],
    "INFINITY": [],
    "DEEPGRAM": [],
    "ELEVENLABS": [],
    "NOVITA": [],
    "AIOHTTP_OPENAI": [],
    "LANGFUSE": [],
    "HUMANLOOP": [],
    "TOPAZ": [],
    "SAP_GENERATIVE_AI_HUB": [],
    "ASSEMBLYAI": [],
    "GITHUB_COPILOT": [],
    "SNOWFLAKE": [],
    "GRADIENT_AI": [],
    "LLAMA": [],
    "NSCALE": [],
    "PG_VECTOR": [],
    "S3_VECTORS": [],
    "HELICONE": [],
    "HYPERBOLIC": [],
    "RECRAFT": [],
    "FAL_AI": [],
    "STABILITY": [],
    "HEROKU": [],
    "AIML": [],
    "COMETAPI": [],
    "OCI": [],
    "AUTO_ROUTER": [],
    "VERCEL_AI_GATEWAY": [],
    "DOTPROMPT": [],
    "MANUS": [],
    "WANDB": [],
    "OVHCLOUD": [],
    "LEMONADE": [],
    "AMAZON_NOVA": [],
    "A2A_AGENT": [],
    "LANGGRAPH": [],
    "MINIMAX": [],
    "SYNTHETIC": [],
    "APERTIS": [],
    "NANOGPT": [],
    "POE": [],
    "CHUTES": [],
    "XIAOMI_MIMO": [],
    "LITELLM_AGENT": []
  },
  "LlmProvidersSet": [],
  "SearchProviders": {
    "PERPLEXITY": [],
    "TAVILY": [],
    "PARALLEL_AI": [],
    "EXA_AI": [],
    "BRAVE": [],
    "GOOGLE_PSE": [],
    "DATAFORSEO": [],
    "FIRECRAWL": [],
    "SEARXNG": [],
    "LINKUP": [],
    "DUCKDUCKGO": []
  },
  "SearchProvidersSet": [],
  "LiteLLMLoggingBaseClass": {
    "pre_call": [
      "self",
      "input",
      "api_key",
      "model",
      "additional_args"
    ],
    "post_call": [
      "self",
      "original_response",
      "input",
      "api_key",
      "additional_args"
    ]
  },
  "TokenCountResponse": {},
  "CustomHuggingfaceTokenizer": {},
  "LITELLM_IMAGE_VARIATION_PROVIDERS": {
    "OPENAI": [],
    "TOPAZ": []
  },
  "HttpHandlerRequestFields": {},
  "ProviderSpecificHeader": {},
  "SelectTokenizerResponse": {},
  "LiteLLMFineTuningJob": {
    "__init__": [
      "self"
    ]
  },
  "LiteLLMBatch": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "LiteLLMRealtimeStreamLoggingObject": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "RawRequestTypedDict": {},
  "CredentialBase": {},
  "CredentialItem": {},
  "CreateCredentialItem": {
    "check_credential_params": [
      "cls",
      "values"
    ]
  },
  "ExtractedFileData": {},
  "SpecialEnums": {
    "LITELM_MANAGED_FILE_ID_PREFIX": [],
    "LITELLM_MANAGED_FILE_COMPLETE_STR": [],
    "LITELLM_MANAGED_RESPONSE_COMPLETE_STR": [],
    "LITELLM_MANAGED_BATCH_COMPLETE_STR": [],
    "LITELLM_MANAGED_RESPONSE_API_RESPONSE_ID_COMPLETE_STR": [],
    "LITELLM_MANAGED_GENERIC_RESPONSE_COMPLETE_STR": [],
    "LITELLM_MANAGED_VIDEO_COMPLETE_STR": []
  },
  "ServiceTier": {
    "FLEX": [],
    "PRIORITY": []
  },
  "LLMResponseTypes": [],
  "DynamicPromptManagementParamLiteral": {
    "CACHE_CONTROL_INJECTION_POINTS": [],
    "KNOWLEDGE_BASES": [],
    "VECTOR_STORE_IDS": [],
    "list_all_params": [
      "cls"
    ]
  },
  "CallbacksByType": {},
  "CostResponseTypes": [],
  "PriorityReservationDict": {},
  "PriorityReservationSettings": {
    "model_config": []
  },
  "GenericGuardrailAPIInputs": {},
  "AccessGroupCreateRequest": {},
  "AccessGroupUpdateRequest": {},
  "AccessGroupResponse": {},
  "ALL_DELTA_TYPES": [],
  "RealtimeResponseTransformInput": {},
  "RealtimeResponseTypedDict": {},
  "RealtimeModalityResponseTransformOutput": {},
  "RealtimeQueryParams": {},
  "OpenAIFineTuningHyperparameters": {
    "model_config": []
  },
  "DefaultPriorities": {
    "High": [],
    "Medium": [],
    "Low": []
  },
  "AdapterItem": {},
  "VectorStoreFileStatus": {
    "IN_PROGRESS": [],
    "COMPLETED": [],
    "FAILED": [],
    "CANCELLED": []
  },
  "VectorStoreFileChunkingStrategyType": {
    "AUTO": [],
    "STATIC": []
  },
  "VectorStoreFileStaticChunkingConfig": {},
  "VectorStoreFileChunkingStrategy": {},
  "VectorStoreFileObject": {},
  "VectorStoreFileCreateRequest": {},
  "VectorStoreFileUpdateRequest": {},
  "VectorStoreFileListQueryParams": {},
  "VectorStoreFileListResponse": {},
  "VectorStoreFileDeleteResponse": {},
  "VectorStoreFileContentTextPart": {},
  "VectorStoreFileContentResponse": {},
  "VectorStoreFileAuthCredentials": {},
  "RAGChunkingStrategy": {},
  "RAGIngestOCROptions": {},
  "RAGIngestEmbeddingOptions": {},
  "OpenAIVectorStoreOptions": {},
  "BedrockVectorStoreOptions": {},
  "VertexAIVectorStoreOptions": {},
  "S3VectorsVectorStoreOptions": {},
  "RAGIngestVectorStoreOptions": [],
  "RAGIngestOptions": {},
  "RAGIngestResponse": {},
  "RAGIngestRequest": {
    "model_config": []
  },
  "RAGRetrievalConfig": {},
  "RAGRerankConfig": {},
  "RAGQueryRequest": {
    "model_config": []
  },
  "RAGQueryResponse": {},
  "AgentProvider": {},
  "AgentExtension": {},
  "AgentCapabilities": {},
  "SecuritySchemeBase": {},
  "APIKeySecurityScheme": {},
  "HTTPAuthSecurityScheme": {},
  "MutualTLSSecurityScheme": {},
  "OAuthFlows": {},
  "OAuth2SecurityScheme": {},
  "OpenIdConnectSecurityScheme": {},
  "SecurityScheme": [],
  "AgentSkill": {},
  "AgentInterface": {},
  "AgentCardSignature": {},
  "AgentCard": {},
  "AugmentedAgentCard": {},
  "AgentConfig": {},
  "PatchAgentRequest": {},
  "AgentResponse": {},
  "ListAgentsResponse": {},
  "AgentMakePublicResponse": {},
  "MakeAgentsPublicRequest": {},
  "LiteLLMSendMessageResponse": {
    "model_config": [],
    "from_a2a_response": [
      "cls",
      "response"
    ],
    "from_dict": [
      "cls",
      "response_dict"
    ]
  },
  "EmbeddingRequest": {
    "model_config": []
  },
  "LiteLLMCacheType": {
    "LOCAL": [],
    "REDIS": [],
    "REDIS_SEMANTIC": [],
    "S3": [],
    "DISK": [],
    "QDRANT_SEMANTIC": [],
    "AZURE_BLOB": [],
    "GCS": []
  },
  "CachingSupportedCallTypes": [],
  "RedisPipelineIncrementOperation": {},
  "RedisPipelineSetOperation": {},
  "DynamicCacheControl": [],
  "CachePingResponse": {},
  "HealthCheckCacheParams": {},
  "CachedEmbedding": {},
  "ServiceMetrics": {
    "COUNTER": [],
    "HISTOGRAM": [],
    "GAUGE": []
  },
  "ServiceTypes": {
    "REDIS": [],
    "DB": [],
    "BATCH_WRITE_TO_DB": [],
    "RESET_BUDGET_JOB": [],
    "LITELLM": [],
    "ROUTER": [],
    "AUTH": [],
    "PROXY_PRE_CALL": [],
    "POD_LOCK_MANAGER": [],
    "IN_MEMORY_DAILY_SPEND_UPDATE_QUEUE": [],
    "REDIS_DAILY_SPEND_UPDATE_QUEUE": [],
    "REDIS_DAILY_END_USER_SPEND_UPDATE_QUEUE": [],
    "REDIS_DAILY_ORG_SPEND_UPDATE_QUEUE": [],
    "REDIS_DAILY_TEAM_SPEND_UPDATE_QUEUE": [],
    "REDIS_DAILY_AGENT_SPEND_UPDATE_QUEUE": [],
    "REDIS_DAILY_TAG_SPEND_UPDATE_QUEUE": [],
    "IN_MEMORY_SPEND_UPDATE_QUEUE": [],
    "REDIS_SPEND_UPDATE_QUEUE": []
  },
  "ServiceConfig": {},
  "DEFAULT_SERVICE_CONFIGS": [],
  "ServiceEventMetadata": {},
  "ServiceLoggerPayload": {
    "to_json": [
      "self"
    ]
  },
  "ChatCompletionSystemMessageParam": {},
  "ChatCompletionContentPartTextParam": {},
  "ImageURL": {},
  "ChatCompletionContentPartImageParam": {},
  "ChatCompletionContentPartParam": [],
  "ChatCompletionUserMessageParam": {},
  "ChatCompletionToolMessageParam": {},
  "ChatCompletionFunctionMessageParam": {},
  "ChatCompletionMessageToolCallParam": {},
  "ChatCompletionAssistantMessageParam": {},
  "ChatCompletionMessageParam": [],
  "CompletionRequest": {
    "model_config": []
  },
  "RerankRequest": {},
  "OptionalRerankParams": {},
  "RerankBilledUnits": {},
  "RerankTokens": {},
  "RerankResponseMeta": {},
  "RerankResponseDocument": {},
  "RerankResponseResult": {},
  "RerankResponse": {
    "__getitem__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__contains__": [
      "self",
      "key"
    ]
  },
  "SearchProvider": [],
  "SearchToolLiteLLMParams": {},
  "SearchTool": {},
  "SearchToolInfoResponse": {},
  "ListSearchToolsResponse": {},
  "AvailableSearchProvider": {},
  "MCPTransport": {
    "sse": [],
    "http": [],
    "stdio": []
  },
  "MCPSpecVersion": {
    "nov_2024": [],
    "mar_2025": [],
    "jun_2025": []
  },
  "MCPAuth": {
    "none": [],
    "api_key": [],
    "bearer_token": [],
    "basic": [],
    "authorization": [],
    "oauth2": []
  },
  "MCPTransportType": [],
  "MCPSpecVersionType": [],
  "MCPAuthType": [],
  "MCPPublicServer": {},
  "MCPCredentials": {},
  "MCPServerCostInfo": {},
  "MCPStdioConfig": {},
  "MCPPreCallRequestObject": {},
  "MCPPreCallResponseObject": {},
  "MCPDuringCallRequestObject": {},
  "MCPDuringCallResponseObject": {},
  "MCPPostCallResponseObject": {},
  "SupportedVectorStoreIntegrations": {
    "BEDROCK": [],
    "RAGFLOW": []
  },
  "LiteLLM_VectorStoreConfig": {},
  "LiteLLM_ManagedVectorStore": {},
  "LiteLLM_ManagedVectorStoreListResponse": {},
  "VectorStoreUpdateRequest": {},
  "VectorStoreDeleteRequest": {},
  "VectorStoreInfoRequest": {},
  "VectorStoreResultContent": {},
  "VectorStoreSearchResult": {},
  "VectorStoreSearchResponse": {},
  "VectorStoreSearchOptionalRequestParams": {},
  "VectorStoreSearchRequest": {},
  "VectorStoreExpirationPolicy": {},
  "VectorStoreAutoChunkingStrategy": {},
  "VectorStoreStaticChunkingStrategyConfig": {},
  "VectorStoreStaticChunkingStrategy": {},
  "VectorStoreChunkingStrategy": {},
  "VectorStoreFileCounts": {},
  "VectorStoreCreateOptionalRequestParams": {},
  "VectorStoreCreateRequest": {},
  "VectorStoreCreateResponse": {},
  "IndexCreateLiteLLMParams": {},
  "IndexCreateRequest": {},
  "BaseVectorStoreAuthCredentials": {},
  "LiteLLM_ManagedVectorStoreIndex": {},
  "VectorStoreIndexType": {
    "READ": [],
    "WRITE": []
  },
  "VectorStoreIndexEndpoints": {},
  "VECTOR_STORE_OPENAI_PARAMS": [],
  "VectorStoreToolParams": {
    "to_dict": [
      "self"
    ]
  },
  "ConfigurableClientsideParamsCustomAuth": {},
  "CONFIGURABLE_CLIENTSIDE_AUTH_PARAMS": [],
  "ModelConfig": {
    "model_config": []
  },
  "RouterConfig": {
    "model_config": []
  },
  "UpdateRouterConfig": {
    "model_config": []
  },
  "CredentialLiteLLMParams": {},
  "GenericLiteLLMParams": {
    "model_config": [],
    "__init__": [
      "self",
      "custom_llm_provider",
      "max_retries",
      "tpm",
      "rpm",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "stream_timeout",
      "organization",
      "litellm_trace_id",
      "region_name",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_region_name",
      "watsonx_region_name",
      "input_cost_per_token",
      "output_cost_per_token",
      "input_cost_per_second",
      "output_cost_per_second",
      "max_file_size_mb",
      "max_budget",
      "budget_duration",
      "use_in_pass_through",
      "use_litellm_proxy",
      "merge_reasoning_content_in_choices",
      "model_info",
      "mock_response",
      "auto_router_config_path",
      "auto_router_config",
      "auto_router_default_model",
      "auto_router_embedding_model",
      "complexity_router_config",
      "complexity_router_default_model",
      "s3_bucket_name",
      "s3_encryption_key_id",
      "gcs_bucket_name"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "LiteLLM_Params": {
    "model_config": [],
    "__init__": [
      "self",
      "model",
      "custom_llm_provider",
      "max_retries",
      "tpm",
      "rpm",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "stream_timeout",
      "organization",
      "vertex_project",
      "vertex_location",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_region_name",
      "max_file_size_mb",
      "use_in_pass_through",
      "use_litellm_proxy"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "updateLiteLLMParams": {},
  "updateDeployment": {
    "model_config": []
  },
  "LiteLLMParamsTypedDict": {},
  "DeploymentTypedDict": {},
  "SPECIAL_MODEL_INFO_PARAMS": [],
  "Deployment": {
    "model_config": [],
    "__init__": [
      "self",
      "model_name",
      "litellm_params",
      "model_info"
    ],
    "to_json": [
      "self"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "RouterErrors": {
    "user_defined_ratelimit_error": [],
    "no_deployments_available": [],
    "no_deployments_with_tag_routing": [],
    "no_deployments_with_provider_budget_routing": []
  },
  "AllowedFailsPolicy": {},
  "RetryPolicy": {},
  "AlertingConfig": {},
  "ModelGroupInfo": {
    "__init__": [
      "self"
    ]
  },
  "AssistantsTypedDict": {},
  "SearchToolInfoTypedDict": {},
  "SearchToolTypedDict": {},
  "GuardrailLiteLLMParams": {},
  "GuardrailTypedDict": {},
  "FineTuningConfig": {},
  "CustomRoutingStrategyBase": {
    "async_get_available_deployment": [
      "self",
      "model",
      "messages",
      "input",
      "specific_deployment",
      "request_kwargs"
    ],
    "get_available_deployment": [
      "self",
      "model",
      "messages",
      "input",
      "specific_deployment",
      "request_kwargs"
    ]
  },
  "RouterGeneralSettings": {},
  "RouterRateLimitErrorBasic": {
    "__init__": [
      "self",
      "model"
    ]
  },
  "RouterRateLimitError": {
    "__init__": [
      "self",
      "model",
      "cooldown_time",
      "enable_pre_call_checks",
      "cooldown_list"
    ]
  },
  "RouterModelGroupAliasItem": {},
  "VALID_LITELLM_ENVIRONMENTS": [],
  "RoutingStrategy": {
    "LEAST_BUSY": [],
    "LATENCY_BASED": [],
    "COST_BASED": [],
    "USAGE_BASED_ROUTING_V2": [],
    "USAGE_BASED_ROUTING": [],
    "PROVIDER_BUDGET_LIMITING": []
  },
  "RouterCacheEnum": {
    "TPM": [],
    "RPM": []
  },
  "GenericBudgetWindowDetails": {},
  "OptionalPreCallChecks": [],
  "LiteLLM_RouterFileObject": {},
  "MockRouterTestingParams": {
    "from_kwargs": [
      "cls",
      "kwargs"
    ]
  },
  "ModelGroupSettings": {},
  "PreRoutingHookResponse": {},
  "SupportedGuardrailIntegrations": {
    "APORIA": [],
    "BEDROCK": [],
    "GUARDRAILS_AI": [],
    "LAKERA": [],
    "LAKERA_V2": [],
    "PRESIDIO": [],
    "HIDE_SECRETS": [],
    "HIDDENLAYER": [],
    "AIM": [],
    "PANGEA": [],
    "LASSO": [],
    "PILLAR": [],
    "GRAYSWAN": [],
    "PANW_PRISMA_AIRS": [],
    "AZURE_PROMPT_SHIELD": [],
    "AZURE_TEXT_MODERATIONS": [],
    "MODEL_ARMOR": [],
    "OPENAI_MODERATION": [],
    "NOMA": [],
    "TOOL_PERMISSION": [],
    "ZSCALER_AI_GUARD": [],
    "JAVELIN": [],
    "ENKRYPTAI": [],
    "IBM_GUARDRAILS": [],
    "LITELLM_CONTENT_FILTER": [],
    "MCP_SECURITY": [],
    "ONYX": [],
    "PROMPT_SECURITY": [],
    "GENERIC_GUARDRAIL_API": [],
    "QUALIFIRE": [],
    "CUSTOM_CODE": [],
    "SEMANTIC_GUARD": [],
    "MCP_END_USER_PERMISSION": []
  },
  "Role": {
    "SYSTEM": [],
    "ASSISTANT": [],
    "USER": []
  },
  "default_roles": [],
  "GuardrailItemSpec": {},
  "GuardrailItem": {
    "model_config": [],
    "__init__": [
      "self",
      "callbacks",
      "guardrail_name",
      "default_on",
      "logging_only",
      "enabled_roles",
      "callback_args"
    ]
  },
  "LakeraCategoryThresholds": {},
  "PiiAction": {
    "BLOCK": [],
    "MASK": []
  },
  "PiiEntityCategory": {
    "GENERAL": [],
    "FINANCE": [],
    "USA": [],
    "UK": [],
    "SPAIN": [],
    "ITALY": [],
    "POLAND": [],
    "SINGAPORE": [],
    "AUSTRALIA": [],
    "INDIA": [],
    "FINLAND": []
  },
  "PiiEntityType": {
    "CREDIT_CARD": [],
    "CRYPTO": [],
    "DATE_TIME": [],
    "EMAIL_ADDRESS": [],
    "IBAN_CODE": [],
    "IP_ADDRESS": [],
    "NRP": [],
    "LOCATION": [],
    "PERSON": [],
    "PHONE_NUMBER": [],
    "MEDICAL_LICENSE": [],
    "URL": [],
    "US_BANK_NUMBER": [],
    "US_DRIVER_LICENSE": [],
    "US_ITIN": [],
    "US_PASSPORT": [],
    "US_SSN": [],
    "UK_NHS": [],
    "UK_NINO": [],
    "ES_NIF": [],
    "ES_NIE": [],
    "IT_FISCAL_CODE": [],
    "IT_DRIVER_LICENSE": [],
    "IT_VAT_CODE": [],
    "IT_PASSPORT": [],
    "IT_IDENTITY_CARD": [],
    "PL_PESEL": [],
    "SG_NRIC_FIN": [],
    "SG_UEN": [],
    "AU_ABN": [],
    "AU_ACN": [],
    "AU_TFN": [],
    "AU_MEDICARE": [],
    "IN_PAN": [],
    "IN_AADHAAR": [],
    "IN_VEHICLE_REGISTRATION": [],
    "IN_VOTER": [],
    "IN_PASSPORT": [],
    "FI_PERSONAL_IDENTITY_CODE": []
  },
  "PII_ENTITY_CATEGORIES_MAP": [],
  "PiiEntityCategoryMap": {},
  "GuardrailParamUITypes": {
    "BOOL": [],
    "STR": []
  },
  "PresidioPresidioConfigModelUserInterface": {},
  "PresidioConfigModel": {},
  "BedrockGuardrailConfigModel": {},
  "LakeraV2GuardrailConfigModel": {},
  "LassoGuardrailConfigModel": {},
  "PillarGuardrailConfigModel": {},
  "NomaGuardrailConfigModel": {},
  "ZscalerAIGuardConfigModel": {},
  "JavelinGuardrailConfigModel": {},
  "ContentFilterAction": {
    "BLOCK": [],
    "MASK": []
  },
  "BlockedWord": {},
  "ContentFilterPattern": {},
  "ContentFilterConfigModel": {},
  "BaseLitellmParams": {
    "model_config": []
  },
  "Mode": {},
  "LitellmParams": {
    "normalize_lowercase": [
      "cls",
      "v"
    ],
    "__init__": [
      "self"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ]
  },
  "Guardrail": {},
  "guardrailConfig": {},
  "GuardrailEventHooks": {
    "pre_call": [],
    "post_call": [],
    "during_call": [],
    "logging_only": [],
    "pre_mcp_call": [],
    "during_mcp_call": []
  },
  "DynamicGuardrailParams": {},
  "GUARDRAIL_DEFINITION_LOCATION": {
    "DB": [],
    "CONFIG": []
  },
  "GuardrailInfoResponse": {
    "__init__": [
      "self"
    ]
  },
  "ListGuardrailsResponse": {},
  "GuardrailUIAddGuardrailSettings": {},
  "PresidioPerRequestConfig": {},
  "ApplyGuardrailRequest": {},
  "ApplyGuardrailResponse": {},
  "PatchGuardrailRequest": {},
  "VertexPassThroughCredentials": {},
  "EndpointType": {
    "VERTEX_AI": [],
    "ANTHROPIC": [],
    "OPENAI": [],
    "GENERIC": []
  },
  "PassthroughStandardLoggingPayload": {},
  "ASSEMBLY_AI_POLLING_INTERVAL": [],
  "ASSEMBLY_AI_MAX_POLLING_ATTEMPTS": [],
  "Annotation": {},
  "DocumentContent": {},
  "FunctionCallContent": {},
  "Language": {
    "python": []
  },
  "CodeExecutionCallArguments": {},
  "UrlContextCallArguments": {},
  "McpServerToolCallContent": {},
  "GoogleSearchCallArguments": {},
  "CodeExecutionResultContent": {},
  "Status": {
    "success": [],
    "error": [],
    "paywall": [],
    "unsafe": []
  },
  "UrlContextResult": {},
  "GoogleSearchResult": {},
  "FileSearchResult": {},
  "SpeechConfig": {},
  "DynamicAgentConfig": {},
  "CodeExecution": {},
  "UrlContext": {},
  "Environment": {
    "browser": []
  },
  "ComputerUse": {},
  "GoogleSearch": {},
  "FileSearch": {},
  "EventType": {
    "interaction_start": [],
    "interaction_complete": []
  },
  "Status1": {
    "in_progress": [],
    "requires_action": [],
    "completed": [],
    "failed": [],
    "cancelled": []
  },
  "InteractionStatusUpdate": {},
  "TextDelta": {},
  "DocumentDelta": {},
  "ThoughtSignatureDelta": {},
  "FunctionCallDelta": {},
  "CodeExecutionCallDelta": {},
  "UrlContextCallDelta": {},
  "GoogleSearchCallDelta": {},
  "McpServerToolCallDelta": {},
  "CodeExecutionResultDelta": {},
  "UrlContextResultDelta": {},
  "GoogleSearchResultDelta": {},
  "FileSearchResultDelta": {},
  "ContentStop": {},
  "Error": {},
  "MediaResolution": {
    "low": [],
    "medium": [],
    "high": []
  },
  "ToolChoiceType": {
    "auto": [],
    "any": [],
    "none": [],
    "validated": []
  },
  "ThinkingLevel": {
    "low": [],
    "high": []
  },
  "ThinkingSummaries": {
    "auto": [],
    "none": []
  },
  "ResponseModality": {
    "text": [],
    "image": [],
    "audio": []
  },
  "Status3": {
    "UNSPECIFIED": [],
    "IN_PROGRESS": [],
    "REQUIRES_ACTION": [],
    "COMPLETED": [],
    "FAILED": [],
    "CANCELLED": []
  },
  "ModelOption": {},
  "AgentOption": {},
  "ImageMimeTypeOption": {},
  "AudioMimeTypeOption": {},
  "VideoMimeTypeOption": {},
  "TextContent": {},
  "ImageContent": {},
  "AudioContent": {},
  "VideoContent": {},
  "ThoughtSummary1": {},
  "ThoughtSummary": {},
  "CodeExecutionCallContent": {},
  "UrlContextCallContent": {},
  "GoogleSearchCallContent": {},
  "Result": {},
  "FunctionResultContent": {},
  "UrlContextResultContent": {},
  "GoogleSearchResultContent": {},
  "McpServerToolResultContent": {},
  "FileSearchResultContent": {},
  "AllowedTools": {},
  "DeepResearchAgentConfig": {},
  "McpServer": {},
  "ModalityTokens": {},
  "ImageDelta": {},
  "AudioDelta": {},
  "VideoDelta": {},
  "ThoughtSummaryDelta": {},
  "FunctionResultDelta": {},
  "McpServerToolResultDelta": {},
  "ErrorEvent": {},
  "ToolChoiceConfig": {},
  "Tool": {},
  "ThoughtContent": {},
  "ToolChoice": {},
  "ContentDelta": {},
  "Content": {},
  "Turn": {},
  "GenerationConfig": {},
  "ContentStart": {},
  "Interaction": {},
  "CreateModelInteractionParams": {},
  "CreateAgentInteractionParams": {},
  "InteractionEvent": {},
  "InteractionSseEvent": {},
  "InteractionInput": [],
  "InteractionsAPIResponse": {},
  "InteractionsAPIStreamingResponse": {},
  "DeleteInteractionResult": {},
  "CancelInteractionResult": {},
  "InteractionTool": [],
  "InteractionToolChoiceConfig": [],
  "InteractionsAPIOptionalRequestParams": [],
  "GenericResponseOutputItemContentAnnotation": {},
  "OutputText": {},
  "OutputFunctionToolCall": {},
  "OutputImageGenerationCall": {},
  "GenericResponseOutputItem": {},
  "DeleteResponseResult": {},
  "DecodedResponseId": {},
  "VIDEO_ID_PREFIX": [],
  "encode_video_id_with_provider": [
    "video_id",
    "provider",
    "model_id"
  ],
  "decode_video_id_with_provider": [
    "encoded_video_id"
  ],
  "extract_original_video_id": [
    "encoded_video_id"
  ],
  "VideoObject": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "VideoResponse": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "VideoCreateOptionalRequestParams": {},
  "VideoCreateRequestParams": {},
  "DecodedVideoId": {},
  "UsagePerChunk": {},
  "SecretFields": {},
  "CloudZeroInitRequest": {},
  "CloudZeroInitResponse": {},
  "CloudZeroExportRequest": {},
  "CloudZeroExportResponse": {},
  "CloudZeroSettingsView": {},
  "CloudZeroSettingsUpdate": {},
  "ComplianceCheckResult": {},
  "ComplianceResponse": {},
  "ComplianceCheckRequest": {},
  "PluginAuthor": {},
  "PluginOwner": {},
  "RegisterPluginRequest": {},
  "PluginResponse": {},
  "RegisterPluginResponse": {},
  "PluginListItem": {},
  "ListPluginsResponse": {},
  "MarketplacePluginEntry": {},
  "MarketplaceResponse": {},
  "TestPromptRequest": {},
  "ReturnedUITokenObject": {},
  "ParsedOpenIDResult": {},
  "PublicModelHubInfo": {},
  "ProviderCredentialField": {},
  "ProviderCreateInfo": {},
  "AgentCredentialField": {},
  "AgentCreateInfo": {},
  "GroupByDimension": {
    "DATE": [],
    "MODEL": [],
    "API_KEY": [],
    "TEAM": [],
    "ORGANIZATION": [],
    "MODEL_GROUP": [],
    "PROVIDER": []
  },
  "SpendMetrics": {},
  "MetricBase": {},
  "KeyMetadata": {},
  "KeyMetricWithMetadata": {},
  "MetricWithMetadata": {},
  "BreakdownMetrics": {},
  "DailySpendData": {},
  "DailySpendMetadata": {},
  "SpendAnalyticsPaginatedResponse": {},
  "LiteLLM_DailyUserSpend": {},
  "GroupedData": {},
  "LiteLLM_UserScimMetadata": {},
  "SCIMResource": {},
  "SCIMUserName": {},
  "SCIMUserEmail": {},
  "SCIMUserGroup": {},
  "SCIMUser": {},
  "SCIMMember": {},
  "SCIMGroup": {},
  "SCIMListResponse": {},
  "SCIMPatchOperation": {
    "normalize_op": [
      "cls",
      "v"
    ]
  },
  "SCIMPatchOp": {},
  "SCIMFeature": {},
  "SCIMServiceProviderConfig": {},
  "SCIMSchemaExtension": {
    "model_config": [],
    "model_dump": [
      "self"
    ]
  },
  "SCIMResourceType": {
    "model_config": [],
    "model_dump": [
      "self"
    ]
  },
  "SCIMSchemaAttribute": {
    "model_dump": [
      "self"
    ]
  },
  "SCIMSchema": {},
  "ModelGroupInfoProxy": {},
  "UpdateUsefulLinksRequest": {},
  "NewModelGroupRequest": {},
  "NewModelGroupResponse": {},
  "UpdateModelGroupRequest": {},
  "DeleteModelGroupResponse": {},
  "AccessGroupInfo": {},
  "ListAccessGroupsResponse": {},
  "UserListResponse": {},
  "BulkUpdateUserRequest": {
    "validate_request": [
      "cls",
      "v",
      "info"
    ]
  },
  "UserUpdateResult": {},
  "BulkUpdateUserResponse": {},
  "GetTeamMemberPermissionsRequest": {},
  "GetTeamMemberPermissionsResponse": {},
  "UpdateTeamMemberPermissionsRequest": {},
  "TeamListResponse": {},
  "BulkTeamMemberAddRequest": {},
  "TeamMemberAddResult": {},
  "BulkTeamMemberAddResponse": {},
  "BulkUpdateKeyRequestItem": {},
  "BulkUpdateKeyRequest": {},
  "SuccessfulKeyUpdate": {},
  "FailedKeyUpdate": {},
  "BulkUpdateKeyResponse": {},
  "LiteLLM_UpperboundKeyGenerateParams": {},
  "MicrosoftGraphAPIUserGroupDirectoryObject": {},
  "MicrosoftGraphAPIUserGroupResponse": {},
  "MicrosoftServicePrincipalTeam": {},
  "AccessControl_UI_AccessMode": {},
  "RoleMappings": {},
  "TeamMappings": {},
  "SSOConfig": {},
  "DefaultTeamSSOParams": {},
  "InProductNudgeResponse": {},
  "UiDiscoveryEndpoints": {},
  "PolicyMatchContext": {
    "model_config": []
  },
  "ResolvedPolicy": {
    "model_config": []
  },
  "PolicyScopeResponse": {},
  "PolicyGuardrailsResponse": {},
  "PolicyInfoResponse": {},
  "PolicySummaryItem": {},
  "PolicyListResponse": {},
  "PolicyTestResponse": {},
  "PolicyConditionRequest": {},
  "PolicyCreateRequest": {},
  "PolicyUpdateRequest": {},
  "PolicyDBResponse": {},
  "PolicyListDBResponse": {},
  "PolicyAttachmentCreateRequest": {},
  "PolicyAttachmentDBResponse": {},
  "PolicyAttachmentListResponse": {},
  "PipelineTestRequest": {},
  "PolicyResolveRequest": {},
  "PolicyMatchDetail": {},
  "PolicyResolveResponse": {},
  "AttachmentImpactResponse": {},
  "PolicyCondition": {
    "model_config": []
  },
  "PolicyScope": {
    "model_config": [],
    "get_teams": [
      "self"
    ],
    "get_keys": [
      "self"
    ],
    "get_models": [
      "self"
    ],
    "get_tags": [
      "self"
    ]
  },
  "PolicyGuardrails": {
    "model_config": [],
    "get_add": [
      "self"
    ],
    "get_remove": [
      "self"
    ]
  },
  "Policy": {
    "model_config": []
  },
  "PolicyAttachment": {
    "model_config": [],
    "is_global": [
      "self"
    ],
    "to_policy_scope": [
      "self"
    ]
  },
  "PolicyConfig": {
    "model_config": []
  },
  "VALID_PIPELINE_ACTIONS": [],
  "VALID_PIPELINE_MODES": [],
  "PipelineStep": {
    "model_config": [],
    "validate_action": [
      "cls",
      "v"
    ]
  },
  "GuardrailPipeline": {
    "model_config": [],
    "validate_mode": [
      "cls",
      "v"
    ]
  },
  "PipelineStepResult": {},
  "PipelineExecutionResult": {},
  "PolicyValidationErrorType": {
    "INVALID_GUARDRAIL": [],
    "INVALID_TEAM": [],
    "INVALID_KEY": [],
    "INVALID_MODEL": [],
    "INVALID_INHERITANCE": [],
    "CIRCULAR_INHERITANCE": [],
    "INVALID_SCOPE": [],
    "INVALID_SYNTAX": []
  },
  "PolicyValidationError": {
    "model_config": []
  },
  "PolicyValidationResponse": {
    "model_config": []
  },
  "PolicyValidateRequest": {
    "model_config": []
  },
  "ToolPermissionRule": {
    "_blank_to_none": [
      "cls",
      "value"
    ],
    "normalize_decision": [
      "cls",
      "v"
    ],
    "_ensure_target_present": [
      "self"
    ]
  },
  "ToolResult": {},
  "PermissionError": {},
  "ToolPermissionGuardrailConfigModel": {
    "normalize_default_action": [
      "cls",
      "v"
    ],
    "normalize_on_disallowed_action": [
      "cls",
      "v"
    ],
    "ui_friendly_name": []
  },
  "PromptSecurityGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "AimGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "GraySwanGuardrailConfigModelOptionalParams": {},
  "GraySwanGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "PangeaGuardrailConfigModelOptionalParams": {},
  "PangeaGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "QualifireGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "AporiaGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "JavelinGuardInput": {},
  "JavelinGuardRequest": {},
  "JavelinPromptInjectionCategories": {},
  "JavelinPromptInjectionCategoryScores": {},
  "JavelinPromptInjectionResults": {},
  "JavelinPromptInjectionAssessment": {},
  "JavelinTrustSafetyCategories": {},
  "JavelinTrustSafetyCategoryScores": {},
  "JavelinTrustSafetyResults": {},
  "JavelinTrustSafetyAssessment": {},
  "JavelinLanguageDetectionResults": {},
  "JavelinLanguageDetectionAssessment": {},
  "JavelinGuardResponse": {},
  "LassoGuardrailConfigModelOptionalParams": {},
  "GuardrailsAIGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "BedrockTextContent": {},
  "BedrockContentItem": {},
  "BedrockRequest": {},
  "BedrockGuardrailUsage": {},
  "BedrockGuardrailOutput": {},
  "BedrockGuardrailTopicPolicyItem": {},
  "BedrockGuardrailTopicPolicy": {},
  "BedrockGuardrailContentPolicyFilter": {},
  "BedrockGuardrailContentPolicy": {},
  "BedrockGuardrailWordPolicyCustomWord": {},
  "BedrockGuardrailWordPolicyManagedWord": {},
  "BedrockGuardrailWordPolicy": {},
  "BedrockGuardrailPiiEntity": {},
  "BedrockGuardrailRegex": {},
  "BedrockGuardrailSensitiveInformationPolicy": {},
  "BedrockGuardrailContextualGroundingFilter": {},
  "BedrockGuardrailContextualGroundingPolicy": {},
  "BedrockGuardrailCoverage": {},
  "BedrockGuardrailInvocationMetrics": {},
  "BedrockGuardrailAssessment": {},
  "BedrockGuardrailResponse": {},
  "DynamoAIMessage": {},
  "DynamoRequestMetadata": {},
  "DynamoTextType": {
    "MODEL_INPUT": [],
    "MODEL_RESPONSE": []
  },
  "PolicyMethod": {
    "PII": [],
    "TOXICITY": [],
    "ALIGNMENT": [],
    "HALLUCINATION": [],
    "RAG_HALLUCINATION": []
  },
  "PolicyApplicableTo": {
    "INPUT": [],
    "OUTPUT": [],
    "ALL": []
  },
  "DynamoAIRequest": {},
  "PolicyInfo": {},
  "PolicyOutputs": {},
  "AppliedPolicyDto": {},
  "DynamoAIResponse": {},
  "DynamoAIProcessedResult": {},
  "DynamoAIGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "OnyxGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "ModelArmorGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "PanwPrismaAirsGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "LakeraAIRequest": {},
  "LakeraAIPayloadItem": {},
  "LakeraAIBreakdownItem": {},
  "LakeraAIDevInfo": {},
  "LakeraAIResponse": {},
  "PillarGuardrailConfigModelOptionalParams": {},
  "EnkryptAIPolicyViolationDetail": {},
  "EnkryptAIPIIDetail": {},
  "EnkryptAIToxicityDetail": {},
  "EnkryptAIKeywordDetail": {},
  "EnkryptAIBiasDetail": {},
  "EnkryptAIResponseSummary": {},
  "EnkryptAIResponseDetails": {},
  "EnkryptAIResponse": {},
  "EnkryptAIProcessedResult": {},
  "EnkryptAIGuardrailConfigs": {},
  "EnkryptAIGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "CompetitorIntentType": [],
  "CompetitorActionHint": [],
  "CompetitorIntentEvidenceEntry": {},
  "CompetitorIntentResult": {},
  "DetectionType": {
    "PATTERN": [],
    "BLOCKED_WORD": [],
    "CATEGORY_KEYWORD": []
  },
  "PatternDetection": {},
  "BlockedWordDetection": {},
  "CategoryKeywordDetection": {},
  "CompetitorIntentDetection": {},
  "ContentFilterDetection": [],
  "ContentFilterCategoryConfig": {},
  "LitellmContentFilterGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "HiddenlayerAction": {
    "BLOCK": [],
    "REDACT": []
  },
  "HiddenlayerMessages": {
    "BLOCK_MESSAGE": []
  },
  "HiddenlayerGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "PresidioAnalyzeRequest": {},
  "PresidioAnalyzeResponseItem": {},
  "GenericGuardrailAPIMetadata": {},
  "GenericGuardrailAPIOptionalParams": {},
  "GenericGuardrailAPIConfigModel": {
    "ui_friendly_name": []
  },
  "GenericGuardrailAPIRequest": {},
  "GenericGuardrailAPIResponse": {
    "__init__": [
      "self",
      "action",
      "texts",
      "blocked_reason",
      "images",
      "tools"
    ],
    "from_dict": [
      "cls",
      "data"
    ]
  },
  "T": [],
  "GuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "MCPEndUserPermissionGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "IBMDetectorRequestBodyDetectorServer": {},
  "IBMDetectorRequestBodyOrchestrator": {},
  "IBMDetectorDetection": {},
  "IBMDetectorResponseDetectorServer": {},
  "IBMDetectorResponseOrchestrator": {},
  "IBMDetectorOptionalParams": {},
  "IBMDetectorGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "IBMGuardrailsBaseConfigModel": {},
  "BaseOpenAIModerationGuardrailConfigModel": {},
  "OpenAIModerationGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "AzurePromptShieldGuardrailRequestBody": {},
  "UserPromptAnalysis": {},
  "AzurePromptShieldGuardrailResponse": {},
  "AzurePromptShieldGuardrailConfigModel": {
    "ui_friendly_name": []
  },
  "AZURE_CONTENT_SAFETY_CATEGORIES": [],
  "AzureTextModerationRequestBodyOptionalParams": {},
  "AzureTextModerationGuardrailRequestBody": {},
  "AzureTextModerationGuardrailResponseCategoriesAnalysis": {},
  "AzureTextModerationGuardrailResponse": {},
  "AzureHarmCategories": [],
  "AzureTextModerationOptionalParams": {},
  "AzureContentSafetyTextModerationConfigModel": {
    "ui_friendly_name": []
  },
  "AzureContentSafetyConfigModel": {},
  "ImageEditOptionalRequestParams": {},
  "ImageEditRequestParams": {},
  "CacheSettingsField": {},
  "FallbackCreateRequest": {
    "validate_fallback_models": [
      "cls",
      "v"
    ],
    "validate_model": [
      "cls",
      "v"
    ]
  },
  "FallbackResponse": {},
  "FallbackGetResponse": {},
  "FallbackDeleteResponse": {},
  "RouterSettingsField": {},
  "ExpiresAfter": {},
  "ContainerObject": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "DeleteContainerResult": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "ContainerListResponse": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "ContainerCreateOptionalRequestParams": {},
  "ContainerCreateRequestParams": {},
  "ContainerListOptionalRequestParams": {},
  "ContainerFileObject": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "ContainerFileListResponse": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "DeleteContainerFileResponse": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "LinkDict": {},
  "ImageDict": {},
  "PagerDutyPayload": {},
  "PagerDutyRequestBody": {},
  "PagerDutyInternalEvent": {},
  "ArgillaItem": {},
  "ArgillaPayload": {},
  "ArgillaCredentialsObject": {},
  "SUPPORTED_PAYLOAD_FIELDS": [],
  "DD_MAX_BATCH_SIZE": [],
  "DataDogStatus": {
    "INFO": [],
    "WARN": [],
    "ERROR": []
  },
  "DatadogPayload": [],
  "DD_ERRORS": {
    "DATADOG_413_ERROR": []
  },
  "DatadogInitParams": {},
  "DatadogProxyFailureHookJsonMessage": {},
  "WebSearchInterceptionConfig": {},
  "LangsmithInputs": {},
  "LangsmithCredentialsObject": {},
  "LangsmithQueueObject": {},
  "CredentialsKey": {},
  "BatchGroup": {},
  "StandardCustomLoggerInitParams": {},
  "GCS_DEFAULT_BATCH_SIZE": [],
  "GCS_DEFAULT_FLUSH_INTERVAL_SECONDS": [],
  "GCS_DEFAULT_USE_BATCHED_LOGGING": [],
  "GCSLoggingConfig": {},
  "GCSLogQueueItem": {},
  "DatadogCostManagementInitParams": {},
  "DatadogFOCUSCostEntry": {},
  "LangfuseOtelConfig": {},
  "LangfuseSpanAttributes": {
    "LANGFUSE_ENVIRONMENT": [],
    "GENERATION_NAME": [],
    "GENERATION_ID": [],
    "PARENT_OBSERVATION_ID": [],
    "GENERATION_VERSION": [],
    "MASK_INPUT": [],
    "MASK_OUTPUT": [],
    "OBSERVATION_INPUT": [],
    "OBSERVATION_OUTPUT": [],
    "TRACE_USER_ID": [],
    "SESSION_ID": [],
    "TAGS": [],
    "TRACE_NAME": [],
    "TRACE_ID": [],
    "TRACE_METADATA": [],
    "TRACE_VERSION": [],
    "TRACE_RELEASE": [],
    "EXISTING_TRACE_ID": [],
    "UPDATE_TRACE_KEYS": [],
    "DEBUG_LANGFUSE": []
  },
  "CacheControlMessageInjectionPoint": {},
  "CacheControlInjectionPoint": [],
  "LangfuseLoggingConfig": {},
  "LangfuseUsageDetails": {},
  "CBFRecord": {},
  "CBFRecordDict": [],
  "InputMeta": {},
  "OutputMeta": {},
  "DDLLMObsError": {},
  "Meta": {},
  "LLMMetrics": {},
  "LLMObsPayload": {},
  "DDSpanAttributes": {},
  "DDIntakePayload": {},
  "DatadogLLMObsInitParams": {},
  "DDLLMObsLatencyMetrics": {},
  "DDLLMObsSpendMetrics": {},
  "AzureSentinelInitParams": {},
  "POSTHOG_MAX_BATCH_SIZE": [],
  "PostHogEventPayload": {},
  "PostHogCredentialsObject": {},
  "_sanitize_prometheus_label_name": [
    "label"
  ],
  "_sanitize_prometheus_label_value": [
    "value"
  ],
  "MetricValidationError": {
    "message": [
      "self"
    ]
  },
  "LabelValidationError": {
    "message": [
      "self"
    ]
  },
  "ValidationResults": {
    "has_errors": [
      "self"
    ],
    "all_error_messages": [
      "self"
    ]
  },
  "REQUESTED_MODEL": [],
  "EXCEPTION_STATUS": [],
  "EXCEPTION_CLASS": [],
  "STATUS_CODE": [],
  "EXCEPTION_LABELS": [],
  "LATENCY_BUCKETS": [],
  "UserAPIKeyLabelNames": {
    "END_USER": [],
    "USER": [],
    "USER_EMAIL": [],
    "API_KEY_HASH": [],
    "API_KEY_ALIAS": [],
    "TEAM": [],
    "TEAM_ALIAS": [],
    "REQUESTED_MODEL": [],
    "v1_LITELLM_MODEL_NAME": [],
    "v2_LITELLM_MODEL_NAME": [],
    "TAG": [],
    "MODEL_ID": [],
    "API_BASE": [],
    "API_PROVIDER": [],
    "EXCEPTION_STATUS": [],
    "EXCEPTION_CLASS": [],
    "STATUS_CODE": [],
    "FALLBACK_MODEL": [],
    "ROUTE": [],
    "MODEL_GROUP": [],
    "CLIENT_IP": [],
    "USER_AGENT": [],
    "CALLBACK_NAME": []
  },
  "DEFINED_PROMETHEUS_METRICS": [],
  "PrometheusMetricLabels": {
    "litellm_llm_api_latency_metric": [],
    "litellm_llm_api_time_to_first_token_metric": [],
    "litellm_request_total_latency_metric": [],
    "litellm_request_queue_time_seconds": [],
    "litellm_proxy_total_requests_metric": [],
    "litellm_proxy_failed_requests_metric": [],
    "litellm_deployment_latency_per_output_token": [],
    "litellm_overhead_latency_metric": [],
    "litellm_remaining_requests_metric": [],
    "litellm_remaining_tokens_metric": [],
    "litellm_requests_metric": [],
    "litellm_spend_metric": [],
    "litellm_input_tokens_metric": [],
    "litellm_total_tokens_metric": [],
    "litellm_output_tokens_metric": [],
    "litellm_deployment_state": [],
    "litellm_deployment_tpm_limit": [],
    "litellm_deployment_rpm_limit": [],
    "litellm_deployment_cooled_down": [],
    "litellm_deployment_successful_fallbacks": [],
    "litellm_deployment_failed_fallbacks": [],
    "litellm_remaining_team_budget_metric": [],
    "litellm_team_max_budget_metric": [],
    "litellm_team_budget_remaining_hours_metric": [],
    "litellm_remaining_api_key_budget_metric": [],
    "litellm_api_key_max_budget_metric": [],
    "litellm_api_key_budget_remaining_hours_metric": [],
    "litellm_remaining_user_budget_metric": [],
    "litellm_user_max_budget_metric": [],
    "litellm_user_budget_remaining_hours_metric": [],
    "litellm_remaining_api_key_requests_for_model": [],
    "litellm_remaining_api_key_tokens_for_model": [],
    "litellm_callback_logging_failures_metric": [],
    "litellm_deployment_failure_responses": [],
    "litellm_deployment_total_requests": [],
    "litellm_deployment_success_responses": [],
    "litellm_llm_api_failed_requests_metric": [],
    "_cache_metric_labels": [],
    "litellm_cache_hits_metric": [],
    "litellm_cache_misses_metric": [],
    "litellm_cached_tokens_metric": [],
    "get_labels": [
      "label_name"
    ]
  },
  "UserAPIKeyLabelValues": {},
  "PrometheusMetricsConfig": {},
  "PrometheusSettings": {},
  "NoOpMetric": {
    "__init__": [
      "self"
    ],
    "labels": [
      "self"
    ],
    "inc": [
      "self"
    ],
    "set": [
      "self"
    ],
    "observe": [
      "self"
    ]
  },
  "ArizeConfig": {},
  "s3BatchLoggingElement": {},
  "ArizePhoenixConfig": {},
  "SLACK_ALERTING_THRESHOLD_5_PERCENT": [],
  "SLACK_ALERTING_THRESHOLD_15_PERCENT": [],
  "MAX_OLDEST_HANGING_REQUESTS_TO_CHECK": [],
  "HANGING_ALERT_BUFFER_TIME_SECONDS": [],
  "BaseOutageModel": {},
  "OutageModel": {},
  "ProviderRegionOutageModel": {},
  "LITELLM_LOGO_URL": [],
  "LITELLM_SUPPORT_CONTACT": [],
  "SlackAlertingArgsEnum": {
    "daily_report_frequency": [],
    "report_check_interval": [],
    "budget_alert_ttl": [],
    "outage_alert_ttl": [],
    "region_outage_alert_ttl": [],
    "minor_outage_alert_threshold": [],
    "major_outage_alert_threshold": [],
    "max_outage_alert_list_size": []
  },
  "SlackAlertingArgs": {},
  "DeploymentMetrics": {},
  "SlackAlertingCacheKeys": {
    "failed_requests_key": [],
    "latency_key": [],
    "report_sent_key": []
  },
  "AlertType": {
    "llm_exceptions": [],
    "llm_too_slow": [],
    "llm_requests_hanging": [],
    "budget_alerts": [],
    "spend_reports": [],
    "failed_tracking_spend": [],
    "db_exceptions": [],
    "daily_reports": [],
    "cooldown_deployment": [],
    "new_model_added": [],
    "outage_alerts": [],
    "region_outage_alerts": [],
    "fallback_reports": [],
    "new_virtual_key_created": [],
    "virtual_key_updated": [],
    "virtual_key_deleted": [],
    "new_team_created": [],
    "team_updated": [],
    "team_deleted": [],
    "new_internal_user_created": [],
    "internal_user_updated": [],
    "internal_user_deleted": []
  },
  "HangingRequestData": {},
  "WeaveOtelConfig": {},
  "WeaveSpanAttributes": {
    "DISPLAY_NAME": [],
    "THREAD_ID": [],
    "IS_TURN": []
  },
  "IntegrationHealthCheckStatus": {},
  "BedrockKBLocation": {},
  "BedrockKBRowValue": {},
  "BedrockKBContent": {},
  "BedrockKBRetrievalResult": {},
  "BedrockKBResponse": {},
  "BedrockKBMetadataAttribute": {},
  "BedrockKBImplicitFilterConfiguration": {},
  "BedrockKBSelectiveModeConfiguration": {},
  "BedrockKBMetadataConfiguration": {},
  "BedrockKBModelConfiguration": {},
  "BedrockKBRerankingConfiguration": {},
  "BedrockKBVectorSearchConfiguration": {},
  "BedrockKBRetrievalConfiguration": {},
  "BedrockKBRetrievalQuery": {},
  "BedrockKBGuardrailConfiguration": {},
  "BedrockKBRequest": {},
  "SupportedPromptIntegrations": {
    "DOT_PROMPT": [],
    "LANGFUSE": [],
    "CUSTOM": [],
    "BITBUCKET": [],
    "GITLAB": [],
    "GENERIC_PROMPT_MANAGEMENT": [],
    "ARIZE_PHOENIX": []
  },
  "PromptInfo": {
    "model_config": []
  },
  "PromptLiteLLMParams": {
    "model_config": []
  },
  "PromptSpec": {
    "__init__": [
      "self"
    ]
  },
  "PromptTemplateBase": {},
  "PromptInfoResponse": {},
  "ListPromptsResponse": {},
  "MCPTool": {},
  "ToolSchema": {},
  "ListToolsResponse": {},
  "CallToolRequest": {},
  "ContentItem": {},
  "MCPInfo": [],
  "MCPOAuthMetadata": {},
  "MCPServer": {
    "model_config": [],
    "has_client_credentials": [
      "self"
    ],
    "needs_user_oauth_token": [
      "self"
    ]
  },
  "CallObject": {},
  "ToolResultObject": {},
  "ChatHistoryToolResult": {},
  "ToolCallObject": {},
  "ChatHistoryUser": {},
  "ChatHistorySystem": {},
  "ChatHistoryChatBot": {},
  "ChatHistory": [],
  "CohereV2ChatResponseMessageToolCallFunction": {},
  "CohereV2ChatResponseMessageToolCall": {},
  "CohereV2ChatResponseMessageContent": {},
  "CohereV2ChatResponseMessage": {},
  "CohereV2ChatResponseUsageBilledUnits": {},
  "CohereV2ChatResponseUsageTokens": {},
  "CohereV2ChatResponseUsage": {},
  "CohereV2ChatResponseLogProbs": {},
  "CohereV2ChatResponse": {},
  "CustomLLMItem": {},
  "httpxSpecialProvider": {
    "LoggingCallback": [],
    "GuardrailCallback": [],
    "Caching": [],
    "Oauth2Check": [],
    "Oauth2Register": [],
    "SecretManager": [],
    "PassThroughEndpoint": [],
    "PromptFactory": [],
    "SSO_HANDLER": [],
    "Search": [],
    "MCP": [],
    "RAG": [],
    "A2A": [],
    "PromptManagement": [],
    "UI": []
  },
  "VerifyTypes": [],
  "DataSourceConfigCustom": {},
  "DataSourceConfigLogs": {},
  "DataSourceConfigStoredCompletions": {},
  "DataSourceConfig": [],
  "LLMAsJudgeGraderConfig": {},
  "GroundTruthGraderConfig": {},
  "CustomGraderConfig": {},
  "GraderConfig": [],
  "CreateEvalRequest": {},
  "UpdateEvalRequest": {},
  "ListEvalsParams": {},
  "Eval": {},
  "ListEvalsResponse": {},
  "DeleteEvalResponse": {},
  "CancelEvalResponse": {},
  "DataSourceDatasetConfig": {},
  "DataSourceSampleSetConfig": {},
  "DataSourceInlineConfig": {},
  "RunDataSourceConfig": [],
  "CompletionConfig": {},
  "CreateRunRequest": {},
  "ListRunsParams": {},
  "ResultCounts": {},
  "PerTestingCriteriaResult": {},
  "Run": {},
  "ListRunsResponse": {},
  "CancelRunResponse": {},
  "RunDeleteResponse": {},
  "VertexTextToSpeechInput": {},
  "VertexTextToSpeechVoice": {},
  "VertexTextToSpeechAudioConfig": {},
  "VertexTextToSpeechRequest": {},
  "XAIWebSearchFilters": {},
  "XAIWebSearchTool": {},
  "XAIXSearchTool": {},
  "API_VERSION_YEAR_SUPPORTED_RESPONSE_FORMAT": [],
  "API_VERSION_MONTH_SUPPORTED_RESPONSE_FORMAT": [],
  "FileContent": [],
  "FileTypes": [],
  "EmbeddingInput": [],
  "HttpxBinaryResponseContent": {},
  "NotGiven": {
    "__bool__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "NOT_GIVEN": [],
  "ToolResourcesCodeInterpreter": {},
  "ToolResourcesFileSearchVectorStore": {},
  "ToolResourcesFileSearch": {},
  "OpenAICreateThreadParamsToolResources": {},
  "FileSearchToolParam": {},
  "CodeInterpreterToolParam": {},
  "AttachmentTool": [],
  "Attachment": {},
  "ImageFileObject": {},
  "ImageURLObject": {},
  "ImageURLListItem": {},
  "MessageContentTextObject": {},
  "MessageContentImageFileObject": {},
  "MessageContentImageURLObject": {},
  "MessageData": {},
  "Thread": {},
  "OpenAICreateFileRequestOptionalParams": [],
  "OpenAIFilesPurpose": [],
  "OpenAIFileObject": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "CREATE_FILE_REQUESTS_PURPOSE": [],
  "FileExpiresAfter": {},
  "CreateFileRequest": {},
  "FileContentRequest": {},
  "CreateBatchRequest": {},
  "LiteLLMBatchCreateRequest": {},
  "RetrieveBatchRequest": {},
  "CancelBatchRequest": {},
  "ListBatchRequest": {},
  "OpenAIErrorBody": {},
  "BatchJobStatus": [],
  "ChatCompletionAudioDelta": {},
  "ChatCompletionToolCallFunctionChunk": {},
  "ChatCompletionAssistantToolCall": {},
  "ChatCompletionToolCallChunk": {},
  "ChatCompletionDeltaToolCallChunk": {},
  "ChatCompletionCachedContent": {},
  "ChatCompletionThinkingBlock": {},
  "ChatCompletionRedactedThinkingBlock": {},
  "WebSearchOptionsUserLocationApproximate": {},
  "WebSearchOptionsUserLocation": {},
  "WebSearchOptions": {},
  "FileSearchTool": {},
  "ChatCompletionAnnotationURLCitation": {},
  "ChatCompletionAnnotation": {},
  "OpenAIChatCompletionTextObject": {},
  "ChatCompletionTextObject": {},
  "ChatCompletionImageUrlObject": {},
  "ChatCompletionImageObject": {},
  "ChatCompletionVideoUrlObject": {},
  "ChatCompletionVideoObject": {},
  "ChatCompletionAudioObject": {},
  "DocumentObject": {},
  "CitationsObject": {},
  "ChatCompletionDocumentObject": {},
  "ChatCompletionFileObjectFile": {},
  "ChatCompletionFileObject": {},
  "OpenAIMessageContentListBlock": [],
  "OpenAIMessageContent": [],
  "AllPromptValues": [],
  "OpenAIChatCompletionUserMessage": {},
  "OpenAITextCompletionUserMessage": {},
  "ChatCompletionUserMessage": {},
  "OpenAIChatCompletionAssistantMessage": {},
  "ChatCompletionAssistantMessage": {},
  "ChatCompletionToolMessage": {},
  "ChatCompletionFunctionMessage": {},
  "OpenAIChatCompletionSystemMessage": {},
  "OpenAIChatCompletionDeveloperMessage": {},
  "ChatCompletionSystemMessage": {},
  "ChatCompletionDeveloperMessage": {},
  "GenericChatCompletionMessage": {},
  "ValidUserMessageContentTypes": [],
  "ValidUserMessageContentTypesLiteral": [],
  "ValidAssistantMessageContentTypesLiteral": [],
  "ValidAssistantMessageContentTypes": [],
  "ValidChatCompletionMessageContentTypesLiteral": [],
  "ValidChatCompletionMessageContentTypes": [],
  "AllMessageValues": [],
  "ChatCompletionToolChoiceFunctionParam": {},
  "ChatCompletionToolChoiceObjectParam": {},
  "ChatCompletionToolChoiceStringValues": [],
  "ChatCompletionToolChoiceValues": [],
  "ChatCompletionToolParamFunctionChunk": {},
  "OpenAIChatCompletionToolParam": {},
  "ChatCompletionToolParam": {},
  "ChatCompletionNamedToolChoiceParam": {},
  "ChatCompletionRequest": {},
  "ChatCompletionDeltaChunk": {},
  "ChatCompletionAssistantContentValue": [],
  "ChatCompletionResponseMessage": {},
  "ChatCompletionUsageBlock": {},
  "OpenAIChatCompletionChunk": {
    "__init__": [
      "self"
    ]
  },
  "Hyperparameters": {},
  "FineTuningJobCreate": {},
  "LiteLLMFineTuningJobCreate": {
    "model_config": []
  },
  "AllEmbeddingInputValues": [],
  "OpenAIAudioTranscriptionOptionalParams": [],
  "OpenAIImageVariationOptionalParams": [],
  "OpenAIImageGenerationOptionalParams": [],
  "OpenAIImageEditOptionalParams": [],
  "ComputerToolParam": {},
  "ShellToolParam": {},
  "ALL_RESPONSES_API_TOOL_PARAMS": [],
  "PromptObject": {},
  "ContextManagementEntry": {},
  "ResponsesAPIOptionalRequestParams": {},
  "ResponsesAPIRequestParams": {},
  "OutputTokensDetails": {
    "model_config": []
  },
  "InputTokensDetails": {
    "model_config": []
  },
  "ResponseAPIUsage": {
    "model_config": []
  },
  "ResponsesAPIStatus": [],
  "ResponsesAPIResponse": {
    "validate_reasoning_to_dict": [
      "cls",
      "value"
    ],
    "validate_usage": [
      "cls",
      "value"
    ],
    "output_text": [
      "self"
    ]
  },
  "ResponsesAPIStreamEvents": {
    "RESPONSE_CREATED": [],
    "RESPONSE_IN_PROGRESS": [],
    "RESPONSE_COMPLETED": [],
    "RESPONSE_FAILED": [],
    "RESPONSE_INCOMPLETE": [],
    "RESPONSE_PART_ADDED": [],
    "REASONING_SUMMARY_TEXT_DELTA": [],
    "REASONING_SUMMARY_TEXT_DONE": [],
    "REASONING_SUMMARY_PART_DONE": [],
    "OUTPUT_ITEM_ADDED": [],
    "OUTPUT_ITEM_DONE": [],
    "CONTENT_PART_ADDED": [],
    "CONTENT_PART_DONE": [],
    "OUTPUT_TEXT_DELTA": [],
    "OUTPUT_TEXT_ANNOTATION_ADDED": [],
    "OUTPUT_TEXT_DONE": [],
    "REFUSAL_DELTA": [],
    "REFUSAL_DONE": [],
    "FUNCTION_CALL_ARGUMENTS_DELTA": [],
    "FUNCTION_CALL_ARGUMENTS_DONE": [],
    "FILE_SEARCH_CALL_IN_PROGRESS": [],
    "FILE_SEARCH_CALL_SEARCHING": [],
    "FILE_SEARCH_CALL_COMPLETED": [],
    "WEB_SEARCH_CALL_IN_PROGRESS": [],
    "WEB_SEARCH_CALL_SEARCHING": [],
    "WEB_SEARCH_CALL_COMPLETED": [],
    "MCP_LIST_TOOLS_IN_PROGRESS": [],
    "MCP_LIST_TOOLS_COMPLETED": [],
    "MCP_LIST_TOOLS_FAILED": [],
    "MCP_CALL_IN_PROGRESS": [],
    "MCP_CALL_ARGUMENTS_DELTA": [],
    "MCP_CALL_ARGUMENTS_DONE": [],
    "MCP_CALL_COMPLETED": [],
    "MCP_CALL_FAILED": [],
    "IMAGE_GENERATION_PARTIAL_IMAGE": [],
    "SHELL_CALL_IN_PROGRESS": [],
    "SHELL_CALL_COMPLETED": [],
    "SHELL_CALL_OUTPUT": [],
    "ERROR": []
  },
  "ResponseCreatedEvent": {},
  "ResponseInProgressEvent": {},
  "ResponseCompletedEvent": {},
  "ResponseFailedEvent": {},
  "ResponseIncompleteEvent": {},
  "ResponsePartAddedEvent": {},
  "ReasoningSummaryTextDeltaEvent": {},
  "ReasoningSummaryTextDoneEvent": {},
  "ReasoningSummaryPartDoneEvent": {},
  "OutputItemAddedEvent": {},
  "OutputItemDoneEvent": {},
  "OpenAIChatCompletionLogprobsContentTopLogprobs": {},
  "OpenAIChatCompletionLogprobsContent": {},
  "ContentPartAddedEvent": {},
  "ContentPartDonePartOutputText": {},
  "ContentPartDonePartRefusal": {},
  "ContentPartDonePartReasoningText": {},
  "PART_UNION_TYPES": [],
  "ContentPartDoneEvent": {},
  "OutputTextDeltaEvent": {},
  "OutputTextAnnotationAddedEvent": {},
  "OutputTextDoneEvent": {},
  "RefusalDeltaEvent": {},
  "RefusalDoneEvent": {},
  "FunctionCallArgumentsDeltaEvent": {},
  "FunctionCallArgumentsDoneEvent": {},
  "FileSearchCallInProgressEvent": {},
  "FileSearchCallSearchingEvent": {},
  "FileSearchCallCompletedEvent": {},
  "WebSearchCallInProgressEvent": {},
  "WebSearchCallSearchingEvent": {},
  "WebSearchCallCompletedEvent": {},
  "MCPListToolsInProgressEvent": {},
  "MCPListToolsCompletedEvent": {},
  "MCPListToolsFailedEvent": {},
  "MCPCallInProgressEvent": {},
  "MCPCallArgumentsDeltaEvent": {},
  "MCPCallArgumentsDoneEvent": {},
  "MCPCallCompletedEvent": {},
  "MCPCallFailedEvent": {},
  "ImageGenerationPartialImageEvent": {},
  "ErrorEventError": {},
  "GenericEvent": {
    "model_config": []
  },
  "ResponsesAPIStreamingResponse": [],
  "REASONING_EFFORT": [],
  "OpenAIRealtimeStreamSession": {},
  "OpenAIRealtimeStreamSessionEvents": {},
  "OpenAIRealtimeStreamResponseOutputItemContent": {},
  "OpenAIRealtimeStreamResponseOutputItem": {},
  "OpenAIRealtimeStreamResponseOutputItemAdded": {},
  "OpenAIRealtimeStreamResponseBaseObject": {},
  "OpenAIRealtimeConversationObject": {},
  "OpenAIRealtimeConversationCreated": {},
  "OpenAIRealtimeConversationItemCreated": {},
  "OpenAIRealtimeResponseContentPart": {},
  "OpenAIRealtimeResponseContentPartAdded": {},
  "OpenAIRealtimeResponseDelta": {},
  "OpenAIRealtimeResponseTextDone": {},
  "OpenAIRealtimeResponseAudioDone": {},
  "OpenAIRealtimeContentPartDone": {},
  "OpenAIRealtimeOutputItemDone": {},
  "OpenAIRealtimeResponseDoneObject": {},
  "OpenAIRealtimeDoneEvent": {},
  "OpenAIRealtimeEventTypes": {
    "SESSION_CREATED": [],
    "RESPONSE_TEXT_DELTA": [],
    "RESPONSE_AUDIO_DELTA": [],
    "RESPONSE_TEXT_DONE": [],
    "RESPONSE_AUDIO_DONE": [],
    "RESPONSE_DONE": [],
    "RESPONSE_OUTPUT_ITEM_ADDED": [],
    "RESPONSE_CONTENT_PART_ADDED": []
  },
  "OpenAIRealtimeEvents": [],
  "OpenAIRealtimeStreamList": [],
  "ImageGenerationRequestQuality": {
    "LOW": [],
    "MEDIUM": [],
    "HIGH": [],
    "AUTO": [],
    "STANDARD": [],
    "HD": []
  },
  "OpenAIModerationResult": {},
  "OpenAIModerationResponse": {},
  "OpenAIChatCompletionLogprobs": {},
  "OpenAIChatCompletionChoices": {},
  "OpenAIChatCompletionResponse": {},
  "OpenAIBatchResponse": {},
  "OpenAIBatchResult": {},
  "OpenAIChatCompletionFinishReason": [],
  "OpenAIWebSearchUserLocationApproximate": {},
  "OpenAIWebSearchUserLocation": {},
  "OpenAIWebSearchOptions": {},
  "OpenAIRealtimeTurnDetection": {},
  "OpenAIMcpServerTool": {},
  "CreateVideoRequest": {},
  "OpenAIVideoObject": {
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "json": [
      "self"
    ]
  },
  "TOOL_SEARCH_BETA_HEADER_ANTHROPIC": [],
  "TOOL_SEARCH_BETA_HEADER_VERTEX": [],
  "TOOL_SEARCH_BETA_HEADER_BEDROCK": [],
  "get_tool_search_beta_header": [
    "custom_llm_provider"
  ],
  "WatsonXAPIParams": {},
  "WatsonXCredentials": {},
  "WatsonXAudioTranscriptionRequestBody": {},
  "WatsonXAIEndpoint": {
    "TEXT_GENERATION": [],
    "TEXT_GENERATION_STREAM": [],
    "CHAT": [],
    "CHAT_STREAM": [],
    "DEPLOYMENT_TEXT_GENERATION": [],
    "DEPLOYMENT_TEXT_GENERATION_STREAM": [],
    "DEPLOYMENT_CHAT": [],
    "DEPLOYMENT_CHAT_STREAM": [],
    "EMBEDDINGS": [],
    "PROMPTS": [],
    "AVAILABLE_MODELS": [],
    "RERANK": []
  },
  "WatsonXModelPattern": {
    "GRANITE_CHAT": [],
    "IBM_MISTRAL": [],
    "IBM_MISTRALAI": [],
    "GPT_OSS": [],
    "LLAMA3_INSTRUCT": []
  },
  "GeminiFilesState": {
    "STATE_UNSPECIFIED": [],
    "PROCESSING": [],
    "ACTIVE": [],
    "FAILED": []
  },
  "GeminiFilesSource": {
    "SOURCE_UNSPECIFIED": [],
    "UPLOADED": [],
    "GENERATED": []
  },
  "GeminiCreateFilesResponseObject": {},
  "BidiGenerateContentTranscription": {},
  "BidiGenerateContentServerContent": {},
  "BidiGenerateContentServerMessage": {},
  "BidiGenerateContentRealtimeInput": {},
  "StartOfSpeechSensitivityEnum": [],
  "EndOfSpeechSensitivityEnum": [],
  "AutomaticActivityDetection": {},
  "BidiGenerateContentRealtimeInputConfig": {},
  "BidiGenerateContentSetup": {},
  "GeminiImageGenerationInstance": {},
  "GeminiImageGenerationParameters": {},
  "GeminiImageGenerationRequest": {},
  "GeminiGeneratedImage": {},
  "GeminiImageGenerationPrediction": {},
  "GeminiImageGenerationResponse": {},
  "GeminiVideoGenerationInstance": {},
  "GeminiVideoGenerationParameters": {},
  "GeminiVideoGenerationRequest": {},
  "GeminiVideoUri": {},
  "GeminiGeneratedVideoSample": {},
  "GeminiGenerateVideoResponse": {},
  "GeminiOperationResponse": {},
  "GeminiOperationMetadata": {},
  "GeminiLongRunningOperationResponse": {},
  "ImageEmbeddingInput": {},
  "EncodingFormat": [],
  "ImageEmbeddingRequest": {},
  "OllamaToolCallFunction": {},
  "OllamaToolCall": {},
  "OllamaVisionModelObject": {},
  "OllamaChatCompletionMessage": {},
  "CachePointBlock": {},
  "SystemContentBlock": {},
  "SourceBlock": {},
  "BedrockImageTypes": [],
  "ImageBlock": {},
  "BedrockVideoTypes": [],
  "VideoBlock": {},
  "BedrockDocumentTypes": [],
  "DocumentBlock": {},
  "ToolResultContentBlock": {},
  "ToolResultBlock": {},
  "ToolUseBlock": {},
  "BedrockConverseReasoningTextBlock": {},
  "BedrockConverseReasoningContentBlock": {},
  "BedrockConverseReasoningContentBlockDelta": {},
  "GuardrailConverseTextBlock": {},
  "GuardrailConverseContentBlock": {},
  "CitationWebLocationBlock": {},
  "CitationLocationBlock": {},
  "CitationReferenceBlock": {},
  "CitationsContentBlock": {},
  "ContentBlock": {},
  "MessageBlock": {},
  "ConverseMetricsBlock": {},
  "ConverseResponseOutputBlock": {},
  "ConverseTokenUsageBlock": {},
  "ServiceTierBlock": {},
  "ConverseResponseBlock": {},
  "ToolJsonSchemaBlock": {},
  "ToolInputSchemaBlock": {},
  "ToolSpecBlock": {},
  "SystemToolBlock": {},
  "ToolBlock": {},
  "SpecificToolChoiceBlock": {},
  "ToolChoiceValuesBlock": {},
  "ToolConfigBlock": {},
  "GuardrailConfigBlock": {},
  "InferenceConfig": {},
  "ToolBlockDeltaEvent": {},
  "ToolUseBlockStartEvent": {},
  "ContentBlockStartEvent": {},
  "ContentBlockDeltaEvent": {},
  "PerformanceConfigBlock": {},
  "JsonSchemaDefinition": {},
  "OutputFormatStructure": {},
  "OutputFormat": {},
  "OutputConfigBlock": {},
  "CommonRequestObject": {},
  "RequestObject": {},
  "BedrockInvokeNovaRequest": {},
  "Document": {},
  "ServerSentEvent": {
    "__init__": [
      "self"
    ],
    "event": [
      "self"
    ],
    "id": [
      "self"
    ],
    "retry": [
      "self"
    ],
    "data": [
      "self"
    ],
    "json": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "COHERE_EMBEDDING_INPUT_TYPES": [],
  "CohereEmbeddingRequest": {},
  "CohereEmbeddingRequestWithModel": {},
  "CohereEmbeddingResponse": {},
  "AmazonTitanV2EmbeddingRequest": {},
  "AmazonTitanV2EmbeddingsByType": {},
  "AmazonTitanV2EmbeddingResponse": {},
  "AmazonTitanG1EmbeddingRequest": {},
  "AmazonTitanG1EmbeddingResponse": {},
  "AmazonTitanMultimodalEmbeddingConfig": {},
  "AmazonTitanMultimodalEmbeddingRequest": {},
  "AmazonTitanMultimodalEmbeddingResponse": {},
  "TWELVELABS_EMBEDDING_INPUT_TYPES": [],
  "TWELVELABS_EMBEDDING_OPTIONS": [],
  "TwelveLabsS3Location": {},
  "TwelveLabsMediaSource": {},
  "TwelveLabsMarengoEmbeddingRequest": {},
  "TwelveLabsMarengoEmbeddingResponse": {},
  "TwelveLabsS3OutputDataConfig": {},
  "TwelveLabsOutputDataConfig": {},
  "TwelveLabsAsyncInvokeRequest": {},
  "TwelveLabsAsyncInvokeStatusResponse": {},
  "NOVA_EMBEDDING_PURPOSES": [],
  "NOVA_EMBEDDING_DIMENSIONS": [],
  "NOVA_TRUNCATION_MODES": [],
  "NOVA_DETAIL_LEVELS": [],
  "NOVA_EMBEDDING_MODES": [],
  "NOVA_EMBEDDING_TYPES": [],
  "NovaSourceS3Location": {},
  "NovaSourceObject": {},
  "NovaTextParams": {},
  "NovaImageParams": {},
  "NovaVideoParams": {},
  "NovaAudioParams": {},
  "NovaTextSegmentationConfig": {},
  "NovaMediaSegmentationConfig": {},
  "NovaTextParamsWithSegmentation": {},
  "NovaVideoParamsWithSegmentation": {},
  "NovaAudioParamsWithSegmentation": {},
  "NovaSingleEmbeddingParams": {},
  "NovaSegmentedEmbeddingParams": {},
  "NovaEmbeddingRequest": {},
  "NovaEmbeddingItem": {},
  "NovaEmbeddingResponse": {},
  "NovaS3OutputDataConfig": {},
  "NovaOutputDataConfig": {},
  "NovaAsyncInvokeRequest": {},
  "AmazonEmbeddingRequest": [],
  "AmazonStability3TextToImageRequest": {},
  "AmazonStability3TextToImageResponse": {},
  "AmazonTitanTextToImageParams": {},
  "AmazonNovaCanvasRequestBase": {},
  "AmazonNovaCanvasImageGenerationConfig": {},
  "AmazonNovaCanvasTextToImageParams": {},
  "AmazonNovaCanvasTextToImageRequest": {},
  "AmazonNovaCanvasColorGuidedGenerationParams": {},
  "AmazonNovaCanvasColorGuidedRequest": {},
  "AmazonNovaCanvasTextToImageResponse": {},
  "AmazonNovaCanvasInpaintingParams": {},
  "AmazonNovaCanvasInpaintingRequest": {},
  "AmazonTitanImageGenerationRequestBody": {},
  "BedrockPreparedRequest": {},
  "BedrockRerankTextQuery": {},
  "BedrockRerankQuery": {},
  "BedrockRerankModelConfiguration": {},
  "BedrockRerankBedrockRerankingConfiguration": {},
  "BedrockRerankConfiguration": {},
  "BedrockRerankTextDocument": {},
  "BedrockRerankInlineDocumentSource": {},
  "BedrockRerankSource": {},
  "BedrockRerankRequest": {},
  "AmazonDeepSeekR1StreamingResponse": {},
  "BedrockS3InputDataConfig": {},
  "BedrockInputDataConfig": {},
  "BedrockS3OutputDataConfig": {},
  "BedrockOutputDataConfig": {},
  "BedrockCreateBatchRequest": {},
  "BedrockBatchJobStatus": [],
  "BedrockCreateBatchResponse": {},
  "BedrockGetBatchResponse": {},
  "BedrockToolBlock": {},
  "AgentCoreRequestPayload": {},
  "AgentCoreRequest": {},
  "AgentCoreMessageRole": {},
  "AgentCoreMessageStart": {},
  "AgentCoreContentBlockDelta": {},
  "AgentCoreContentBlockDeltaEvent": {},
  "AgentCoreContentBlockStop": {},
  "AgentCoreMessageStop": {},
  "AgentCoreUsage": {},
  "AgentCoreMetrics": {},
  "AgentCoreMetadata": {},
  "AgentCoreEventPayload": {},
  "AgentCoreEvent": {},
  "AgentCoreContentBlock": {},
  "AgentCoreMessage": {},
  "AgentCoreFinalMessage": {},
  "AgentCoreParsedResponse": {},
  "OpenRouterErrorMessage": {},
  "MistralToolCallMessage": {},
  "MistralTextBlock": {},
  "MistralThinkingBlock": {},
  "InfinityRerankResult": {},
  "FunctionResponse": {},
  "FileDataType": {},
  "BlobType": {},
  "PartType": {},
  "HttpxFunctionCall": {},
  "HttpxExecutableCode": {},
  "HttpxCodeExecutionResult": {},
  "HttpxBlobType": {},
  "HttpxPartType": {},
  "HttpxContentType": {},
  "ContentType": {},
  "SystemInstructions": {},
  "Schema": {},
  "FunctionDeclaration": {},
  "VertexAISearch": {},
  "Retrieval": {},
  "FunctionCallingConfig": {},
  "HarmCategory": [],
  "HarmBlockThreshold": [],
  "HarmBlockMethod": [],
  "HarmProbability": [],
  "HarmSeverity": [],
  "SafetSettingsConfig": {},
  "GeminiThinkingConfig": {},
  "GeminiResponseModalities": [],
  "GeminiImageAspectRatio": [],
  "GeminiImageSize": [],
  "GeminiImageConfig": {},
  "PrebuiltVoiceConfig": {},
  "VoiceConfig": {},
  "VertexToolName": {
    "GOOGLE_SEARCH": [],
    "GOOGLE_SEARCH_RETRIEVAL": [],
    "ENTERPRISE_WEB_SEARCH": [],
    "URL_CONTEXT": [],
    "CODE_EXECUTION": [],
    "GOOGLE_MAPS": [],
    "COMPUTER_USE": []
  },
  "Tools": {},
  "ToolConfig": {},
  "TTL": {},
  "PromptTokensDetails": {},
  "UsageMetadata": {},
  "TokenCountDetailsResponse": {},
  "CachedContent": {},
  "RequestBody": {},
  "CachedContentRequestBody": {},
  "CachedContentListAllResponseBody": {},
  "SafetyRatings": {},
  "Date": {},
  "Citation": {},
  "CitationMetadata": {},
  "SearchEntryPoint": {},
  "GroundingMetadata": {},
  "LogprobsCandidate": {},
  "LogprobsTopCandidate": {},
  "LogprobsResult": {},
  "UrlMetadata": {},
  "UrlContextMetadata": {},
  "Candidates": {},
  "PromptFeedback": {},
  "GenerateContentResponseBody": {},
  "FineTuneHyperparameters": {},
  "FineTunesupervisedTuningSpec": {},
  "FineTuneJobCreate": {},
  "ResponseSupervisedTuningSpec": {},
  "ResponseTuningJob": {},
  "VideoSegmentConfig": {},
  "InstanceVideo": {},
  "InstanceImage": {},
  "Instance": {},
  "VertexMultimodalEmbeddingRequest": {},
  "VideoEmbedding": {},
  "MultimodalPrediction": {},
  "MultimodalPredictions": {},
  "VertexAICachedContentResponseObject": {},
  "TaskTypeEnum": {
    "TASK_TYPE_UNSPECIFIED": [],
    "RETRIEVAL_QUERY": [],
    "RETRIEVAL_DOCUMENT": [],
    "SEMANTIC_SIMILARITY": [],
    "CLASSIFICATION": [],
    "CLUSTERING": [],
    "QUESTION_ANSWERING": [],
    "FACT_VERIFICATION": []
  },
  "VertexAITextEmbeddingsRequestBody": {},
  "ContentEmbeddings": {},
  "VertexAITextEmbeddingsResponseObject": {},
  "EmbedContentRequest": {},
  "VertexAIBatchEmbeddingsRequestBody": {},
  "VertexAIBatchEmbeddingsResponseObject": {},
  "GcsSource": {},
  "InputConfig": {},
  "GcsDestination": {},
  "OutputConfig": {},
  "OutputInfo": {},
  "GcsBucketResponse": {},
  "VertexAIBatchPredictionJob": {},
  "VertexBatchPredictionResponse": {},
  "VertexVideoImage": {},
  "VertexVideoGenerationInstance": {},
  "VertexVideoGenerationParameters": {},
  "VertexVideoGenerationRequest": {},
  "VertexVideoOutput": {},
  "VertexVideoGenerationResponse": {},
  "VERTEX_CREDENTIALS_TYPES": [],
  "VertexPartnerProvider": {
    "mistralai": [],
    "llama": [],
    "ai21": [],
    "claude": []
  },
  "DatabricksTextContent": {},
  "DatabricksReasoningSummary": {},
  "DatabricksReasoningContent": {},
  "AllDatabricksContentListValues": [],
  "AllDatabricksContentValues": [],
  "DatabricksFunction": {},
  "DatabricksTool": {},
  "DatabricksMessage": {},
  "DatabricksChoice": {},
  "DatabricksResponse": {},
  "StabilityImageGenerationRequest": {},
  "StabilityImageEditRequest": {},
  "StabilityImageGenerationResponse": {},
  "StabilityUpscaleRequest": {},
  "StabilityInpaintRequest": {},
  "StabilityOutpaintRequest": {},
  "StabilityEraseRequest": {},
  "StabilitySearchReplaceRequest": {},
  "StabilityRemoveBackgroundRequest": {},
  "StabilityControlRequest": {},
  "StabilityEditResponse": {},
  "OPENAI_SIZE_TO_STABILITY_ASPECT_RATIO": [],
  "STABILITY_ASPECT_RATIOS": [],
  "STABILITY_GENERATION_MODELS": [],
  "STABILITY_EDIT_ENDPOINTS": [],
  "LangGraphMessage": {},
  "LangGraphInput": {},
  "LangGraphRequest": {},
  "LangGraphStreamEvent": {},
  "LangGraphResponseMessage": {},
  "LangGraphResponse": {},
  "LangGraphParsedResponse": {},
  "RecraftImageGenerationRequestParams": {},
  "RecraftImageEditRequestParams": {},
  "AnthropicMessagesToolChoice": {},
  "AnthropicInputSchema": [],
  "AnthropicOutputSchema": {},
  "AnthropicOutputConfig": {},
  "AnthropicMessagesTool": {},
  "AnthropicComputerTool": {},
  "AnthropicWebSearchUserLocation": {},
  "AnthropicWebSearchTool": {},
  "AnthropicHostedTools": {},
  "AnthropicCodeExecutionTool": {},
  "AnthropicMemoryTool": {},
  "AnthropicToolSearchToolRegex": {},
  "AnthropicToolSearchToolBM25": {},
  "ToolReference": {},
  "DirectToolCaller": {},
  "CodeExecutionToolCaller": {},
  "ToolCaller": [],
  "AnthropicContainer": {},
  "AllAnthropicToolsValues": [],
  "AnthropicMcpServerToolConfiguration": {},
  "AnthropicMcpServerTool": {},
  "AnthropicMessagesTextParam": {},
  "AnthropicMessagesToolUseParam": {},
  "AnthropicMessagesAssistantMessageValues": [],
  "AnthopicMessagesAssistantMessageParam": {},
  "AnthropicContentParamSource": {},
  "AnthropicContentParamSourceUrl": {},
  "AnthropicContentParamSourceFileId": {},
  "AnthropicMessagesContainerUploadParam": {},
  "AnthropicMessagesImageParam": {},
  "AnthropicCitationPageLocation": {},
  "AnthropicCitationCharLocation": {},
  "AnthropicCitation": [],
  "AnthropicMessagesDocumentParam": {},
  "AnthropicMessagesToolResultContent": {},
  "AnthropicMessagesToolResultParam": {},
  "AnthropicMessagesUserMessageValues": [],
  "AnthropicMessagesUserMessageParam": {},
  "AnthropicMetadata": {},
  "AnthropicSystemMessageContent": {},
  "AllAnthropicMessageValues": [],
  "AnthropicMessagesRequestOptionalParams": {},
  "AnthropicMessagesRequest": {},
  "ContentTextBlockDelta": {},
  "ContentCitationsBlockDelta": {},
  "ContentJsonBlockDelta": {},
  "ContentThinkingBlockDelta": {},
  "ContentThinkingSignatureBlockDelta": {},
  "ContentBlockDelta": {},
  "ContentBlockStop": {},
  "TextBlock": {},
  "ContentBlockStartToolUse": {},
  "ContentBlockStartText": {},
  "ContentBlockContentBlockDict": [],
  "ContentBlockStart": [],
  "MessageDelta": {},
  "UsageDelta": {},
  "MessageBlockDelta": {},
  "MessageChunk": {},
  "MessageStartBlock": {},
  "AnthropicResponseContentBlockText": {},
  "AnthropicResponseContentBlockToolUse": {
    "model_config": []
  },
  "AnthropicResponseContentBlockThinking": {},
  "AnthropicResponseContentBlockRedactedThinking": {},
  "AnthropicResponseUsageBlock": {},
  "AnthropicFinishReason": [],
  "AnthropicResponse": {},
  "AnthropicChatCompletionUsageBlock": {},
  "ANTHROPIC_API_HEADERS": [],
  "ANTHROPIC_API_ONLY_HEADERS": [],
  "AnthropicThinkingParam": {},
  "ANTHROPIC_HOSTED_TOOLS": {
    "WEB_SEARCH": [],
    "BASH": [],
    "TEXT_EDITOR": [],
    "CODE_EXECUTION": [],
    "WEB_FETCH": [],
    "MEMORY": []
  },
  "ANTHROPIC_BETA_HEADER_VALUES": {
    "WEB_FETCH_2025_09_10": [],
    "WEB_SEARCH_2025_03_05": [],
    "CONTEXT_MANAGEMENT_2025_06_27": [],
    "COMPACT_2026_01_12": [],
    "STRUCTURED_OUTPUT_2025_09_25": [],
    "ADVANCED_TOOL_USE_2025_11_20": [],
    "FAST_MODE_2026_02_01": []
  },
  "ANTHROPIC_TOOL_SEARCH_BETA_HEADER": [],
  "ANTHROPIC_EFFORT_BETA_HEADER": [],
  "ANTHROPIC_OAUTH_TOKEN_PREFIX": [],
  "ANTHROPIC_OAUTH_BETA_HEADER": [],
  "ANTHROPIC_PROMPT_CACHING_SCOPE_BETA_HEADER": [],
  "OCIRoles": [],
  "OCIVendors": {
    "COHERE": [],
    "GEMINI": [],
    "GENERIC": []
  },
  "OCIContentPart": {},
  "OCITextContentPart": {},
  "OCIImageUrl": {},
  "OCIImageContentPart": {},
  "OCIContentPartUnion": [],
  "OCIToolCall": {},
  "OCIToolDefinition": {},
  "OCIMessage": {},
  "OCIChatRequestPayload": {},
  "OCIServingMode": {},
  "OCICompletionPayload": {},
  "OCICompletionTokenDetails": {},
  "OCIPromptTokensDetails": {},
  "OCIResponseUsage": {},
  "OCIResponseChoice": {},
  "OCIChatResponse": {},
  "OCICompletionResponse": {},
  "OCIStreamDelta": {},
  "OCIStreamChunk": {},
  "CohereStreamChunk": {},
  "CohereMessage": {},
  "CohereUserMessage": {},
  "CohereChatBotMessage": {},
  "CohereSystemMessage": {},
  "CohereToolMessage": {},
  "CohereParameterDefinition": {},
  "CohereTool": {},
  "CohereToolCall": {},
  "CohereToolResult": {},
  "CohereResponseFormat": {},
  "CohereResponseTextFormat": {},
  "CohereResponseJSONSchemaFormat": {},
  "CohereChatRequest": {},
  "CohereUsage": {},
  "CohereCitation": {},
  "CohereSearchQuery": {},
  "CohereChatResponse": {},
  "CohereChatDetails": {},
  "CohereChatResult": {},
  "AimlImageSize": {},
  "AimlImageGenerationRequestParams": {},
  "CreateSkillRequest": {},
  "ListSkillsParams": {},
  "Skill": {},
  "ListSkillsResponse": {},
  "DeleteSkillResponse": {},
  "CreateSkillVersionRequest": {},
  "SkillVersion": {},
  "ListSkillVersionsResponse": {},
  "DeleteSkillVersionResponse": {},
  "InvokeAgentEventHeaders": {},
  "InvokeAgentUsage": {},
  "InvokeAgentMetadata": {},
  "InvokeAgentModelInvocationInput": {},
  "InvokeAgentModelInvocationOutput": {},
  "InvokeAgentOrchestrationTrace": {},
  "InvokeAgentPreProcessingTrace": {},
  "InvokeAgentTrace": {},
  "InvokeAgentCallerChain": {},
  "InvokeAgentTracePayload": {},
  "InvokeAgentChunkPayload": {},
  "InvokeAgentEventPayload": {},
  "InvokeAgentEvent": {},
  "InvokeAgentEventList": [],
  "InvokeAgentTraceEvent": [],
  "InvokeAgentChunkEvent": [],
  "LiteLLMPydanticObjectBase": {
    "json": [
      "self"
    ],
    "fields_set": [
      "self"
    ],
    "model_config": []
  },
  "BaseLiteLLMOpenAIResponseObject": {
    "model_config": [],
    "__getitem__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "items": [
      "self"
    ]
  },
  "HiddenParams": {
    "model_config": [],
    "get": [
      "self",
      "key",
      "default"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "json": [
      "self"
    ],
    "model_dump": [
      "self"
    ]
  },
  "AnthropicResponseTextBlock": {},
  "AnthropicResponseToolUseBlock": {},
  "AnthropicResponseThinkingBlock": {},
  "AnthropicResponseRedactedThinkingBlock": {},
  "AnthropicUsage": {},
  "AnthropicMessagesResponse": {},
  "AzureCredentialType": {
    "ClientSecretCredential": [],
    "ManagedIdentityCredential": [],
    "CertificateCredential": [],
    "DefaultAzureCredential": []
  },
  "KeyManagementSystem": {
    "GOOGLE_KMS": [],
    "AZURE_KEY_VAULT": [],
    "AWS_SECRET_MANAGER": [],
    "GOOGLE_SECRET_MANAGER": [],
    "HASHICORP_VAULT": [],
    "CYBERARK": [],
    "LOCAL": [],
    "AWS_KMS": [],
    "CUSTOM": []
  },
  "KeyManagementSettings": {},
  "INTERACTIONS_API_OPTIONAL_PARAMS": [],
  "get_provider_interactions_api_config": [
    "provider",
    "model"
  ],
  "InteractionsAPIRequestUtils": {
    "get_requested_interactions_api_optional_params": [
      "params"
    ]
  },
  "BaseInteractionsAPIStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "interactions_api_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider"
    ],
    "_process_chunk": [
      "self",
      "chunk"
    ],
    "_handle_logging_completed_response": [
      "self"
    ]
  },
  "InteractionsAPIStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "interactions_api_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "_handle_logging_completed_response": [
      "self"
    ]
  },
  "SyncInteractionsAPIStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "interactions_api_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_handle_logging_completed_response": [
      "self"
    ]
  },
  "create": [
    "model",
    "agent",
    "input",
    "tools",
    "system_instruction",
    "generation_config",
    "stream",
    "store",
    "background",
    "response_modalities",
    "response_format",
    "response_mime_type",
    "previous_interaction_id",
    "extra_headers",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "aget": [
    "interaction_id",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "get": [
    "interaction_id",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "adelete": [
    "interaction_id",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "delete": [
    "interaction_id",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "acancel": [
    "interaction_id",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "cancel": [
    "interaction_id",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "InteractionsHTTPHandler": {
    "_handle_error": [
      "self",
      "e",
      "provider_config"
    ],
    "create_interaction": [
      "self",
      "interactions_api_config",
      "optional_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "model",
      "agent",
      "input",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "stream"
    ],
    "async_create_interaction": [
      "self",
      "interactions_api_config",
      "optional_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "model",
      "agent",
      "input",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "stream"
    ],
    "_create_sync_streaming_iterator": [
      "self",
      "response",
      "model",
      "logging_obj",
      "interactions_api_config"
    ],
    "_create_async_streaming_iterator": [
      "self",
      "response",
      "model",
      "logging_obj",
      "interactions_api_config"
    ],
    "get_interaction": [
      "self",
      "interaction_id",
      "interactions_api_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async"
    ],
    "async_get_interaction": [
      "self",
      "interaction_id",
      "interactions_api_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client"
    ],
    "delete_interaction": [
      "self",
      "interaction_id",
      "interactions_api_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async"
    ],
    "async_delete_interaction": [
      "self",
      "interaction_id",
      "interactions_api_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client"
    ],
    "cancel_interaction": [
      "self",
      "interaction_id",
      "interactions_api_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async"
    ],
    "async_cancel_interaction": [
      "self",
      "interaction_id",
      "interactions_api_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client"
    ]
  },
  "interactions_http_handler": [],
  "LiteLLMResponsesInteractionsConfig": {
    "transform_interactions_request_to_responses_request": [
      "model",
      "input",
      "optional_params"
    ],
    "_transform_interactions_input_to_responses_input": [
      "input"
    ],
    "_transform_content_array": [
      "content"
    ],
    "transform_responses_response_to_interactions_response": [
      "responses_response",
      "model"
    ]
  },
  "LiteLLMResponsesInteractionsStreamingIterator": {
    "__init__": [
      "self",
      "model",
      "litellm_custom_stream_wrapper",
      "request_input",
      "optional_params",
      "custom_llm_provider",
      "litellm_metadata"
    ],
    "_transform_responses_chunk_to_interactions_chunk": [
      "self",
      "responses_chunk"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "LiteLLMResponsesInteractionsHandler": {
    "interactions_api_handler": [
      "self",
      "model",
      "input",
      "optional_params",
      "custom_llm_provider",
      "_is_async",
      "stream"
    ],
    "async_interactions_api_handler": [
      "self",
      "responses_request",
      "model",
      "input",
      "optional_params"
    ]
  },
  "SpeechToCompletionBridgeTransformationHandler": {
    "transform_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers",
      "litellm_logging_obj",
      "custom_llm_provider"
    ],
    "_convert_pcm16_to_wav": [
      "self",
      "pcm_data",
      "sample_rate",
      "channels"
    ],
    "_is_gemini_tts_model": [
      "self",
      "model"
    ],
    "transform_response": [
      "self",
      "model_response"
    ]
  },
  "SpeechToCompletionBridgeHandlerInputKwargs": {},
  "SpeechToCompletionBridgeHandler": {
    "__init__": [
      "self"
    ],
    "validate_input_kwargs": [
      "self",
      "kwargs"
    ],
    "speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers",
      "logging_obj",
      "custom_llm_provider"
    ]
  },
  "speech_to_completion_bridge_handler": [],
  "get_optional_params_add_message": [
    "role",
    "content",
    "attachments",
    "metadata",
    "custom_llm_provider"
  ],
  "openai_assistants_api": [],
  "azure_assistants_api": [],
  "aget_assistants": [
    "custom_llm_provider",
    "client"
  ],
  "get_assistants": [
    "custom_llm_provider",
    "client",
    "api_key",
    "api_base",
    "api_version"
  ],
  "acreate_assistants": [
    "custom_llm_provider",
    "client"
  ],
  "create_assistants": [
    "custom_llm_provider",
    "model",
    "name",
    "description",
    "instructions",
    "tools",
    "tool_resources",
    "metadata",
    "temperature",
    "top_p",
    "response_format",
    "client",
    "api_key",
    "api_base",
    "api_version"
  ],
  "adelete_assistant": [
    "custom_llm_provider",
    "client"
  ],
  "delete_assistant": [
    "custom_llm_provider",
    "assistant_id",
    "client",
    "api_key",
    "api_base",
    "api_version"
  ],
  "acreate_thread": [
    "custom_llm_provider"
  ],
  "create_thread": [
    "custom_llm_provider",
    "messages",
    "metadata",
    "tool_resources",
    "client"
  ],
  "aget_thread": [
    "custom_llm_provider",
    "thread_id",
    "client"
  ],
  "get_thread": [
    "custom_llm_provider",
    "thread_id",
    "client"
  ],
  "a_add_message": [
    "custom_llm_provider",
    "thread_id",
    "role",
    "content",
    "attachments",
    "metadata",
    "client"
  ],
  "add_message": [
    "custom_llm_provider",
    "thread_id",
    "role",
    "content",
    "attachments",
    "metadata",
    "client"
  ],
  "aget_messages": [
    "custom_llm_provider",
    "thread_id",
    "client"
  ],
  "get_messages": [
    "custom_llm_provider",
    "thread_id",
    "client"
  ],
  "arun_thread_stream": [],
  "arun_thread": [
    "custom_llm_provider",
    "thread_id",
    "assistant_id",
    "additional_instructions",
    "instructions",
    "metadata",
    "model",
    "stream",
    "tools",
    "client"
  ],
  "run_thread_stream": [],
  "run_thread": [
    "custom_llm_provider",
    "thread_id",
    "assistant_id",
    "additional_instructions",
    "instructions",
    "metadata",
    "model",
    "stream",
    "tools",
    "client",
    "event_handler"
  ],
  "get_optional_rerank_params": [
    "rerank_provider_config",
    "model",
    "drop_params",
    "query",
    "documents",
    "custom_llm_provider",
    "top_n",
    "rank_fields",
    "return_documents",
    "max_chunks_per_doc",
    "max_tokens_per_doc",
    "non_default_params"
  ],
  "together_rerank": [],
  "bedrock_rerank": [],
  "arerank": [
    "model",
    "query",
    "documents",
    "custom_llm_provider",
    "top_n",
    "rank_fields",
    "return_documents",
    "max_chunks_per_doc"
  ],
  "rerank": [
    "model",
    "query",
    "documents",
    "custom_llm_provider",
    "top_n",
    "rank_fields",
    "return_documents",
    "max_chunks_per_doc",
    "max_tokens_per_doc"
  ],
  "ResponsesAPIRequestUtils": {
    "_check_valid_arg": [
      "supported_params",
      "non_default_params",
      "drop_params",
      "custom_llm_provider",
      "model"
    ],
    "get_optional_params_responses_api": [
      "model",
      "responses_api_provider_config",
      "response_api_optional_params",
      "allowed_openai_params"
    ],
    "get_requested_response_api_optional_param": [
      "params"
    ],
    "_update_responses_api_response_id_with_model_id": [
      "responses_api_response",
      "custom_llm_provider",
      "litellm_metadata"
    ],
    "_build_responses_api_response_id": [
      "custom_llm_provider",
      "model_id",
      "response_id"
    ],
    "_decode_responses_api_response_id": [
      "response_id"
    ],
    "get_model_id_from_response_id": [
      "response_id"
    ],
    "decode_previous_response_id_to_original_previous_response_id": [
      "previous_response_id"
    ],
    "convert_text_format_to_text_param": [
      "text_format",
      "text"
    ],
    "extract_mcp_headers_from_request": [
      "secret_fields",
      "tools"
    ]
  },
  "ResponseAPILoggingUtils": {
    "_is_response_api_usage": [
      "usage"
    ],
    "_transform_response_api_usage_to_chat_usage": [
      "usage_input"
    ]
  },
  "BaseResponsesAPIStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "responses_api_provider_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider",
      "request_data",
      "call_type"
    ],
    "_process_chunk": [
      "self",
      "chunk"
    ],
    "_handle_logging_completed_response": [
      "self"
    ],
    "_call_post_streaming_deployment_hook": [
      "self",
      "chunk"
    ],
    "call_post_streaming_hooks_for_testing": [
      "self",
      "chunk"
    ],
    "_run_post_success_hooks": [
      "self",
      "end_time"
    ],
    "_handle_failure": [
      "self",
      "exception"
    ]
  },
  "call_post_streaming_hooks_for_testing": [
    "iterator",
    "chunk"
  ],
  "ResponsesAPIStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "responses_api_provider_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider",
      "request_data",
      "call_type"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "_handle_logging_completed_response": [
      "self"
    ]
  },
  "SyncResponsesAPIStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "responses_api_provider_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider",
      "request_data",
      "call_type"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_handle_logging_completed_response": [
      "self"
    ]
  },
  "MockResponsesAPIStreamingIterator": {
    "CHUNK_SIZE": [],
    "__init__": [
      "self",
      "response",
      "model",
      "responses_api_provider_config",
      "logging_obj",
      "litellm_metadata",
      "custom_llm_provider",
      "request_data",
      "call_type"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_collect_text": [
      "self",
      "resp"
    ]
  },
  "litellm_completion_transformation_handler": [],
  "mock_responses_api_response": [
    "mock_response"
  ],
  "aresponses_api_with_mcp": [
    "input",
    "model",
    "include",
    "instructions",
    "max_output_tokens",
    "prompt",
    "metadata",
    "parallel_tool_calls",
    "previous_response_id",
    "reasoning",
    "store",
    "background",
    "stream",
    "temperature",
    "text",
    "tool_choice",
    "tools",
    "top_p",
    "truncation",
    "user",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "aresponses": [
    "input",
    "model",
    "include",
    "instructions",
    "max_output_tokens",
    "prompt",
    "metadata",
    "parallel_tool_calls",
    "previous_response_id",
    "reasoning",
    "store",
    "background",
    "stream",
    "temperature",
    "text",
    "text_format",
    "tool_choice",
    "tools",
    "top_p",
    "truncation",
    "user",
    "service_tier",
    "safety_identifier",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "responses": [
    "input",
    "model",
    "include",
    "instructions",
    "max_output_tokens",
    "prompt",
    "metadata",
    "parallel_tool_calls",
    "previous_response_id",
    "reasoning",
    "store",
    "background",
    "stream",
    "temperature",
    "text",
    "text_format",
    "tool_choice",
    "tools",
    "top_p",
    "truncation",
    "user",
    "service_tier",
    "safety_identifier",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "allowed_openai_params",
    "custom_llm_provider"
  ],
  "adelete_responses": [
    "response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "delete_responses": [
    "response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "aget_responses": [
    "response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "get_responses": [
    "response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "alist_input_items": [
    "response_id",
    "after",
    "before",
    "include",
    "limit",
    "order",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "list_input_items": [
    "response_id",
    "after",
    "before",
    "include",
    "limit",
    "order",
    "extra_headers",
    "timeout",
    "custom_llm_provider"
  ],
  "acancel_responses": [
    "response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "cancel_responses": [
    "response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "acompact_responses": [
    "input",
    "model",
    "instructions",
    "previous_response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "compact_responses": [
    "input",
    "model",
    "instructions",
    "previous_response_id",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "create_mcp_list_tools_events": [
    "mcp_tools_with_litellm_proxy",
    "user_api_key_auth",
    "base_item_id",
    "pre_processed_mcp_tools"
  ],
  "create_mcp_call_events": [
    "tool_name",
    "tool_call_id",
    "arguments",
    "result",
    "base_item_id",
    "sequence_start"
  ],
  "MCPEnhancedStreamingIterator": {
    "__init__": [
      "self",
      "base_iterator",
      "mcp_events",
      "tool_server_map",
      "mcp_tools_with_litellm_proxy",
      "user_api_key_auth",
      "original_request_params"
    ],
    "_extract_mcp_headers_from_params": [
      "self"
    ],
    "_should_auto_execute_tools": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "_is_response_completed": [
      "self",
      "chunk"
    ],
    "_create_initial_response_iterator": [
      "self"
    ],
    "_generate_tool_execution_events": [
      "self"
    ],
    "_create_follow_up_iterator": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "ToolParam": [],
  "LITELLM_PROXY_MCP_SERVER_URL": [],
  "LITELLM_PROXY_MCP_SERVER_URL_PREFIX": [],
  "LiteLLM_Proxy_MCP_Handler": {
    "_should_use_litellm_mcp_gateway": [
      "tools"
    ],
    "_parse_mcp_tools": [
      "tools"
    ],
    "_get_mcp_tools_from_manager": [
      "user_api_key_auth",
      "mcp_tools_with_litellm_proxy",
      "litellm_trace_id"
    ],
    "_deduplicate_mcp_tools": [
      "mcp_tools",
      "allowed_mcp_servers"
    ],
    "_filter_mcp_tools_by_allowed_tools": [
      "mcp_tools",
      "mcp_tools_with_litellm_proxy"
    ],
    "_process_mcp_tools_to_openai_format": [
      "user_api_key_auth",
      "mcp_tools_with_litellm_proxy",
      "litellm_trace_id"
    ],
    "_process_mcp_tools_without_openai_transform": [
      "user_api_key_auth",
      "mcp_tools_with_litellm_proxy",
      "litellm_trace_id"
    ],
    "_transform_mcp_tools_to_openai": [
      "mcp_tools",
      "target_format"
    ],
    "_should_auto_execute_tools": [
      "mcp_tools_with_litellm_proxy"
    ],
    "_extract_tool_calls_from_response": [
      "response"
    ],
    "_extract_tool_calls_from_chat_response": [
      "response"
    ],
    "_extract_tool_call_details": [
      "tool_call"
    ],
    "_parse_tool_arguments": [
      "tool_arguments"
    ],
    "_parse_mcp_result": [
      "result"
    ],
    "_execute_tool_calls": [
      "tool_server_map",
      "tool_calls",
      "user_api_key_auth",
      "mcp_auth_header",
      "mcp_server_auth_headers",
      "oauth2_headers",
      "raw_headers",
      "litellm_call_id",
      "litellm_trace_id"
    ],
    "_create_follow_up_messages_for_chat": [
      "original_messages",
      "response",
      "tool_results"
    ],
    "_create_follow_up_input": [
      "response",
      "tool_results",
      "original_input"
    ],
    "_make_follow_up_call": [
      "follow_up_input",
      "model",
      "all_tools",
      "response_id"
    ],
    "_log_mcp_tool_failure": [],
    "_create_mcp_streaming_response": [
      "input",
      "model",
      "all_tools",
      "mcp_tools_with_litellm_proxy",
      "mcp_discovery_events",
      "call_params",
      "previous_response_id",
      "tool_server_map"
    ],
    "_build_request_params": [
      "input",
      "model",
      "all_tools",
      "call_params",
      "previous_response_id"
    ],
    "_create_tool_execution_events": [
      "tool_calls",
      "tool_results"
    ],
    "_prepare_initial_call_params": [
      "call_params",
      "should_auto_execute"
    ],
    "_prepare_follow_up_call_params": [
      "call_params",
      "original_stream_setting"
    ],
    "_add_mcp_output_elements_to_response": [
      "response",
      "mcp_tools_fetched",
      "tool_results"
    ]
  },
  "_add_mcp_metadata_to_response": [
    "response",
    "openai_tools",
    "tool_calls",
    "tool_results"
  ],
  "acompletion_with_mcp": [
    "model",
    "messages",
    "tools"
  ],
  "TOOL_CALLS_CACHE": [],
  "ChatCompletionSession": {},
  "LiteLLMCompletionResponsesConfig": {
    "get_supported_openai_params": [
      "model"
    ],
    "_transform_tool_choice": [
      "tool_choice"
    ],
    "transform_responses_api_request_to_chat_completion_request": [
      "model",
      "input",
      "responses_api_request",
      "custom_llm_provider",
      "stream",
      "extra_headers"
    ],
    "transform_responses_api_input_to_messages": [
      "input",
      "responses_api_request"
    ],
    "async_responses_api_session_handler": [
      "previous_response_id",
      "litellm_completion_request"
    ],
    "_transform_response_input_param_to_chat_completion_message": [
      "input"
    ],
    "_deduplicate_tool_call_output_messages": [
      "tool_call_output_messages",
      "existing_tool_call_ids"
    ],
    "_ensure_tool_call_output_has_corresponding_tool_call": [
      "messages"
    ],
    "_find_previous_assistant_idx": [
      "messages",
      "current_idx"
    ],
    "_recover_tool_call_id_from_assistant": [
      "assistant_message",
      "message"
    ],
    "_get_tool_calls_list": [
      "assistant_message"
    ],
    "_check_tool_call_exists": [
      "tool_calls",
      "tool_call_id"
    ],
    "_reconstruct_tool_call_from_tools": [
      "tool_call_id",
      "tools"
    ],
    "_get_mapping_or_attr_value": [
      "obj",
      "key",
      "default"
    ],
    "_create_tool_call_chunk": [
      "tool_use_definition",
      "tool_call_id",
      "index"
    ],
    "_normalize_tool_use_definition": [
      "tool_use_definition",
      "tool_call_id"
    ],
    "_add_tool_call_to_assistant": [
      "assistant_message",
      "tool_call_chunk"
    ],
    "_ensure_tool_results_have_corresponding_tool_calls": [
      "messages",
      "tools"
    ],
    "_transform_responses_api_input_item_to_chat_completion_message": [
      "input_item"
    ],
    "_is_input_item_tool_call_output": [
      "input_item"
    ],
    "_is_input_item_function_call": [
      "input_item"
    ],
    "_transform_responses_api_tool_call_output_to_chat_completion_message": [
      "tool_call_output"
    ],
    "_transform_responses_api_function_call_to_chat_completion_message": [
      "function_call"
    ],
    "_transform_input_file_item_to_file_item": [
      "item"
    ],
    "_transform_input_image_item_to_image_item": [
      "item"
    ],
    "_transform_responses_api_content_to_chat_completion_content": [
      "content"
    ],
    "_get_chat_completion_request_content_type": [
      "content_type"
    ],
    "transform_instructions_to_system_message": [
      "instructions"
    ],
    "transform_responses_api_tools_to_chat_completion_tools": [
      "tools"
    ],
    "transform_chat_completion_tool_params_to_responses_api_tools": [
      "chat_completion_tools"
    ],
    "transform_chat_completion_tools_to_responses_tools": [
      "chat_completion_response"
    ],
    "_map_chat_completion_finish_reason_to_responses_status": [
      "finish_reason"
    ],
    "convert_response_function_tool_call_to_chat_completion_tool_call": [
      "tool_call_item",
      "index"
    ],
    "transform_chat_completion_response_to_responses_api_response": [
      "request_input",
      "responses_api_request",
      "chat_completion_response"
    ],
    "_transform_chat_completion_choices_to_responses_output": [
      "chat_completion_response",
      "choices"
    ],
    "_extract_reasoning_output_items": [
      "chat_completion_response",
      "choices"
    ],
    "_extract_image_generation_output_items": [
      "chat_completion_response",
      "choice"
    ],
    "_map_finish_reason_to_image_generation_status": [
      "finish_reason"
    ],
    "_extract_base64_from_data_url": [
      "data_url"
    ],
    "_extract_message_output_items": [
      "chat_completion_response",
      "choices"
    ],
    "_transform_responses_api_outputs_to_chat_completion_messages": [
      "responses_api_output"
    ],
    "_transform_responses_output_tool_call_to_chat_completion_output_tool_call": [
      "tool_call"
    ],
    "_transform_chat_message_to_response_output_text": [
      "message"
    ],
    "_transform_chat_completion_annotations_to_response_output_annotations": [
      "annotations"
    ],
    "_transform_chat_completion_usage_to_responses_usage": [
      "chat_completion_response"
    ],
    "_transform_text_format_to_response_format": [
      "text_param"
    ]
  },
  "LiteLLMCompletionStreamingIterator": {
    "__init__": [
      "self",
      "model",
      "litellm_custom_stream_wrapper",
      "request_input",
      "responses_api_request",
      "custom_llm_provider",
      "litellm_metadata"
    ],
    "_get_or_assign_tool_output_index": [
      "self",
      "call_id"
    ],
    "_normalize_tool_call_index": [
      "self",
      "tool_call"
    ],
    "_is_reasoning_end": [
      "self",
      "chunk"
    ],
    "_queue_tool_call_delta_events": [
      "self",
      "tool_calls"
    ],
    "_queue_final_tool_call_done_events": [
      "self",
      "litellm_complete_object"
    ],
    "_default_response_created_event_data": [
      "self"
    ],
    "create_response_created_event": [
      "self"
    ],
    "create_response_in_progress_event": [
      "self"
    ],
    "create_output_item_added_event": [
      "self"
    ],
    "create_content_part_added_event": [
      "self"
    ],
    "create_litellm_model_response": [
      "self"
    ],
    "_snapshot_chunk_for_stream_chunk_builder": [
      "chunk"
    ],
    "create_reasoning_summary_text_done_event": [
      "self",
      "reasoning_item_id",
      "reasoning_content",
      "sequence_number"
    ],
    "create_reasoning_summary_part_done_event": [
      "self",
      "reasoning_item_id",
      "reasoning_content",
      "sequence_number"
    ],
    "create_output_text_done_event": [
      "self",
      "litellm_complete_object"
    ],
    "create_output_content_part_done_event": [
      "self",
      "litellm_complete_object"
    ],
    "create_output_item_done_event": [
      "self",
      "litellm_complete_object"
    ],
    "create_reasoning_output_item_done_event": [
      "self",
      "reasoning_item_id",
      "reasoning_content",
      "sequence_number"
    ],
    "return_default_done_events": [
      "self",
      "litellm_complete_object"
    ],
    "return_default_initial_events": [
      "self"
    ],
    "is_stream_finished": [
      "self"
    ],
    "common_done_event_logic": [
      "self",
      "sync_mode"
    ],
    "_ensure_output_item_for_chunk": [
      "self",
      "chunk"
    ],
    "__anext__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_transform_chat_completion_chunk_to_response_api_chunk": [
      "self",
      "chunk"
    ],
    "_get_delta_string_from_streaming_choices": [
      "self",
      "choices"
    ],
    "_emit_response_completed_event": [
      "self",
      "litellm_model_response"
    ]
  },
  "LiteLLMCompletionTransformationHandler": {
    "response_api_handler": [
      "self",
      "model",
      "input",
      "responses_api_request",
      "custom_llm_provider",
      "_is_async",
      "stream",
      "extra_headers"
    ],
    "async_response_api_handler": [
      "self",
      "litellm_completion_request",
      "request_input",
      "responses_api_request"
    ]
  },
  "COLD_STORAGE_HANDLER": [],
  "ResponsesSessionHandler": {
    "get_chat_completion_message_history_for_previous_response_id": [
      "previous_response_id"
    ],
    "extend_chat_completion_message_with_spend_log_payload": [
      "spend_log",
      "chat_completion_message_history"
    ],
    "get_proxy_server_request_from_spend_log": [
      "spend_log"
    ],
    "_get_cold_storage_object_key_from_spend_log": [
      "spend_log"
    ],
    "get_proxy_server_request_from_cold_storage_with_object_key": [
      "object_key"
    ],
    "_should_check_cold_storage_for_full_payload": [
      "proxy_server_request_dict"
    ],
    "get_all_spend_logs_for_previous_response_id": [
      "previous_response_id"
    ]
  },
  "VectorStoreRequestUtils": {
    "get_requested_vector_store_search_optional_param": [
      "params",
      "vector_store_provider_config"
    ],
    "get_requested_vector_store_create_optional_param": [
      "params"
    ]
  },
  "VectorStoreIndexRegistry": {
    "__init__": [
      "self",
      "vector_store_indexes"
    ],
    "get_vector_store_indexes": [
      "self"
    ],
    "get_vector_store_index_by_name": [
      "self",
      "vector_store_index_name"
    ],
    "upsert_vector_store_index": [
      "self",
      "vector_store_index"
    ],
    "delete_vector_store_index": [
      "self",
      "vector_store_index"
    ],
    "is_vector_store_index": [
      "self",
      "vector_store_index_name"
    ],
    "_get_vector_store_indexes_from_db": [
      "prisma_client"
    ]
  },
  "VectorStoreRegistry": {
    "__init__": [
      "self",
      "vector_stores"
    ],
    "_extract_tool_params": [
      "self",
      "tool"
    ],
    "get_vector_store_ids_to_run": [
      "self",
      "non_default_params",
      "tools"
    ],
    "get_and_pop_recognised_vector_store_tools": [
      "self",
      "tools",
      "vector_store_ids"
    ],
    "get_vector_store_to_run": [
      "self",
      "non_default_params",
      "tools"
    ],
    "get_litellm_managed_vector_store_from_registry": [
      "self",
      "vector_store_id"
    ],
    "get_litellm_managed_vector_store_from_registry_or_db": [
      "self",
      "vector_store_id",
      "prisma_client"
    ],
    "get_litellm_managed_vector_store_from_registry_by_name": [
      "self",
      "vector_store_name"
    ],
    "pop_vector_stores_to_run": [
      "self",
      "non_default_params",
      "tools"
    ],
    "pop_vector_stores_to_run_with_db_fallback": [
      "self",
      "non_default_params",
      "tools",
      "prisma_client"
    ],
    "_get_vector_store_ids_from_tool_calls": [
      "self",
      "tools",
      "vector_store_ids"
    ],
    "load_vector_stores_from_config": [
      "self",
      "vector_stores_config"
    ],
    "list_all_vector_stores": [
      "self"
    ],
    "add_vector_store_to_registry": [
      "self",
      "vector_store"
    ],
    "delete_vector_store_from_registry": [
      "self",
      "vector_store_id"
    ],
    "update_vector_store_in_registry": [
      "self",
      "vector_store_id",
      "updated_data"
    ],
    "_get_vector_stores_from_db": [
      "prisma_client"
    ],
    "get_credentials_for_vector_store": [
      "self",
      "vector_store_id"
    ]
  },
  "mock_vector_store_search_response": [
    "mock_results"
  ],
  "mock_vector_store_create_response": [
    "mock_response"
  ],
  "asearch": [
    "vector_store_id",
    "query",
    "filters",
    "max_num_results",
    "ranking_options",
    "rewrite_query",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "search": [
    "vector_store_id",
    "query",
    "filters",
    "max_num_results",
    "ranking_options",
    "rewrite_query",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "VideoGenerationRequestUtils": {
    "get_optional_params_video_generation": [
      "model",
      "video_generation_provider_config",
      "video_generation_optional_params"
    ],
    "get_requested_video_generation_optional_param": [
      "params"
    ]
  },
  "avideo_generation": [
    "prompt",
    "model",
    "input_reference",
    "seconds",
    "size",
    "user",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "video_generation": [
    "prompt",
    "model",
    "input_reference",
    "seconds",
    "size",
    "user",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "video_content": [
    "video_id",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "avideo_content": [
    "video_id",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "avideo_remix": [
    "video_id",
    "prompt",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "video_remix": [
    "video_id",
    "prompt",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "avideo_list": [
    "after",
    "limit",
    "order",
    "api_key",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "video_list": [
    "after",
    "limit",
    "order",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "avideo_status": [
    "video_id",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "video_status": [
    "video_id",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "get_modified_max_tokens": [
    "model",
    "base_model",
    "messages",
    "user_max_tokens",
    "buffer_perc",
    "buffer_num"
  ],
  "resize_image_high_res": [
    "width",
    "height"
  ],
  "calculate_tiles_needed": [
    "resized_width",
    "resized_height",
    "tile_width",
    "tile_height"
  ],
  "get_image_type": [
    "image_data"
  ],
  "get_image_dimensions": [
    "data"
  ],
  "calculate_img_tokens": [
    "data",
    "mode",
    "base_tokens",
    "use_default_image_token_count"
  ],
  "TokenCounterFunction": [],
  "_MessageCountParams": {
    "__init__": [
      "self",
      "model",
      "custom_tokenizer"
    ]
  },
  "_count_messages": [
    "params",
    "messages",
    "use_default_image_token_count",
    "default_token_count"
  ],
  "_count_extra": [
    "count_function",
    "tools",
    "tool_choice",
    "includes_system_message"
  ],
  "_get_count_function": [
    "model",
    "custom_tokenizer"
  ],
  "_fix_model_name": [
    "model"
  ],
  "_count_image_tokens": [
    "image_url",
    "use_default_image_token_count"
  ],
  "_validate_anthropic_content": [
    "content"
  ],
  "_count_anthropic_content": [
    "content",
    "count_function",
    "use_default_image_token_count",
    "default_token_count"
  ],
  "_count_content_list": [
    "count_function",
    "content_list",
    "use_default_image_token_count",
    "default_token_count"
  ],
  "_format_function_definitions": [
    "tools"
  ],
  "_format_object_parameters": [
    "parameters",
    "indent"
  ],
  "_format_type": [
    "props",
    "indent"
  ],
  "CoroutineChecker": {
    "__init__": [
      "self"
    ],
    "is_async_callable": [
      "self",
      "callback"
    ]
  },
  "coroutine_checker": [],
  "_route_matches_pattern": [
    "route",
    "pattern"
  ],
  "get_call_types_for_route": [
    "route"
  ],
  "get_routes_for_call_type": [
    "call_type"
  ],
  "CredentialAccessor": {
    "get_credential_values": [
      "credential_name"
    ],
    "upsert_credentials": [
      "credentials"
    ]
  },
  "MAX_THREADS": [],
  "executor": [],
  "LoggingTask": {},
  "LoggingWorker": {
    "__init__": [
      "self",
      "timeout",
      "max_queue_size",
      "concurrency"
    ],
    "_ensure_queue": [
      "self"
    ],
    "start": [
      "self"
    ],
    "_process_log_task": [
      "self",
      "task",
      "sem"
    ],
    "_worker_loop": [
      "self"
    ],
    "enqueue": [
      "self",
      "coroutine"
    ],
    "_should_start_aggressive_clear": [
      "self"
    ],
    "_mark_aggressive_clear_started": [
      "self"
    ],
    "_handle_queue_full": [
      "self",
      "task"
    ],
    "_calculate_retry_delay": [
      "self"
    ],
    "_schedule_delayed_enqueue_retry": [
      "self",
      "task"
    ],
    "_retry_enqueue_task": [
      "self",
      "task",
      "delay"
    ],
    "_extract_tasks_from_queue": [
      "self"
    ],
    "_aggressively_clear_queue_async": [
      "self",
      "new_task"
    ],
    "_process_single_task": [
      "self",
      "task"
    ],
    "_process_extracted_tasks": [
      "self",
      "tasks"
    ],
    "ensure_initialized_and_enqueue": [
      "self",
      "async_coroutine"
    ],
    "stop": [
      "self"
    ],
    "flush": [
      "self"
    ],
    "clear_queue": [
      "self"
    ],
    "_safe_log": [
      "self",
      "level",
      "message"
    ],
    "_flush_on_exit": [
      "self"
    ]
  },
  "GLOBAL_LOGGING_WORKER": [],
  "is_non_root": [],
  "_max_retries": [],
  "_retry_delay": [],
  "safe_json_loads": [
    "data",
    "default"
  ],
  "_extract_from_regex": [
    "duration"
  ],
  "get_last_day_of_month": [
    "year",
    "month"
  ],
  "duration_in_seconds": [
    "duration"
  ],
  "get_next_standardized_reset_time": [
    "duration",
    "current_time",
    "timezone_str"
  ],
  "_setup_timezone": [
    "current_time",
    "timezone_str"
  ],
  "_parse_duration": [
    "duration"
  ],
  "_handle_day_reset": [
    "current_time",
    "base_midnight",
    "value",
    "timezone"
  ],
  "_handle_hour_reset": [
    "current_time",
    "base_midnight",
    "value"
  ],
  "_handle_minute_reset": [
    "current_time",
    "base_midnight",
    "value"
  ],
  "_handle_second_reset": [
    "current_time",
    "base_midnight",
    "value"
  ],
  "_handle_month_reset": [
    "current_time",
    "base_midnight",
    "value"
  ],
  "get_litellm_logging_class": [],
  "get_coroutine_checker": [],
  "get_set_callbacks": [],
  "clear_cached_imports": [],
  "deepevalLogger": [],
  "ServiceTraceIDCache": {
    "__init__": [
      "self"
    ],
    "get_cache": [
      "self",
      "litellm_call_id",
      "service_name"
    ],
    "set_cache": [
      "self",
      "litellm_call_id",
      "service_name",
      "trace_id"
    ]
  },
  "in_memory_trace_id_cache": [],
  "in_memory_dynamic_logger_cache": [],
  "_PrometheusLogger": [],
  "_get_cached_prometheus_logger": [],
  "Logging": {
    "stream_options": [],
    "__init__": [
      "self",
      "model",
      "messages",
      "stream",
      "call_type",
      "start_time",
      "litellm_call_id",
      "function_id",
      "litellm_trace_id",
      "dynamic_input_callbacks",
      "dynamic_success_callbacks",
      "dynamic_async_success_callbacks",
      "dynamic_failure_callbacks",
      "dynamic_async_failure_callbacks",
      "applied_guardrails",
      "kwargs",
      "log_raw_request_response"
    ],
    "process_dynamic_callbacks": [
      "self"
    ],
    "_process_dynamic_callback_list": [
      "self",
      "callback_list",
      "dynamic_callbacks_type"
    ],
    "initialize_standard_callback_dynamic_params": [
      "self",
      "kwargs"
    ],
    "initialize_standard_built_in_tools_params": [
      "self",
      "kwargs"
    ],
    "update_environment_variables": [
      "self",
      "litellm_params",
      "optional_params",
      "model",
      "user"
    ],
    "update_messages": [
      "self",
      "messages"
    ],
    "should_run_prompt_management_hooks": [
      "self",
      "non_default_params",
      "prompt_id",
      "tools"
    ],
    "_should_run_prompt_management_hooks_without_prompt_id": [
      "self",
      "non_default_params",
      "tools"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_variables",
      "prompt_id",
      "prompt_spec",
      "prompt_management_logger",
      "prompt_label",
      "prompt_version"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_variables",
      "prompt_id",
      "prompt_spec",
      "prompt_management_logger",
      "tools",
      "prompt_label",
      "prompt_version"
    ],
    "_auto_detect_prompt_management_logger": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "get_custom_logger_for_prompt_management": [
      "self",
      "model",
      "non_default_params",
      "tools",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "get_custom_logger_for_anthropic_cache_control_hook": [
      "self",
      "non_default_params"
    ],
    "_get_raw_request_body": [
      "self",
      "data"
    ],
    "_get_masked_api_base": [
      "self",
      "api_base"
    ],
    "_pre_call": [
      "self",
      "input",
      "api_key",
      "model",
      "additional_args"
    ],
    "pre_call": [
      "self",
      "input",
      "api_key",
      "model",
      "additional_args"
    ],
    "_print_llm_call_debugging_log": [
      "self",
      "api_base",
      "headers",
      "additional_args"
    ],
    "_get_request_body": [
      "self",
      "data"
    ],
    "_get_request_curl_command": [
      "self",
      "api_base",
      "headers",
      "additional_args",
      "data"
    ],
    "_get_masked_headers": [
      "self",
      "headers",
      "ignore_sensitive_headers"
    ],
    "post_call": [
      "self",
      "original_response",
      "input",
      "api_key",
      "additional_args"
    ],
    "async_post_mcp_tool_call_hook": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_parse_post_mcp_call_hook_response": [
      "self",
      "response"
    ],
    "get_response_ms": [
      "self"
    ],
    "set_cost_breakdown": [
      "self",
      "input_cost",
      "output_cost",
      "total_cost",
      "cost_for_built_in_tools_cost_usd_dollar",
      "additional_costs",
      "original_cost",
      "discount_percent",
      "discount_amount",
      "margin_percent",
      "margin_fixed_amount",
      "margin_total_amount"
    ],
    "_response_cost_calculator": [
      "self",
      "result",
      "cache_hit",
      "litellm_model_name",
      "router_model_id"
    ],
    "_response_cost_calculator_async": [
      "self",
      "result",
      "cache_hit"
    ],
    "should_run_logging": [
      "self",
      "event_type",
      "stream"
    ],
    "has_run_logging": [
      "self",
      "event_type"
    ],
    "should_run_callback": [
      "self",
      "callback",
      "litellm_params",
      "event_hook"
    ],
    "_update_completion_start_time": [
      "self",
      "completion_start_time"
    ],
    "normalize_logging_result": [
      "self",
      "result"
    ],
    "_process_hidden_params_and_response_cost": [
      "self",
      "logging_result",
      "start_time",
      "end_time"
    ],
    "_build_standard_logging_payload": [
      "self",
      "init_response_obj",
      "start_time",
      "end_time"
    ],
    "_transform_usage_objects": [
      "self",
      "result"
    ],
    "_success_handler_helper_fn": [
      "self",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "standard_logging_object"
    ],
    "_is_recognized_call_type_for_logging": [
      "self",
      "logging_result"
    ],
    "_flush_passthrough_collected_chunks_helper": [
      "self",
      "raw_bytes",
      "provider_config"
    ],
    "flush_passthrough_collected_chunks": [
      "self",
      "raw_bytes",
      "provider_config"
    ],
    "async_flush_passthrough_collected_chunks": [
      "self",
      "raw_bytes",
      "provider_config"
    ],
    "success_handler": [
      "self",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "async_success_handler": [
      "self",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "_handle_callback_failure": [
      "self",
      "callback"
    ],
    "_failure_handler_helper_fn": [
      "self",
      "exception",
      "traceback_exception",
      "start_time",
      "end_time"
    ],
    "special_failure_handlers": [
      "self",
      "exception"
    ],
    "failure_handler": [
      "self",
      "exception",
      "traceback_exception",
      "start_time",
      "end_time"
    ],
    "async_failure_handler": [
      "self",
      "exception",
      "traceback_exception",
      "start_time",
      "end_time"
    ],
    "_get_trace_id": [
      "self",
      "service_name"
    ],
    "_get_callback_object": [
      "self",
      "service_name"
    ],
    "handle_sync_success_callbacks_for_async_calls": [
      "self",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "_should_run_sync_callbacks_for_async_calls": [
      "self"
    ],
    "get_combined_callback_list": [
      "self",
      "dynamic_success_callbacks",
      "global_callbacks"
    ],
    "_remove_internal_litellm_callbacks": [
      "self",
      "callbacks"
    ],
    "_get_callback_name": [
      "self",
      "cb"
    ],
    "_is_internal_litellm_proxy_callback": [
      "self",
      "cb"
    ],
    "_remove_internal_custom_logger_callbacks": [
      "self",
      "callbacks"
    ],
    "_get_assembled_streaming_response": [
      "self",
      "result",
      "start_time",
      "end_time",
      "is_async",
      "streaming_chunks"
    ],
    "_handle_anthropic_messages_response_logging": [
      "self",
      "result"
    ],
    "_handle_non_streaming_google_genai_generate_content_response_logging": [
      "self",
      "result"
    ],
    "_handle_a2a_response_logging": [
      "self",
      "result"
    ]
  },
  "_get_masked_values": [
    "sensitive_object",
    "ignore_sensitive_values",
    "mask_all_values",
    "unmasked_length",
    "number_of_asterisks"
  ],
  "set_callbacks": [
    "callback_list",
    "function_id"
  ],
  "_init_custom_logger_compatible_class": [
    "logging_integration",
    "internal_usage_cache",
    "llm_router",
    "custom_logger_init_args"
  ],
  "get_custom_logger_compatible_class": [
    "logging_integration"
  ],
  "_get_custom_logger_settings_from_proxy_server": [
    "callback_name"
  ],
  "use_custom_pricing_for_model": [
    "litellm_params"
  ],
  "is_valid_sha256_hash": [
    "value"
  ],
  "StandardLoggingPayloadSetup": {
    "cleanup_timestamps": [
      "start_time",
      "end_time",
      "completion_start_time"
    ],
    "append_system_prompt_messages": [
      "kwargs",
      "messages"
    ],
    "merge_litellm_metadata": [
      "litellm_params"
    ],
    "get_standard_logging_metadata": [
      "metadata",
      "litellm_params",
      "prompt_integration",
      "applied_guardrails",
      "mcp_tool_call_metadata",
      "vector_store_request_metadata",
      "usage_object",
      "proxy_server_request",
      "start_time",
      "response_id"
    ],
    "get_usage_from_response_obj": [
      "response_obj",
      "combined_usage_object"
    ],
    "get_usage_as_dict": [
      "response_obj",
      "combined_usage_object"
    ],
    "get_model_cost_information": [
      "base_model",
      "custom_pricing",
      "custom_llm_provider",
      "init_response_obj"
    ],
    "get_final_response_obj": [
      "response_obj",
      "init_response_obj",
      "kwargs"
    ],
    "get_additional_headers": [
      "additiona_headers"
    ],
    "get_hidden_params": [
      "hidden_params"
    ],
    "strip_trailing_slash": [
      "api_base"
    ],
    "_generate_cold_storage_object_key": [
      "start_time",
      "response_id",
      "team_alias"
    ],
    "get_error_information": [
      "original_exception",
      "traceback_str"
    ],
    "get_response_time": [
      "start_time_float",
      "end_time_float",
      "completion_start_time_float",
      "stream"
    ],
    "_get_standard_logging_payload_trace_id": [
      "logging_obj",
      "litellm_params"
    ],
    "_get_user_agent_tags": [
      "proxy_server_request"
    ],
    "_get_extra_header_tags": [
      "proxy_server_request"
    ],
    "_get_request_tags": [
      "litellm_params",
      "proxy_server_request"
    ]
  },
  "_get_status_fields": [
    "status",
    "guardrail_information",
    "error_str"
  ],
  "_extract_response_obj_and_hidden_params": [
    "init_response_obj",
    "original_exception"
  ],
  "get_standard_logging_object_payload": [
    "kwargs",
    "init_response_obj",
    "start_time",
    "end_time",
    "logging_obj",
    "status",
    "error_str",
    "original_exception",
    "standard_built_in_tools_params"
  ],
  "emit_standard_logging_payload": [
    "payload"
  ],
  "get_standard_logging_metadata": [
    "metadata"
  ],
  "scrub_sensitive_keys_in_metadata": [
    "litellm_params"
  ],
  "modify_integration": [
    "integration_name",
    "integration_params"
  ],
  "_get_traceback_str_for_error": [
    "error_str"
  ],
  "create_dummy_standard_logging_payload": [],
  "T_ParamSpec": [],
  "T_Retval": [],
  "function_has_argument": [
    "function",
    "arg_name"
  ],
  "asyncify": [
    "function"
  ],
  "run_async_function": [
    "async_function"
  ],
  "GetModelCostMap": {
    "load_local_model_cost_map": [],
    "_get_backup_model_count": [
      "cls"
    ],
    "_check_is_valid_dict": [
      "fetched_map"
    ],
    "_check_model_count_not_reduced": [
      "cls",
      "fetched_map",
      "backup_model_count",
      "min_model_count",
      "max_shrink_ratio"
    ],
    "validate_model_cost_map": [
      "cls",
      "fetched_map",
      "backup_model_count",
      "min_model_count",
      "max_shrink_ratio"
    ],
    "fetch_remote_model_cost_map": [
      "url",
      "timeout"
    ]
  },
  "get_model_cost_map": [
    "url"
  ],
  "safe_divide_seconds": [
    "seconds",
    "denominator",
    "default"
  ],
  "safe_divide": [
    "numerator",
    "denominator",
    "default"
  ],
  "map_finish_reason": [
    "finish_reason"
  ],
  "remove_index_from_tool_calls": [
    "messages"
  ],
  "remove_items_at_indices": [
    "items",
    "indices"
  ],
  "add_missing_spend_metadata_to_litellm_metadata": [
    "litellm_metadata",
    "metadata"
  ],
  "get_metadata_variable_name_from_kwargs": [
    "kwargs"
  ],
  "get_litellm_metadata_from_kwargs": [
    "kwargs"
  ],
  "reconstruct_model_name": [
    "model_name",
    "custom_llm_provider",
    "metadata"
  ],
  "_get_parent_otel_span_from_kwargs": [
    "kwargs"
  ],
  "process_response_headers": [
    "response_headers"
  ],
  "preserve_upstream_non_openai_attributes": [
    "model_response",
    "original_chunk"
  ],
  "safe_deep_copy": [
    "data"
  ],
  "filter_exceptions_from_params": [
    "data",
    "max_depth"
  ],
  "filter_internal_params": [
    "data",
    "additional_internal_params"
  ],
  "mock_embedding": [
    "model",
    "mock_response"
  ],
  "mock_image_generation": [
    "model",
    "mock_response"
  ],
  "ExceptionCheckers": {
    "is_error_str_rate_limit": [
      "error_str"
    ],
    "is_error_str_context_window_exceeded": [
      "error_str"
    ],
    "is_azure_content_policy_violation_error": [
      "error_str"
    ]
  },
  "get_error_message": [
    "error_obj"
  ],
  "_get_response_headers": [
    "original_exception"
  ],
  "extract_and_raise_litellm_exception": [
    "response",
    "error_str",
    "model",
    "custom_llm_provider"
  ],
  "exception_type": [
    "model",
    "original_exception",
    "custom_llm_provider",
    "completion_kwargs",
    "extra_kwargs"
  ],
  "exception_logging": [
    "additional_args",
    "logger_fn",
    "exception"
  ],
  "_add_key_name_and_team_to_alert": [
    "request_info",
    "metadata"
  ],
  "get_nested_value": [
    "data",
    "key_path",
    "default"
  ],
  "_parse_path_segments": [
    "path"
  ],
  "_delete_nested_value_custom": [
    "data",
    "segments",
    "segment_index"
  ],
  "delete_nested_value": [
    "data",
    "path",
    "depth",
    "max_depth"
  ],
  "is_nested_path": [
    "path"
  ],
  "AppCrypto": {
    "__init__": [
      "self",
      "master_key"
    ],
    "encrypt_json": [
      "self",
      "data",
      "aad"
    ],
    "decrypt_json": [
      "self",
      "enc",
      "aad"
    ]
  },
  "Rules": {
    "__init__": [
      "self"
    ],
    "has_pre_call_rules": [],
    "pre_call_rules": [
      "self",
      "input",
      "model"
    ],
    "post_call_rules": [
      "self",
      "input",
      "model"
    ]
  },
  "TEST_PDF_URL": [],
  "HealthCheckHelpers": {
    "ahealth_check_wildcard_models": [
      "model",
      "custom_llm_provider",
      "model_params",
      "litellm_logging_obj"
    ],
    "_update_model_params_with_health_check_tracking_information": [
      "model_params"
    ],
    "_get_metadata_for_health_check_call": [],
    "get_mode_handlers": [
      "model",
      "custom_llm_provider",
      "model_params",
      "prompt",
      "input"
    ]
  },
  "normalize_json_schema_types": [
    "schema",
    "depth",
    "max_depth"
  ],
  "normalize_tool_schema": [
    "tool"
  ],
  "validate_schema": [
    "schema",
    "response"
  ],
  "CustomLoggerRegistry": {
    "CALLBACK_CLASS_STR_TO_CLASS_TYPE": [],
    "get_callback_str_from_class_type": [
      "cls",
      "class_type"
    ],
    "get_all_callback_strs_from_class_type": [
      "cls",
      "class_type"
    ],
    "get_class_type_for_custom_logger_name": [
      "cls",
      "custom_logger_name"
    ]
  },
  "ChunkProcessor": {
    "__init__": [
      "self",
      "chunks",
      "messages"
    ],
    "_sort_chunks": [
      "self",
      "chunks"
    ],
    "update_model_response_with_hidden_params": [
      "self",
      "model_response",
      "chunk"
    ],
    "_get_chunk_id": [
      "chunks"
    ],
    "_get_model_from_chunks": [
      "chunks",
      "first_chunk_model"
    ],
    "build_base_response": [
      "self",
      "chunks"
    ],
    "get_combined_tool_content": [
      "self",
      "tool_call_chunks"
    ],
    "get_combined_function_call_content": [
      "self",
      "function_call_chunks"
    ],
    "get_combined_content": [
      "self",
      "chunks",
      "delta_key"
    ],
    "get_combined_thinking_content": [
      "self",
      "chunks"
    ],
    "get_combined_reasoning_content": [
      "self",
      "chunks"
    ],
    "get_combined_audio_content": [
      "self",
      "chunks"
    ],
    "_usage_chunk_calculation_helper": [
      "self",
      "usage_chunk"
    ],
    "count_reasoning_tokens": [
      "self",
      "response"
    ],
    "_calculate_usage_per_chunk": [
      "self",
      "chunks"
    ],
    "calculate_usage": [
      "self",
      "chunks",
      "model",
      "completion_output",
      "messages",
      "reasoning_tokens"
    ]
  },
  "concatenate_base64_list": [
    "base64_strings"
  ],
  "_supported_callback_params": [],
  "initialize_standard_callback_dynamic_params": [
    "kwargs"
  ],
  "_ensure_extra_body_is_safe": [
    "extra_body"
  ],
  "pick_cheapest_chat_models_from_llm_provider": [
    "custom_llm_provider",
    "n"
  ],
  "get_proxy_server_request_headers": [
    "litellm_params"
  ],
  "SensitiveDataMasker": {
    "__init__": [
      "self",
      "sensitive_patterns",
      "non_sensitive_overrides",
      "visible_prefix",
      "visible_suffix",
      "mask_char"
    ],
    "_mask_value": [
      "self",
      "value"
    ],
    "is_sensitive_key": [
      "self",
      "key",
      "excluded_keys"
    ],
    "_mask_sequence": [
      "self",
      "values",
      "depth",
      "max_depth",
      "excluded_keys",
      "key_is_sensitive"
    ],
    "mask_dict": [
      "self",
      "data",
      "depth",
      "max_depth",
      "excluded_keys"
    ]
  },
  "_filter_model_params": [
    "model_params"
  ],
  "_create_health_check_response": [
    "response_headers"
  ],
  "ProviderSpecificHeaderUtils": {
    "get_provider_specific_headers": [
      "provider_specific_header",
      "custom_llm_provider"
    ]
  },
  "DefaultLoggedRealTimeEventTypes": [],
  "RealTimeStreaming": {
    "__init__": [
      "self",
      "websocket",
      "backend_ws",
      "logging_obj",
      "provider_config",
      "model"
    ],
    "_should_store_message": [
      "self",
      "message_obj"
    ],
    "store_message": [
      "self",
      "message"
    ],
    "store_input": [
      "self",
      "message"
    ],
    "log_messages": [
      "self"
    ],
    "backend_to_client_send_messages": [
      "self"
    ],
    "client_ack_messages": [
      "self"
    ],
    "bidirectional_forward": [
      "self"
    ]
  },
  "ModelParamHelper": {
    "get_standard_logging_model_parameters": [
      "model_parameters"
    ],
    "get_exclude_params_for_model_parameters": [],
    "_get_relevant_args_to_use_for_logging": [],
    "_get_all_llm_api_params": [],
    "get_litellm_provider_specific_params_for_chat_params": [],
    "_get_litellm_supported_chat_completion_kwargs": [],
    "_get_litellm_supported_text_completion_kwargs": [],
    "_get_litellm_supported_rerank_kwargs": [],
    "_get_litellm_supported_embedding_kwargs": [],
    "_get_litellm_supported_transcription_kwargs": [],
    "_get_exclude_kwargs": []
  },
  "is_model_response_stream_empty": [
    "model_response"
  ],
  "_has_meaningful_content": [
    "value"
  ],
  "_is_choice_non_empty": [
    "choice"
  ],
  "_is_delta_non_empty": [
    "delta"
  ],
  "NullSpan": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "finish": [
      "self"
    ]
  },
  "null_tracer": [
    "name"
  ],
  "NullTracer": {
    "trace": [
      "self",
      "name"
    ],
    "wrap": [
      "self",
      "name"
    ]
  },
  "_should_use_dd_tracer": [],
  "_should_use_dd_profiler": [],
  "should_use_dd_tracer": [],
  "redact_message_input_output_from_custom_logger": [
    "litellm_logging_obj",
    "result",
    "custom_logger"
  ],
  "_redact_choice_content": [
    "choice"
  ],
  "_redact_responses_api_output": [
    "output_items"
  ],
  "perform_redaction": [
    "model_call_details",
    "result"
  ],
  "should_redact_message_logging": [
    "model_call_details"
  ],
  "redact_message_input_output_from_logging": [
    "model_call_details",
    "result",
    "input"
  ],
  "_get_turn_off_message_logging_from_dynamic_params": [
    "model_call_details"
  ],
  "redact_user_api_key_info": [
    "metadata"
  ],
  "AUDIO_ATTRIBUTE": [],
  "IMAGE_ATTRIBUTE": [],
  "TOOL_CALLS_ATTRIBUTE": [],
  "FUNCTION_CALL_ATTRIBUTE": [],
  "is_async_iterable": [
    "obj"
  ],
  "CustomStreamWrapper": {
    "__init__": [
      "self",
      "completion_stream",
      "model",
      "logging_obj",
      "custom_llm_provider",
      "stream_options",
      "make_call",
      "_response_headers"
    ],
    "__iter__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "aclose": [
      "self"
    ],
    "check_send_stream_usage": [
      "self",
      "stream_options"
    ],
    "check_is_function_call": [
      "self",
      "logging_obj"
    ],
    "process_chunk": [
      "self",
      "chunk"
    ],
    "safety_checker": [
      "self"
    ],
    "check_special_tokens": [
      "self",
      "chunk",
      "finish_reason"
    ],
    "handle_predibase_chunk": [
      "self",
      "chunk"
    ],
    "handle_ai21_chunk": [
      "self",
      "chunk"
    ],
    "handle_maritalk_chunk": [
      "self",
      "chunk"
    ],
    "handle_nlp_cloud_chunk": [
      "self",
      "chunk"
    ],
    "handle_aleph_alpha_chunk": [
      "self",
      "chunk"
    ],
    "handle_azure_chunk": [
      "self",
      "chunk"
    ],
    "handle_replicate_chunk": [
      "self",
      "chunk"
    ],
    "handle_openai_chat_completion_chunk": [
      "self",
      "chunk"
    ],
    "handle_azure_text_completion_chunk": [
      "self",
      "chunk"
    ],
    "handle_openai_text_completion_chunk": [
      "self",
      "chunk"
    ],
    "handle_baseten_chunk": [
      "self",
      "chunk"
    ],
    "handle_triton_stream": [
      "self",
      "chunk"
    ],
    "model_response_creator": [
      "self",
      "chunk",
      "hidden_params"
    ],
    "is_delta_empty": [
      "self",
      "delta"
    ],
    "set_model_id": [
      "self",
      "id",
      "model_response"
    ],
    "copy_model_response_level_provider_specific_fields": [
      "self",
      "original_chunk",
      "model_response"
    ],
    "is_chunk_non_empty": [
      "self",
      "completion_obj",
      "model_response",
      "response_obj"
    ],
    "strip_role_from_delta": [
      "self",
      "model_response"
    ],
    "_has_special_delta_content": [
      "self",
      "model_response"
    ],
    "_handle_special_delta_content": [
      "self",
      "model_response"
    ],
    "_has_special_delta_attribute": [
      "self",
      "delta",
      "attribute_name"
    ],
    "_copy_delta_attribute": [
      "self",
      "source_delta",
      "target_delta",
      "attribute_name"
    ],
    "_has_any_special_delta_attributes": [
      "self",
      "delta"
    ],
    "_handle_special_delta_attributes": [
      "self",
      "delta",
      "model_response"
    ],
    "return_processed_chunk_logic": [
      "self",
      "completion_obj",
      "model_response",
      "response_obj"
    ],
    "_optional_combine_thinking_block_in_choices": [
      "self",
      "model_response"
    ],
    "chunk_creator": [
      "self",
      "chunk"
    ],
    "set_logging_event_loop": [
      "self",
      "loop"
    ],
    "_call_post_streaming_deployment_hook": [
      "self",
      "chunk"
    ],
    "_add_mcp_list_tools_to_first_chunk": [
      "self",
      "chunk"
    ],
    "_add_mcp_metadata_to_final_chunk": [
      "self",
      "chunk"
    ],
    "cache_streaming_response": [
      "self",
      "processed_chunk",
      "cache_hit"
    ],
    "async_cache_streaming_response": [
      "self",
      "processed_chunk",
      "cache_hit"
    ],
    "run_success_logging_and_cache_storage": [
      "self",
      "processed_chunk",
      "cache_hit"
    ],
    "finish_reason_handler": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "fetch_sync_stream": [
      "self"
    ],
    "fetch_stream": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "_strip_sse_data_from_chunk": [
      "chunk"
    ]
  },
  "calculate_total_usage": [
    "chunks"
  ],
  "generic_chunk_has_all_required_fields": [
    "chunk"
  ],
  "convert_generic_chunk_to_model_response_stream": [
    "chunk"
  ],
  "_OPTIONAL_KWARGS_KEYS": [],
  "_get_base_model_from_litellm_call_metadata": [
    "metadata"
  ],
  "get_litellm_params": [
    "api_key",
    "force_timeout",
    "azure",
    "logger_fn",
    "verbose",
    "hugging_face",
    "replicate",
    "together_ai",
    "custom_llm_provider",
    "api_base",
    "litellm_call_id",
    "model_alias_map",
    "completion_call_id",
    "metadata",
    "model_info",
    "proxy_server_request",
    "acompletion",
    "aembedding",
    "preset_cache_key",
    "no_log",
    "input_cost_per_second",
    "input_cost_per_token",
    "output_cost_per_token",
    "output_cost_per_second",
    "cost_per_query",
    "cooldown_time",
    "text_completion",
    "azure_ad_token_provider",
    "user_continue_message",
    "base_model",
    "litellm_trace_id",
    "litellm_session_id",
    "hf_model_name",
    "custom_prompt_dict",
    "litellm_metadata",
    "disable_add_transform_inline_image_block",
    "drop_params",
    "prompt_id",
    "prompt_variables",
    "async_call",
    "ssl_verify",
    "merge_reasoning_content_in_choices",
    "use_litellm_proxy",
    "api_version",
    "max_retries",
    "litellm_request_debug"
  ],
  "_BYTES_PER_KIB": [],
  "_BYTES_PER_MIB": [],
  "_DATA_URI_RE": [],
  "_MAX_TRUNCATION_DEPTH": [],
  "_format_base64_size": [
    "num_chars"
  ],
  "_base64_data_uri_replacer": [
    "match"
  ],
  "_truncate_base64_in_string": [
    "value"
  ],
  "_truncate_base64_in_value": [
    "value"
  ],
  "truncate_base64_in_messages": [
    "messages"
  ],
  "_service_logger": [],
  "_get_service_logger": [],
  "_get_parent_otel_span_from_logging_obj": [
    "logging_obj"
  ],
  "convert_litellm_response_object_to_str": [
    "response_obj"
  ],
  "_assemble_complete_response_from_streaming_chunks": [
    "result",
    "start_time",
    "end_time",
    "request_kwargs",
    "streaming_chunks",
    "is_async"
  ],
  "_set_duration_in_model_call_details": [
    "logging_obj",
    "start_time",
    "end_time"
  ],
  "track_llm_api_timing": [],
  "get_cli_token_file_path": [],
  "load_cli_token": [],
  "get_litellm_gateway_api_key": [],
  "_is_non_openai_azure_model": [
    "model"
  ],
  "_is_azure_claude_model": [
    "model"
  ],
  "handle_cohere_chat_model_custom_llm_provider": [
    "model",
    "custom_llm_provider"
  ],
  "handle_anthropic_text_model_custom_llm_provider": [
    "model",
    "custom_llm_provider"
  ],
  "get_llm_provider": [
    "model",
    "custom_llm_provider",
    "api_base",
    "api_key",
    "litellm_params"
  ],
  "_get_openai_compatible_provider_info": [
    "model",
    "api_base",
    "api_key",
    "dynamic_api_key"
  ],
  "safe_dumps": [
    "data",
    "max_depth"
  ],
  "get_env_int": [
    "env_var",
    "default"
  ],
  "get_supported_openai_params": [
    "model",
    "custom_llm_provider",
    "request_type"
  ],
  "LoggingCallbackManager": {
    "MAX_CALLBACKS": [],
    "_is_async_callable": [
      "self",
      "callback"
    ],
    "add_litellm_input_callback": [
      "self",
      "callback"
    ],
    "add_litellm_service_callback": [
      "self",
      "callback"
    ],
    "add_litellm_callback": [
      "self",
      "callback"
    ],
    "add_litellm_success_callback": [
      "self",
      "callback"
    ],
    "add_litellm_failure_callback": [
      "self",
      "callback"
    ],
    "add_litellm_async_success_callback": [
      "self",
      "callback"
    ],
    "add_litellm_async_failure_callback": [
      "self",
      "callback"
    ],
    "remove_callback_from_list_by_object": [
      "self",
      "callback_list",
      "obj",
      "require_self"
    ],
    "remove_callbacks_by_type": [
      "self",
      "callback_list",
      "callback_type"
    ],
    "_add_string_callback_to_list": [
      "self",
      "callback",
      "parent_list"
    ],
    "_check_callback_list_size": [
      "self",
      "parent_list"
    ],
    "_add_custom_callback_generic_api_str": [
      "callback"
    ],
    "_safe_add_callback_to_list": [
      "self",
      "callback",
      "parent_list"
    ],
    "_add_callback_function_to_list": [
      "self",
      "callback",
      "parent_list"
    ],
    "_add_custom_logger_to_list": [
      "self",
      "custom_logger",
      "parent_list"
    ],
    "_get_custom_logger_key": [
      "self",
      "custom_logger"
    ],
    "_reset_all_callbacks": [
      "self"
    ],
    "_get_all_callbacks": [
      "self"
    ],
    "get_active_additional_logging_utils_from_custom_logger": [
      "self"
    ],
    "get_custom_loggers_for_type": [
      "self",
      "callback_type"
    ],
    "callback_is_active": [
      "self",
      "callback_type"
    ],
    "get_callbacks_by_type": [
      "self"
    ],
    "_get_callback_string": [
      "self",
      "callback"
    ],
    "get_active_custom_logger_for_callback_name": [
      "self",
      "callback_name"
    ]
  },
  "async_completion_with_fallbacks": [],
  "completion_with_fallbacks": [],
  "LangfuseInMemoryCache": {
    "_remove_key": [
      "self",
      "key"
    ]
  },
  "DynamicLoggingCache": {
    "__init__": [
      "self"
    ],
    "get_cache_key": [
      "self",
      "args"
    ],
    "get_cache": [
      "self",
      "credentials",
      "service_name"
    ],
    "set_cache": [
      "self",
      "credentials",
      "service_name",
      "logging_obj"
    ]
  },
  "default_pt": [
    "messages"
  ],
  "prompt_injection_detection_default_pt": [],
  "BAD_MESSAGE_ERROR_STR": [],
  "THOUGHT_SIGNATURE_SEPARATOR": [],
  "DEFAULT_USER_CONTINUE_MESSAGE": [],
  "DEFAULT_USER_CONTINUE_MESSAGE_TYPED": [],
  "DEFAULT_ASSISTANT_CONTINUE_MESSAGE": [],
  "map_system_message_pt": [
    "messages"
  ],
  "alpaca_pt": [
    "messages"
  ],
  "llama_2_chat_pt": [
    "messages"
  ],
  "convert_to_ollama_image": [
    "openai_image_url"
  ],
  "_handle_ollama_system_message": [
    "messages",
    "prompt",
    "msg_i"
  ],
  "ollama_pt": [
    "model",
    "messages"
  ],
  "mistral_instruct_pt": [
    "messages"
  ],
  "falcon_instruct_pt": [
    "messages"
  ],
  "falcon_chat_pt": [
    "messages"
  ],
  "mpt_chat_pt": [
    "messages"
  ],
  "wizardcoder_pt": [
    "messages"
  ],
  "phind_codellama_pt": [
    "messages"
  ],
  "_render_chat_template": [
    "env",
    "chat_template",
    "bos_token",
    "eos_token",
    "messages"
  ],
  "_afetch_and_extract_template": [
    "model",
    "chat_template",
    "get_config_fn",
    "get_template_fn"
  ],
  "_fetch_and_extract_template": [
    "model",
    "chat_template",
    "get_config_fn",
    "get_template_fn"
  ],
  "ahf_chat_template": [
    "model",
    "messages",
    "chat_template"
  ],
  "hf_chat_template": [
    "model",
    "messages",
    "chat_template"
  ],
  "deepseek_r1_pt": [
    "messages"
  ],
  "claude_2_1_pt": [
    "messages"
  ],
  "ibm_granite_pt": [
    "messages"
  ],
  "anthropic_pt": [
    "messages"
  ],
  "construct_format_parameters_prompt": [
    "parameters"
  ],
  "construct_format_tool_for_claude_prompt": [
    "name",
    "description",
    "parameters"
  ],
  "construct_tool_use_system_prompt": [
    "tools"
  ],
  "convert_generic_image_chunk_to_openai_image_obj": [
    "image_chunk"
  ],
  "convert_to_anthropic_image_obj": [
    "openai_image_url",
    "format"
  ],
  "create_anthropic_image_param": [
    "image_url_input",
    "format",
    "is_bedrock_invoke"
  ],
  "convert_to_anthropic_tool_result_xml": [
    "message"
  ],
  "convert_to_anthropic_tool_invoke_xml": [
    "tool_calls"
  ],
  "anthropic_messages_pt_xml": [
    "messages"
  ],
  "_azure_tool_call_invoke_helper": [
    "function_call_params"
  ],
  "_azure_image_url_helper": [
    "content"
  ],
  "convert_to_azure_openai_messages": [
    "messages"
  ],
  "infer_protocol_value": [
    "value"
  ],
  "_gemini_tool_call_invoke_helper": [
    "function_call_params"
  ],
  "_encode_tool_call_id_with_signature": [
    "tool_call_id",
    "thought_signature"
  ],
  "_get_thought_signature_from_tool": [
    "tool",
    "model"
  ],
  "_get_dummy_thought_signature": [],
  "convert_to_gemini_tool_call_invoke": [
    "message",
    "model"
  ],
  "convert_to_gemini_tool_call_result": [
    "message",
    "last_message_with_tool_calls"
  ],
  "_sanitize_anthropic_tool_use_id": [
    "tool_use_id"
  ],
  "convert_to_anthropic_tool_result": [
    "message",
    "force_base64"
  ],
  "convert_function_to_anthropic_tool_invoke": [
    "function_call"
  ],
  "convert_to_anthropic_tool_invoke": [
    "tool_calls",
    "web_search_results"
  ],
  "add_cache_control_to_content": [
    "anthropic_content_element",
    "original_content_element"
  ],
  "_anthropic_content_element_factory": [
    "image_chunk"
  ],
  "select_anthropic_content_block_type_for_file": [
    "format"
  ],
  "anthropic_infer_file_id_content_type": [
    "file_id"
  ],
  "anthropic_process_openai_file_message": [
    "message"
  ],
  "_sanitize_empty_text_content": [
    "message"
  ],
  "_add_missing_tool_results": [
    "current_message",
    "messages",
    "current_index"
  ],
  "_is_orphaned_tool_result": [
    "current_message",
    "sanitized_messages"
  ],
  "sanitize_messages_for_tool_calling": [
    "messages"
  ],
  "anthropic_messages_pt": [
    "messages",
    "model",
    "llm_provider"
  ],
  "extract_between_tags": [
    "tag",
    "string",
    "strip"
  ],
  "contains_tag": [
    "tag",
    "string"
  ],
  "parse_xml_params": [
    "xml_content",
    "json_schema"
  ],
  "get_system_prompt": [
    "messages"
  ],
  "convert_openai_message_to_cohere_tool_result": [
    "message",
    "tool_calls"
  ],
  "get_all_tool_calls": [
    "messages"
  ],
  "convert_to_cohere_tool_invoke": [
    "tool_calls"
  ],
  "cohere_messages_pt_v2": [
    "messages",
    "model",
    "llm_provider"
  ],
  "cohere_message_pt": [
    "messages"
  ],
  "amazon_titan_pt": [
    "messages"
  ],
  "_load_image_from_url": [
    "image_url"
  ],
  "_gemini_vision_convert_messages": [
    "messages"
  ],
  "gemini_text_image_pt": [
    "messages"
  ],
  "azure_text_pt": [
    "messages"
  ],
  "stringify_json_tool_call_content": [
    "messages"
  ],
  "_parse_content_type": [
    "content_type"
  ],
  "_parse_mime_type": [
    "base64_data"
  ],
  "BedrockImageProcessor": {
    "_post_call_image_processing": [
      "response",
      "image_url"
    ],
    "get_image_details_async": [
      "image_url"
    ],
    "get_image_details": [
      "image_url"
    ],
    "_parse_base64_image": [
      "image_url"
    ],
    "_validate_format": [
      "mime_type",
      "image_format"
    ],
    "_get_document_format": [
      "mime_type",
      "supported_doc_formats"
    ],
    "_create_bedrock_block": [
      "image_bytes",
      "mime_type",
      "image_format"
    ],
    "process_image_sync": [
      "cls",
      "image_url",
      "format"
    ],
    "process_image_async": [
      "cls",
      "image_url",
      "format"
    ]
  },
  "_convert_to_bedrock_tool_call_invoke": [
    "tool_calls"
  ],
  "_convert_to_bedrock_tool_call_result": [
    "message"
  ],
  "_deduplicate_bedrock_content_blocks": [
    "blocks",
    "block_key",
    "id_key"
  ],
  "_deduplicate_bedrock_tool_content": [
    "tool_content"
  ],
  "_insert_assistant_continue_message": [
    "messages",
    "assistant_continue_message"
  ],
  "get_user_message_block_or_continue_message": [
    "message",
    "user_continue_message"
  ],
  "return_assistant_continue_message": [
    "assistant_continue_message"
  ],
  "_skip_empty_dict_blocks": [
    "blocks"
  ],
  "skip_empty_text_blocks": [
    "message"
  ],
  "process_empty_text_blocks": [
    "message",
    "assistant_continue_message"
  ],
  "get_assistant_message_block_or_continue_message": [
    "message",
    "assistant_continue_message"
  ],
  "BedrockConverseMessagesProcessor": {
    "_initial_message_setup": [
      "messages",
      "model",
      "llm_provider",
      "user_continue_message"
    ],
    "_bedrock_converse_messages_pt_async": [
      "messages",
      "model",
      "llm_provider",
      "user_continue_message",
      "assistant_continue_message"
    ],
    "translate_thinking_blocks_to_reasoning_content_blocks": [
      "thinking_blocks"
    ],
    "_process_file_message": [
      "message"
    ],
    "_async_process_file_message": [
      "message"
    ],
    "add_thinking_blocks_to_assistant_content": [
      "thinking_blocks",
      "assistant_parts"
    ]
  },
  "_bedrock_converse_messages_pt": [
    "messages",
    "model",
    "llm_provider",
    "user_continue_message",
    "assistant_continue_message"
  ],
  "make_valid_bedrock_tool_name": [
    "input_tool_name"
  ],
  "add_cache_point_tool_block": [
    "tool"
  ],
  "_is_bedrock_tool_block": [
    "tool"
  ],
  "_bedrock_tools_pt": [
    "tools"
  ],
  "function_call_prompt": [
    "messages",
    "functions"
  ],
  "response_schema_prompt": [
    "model",
    "response_schema"
  ],
  "default_response_schema_prompt": [
    "response_schema"
  ],
  "custom_prompt": [
    "role_dict",
    "messages",
    "initial_prompt_value",
    "final_prompt_value",
    "bos_token",
    "eos_token"
  ],
  "prompt_factory": [
    "model",
    "messages",
    "custom_llm_provider",
    "api_key"
  ],
  "get_attribute_or_key": [
    "tool_or_function",
    "attribute",
    "default"
  ],
  "strftime_now": [
    "fmt"
  ],
  "_get_tokenizer_config": [
    "hf_model_name"
  ],
  "_aget_tokenizer_config": [
    "hf_model_name"
  ],
  "_get_chat_template_file": [
    "hf_model_name"
  ],
  "_aget_chat_template_file": [
    "hf_model_name"
  ],
  "_extract_token_value": [
    "token_value"
  ],
  "MAX_IMGS_IN_MEMORY": [],
  "in_memory_cache": [],
  "_process_image_response": [
    "response",
    "url"
  ],
  "async_convert_url_to_base64": [
    "url"
  ],
  "convert_url_to_base64": [
    "url"
  ],
  "handle_any_messages_to_chat_completion_str_messages_conversion": [
    "messages"
  ],
  "handle_messages_with_content_list_to_str_conversion": [
    "messages"
  ],
  "strip_name_from_message": [
    "message",
    "allowed_name_roles"
  ],
  "strip_name_from_messages": [
    "messages",
    "allowed_name_roles"
  ],
  "strip_none_values_from_message": [
    "message"
  ],
  "convert_content_list_to_str": [
    "message"
  ],
  "get_str_from_messages": [
    "messages"
  ],
  "is_non_content_values_set": [
    "message"
  ],
  "_audio_or_image_in_message_content": [
    "message"
  ],
  "convert_openai_message_to_only_content_messages": [
    "messages"
  ],
  "get_content_from_model_response": [
    "response"
  ],
  "detect_first_expected_role": [
    "messages"
  ],
  "_insert_user_continue_message": [
    "messages",
    "user_continue_message",
    "ensure_alternating_roles"
  ],
  "get_completion_messages": [
    "messages",
    "assistant_continue_message",
    "user_continue_message",
    "ensure_alternating_roles"
  ],
  "get_format_from_file_id": [
    "file_id"
  ],
  "update_messages_with_model_file_ids": [
    "messages",
    "model_id",
    "model_file_id_mapping"
  ],
  "update_responses_input_with_model_file_ids": [
    "input",
    "model_id",
    "model_file_id_mapping"
  ],
  "update_responses_tools_with_model_file_ids": [
    "tools",
    "model_id",
    "model_file_id_mapping"
  ],
  "extract_file_data": [
    "file_data"
  ],
  "unpack_defs": [
    "schema",
    "defs"
  ],
  "_get_image_mime_type_from_url": [
    "url"
  ],
  "infer_content_type_from_url_and_content": [
    "url",
    "content",
    "current_content_type"
  ],
  "get_tool_call_names": [
    "tools"
  ],
  "is_function_call": [
    "optional_params"
  ],
  "get_file_ids_from_messages": [
    "messages"
  ],
  "check_is_function_call": [
    "logging_obj"
  ],
  "filter_value_from_dict": [
    "dictionary",
    "key",
    "depth"
  ],
  "migrate_file_to_image_url": [
    "message"
  ],
  "get_last_user_message": [
    "messages"
  ],
  "set_last_user_message": [
    "messages",
    "content"
  ],
  "add_system_prompt_to_messages": [
    "messages",
    "system_prompt",
    "merge_with_first_system"
  ],
  "convert_prefix_message_to_non_prefix_messages": [
    "messages"
  ],
  "_extract_reasoning_content": [
    "message"
  ],
  "_parse_content_for_reasoning": [
    "message_text"
  ],
  "_extract_base64_data": [
    "image_url"
  ],
  "extract_images_from_message": [
    "message"
  ],
  "parse_tool_call_arguments": [
    "arguments",
    "tool_name",
    "context"
  ],
  "split_concatenated_json_objects": [
    "raw"
  ],
  "TranscriptionUsageObjectTransformation": {
    "is_transcription_usage_object": [
      "usage_object"
    ],
    "transform_transcription_usage_object": [
      "usage_object"
    ]
  },
  "_IMAGE_RESPONSE_CALL_TYPES": [],
  "_is_above_128k": [
    "tokens"
  ],
  "get_billable_input_tokens": [
    "usage"
  ],
  "select_cost_metric_for_model": [
    "model_info"
  ],
  "_generic_cost_per_character": [
    "model",
    "custom_llm_provider",
    "prompt_characters",
    "completion_characters",
    "custom_prompt_cost",
    "custom_completion_cost"
  ],
  "_get_service_tier_cost_key": [
    "base_key",
    "service_tier"
  ],
  "_get_token_base_cost": [
    "model_info",
    "usage",
    "service_tier"
  ],
  "calculate_cost_component": [
    "model_info",
    "cost_key",
    "usage_value"
  ],
  "_get_cost_per_unit": [
    "model_info",
    "cost_key",
    "default_value"
  ],
  "calculate_cache_writing_cost": [
    "cache_creation_tokens",
    "cache_creation_token_details",
    "cache_creation_cost_above_1hr",
    "cache_creation_cost"
  ],
  "PromptTokensDetailsResult": {},
  "_parse_prompt_tokens_details": [
    "usage"
  ],
  "CompletionTokensDetailsResult": {},
  "_parse_completion_tokens_details": [
    "usage"
  ],
  "_calculate_input_cost": [
    "prompt_tokens_details",
    "model_info",
    "prompt_base_cost",
    "cache_read_cost",
    "cache_creation_cost",
    "cache_creation_cost_above_1hr"
  ],
  "generic_cost_per_token": [
    "model",
    "usage",
    "custom_llm_provider",
    "service_tier"
  ],
  "CostCalculatorUtils": {
    "_call_type_has_image_response": [
      "call_type"
    ],
    "route_image_generation_cost_calculator": [
      "model",
      "completion_response",
      "custom_llm_provider",
      "quality",
      "n",
      "size",
      "optional_params",
      "call_type"
    ]
  },
  "StandardBuiltInToolCostTracking": {
    "get_cost_for_built_in_tools": [
      "model",
      "response_object",
      "usage",
      "custom_llm_provider",
      "standard_built_in_tools_params"
    ],
    "_handle_web_search_cost": [
      "model",
      "custom_llm_provider",
      "usage",
      "standard_built_in_tools_params"
    ],
    "_handle_file_search_cost": [
      "model",
      "custom_llm_provider",
      "standard_built_in_tools_params"
    ],
    "_handle_azure_assistant_costs": [
      "model",
      "custom_llm_provider",
      "standard_built_in_tools_params"
    ],
    "_extract_file_search_params": [
      "file_search_usage"
    ],
    "_get_vector_store_cost": [
      "model_info",
      "custom_llm_provider",
      "standard_built_in_tools_params"
    ],
    "_get_computer_use_cost": [
      "model_info",
      "custom_llm_provider",
      "standard_built_in_tools_params"
    ],
    "_get_code_interpreter_cost": [
      "model_info",
      "custom_llm_provider",
      "standard_built_in_tools_params"
    ],
    "_extract_token_counts": [
      "computer_use_usage"
    ],
    "_safe_convert_to_int": [
      "value"
    ],
    "response_object_includes_web_search_call": [
      "response_object",
      "usage"
    ],
    "response_object_includes_file_search_call": [
      "response_object"
    ],
    "response_includes_annotation_type": [
      "response_object",
      "annotation_type"
    ],
    "response_includes_output_type": [
      "response_object",
      "output_type"
    ],
    "_safe_get_model_info": [
      "model",
      "custom_llm_provider"
    ],
    "get_cost_for_web_search": [
      "web_search_options",
      "model_info"
    ],
    "get_default_cost_for_web_search": [
      "model_info"
    ],
    "get_cost_for_file_search": [
      "file_search",
      "provider",
      "model_info",
      "storage_gb",
      "days"
    ],
    "get_cost_for_vector_store": [
      "vector_store_usage",
      "provider",
      "model_info"
    ],
    "get_cost_for_computer_use": [
      "input_tokens",
      "output_tokens",
      "provider",
      "model_info"
    ],
    "_get_code_interpreter_cost_from_model_map": [
      "provider"
    ],
    "get_cost_for_code_interpreter": [
      "sessions",
      "provider",
      "model_info"
    ],
    "chat_completion_response_includes_annotations": [
      "response_object"
    ],
    "_get_web_search_options": [
      "kwargs"
    ],
    "_get_tools_from_kwargs": [
      "kwargs",
      "tool_type"
    ],
    "_get_file_search_tool_call": [
      "kwargs"
    ],
    "_is_web_search_tool_call": [
      "tool"
    ],
    "_is_file_search_tool_call": [
      "tool"
    ]
  },
  "ProcessedAudioFile": {},
  "process_audio_file": [
    "audio_file"
  ],
  "get_audio_file_name": [
    "file_obj"
  ],
  "get_audio_file_content_hash": [
    "file_obj"
  ],
  "get_audio_file_for_health_check": [],
  "calculate_request_duration": [
    "file"
  ],
  "get_formatted_prompt": [
    "data",
    "call_type"
  ],
  "get_api_base": [
    "model",
    "optional_params"
  ],
  "_safe_convert_created_field": [
    "created_value"
  ],
  "convert_tool_call_to_json_mode": [
    "tool_calls",
    "convert_tool_call_to_json_mode"
  ],
  "convert_to_streaming_response_async": [
    "response_object"
  ],
  "convert_to_streaming_response": [
    "response_object"
  ],
  "_handle_invalid_parallel_tool_calls": [
    "tool_calls"
  ],
  "LiteLLMResponseObjectHandler": {
    "convert_to_image_response": [
      "response_object",
      "model_response_object",
      "hidden_params"
    ],
    "convert_to_moderation_response": [
      "response_object"
    ],
    "convert_chat_to_text_completion": [
      "response",
      "text_completion_response",
      "custom_llm_provider"
    ],
    "_convert_provider_response_logprobs_to_text_completion_logprobs": [
      "response",
      "custom_llm_provider"
    ]
  },
  "_should_convert_tool_call_to_json_mode": [
    "tool_calls",
    "convert_tool_call_to_json_mode"
  ],
  "convert_to_model_response_object": [
    "response_object",
    "model_response_object",
    "response_type",
    "stream",
    "start_time",
    "end_time",
    "hidden_params",
    "_response_headers",
    "convert_tool_call_to_json_mode"
  ],
  "get_response_headers": [
    "_response_headers"
  ],
  "_get_llm_provider_headers": [
    "response_headers"
  ],
  "ResponseMetadata": {
    "__init__": [
      "self",
      "result"
    ],
    "supports_response_time": [
      "self"
    ],
    "set_hidden_params": [
      "self",
      "logging_obj",
      "model",
      "kwargs"
    ],
    "_update_hidden_params": [
      "self",
      "new_params"
    ],
    "_get_value_from_hidden_params": [
      "self",
      "key"
    ],
    "set_timing_metrics": [
      "self",
      "start_time",
      "end_time",
      "logging_obj"
    ],
    "apply": [
      "self"
    ]
  },
  "update_response_metadata": [
    "result",
    "logging_obj",
    "model",
    "kwargs",
    "start_time",
    "end_time"
  ],
  "_SPECIAL_HEADERS_CACHE": [],
  "service_logger_obj": [],
  "parse_cache_control": [
    "cache_control"
  ],
  "LITELLM_METADATA_ROUTES": [],
  "_get_metadata_variable_name": [
    "request"
  ],
  "safe_add_api_version_from_query_params": [
    "data",
    "request"
  ],
  "convert_key_logging_metadata_to_callback": [
    "data",
    "team_callback_settings_obj"
  ],
  "KeyAndTeamLoggingSettings": {
    "get_key_dynamic_logging_settings": [
      "user_api_key_dict"
    ],
    "get_team_dynamic_logging_settings": [
      "user_api_key_dict"
    ]
  },
  "_get_dynamic_logging_metadata": [
    "user_api_key_dict",
    "proxy_config"
  ],
  "clean_headers": [
    "headers",
    "litellm_key_header_name"
  ],
  "LiteLLMProxyRequestSetup": {
    "_get_timeout_from_request": [
      "headers"
    ],
    "_get_stream_timeout_from_request": [
      "headers"
    ],
    "_get_num_retries_from_request": [
      "headers"
    ],
    "_get_spend_logs_metadata_from_request_headers": [
      "headers"
    ],
    "_get_forwardable_headers": [
      "headers"
    ],
    "_get_case_insensitive_header": [
      "headers",
      "key"
    ],
    "add_internal_user_from_user_mapping": [
      "general_settings",
      "user_api_key_dict",
      "headers"
    ],
    "get_user_from_headers": [
      "headers",
      "general_settings"
    ],
    "get_openai_org_id_from_headers": [
      "headers",
      "general_settings"
    ],
    "add_headers_to_llm_call": [
      "headers",
      "user_api_key_dict"
    ],
    "add_headers_to_llm_call_by_model_group": [
      "data",
      "headers",
      "user_api_key_dict"
    ],
    "get_internal_user_header_from_mapping": [
      "user_header_mapping"
    ],
    "add_litellm_data_for_backend_llm_call": [],
    "add_litellm_metadata_from_request_headers": [
      "headers",
      "data",
      "_metadata_variable_name"
    ],
    "get_sanitized_user_information_from_key": [
      "user_api_key_dict"
    ],
    "add_user_api_key_auth_to_request_metadata": [
      "data",
      "user_api_key_dict",
      "_metadata_variable_name"
    ],
    "add_management_endpoint_metadata_to_request_metadata": [
      "data",
      "management_endpoint_metadata",
      "_metadata_variable_name"
    ],
    "add_key_level_controls": [
      "key_metadata",
      "data",
      "_metadata_variable_name"
    ],
    "_merge_tags": [
      "request_tags",
      "tags_to_add"
    ],
    "add_team_based_callbacks_from_config": [
      "team_id",
      "proxy_config"
    ],
    "add_request_tag_to_metadata": [
      "llm_router",
      "headers",
      "data"
    ]
  },
  "add_litellm_data_to_request": [
    "data",
    "request",
    "user_api_key_dict",
    "proxy_config",
    "general_settings",
    "version"
  ],
  "_update_model_if_team_alias_exists": [
    "data",
    "user_api_key_dict"
  ],
  "_update_model_if_key_alias_exists": [
    "data",
    "user_api_key_dict"
  ],
  "_get_enforced_params": [
    "general_settings",
    "user_api_key_dict"
  ],
  "check_if_token_is_service_account": [
    "valid_token"
  ],
  "_enforced_params_check": [
    "request_body",
    "general_settings",
    "user_api_key_dict",
    "premium_user"
  ],
  "_add_guardrails_from_key_or_team_metadata": [
    "key_metadata",
    "team_metadata",
    "data",
    "metadata_variable_name"
  ],
  "_add_guardrails_from_policies_in_metadata": [
    "key_metadata",
    "team_metadata",
    "data",
    "metadata_variable_name"
  ],
  "move_guardrails_to_metadata": [
    "data",
    "_metadata_variable_name",
    "user_api_key_dict"
  ],
  "_match_and_track_policies": [
    "data",
    "context",
    "request_body_policies"
  ],
  "_apply_resolved_guardrails_to_metadata": [
    "data",
    "metadata_variable_name",
    "context"
  ],
  "add_guardrails_from_policy_engine": [
    "data",
    "metadata_variable_name",
    "user_api_key_dict"
  ],
  "add_provider_specific_headers_to_request": [
    "data",
    "headers"
  ],
  "_add_otel_traceparent_to_data": [
    "data",
    "request"
  ],
  "result": [],
  "exit_code": [],
  "custom_sso_handler": [
    "userIDPInfo"
  ],
  "unified_guardrail": [],
  "_get_email_logger_class": [],
  "InternalUsageCache": {
    "__init__": [
      "self",
      "dual_cache"
    ],
    "async_get_cache": [
      "self",
      "key",
      "litellm_parent_otel_span",
      "local_only"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value",
      "litellm_parent_otel_span",
      "local_only"
    ],
    "async_batch_set_cache": [
      "self",
      "cache_list",
      "litellm_parent_otel_span",
      "local_only"
    ],
    "async_batch_get_cache": [
      "self",
      "keys",
      "parent_otel_span",
      "local_only"
    ],
    "async_increment_cache": [
      "self",
      "key",
      "value",
      "litellm_parent_otel_span",
      "local_only"
    ],
    "set_cache": [
      "self",
      "key",
      "value",
      "local_only"
    ],
    "get_cache": [
      "self",
      "key",
      "local_only"
    ]
  },
  "ProxyLogging": {
    "__init__": [
      "self",
      "user_api_key_cache",
      "premium_user"
    ],
    "startup_event": [
      "self",
      "llm_router",
      "redis_usage_cache"
    ],
    "update_values": [
      "self",
      "alerting",
      "alerting_threshold",
      "redis_cache",
      "alert_types",
      "alerting_args",
      "alert_to_webhook_url"
    ],
    "_add_proxy_hooks": [
      "self",
      "llm_router"
    ],
    "get_proxy_hook": [
      "self",
      "hook"
    ],
    "_init_litellm_callbacks": [
      "self",
      "llm_router"
    ],
    "update_request_status": [
      "self",
      "litellm_call_id",
      "status"
    ],
    "_convert_user_api_key_auth_to_dict": [
      "self",
      "user_api_key_auth_obj"
    ],
    "_convert_mcp_to_llm_format": [
      "self",
      "request_obj",
      "kwargs"
    ],
    "_convert_llm_result_to_mcp_response": [
      "self",
      "llm_result",
      "request_obj"
    ],
    "_extract_modified_arguments_from_content": [
      "self",
      "masked_content",
      "request_obj"
    ],
    "_parse_arguments_manually": [
      "self",
      "args_text",
      "original_args"
    ],
    "_convert_llm_result_to_mcp_during_response": [
      "self",
      "llm_result",
      "request_obj"
    ],
    "get_combined_callback_list": [
      "self",
      "dynamic_success_callbacks",
      "global_callbacks"
    ],
    "_parse_pre_mcp_call_hook_response": [
      "self",
      "response",
      "original_request"
    ],
    "_create_mcp_request_object_from_kwargs": [
      "self",
      "kwargs"
    ],
    "_convert_mcp_hook_response_to_kwargs": [
      "self",
      "response_data",
      "original_kwargs"
    ],
    "process_pre_call_hook_response": [
      "self",
      "response",
      "data",
      "call_type"
    ],
    "_should_use_guardrail_load_balancing": [
      "self",
      "guardrail_name"
    ],
    "_execute_guardrail_hook": [
      "self",
      "callback",
      "hook_type",
      "data",
      "user_api_key_dict",
      "call_type",
      "response"
    ],
    "_execute_guardrail_with_load_balancing": [
      "self",
      "guardrail_name",
      "hook_type",
      "data",
      "user_api_key_dict",
      "call_type",
      "response"
    ],
    "_process_guardrail_callback": [
      "self",
      "callback",
      "data",
      "user_api_key_dict",
      "call_type",
      "event_type"
    ],
    "_process_prompt_template": [
      "self",
      "data",
      "litellm_logging_obj",
      "prompt_id",
      "prompt_version",
      "call_type"
    ],
    "_process_guardrail_metadata": [
      "self",
      "data"
    ],
    "_maybe_execute_pipelines": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type",
      "event_hook"
    ],
    "_handle_pipeline_result": [
      "result",
      "data",
      "policy_name"
    ],
    "pre_call_hook": [
      "self",
      "user_api_key_dict",
      "data",
      "call_type"
    ],
    "during_call_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "failed_tracking_alert": [
      "self",
      "error_message",
      "failing_model"
    ],
    "budget_alerts": [
      "self",
      "type",
      "user_info"
    ],
    "alerting_handler": [
      "self",
      "message",
      "level",
      "alert_type",
      "request_data"
    ],
    "failure_handler": [
      "self",
      "original_exception",
      "duration",
      "call_type",
      "traceback_str"
    ],
    "post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "error_type",
      "route",
      "traceback_str"
    ],
    "_is_proxy_only_llm_api_error": [
      "self",
      "original_exception",
      "error_type",
      "route"
    ],
    "_handle_logging_proxy_only_error": [
      "self",
      "request_data",
      "user_api_key_dict",
      "route",
      "original_exception"
    ],
    "post_call_success_hook": [
      "self",
      "data",
      "response",
      "user_api_key_dict"
    ],
    "post_call_response_headers_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response",
      "request_headers"
    ],
    "is_a2a_streaming_response": [
      "self",
      "response"
    ],
    "async_post_call_streaming_hook": [
      "self",
      "data",
      "response",
      "user_api_key_dict",
      "str_so_far"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "response",
      "user_api_key_dict",
      "request_data"
    ],
    "_init_response_taking_too_long_task": [
      "self",
      "data"
    ]
  },
  "on_backoff": [
    "details"
  ],
  "jsonify_object": [
    "data"
  ],
  "_DEPRECATED_KEY_CACHE_TTL_SECONDS": [],
  "_lookup_deprecated_key": [
    "db",
    "hashed_token"
  ],
  "PrismaClient": {
    "_spend_log_transactions_lock": [],
    "__init__": [
      "self",
      "database_url",
      "proxy_logging_obj",
      "http_client"
    ],
    "get_request_status": [
      "self",
      "payload"
    ],
    "hash_token": [
      "self",
      "token"
    ],
    "jsonify_object": [
      "self",
      "data"
    ],
    "check_view_exists": [
      "self"
    ],
    "get_generic_data": [
      "self",
      "key",
      "value",
      "table_name"
    ],
    "_query_first_with_cached_plan_fallback": [
      "self",
      "sql_query"
    ],
    "get_data": [
      "self",
      "token",
      "user_id",
      "user_id_list",
      "team_id",
      "team_id_list",
      "key_val",
      "table_name",
      "query_type",
      "expires",
      "reset_at",
      "offset",
      "limit",
      "parent_otel_span",
      "proxy_logging_obj",
      "budget_id_list",
      "check_deprecated"
    ],
    "jsonify_team_object": [
      "self",
      "db_data"
    ],
    "insert_data": [
      "self",
      "data",
      "table_name"
    ],
    "update_data": [
      "self",
      "token",
      "data",
      "data_list",
      "user_id",
      "team_id",
      "query_type",
      "table_name",
      "update_key_values",
      "update_key_values_custom_query"
    ],
    "delete_data": [
      "self",
      "tokens",
      "team_id_list",
      "table_name",
      "user_id"
    ],
    "connect": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "_run_reconnect_cycle": [
      "self",
      "timeout_seconds"
    ],
    "attempt_db_reconnect": [
      "self",
      "reason",
      "force",
      "timeout_seconds",
      "lock_timeout_seconds"
    ],
    "_attempt_reconnect_with_lock_timeout": [
      "self",
      "reconnect_fn",
      "reason",
      "lock_timeout_seconds"
    ],
    "start_db_health_watchdog_task": [
      "self"
    ],
    "stop_db_health_watchdog_task": [
      "self"
    ],
    "_db_health_watchdog_loop": [
      "self"
    ],
    "health_check": [
      "self"
    ],
    "_get_spend_logs_row_count": [
      "self"
    ],
    "_set_spend_logs_row_count_in_proxy_state": [
      "self"
    ],
    "_validate_response_time": [
      "self",
      "response_time_ms"
    ],
    "_clean_details": [
      "self",
      "details"
    ],
    "save_health_check_result": [
      "self",
      "model_name",
      "status",
      "healthy_count",
      "unhealthy_count",
      "error_message",
      "response_time_ms",
      "details",
      "checked_by",
      "model_id"
    ],
    "get_health_check_history": [
      "self",
      "model_name",
      "limit",
      "offset",
      "status_filter"
    ],
    "get_all_latest_health_checks": [
      "self"
    ]
  },
  "_cache_user_row": [
    "user_id",
    "cache",
    "db"
  ],
  "send_email": [
    "receiver_email",
    "subject",
    "html"
  ],
  "hash_token": [
    "token"
  ],
  "_hash_token_if_needed": [
    "token"
  ],
  "ProxyUpdateSpend": {
    "update_end_user_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "end_user_list_transactions"
    ],
    "update_spend_logs": [
      "n_retry_times",
      "prisma_client",
      "db_writer_client",
      "proxy_logging_obj"
    ],
    "disable_spend_updates": []
  },
  "update_spend": [
    "prisma_client",
    "db_writer_client",
    "proxy_logging_obj"
  ],
  "update_spend_logs_job": [
    "prisma_client",
    "db_writer_client",
    "proxy_logging_obj"
  ],
  "_monitor_spend_logs_queue": [
    "prisma_client",
    "db_writer_client",
    "proxy_logging_obj"
  ],
  "_raise_failed_update_spend_exception": [
    "e",
    "start_time",
    "proxy_logging_obj"
  ],
  "_get_month_end_date": [
    "today"
  ],
  "_is_projected_spend_over_limit": [
    "current_spend",
    "soft_budget_limit"
  ],
  "_get_projected_spend_over_limit": [
    "current_spend",
    "soft_budget_limit"
  ],
  "_is_valid_team_configs": [
    "team_id",
    "team_config",
    "request_data"
  ],
  "_to_ns": [
    "dt"
  ],
  "_check_and_merge_model_level_guardrails": [
    "data",
    "llm_router"
  ],
  "_merge_guardrails_with_existing": [
    "data",
    "model_level_guardrails"
  ],
  "get_error_message_str": [
    "e"
  ],
  "_get_redoc_url": [],
  "_get_docs_url": [],
  "handle_exception_on_proxy": [
    "e"
  ],
  "_premium_user_check": [
    "feature"
  ],
  "is_known_model": [
    "model",
    "llm_router"
  ],
  "is_known_vector_store_index": [
    "index_name"
  ],
  "join_paths": [
    "base_path",
    "route"
  ],
  "get_custom_url": [
    "request_base_url",
    "route"
  ],
  "get_proxy_base_url": [],
  "get_server_root_path": [],
  "get_prisma_client_or_throw": [
    "message"
  ],
  "is_valid_api_key": [
    "key"
  ],
  "construct_database_url_from_env_vars": [],
  "get_available_models_for_user": [
    "user_api_key_dict",
    "llm_router",
    "general_settings",
    "user_model",
    "prisma_client",
    "proxy_logging_obj",
    "team_id",
    "include_model_access_groups",
    "only_model_access_groups",
    "return_wildcard_routes",
    "user_api_key_cache"
  ],
  "create_model_info_response": [
    "model_id",
    "provider",
    "include_metadata",
    "fallback_type",
    "llm_router"
  ],
  "validate_model_access": [
    "model_id",
    "available_models"
  ],
  "model_dump_with_preserved_fields": [
    "obj",
    "preserve_fields",
    "exclude_unset"
  ],
  "my_custom_validate": [
    "token"
  ],
  "get_current_time": [
    "params"
  ],
  "get_current_date": [
    "params"
  ],
  "masker": [],
  "router": [],
  "_extract_cache_params": [],
  "cache_ping": [],
  "cache_delete": [
    "request"
  ],
  "_get_redis_client_info": [
    "cache_instance"
  ],
  "cache_redis_info": [],
  "cache_flushall": [],
  "SupportedDBObjectType": {
    "MODELS": [],
    "MCP": [],
    "GUARDRAILS": [],
    "POLICIES": [],
    "VECTOR_STORES": [],
    "PASS_THROUGH_ENDPOINTS": [],
    "PROMPTS": [],
    "MODEL_COST_MAP": [],
    "__str__": [
      "self"
    ]
  },
  "LiteLLMTeamRoles": {
    "TEAM_ADMIN": [],
    "TEAM_MEMBER": []
  },
  "LitellmUserRoles": {
    "PROXY_ADMIN": [],
    "PROXY_ADMIN_VIEW_ONLY": [],
    "ORG_ADMIN": [],
    "INTERNAL_USER": [],
    "INTERNAL_USER_VIEW_ONLY": [],
    "TEAM": [],
    "CUSTOMER": [],
    "__str__": [
      "self"
    ],
    "values": [
      "self"
    ],
    "description": [
      "self"
    ],
    "ui_label": [
      "self"
    ],
    "is_internal_user_role": [
      "self"
    ]
  },
  "LitellmTableNames": {
    "TEAM_TABLE_NAME": [],
    "USER_TABLE_NAME": [],
    "KEY_TABLE_NAME": [],
    "PROXY_MODEL_TABLE_NAME": [],
    "MANAGED_FILE_TABLE_NAME": []
  },
  "Litellm_EntityType": {
    "KEY": [],
    "USER": [],
    "END_USER": [],
    "TEAM": [],
    "TEAM_MEMBER": [],
    "ORGANIZATION": [],
    "PROJECT": [],
    "TAG": [],
    "PROXY": []
  },
  "KeyManagementRoutes": {
    "KEY_GENERATE": [],
    "KEY_UPDATE": [],
    "KEY_DELETE": [],
    "KEY_REGENERATE": [],
    "KEY_GENERATE_SERVICE_ACCOUNT": [],
    "KEY_REGENERATE_WITH_PATH_PARAM": [],
    "KEY_BLOCK": [],
    "KEY_UNBLOCK": [],
    "KEY_BULK_UPDATE": [],
    "KEY_RESET_SPEND": [],
    "KEY_INFO": [],
    "KEY_HEALTH": [],
    "KEY_LIST": [],
    "TEAM_DAILY_ACTIVITY": []
  },
  "LiteLLMRoutes": {
    "openai_route_names": [],
    "openai_routes": [],
    "mapped_pass_through_routes": [],
    "passthrough_routes_wildcard": [],
    "litellm_native_routes": [],
    "anthropic_routes": [],
    "mcp_routes": [],
    "agent_routes": [],
    "google_routes": [],
    "apply_guardrail_routes": [],
    "llm_api_routes": [],
    "info_routes": [],
    "master_key_only_routes": [],
    "key_management_routes": [],
    "management_routes": [],
    "spend_tracking_routes": [],
    "global_spend_tracking_routes": [],
    "public_routes": [],
    "ui_routes": [],
    "internal_user_routes": [],
    "internal_user_view_only_routes": [],
    "self_managed_routes": [],
    "org_admin_only_routes": [],
    "admin_viewer_routes": [],
    "org_admin_allowed_routes": []
  },
  "LiteLLMPromptInjectionParams": {
    "check_llm_api_params": [
      "cls",
      "values"
    ]
  },
  "ProxyChatCompletionRequest": {},
  "ModelInfoDelete": {},
  "ProviderInfo": {},
  "BlockUsers": {},
  "ModelParams": {
    "model_config": [],
    "set_model_info": [
      "cls",
      "values"
    ]
  },
  "LiteLLM_ObjectPermissionBase": {},
  "GenerateRequestBase": {
    "model_config": [],
    "check_max_budget": [
      "cls",
      "v"
    ]
  },
  "AllowedVectorStoreIndexItem": {},
  "KeyRequestBase": {},
  "LiteLLMKeyType": {
    "LLM_API": [],
    "MANAGEMENT": [],
    "READ_ONLY": [],
    "DEFAULT": []
  },
  "GenerateKeyRequest": {},
  "GenerateKeyResponse": {
    "set_model_info": [
      "cls",
      "values"
    ]
  },
  "UpdateKeyRequest": {
    "validate_temp_budget": [
      "self"
    ]
  },
  "RegenerateKeyRequest": {},
  "ResetSpendRequest": {},
  "KeyRequest": {
    "validate_at_least_one": [
      "cls",
      "values"
    ]
  },
  "LiteLLM_ModelTable": {
    "model_config": []
  },
  "LiteLLM_ProxyModelTable": {
    "check_potential_json_str": [
      "cls",
      "values"
    ]
  },
  "SpecialMCPServerName": {
    "all_team_servers": [],
    "all_proxy_servers": []
  },
  "NewMCPServerRequest": {
    "validate_transport_fields": [
      "cls",
      "values"
    ],
    "validate_credentials_requirements": [
      "cls",
      "values"
    ]
  },
  "UpdateMCPServerRequest": {
    "validate_transport_fields": [
      "cls",
      "values"
    ]
  },
  "LiteLLM_MCPServerTable": {},
  "MakeMCPServersPublicRequest": {},
  "NewSkillRequest": {},
  "UpdateSkillRequest": {},
  "LiteLLM_SkillsTable": {},
  "ListSkillsRequest": {},
  "NewUserRequestTeam": {},
  "NewUserRequest": {},
  "NewUserResponse": {},
  "UpdateUserRequestNoUserIDorEmail": {},
  "UpdateUserRequest": {
    "check_user_info": [
      "cls",
      "values"
    ]
  },
  "DeleteUserRequest": {},
  "AllowedModelRegion": [],
  "BudgetNewRequest": {},
  "BudgetRequest": {},
  "BudgetDeleteRequest": {},
  "CustomerBase": {},
  "NewCustomerRequest": {
    "check_user_info": [
      "cls",
      "values"
    ]
  },
  "UpdateCustomerRequest": {},
  "DeleteCustomerRequest": {},
  "MemberBase": {
    "check_user_info": [
      "cls",
      "values"
    ]
  },
  "Member": {},
  "OrgMember": {},
  "TeamBase": {},
  "NewTeamRequest": {
    "model_config": []
  },
  "GlobalEndUsersSpend": {},
  "UpdateTeamRequest": {},
  "ResetTeamBudgetRequest": {},
  "DeleteTeamRequest": {},
  "BlockTeamRequest": {},
  "BlockKeyRequest": {},
  "AddTeamCallback": {
    "validate_callback_vars": [
      "cls",
      "values"
    ]
  },
  "TeamCallbackMetadata": {
    "validate_callback_vars": [
      "cls",
      "values"
    ]
  },
  "LiteLLM_ObjectPermissionTable": {},
  "LiteLLM_TeamTable": {
    "model_config": [],
    "set_model_info": [
      "cls",
      "values"
    ]
  },
  "LiteLLM_TeamTableCachedObj": {},
  "LiteLLM_DeletedTeamTable": {
    "model_config": []
  },
  "TeamRequest": {},
  "LiteLLM_BudgetTable": {
    "model_config": []
  },
  "LiteLLM_BudgetTableFull": {},
  "LiteLLM_TeamMemberTable": {
    "model_config": []
  },
  "NewOrganizationRequest": {},
  "OrganizationRequest": {},
  "DeleteOrganizationRequest": {},
  "TeamDefaultSettings": {
    "model_config": []
  },
  "DynamoDBArgs": {},
  "PassThroughGuardrailSettings": {},
  "PassThroughGuardrailsConfig": [],
  "PassThroughGenericEndpoint": {},
  "PassThroughEndpointResponse": {},
  "ConfigFieldUpdate": {},
  "ConfigFieldDelete": {},
  "CallbackDelete": {},
  "FieldDetail": {},
  "ConfigList": {},
  "UserHeaderMapping": {
    "model_config": []
  },
  "UserMCPManagementMode": [],
  "ConfigGeneralSettings": {},
  "ConfigYAML": {
    "model_config": []
  },
  "LiteLLM_VerificationToken": {
    "model_config": []
  },
  "LiteLLM_DeletedVerificationToken": {
    "model_config": []
  },
  "LiteLLM_VerificationTokenView": {
    "__init__": [
      "self"
    ]
  },
  "UserAPIKeyAuth": {
    "model_config": [],
    "check_api_key": [
      "cls",
      "values"
    ],
    "_safe_hash_litellm_api_key": [
      "cls",
      "api_key"
    ],
    "get_litellm_internal_health_check_user_api_key_auth": [
      "cls"
    ],
    "get_litellm_cli_user_api_key_auth": [
      "cls"
    ],
    "get_litellm_internal_jobs_user_api_key_auth": [
      "cls"
    ]
  },
  "UserInfoResponse": {},
  "LiteLLM_Config": {},
  "LiteLLM_OrganizationMembershipTable": {
    "model_config": [],
    "populate_user_email": [
      "self"
    ]
  },
  "LiteLLM_OrganizationTableUpdate": {
    "set_model_info": [
      "cls",
      "values"
    ]
  },
  "LiteLLM_UserTable": {
    "set_model_info": [
      "cls",
      "values"
    ],
    "model_config": []
  },
  "LiteLLM_OrganizationTable": {},
  "LiteLLM_OrganizationTableWithMembers": {},
  "NewOrganizationResponse": {},
  "ProjectBase": {},
  "NewProjectRequest": {
    "set_model_info": [
      "cls",
      "values"
    ]
  },
  "UpdateProjectRequest": {
    "set_model_info": [
      "cls",
      "values"
    ]
  },
  "DeleteProjectRequest": {},
  "LiteLLM_ProjectTable": {},
  "NewProjectResponse": {},
  "LiteLLM_ProjectTableCachedObj": {},
  "LiteLLM_UserTableFiltered": {},
  "LiteLLM_UserTableWithKeyCount": {},
  "LiteLLM_EndUserTable": {
    "set_model_info": [
      "cls",
      "values"
    ],
    "model_config": []
  },
  "LiteLLM_TagTable": {
    "set_model_info": [
      "cls",
      "values"
    ],
    "model_config": []
  },
  "LiteLLM_AccessGroupTable": {},
  "LiteLLM_SpendLogs": {},
  "LiteLLM_ErrorLogs": {},
  "AUDIT_ACTIONS": [],
  "LiteLLM_AuditLogs": {
    "cast_changed_by_to_str": [
      "cls",
      "values"
    ],
    "mask_api_keys": [
      "self"
    ]
  },
  "LiteLLM_SpendLogs_ResponseObject": {},
  "TokenCountRequest": {},
  "CallInfo": {},
  "WebhookEvent": {},
  "SpecialModelNames": {
    "all_team_models": [],
    "all_proxy_models": [],
    "no_default_models": []
  },
  "SpecialProxyStrings": {
    "default_user_id": []
  },
  "InvitationNew": {},
  "InvitationUpdate": {},
  "InvitationDelete": {},
  "InvitationModel": {},
  "InvitationClaim": {},
  "ConfigFieldInfo": {},
  "CallbackOnUI": {},
  "AllCallbacks": {},
  "SpendLogsMetadata": {},
  "SpendLogsPayload": {},
  "SpanAttributes": {
    "LLM_SYSTEM": [],
    "LLM_REQUEST_MODEL": [],
    "LLM_REQUEST_MAX_TOKENS": [],
    "LLM_REQUEST_TEMPERATURE": [],
    "LLM_REQUEST_TOP_P": [],
    "LLM_PROMPTS": [],
    "LLM_COMPLETIONS": [],
    "LLM_RESPONSE_MODEL": [],
    "LLM_USAGE_COMPLETION_TOKENS": [],
    "LLM_USAGE_PROMPT_TOKENS": [],
    "GEN_AI_INPUT_MESSAGES": [],
    "GEN_AI_OUTPUT_MESSAGES": [],
    "GEN_AI_USAGE_INPUT_TOKENS": [],
    "GEN_AI_USAGE_OUTPUT_TOKENS": [],
    "GEN_AI_USAGE_TOTAL_TOKENS": [],
    "GEN_AI_OPERATION_NAME": [],
    "GEN_AI_REQUEST_ID": [],
    "GEN_AI_SYSTEM_INSTRUCTIONS": [],
    "GEN_AI_RESPONSE_FINISH_REASONS": [],
    "LLM_TOKEN_TYPE": [],
    "LLM_REQUEST_TYPE": [],
    "LLM_USAGE_TOTAL_TOKENS": [],
    "LLM_USAGE_TOKEN_TYPE": [],
    "LLM_USER": [],
    "LLM_HEADERS": [],
    "LLM_TOP_K": [],
    "LLM_IS_STREAMING": [],
    "LLM_FREQUENCY_PENALTY": [],
    "LLM_PRESENCE_PENALTY": [],
    "LLM_CHAT_STOP_SEQUENCES": [],
    "LLM_REQUEST_FUNCTIONS": [],
    "LLM_REQUEST_REPETITION_PENALTY": [],
    "LLM_RESPONSE_FINISH_REASON": [],
    "LLM_RESPONSE_STOP_REASON": [],
    "LLM_CONTENT_COMPLETION_CHUNK": [],
    "LLM_OPENAI_RESPONSE_SYSTEM_FINGERPRINT": [],
    "LLM_OPENAI_API_BASE": [],
    "LLM_OPENAI_API_VERSION": [],
    "LLM_OPENAI_API_TYPE": []
  },
  "ManagementEndpointLoggingPayload": {},
  "ProxyException": {
    "__init__": [
      "self",
      "message",
      "type",
      "param",
      "code",
      "headers",
      "openai_code",
      "provider_specific_fields"
    ],
    "to_dict": [
      "self"
    ]
  },
  "CommonProxyErrors": {
    "db_not_connected_error": [],
    "no_llm_router": [],
    "not_allowed_access": [],
    "not_premium_user": [],
    "max_parallel_request_limit_reached": [],
    "missing_enterprise_package": [],
    "missing_enterprise_package_docker": []
  },
  "SpendCalculateRequest": {},
  "ProxyErrorTypes": {
    "budget_exceeded": [],
    "no_db_connection": [],
    "token_not_found_in_db": [],
    "key_model_access_denied": [],
    "team_model_access_denied": [],
    "user_model_access_denied": [],
    "org_model_access_denied": [],
    "project_model_access_denied": [],
    "expired_key": [],
    "auth_error": [],
    "internal_server_error": [],
    "bad_request_error": [],
    "not_found_error": [],
    "validation_error": [],
    "cache_ping_error": [],
    "team_member_permission_error": [],
    "key_vector_store_access_denied": [],
    "team_vector_store_access_denied": [],
    "org_vector_store_access_denied": [],
    "team_member_already_in_team": [],
    "get_model_access_error_type_for_object": [
      "cls",
      "object_type"
    ],
    "get_vector_store_access_error_type_for_object": [
      "cls",
      "object_type"
    ]
  },
  "DB_CONNECTION_ERROR_TYPES": [],
  "SSOUserDefinedValues": {},
  "VirtualKeyEvent": {},
  "CreatePassThroughEndpoint": {},
  "LiteLLM_TeamMembership": {
    "safe_get_team_member_rpm_limit": [
      "self"
    ],
    "safe_get_team_member_tpm_limit": [
      "self"
    ]
  },
  "MemberAddRequest": {
    "__init__": [
      "self"
    ]
  },
  "OrgMemberAddRequest": {
    "__init__": [
      "self"
    ]
  },
  "TeamAddMemberResponse": {},
  "OrganizationAddMemberResponse": {},
  "MemberDeleteRequest": {
    "check_user_info": [
      "cls",
      "values"
    ]
  },
  "MemberUpdateResponse": {},
  "TeamMemberAddRequest": {},
  "TeamMemberDeleteRequest": {},
  "TeamMemberUpdateRequest": {},
  "TeamMemberUpdateResponse": {},
  "TeamModelAddRequest": {},
  "TeamModelDeleteRequest": {},
  "OrganizationMemberAddRequest": {},
  "OrganizationMemberDeleteRequest": {},
  "ROLES_WITHIN_ORG": [],
  "OrganizationMemberUpdateRequest": {
    "validate_role": [
      "cls",
      "value"
    ]
  },
  "OrganizationMemberUpdateResponse": {},
  "TeamInfoResponseObjectTeamTable": {},
  "TeamInfoResponseObject": {},
  "TeamListResponseObject": {},
  "KeyListResponseObject": {},
  "CurrentItemRateLimit": {},
  "LoggingCallbackStatus": {},
  "KeyHealthResponse": {},
  "SpecialHeaders": {
    "openai_authorization": [],
    "azure_authorization": [],
    "anthropic_authorization": [],
    "google_ai_studio_authorization": [],
    "azure_apim_authorization": [],
    "custom_litellm_api_key": [],
    "mcp_auth": [],
    "mcp_servers": [],
    "mcp_access_groups": []
  },
  "LitellmDataForBackendLLMCall": {},
  "LitellmMetadataFromRequestHeaders": {},
  "JWTKeyItem": {},
  "JWKKeyValue": [],
  "JWKUrlResponse": {},
  "UserManagementEndpointParamDocStringEnums": {
    "user_id_doc_str": [],
    "user_alias_doc_str": [],
    "teams_doc_str": [],
    "user_email_doc_str": [],
    "send_invite_email_doc_str": [],
    "user_role_doc_str": [],
    "max_budget_doc_str": [],
    "budget_duration_doc_str": [],
    "models_doc_str": [],
    "tpm_limit_doc_str": [],
    "rpm_limit_doc_str": [],
    "auto_create_key_doc_str": [],
    "aliases_doc_str": [],
    "config_doc_str": [],
    "allowed_cache_controls_doc_str": [],
    "blocked_doc_str": [],
    "guardrails_doc_str": [],
    "permissions_doc_str": [],
    "metadata_doc_str": [],
    "max_parallel_requests_doc_str": [],
    "soft_budget_doc_str": [],
    "model_max_budget_doc_str": [],
    "model_rpm_limit_doc_str": [],
    "model_tpm_limit_doc_str": [],
    "spend_doc_str": [],
    "team_id_doc_str": [],
    "duration_doc_str": []
  },
  "PassThroughEndpointLoggingResultValues": [],
  "PassThroughEndpointLoggingTypedDict": {},
  "LiteLLM_ManagementEndpoint_MetadataFields": [],
  "LiteLLM_ManagementEndpoint_MetadataFields_Premium": [],
  "ProviderBudgetResponseObject": {},
  "ProviderBudgetResponse": {},
  "ProxyStateVariables": {},
  "UI_TEAM_ID": [],
  "JWTAuthBuilderResult": {},
  "ClientSideFallbackModel": {},
  "ALL_FALLBACK_MODEL_VALUES": [],
  "RBAC_ROLES": [],
  "OIDCPermissions": {},
  "RoleBasedPermissions": {
    "model_config": []
  },
  "RoleMapping": {},
  "JWTLiteLLMRoleMap": {},
  "ScopeMapping": {
    "model_config": []
  },
  "LiteLLM_JWTAuth": {
    "__init__": [
      "self"
    ]
  },
  "PrismaCompatibleUpdateDBModel": {},
  "SpecialManagementEndpointEnums": {
    "DEFAULT_ORGANIZATION": []
  },
  "TransformRequestBody": {},
  "DefaultInternalUserParams": {},
  "BaseDailySpendTransaction": {},
  "DailyTeamSpendTransaction": {},
  "DailyOrganizationSpendTransaction": {},
  "DailyUserSpendTransaction": {},
  "DailyEndUserSpendTransaction": {},
  "DailyTagSpendTransaction": {},
  "DailyAgentSpendTransaction": {},
  "DBSpendUpdateTransactions": {},
  "SpendUpdateQueueItem": {},
  "LiteLLM_ManagedFileTable": {},
  "LiteLLM_ManagedObjectTable": {},
  "LiteLLM_ManagedVectorStoreTable": {},
  "EnterpriseLicenseData": {},
  "LiteLLM_ManagedVectorStoresTable": {},
  "ResponseLiteLLM_ManagedVectorStore": {},
  "CostEstimateRequest": {},
  "CostEstimateResponse": {},
  "post_response_rule": [
    "input"
  ],
  "logger": [],
  "ILLEGAL_DISPLAY_PARAMS": [],
  "MINIMAL_DISPLAY_PARAMS": [],
  "_get_random_llm_message": [],
  "_clean_endpoint_data": [
    "endpoint_data",
    "details"
  ],
  "filter_deployments_by_id": [
    "model_list"
  ],
  "run_with_timeout": [
    "task",
    "timeout"
  ],
  "_perform_health_check": [
    "model_list",
    "details"
  ],
  "_update_litellm_params_for_health_check": [
    "model_info",
    "litellm_params"
  ],
  "perform_health_check": [
    "model_list",
    "model",
    "cli_model",
    "details"
  ],
  "X42PromptManagement": {
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "integration_name": [
      "self"
    ]
  },
  "x42_prompt_management": [],
  "StreamChunkSerializer": [],
  "StreamErrorSerializer": [],
  "_parse_event_data_for_error": [
    "event_line"
  ],
  "_extract_error_from_sse_chunk": [
    "event_line"
  ],
  "create_response": [
    "generator",
    "media_type",
    "headers",
    "default_status_code"
  ],
  "_override_openai_response_model": [],
  "_get_cost_breakdown_from_logging_obj": [
    "litellm_logging_obj"
  ],
  "ProxyBaseLLMRequestProcessing": {
    "__init__": [
      "self",
      "data"
    ],
    "get_custom_headers": [],
    "common_processing_pre_call_logic": [
      "self",
      "request",
      "general_settings",
      "user_api_key_dict",
      "proxy_logging_obj",
      "proxy_config",
      "route_type",
      "version",
      "user_model",
      "user_temperature",
      "user_request_timeout",
      "user_max_tokens",
      "user_api_base",
      "model",
      "llm_router"
    ],
    "_get_model_id_from_response": [
      "hidden_params",
      "data"
    ],
    "_debug_log_request_payload": [
      "self"
    ],
    "base_process_llm_request": [
      "self",
      "request",
      "fastapi_response",
      "user_api_key_dict",
      "route_type",
      "proxy_logging_obj",
      "general_settings",
      "proxy_config",
      "select_data_generator",
      "llm_router",
      "model",
      "user_model",
      "user_temperature",
      "user_request_timeout",
      "user_max_tokens",
      "user_api_base",
      "version",
      "is_streaming_request",
      "contents"
    ],
    "base_passthrough_process_llm_request": [
      "self",
      "request",
      "fastapi_response",
      "user_api_key_dict",
      "proxy_logging_obj",
      "general_settings",
      "proxy_config",
      "select_data_generator",
      "llm_router",
      "model",
      "user_model",
      "user_temperature",
      "user_request_timeout",
      "user_max_tokens",
      "user_api_base",
      "version"
    ],
    "_is_streaming_response": [
      "self",
      "response"
    ],
    "_is_streaming_request": [
      "self",
      "data",
      "is_streaming_request"
    ],
    "_handle_llm_api_exception": [
      "self",
      "e",
      "user_api_key_dict",
      "proxy_logging_obj",
      "version"
    ],
    "return_sse_chunk": [
      "chunk"
    ],
    "async_streaming_data_generator": [
      "response",
      "user_api_key_dict",
      "request_data",
      "proxy_logging_obj"
    ],
    "async_sse_data_generator": [
      "response",
      "user_api_key_dict",
      "request_data",
      "proxy_logging_obj"
    ],
    "_process_chunk_with_cost_injection": [
      "chunk",
      "model_name"
    ],
    "_inject_cost_into_sse_frame_str": [
      "frame_str",
      "model_name"
    ],
    "_inject_cost_into_usage_dict": [
      "obj",
      "model_name"
    ],
    "maybe_get_model_id": [
      "self",
      "_logging_obj"
    ]
  },
  "showwarning": [
    "message",
    "category",
    "filename",
    "lineno",
    "file",
    "line"
  ],
  "list_of_messages": [],
  "generate_feedback_box": [],
  "enterprise_router": [],
  "server_root_path": [],
  "_license_check": [],
  "proxy_state": [],
  "SENSITIVE_DATA_MASKER": [],
  "ui_link": [],
  "fallback_login_link": [],
  "model_hub_link": [],
  "ui_message": [],
  "custom_swagger_message": [],
  "_title": [],
  "_description": [],
  "cleanup_router_config_variables": [],
  "proxy_shutdown_event": [],
  "_initialize_shared_aiohttp_session": [],
  "proxy_startup_event": [
    "app"
  ],
  "app": [],
  "vertex_live_passthrough_vertex_base": [],
  "get_openapi_schema": [],
  "custom_openapi": [],
  "UserAPIKeyCacheTTLEnum": {
    "in_memory_cache_ttl": []
  },
  "openai_exception_handler": [
    "request",
    "exc"
  ],
  "origins": [],
  "current_dir": [],
  "mount_swagger_ui": [],
  "docs_url": [],
  "user_api_base": [],
  "user_model": [],
  "user_debug": [],
  "user_max_tokens": [],
  "user_request_timeout": [],
  "user_temperature": [],
  "user_telemetry": [],
  "user_config": [],
  "user_headers": [],
  "local_logging": [],
  "experimental": [],
  "log_file": [],
  "worker_config": [],
  "otel_logging": [],
  "user_api_key_cache": [],
  "model_max_budget_limiter": [],
  "user_custom_auth": [],
  "user_custom_key_generate": [],
  "user_custom_sso": [],
  "user_custom_ui_sso_sign_in_handler": [],
  "use_background_health_checks": [],
  "use_shared_health_check": [],
  "use_queue": [],
  "health_check_interval": [],
  "health_check_details": [],
  "litellm_proxy_budget_name": [],
  "litellm_proxy_admin_name": [],
  "proxy_budget_rescheduler_min_time": [],
  "proxy_budget_rescheduler_max_time": [],
  "proxy_batch_polling_interval": [],
  "proxy_batch_write_at": [],
  "litellm_master_key_hash": [],
  "disable_spend_logs": [],
  "jwt_handler": [],
  "proxy_logging_obj": [],
  "async_result": [],
  "celery_app_conn": [],
  "celery_fn": [],
  "scheduler": [],
  "last_model_cost_map_reload": [],
  "last_anthropic_beta_headers_reload": [],
  "check_request_disconnection": [
    "request",
    "llm_api_call_task"
  ],
  "_resolve_typed_dict_type": [
    "typ"
  ],
  "_resolve_pydantic_type": [
    "typ"
  ],
  "load_from_azure_key_vault": [
    "use_azure_key_vault"
  ],
  "cost_tracking": [],
  "update_cache": [
    "token",
    "user_id",
    "end_user_id",
    "team_id",
    "response_cost",
    "parent_otel_span",
    "tags"
  ],
  "run_ollama_serve": [],
  "_run_background_health_check": [],
  "StreamingCallbackError": {},
  "ProxyConfig": {
    "__init__": [
      "self"
    ],
    "is_yaml": [
      "self",
      "config_file_path"
    ],
    "_load_yaml_file": [
      "self",
      "file_path"
    ],
    "_get_config_from_file": [
      "self",
      "config_file_path"
    ],
    "_process_includes": [
      "self",
      "config",
      "base_dir"
    ],
    "save_config": [
      "self",
      "new_config"
    ],
    "_check_for_os_environ_vars": [
      "self",
      "config",
      "depth",
      "max_depth"
    ],
    "_get_team_config": [
      "self",
      "team_id",
      "all_teams_config"
    ],
    "load_team_config": [
      "self",
      "team_id"
    ],
    "_init_cache": [
      "self",
      "cache_params"
    ],
    "switch_on_llm_response_caching": [
      "self"
    ],
    "get_config": [
      "self",
      "config_file_path"
    ],
    "update_config_state": [
      "self",
      "config"
    ],
    "get_config_state": [
      "self"
    ],
    "load_credential_list": [
      "self",
      "config"
    ],
    "parse_search_tools": [
      "self",
      "config"
    ],
    "_load_environment_variables": [
      "self",
      "config"
    ],
    "load_config": [
      "self",
      "router",
      "config_file_path"
    ],
    "_init_non_llm_configs": [
      "self",
      "config"
    ],
    "_init_policy_engine": [
      "self",
      "config",
      "prisma_client",
      "llm_router"
    ],
    "_load_alerting_settings": [
      "self",
      "general_settings"
    ],
    "initialize_secret_manager": [
      "self",
      "key_management_system",
      "config_file_path"
    ],
    "get_model_info_with_id": [
      "self",
      "model",
      "db_model"
    ],
    "_delete_deployment": [
      "self",
      "db_models"
    ],
    "_add_deployment": [
      "self",
      "db_models"
    ],
    "decrypt_model_list_from_db": [
      "self",
      "new_models"
    ],
    "_update_llm_router": [
      "self",
      "new_models",
      "proxy_logging_obj"
    ],
    "_add_callback_from_db_to_in_memory_litellm_callbacks": [
      "self",
      "callback",
      "event_types",
      "existing_callbacks"
    ],
    "_add_callbacks_from_db_config": [
      "self",
      "config_data"
    ],
    "_encrypt_env_variables": [
      "self",
      "environment_variables",
      "new_encryption_key"
    ],
    "_decrypt_and_set_db_env_variables": [
      "self",
      "environment_variables",
      "return_original_value"
    ],
    "_decrypt_db_variables": [
      "self",
      "variables_dict"
    ],
    "_parse_router_settings_value": [
      "value"
    ],
    "_get_hierarchical_router_settings": [
      "self",
      "user_api_key_dict",
      "prisma_client",
      "proxy_logging_obj"
    ],
    "_add_router_settings_from_db_config": [
      "self",
      "config_data",
      "llm_router",
      "prisma_client"
    ],
    "_add_general_settings_from_db_config": [
      "self",
      "config_data",
      "general_settings",
      "proxy_logging_obj"
    ],
    "_reschedule_spend_log_cleanup_job": [
      "self"
    ],
    "_update_general_settings": [
      "self",
      "db_general_settings"
    ],
    "_update_config_fields": [
      "self",
      "current_config",
      "param_name",
      "db_param_value"
    ],
    "_update_config_from_db": [
      "self",
      "prisma_client",
      "config",
      "store_model_in_db"
    ],
    "_should_load_db_object": [
      "self",
      "object_type"
    ],
    "_get_models_from_db": [
      "self",
      "prisma_client"
    ],
    "add_deployment": [
      "self",
      "prisma_client",
      "proxy_logging_obj"
    ],
    "_init_non_llm_objects_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_semantic_filter_settings_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_sso_settings_in_db": [
      "self",
      "prisma_client"
    ],
    "_check_and_reload_model_cost_map": [
      "self",
      "prisma_client"
    ],
    "_check_and_reload_anthropic_beta_headers": [
      "self",
      "prisma_client"
    ],
    "_get_prompt_spec_for_db_prompt": [
      "self",
      "db_prompt"
    ],
    "_init_prompts_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_guardrails_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_policies_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_vector_stores_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_vector_store_indexes_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_mcp_servers_in_db": [
      "self"
    ],
    "_init_agents_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_search_tools_in_db": [
      "self",
      "prisma_client"
    ],
    "_init_pass_through_endpoints_in_db": [
      "self"
    ],
    "decrypt_credentials": [
      "self",
      "credential"
    ],
    "delete_credentials": [
      "self",
      "db_credentials"
    ],
    "get_credentials": [
      "self",
      "prisma_client"
    ]
  },
  "proxy_config": [],
  "save_worker_config": [],
  "initialize": [
    "model",
    "alias",
    "api_base",
    "api_version",
    "debug",
    "detailed_debug",
    "temperature",
    "max_tokens",
    "request_timeout",
    "max_budget",
    "telemetry",
    "drop_params",
    "add_function_to_prompt",
    "headers",
    "save",
    "use_queue",
    "config"
  ],
  "data_generator": [
    "response"
  ],
  "async_assistants_data_generator": [
    "response",
    "user_api_key_dict",
    "request_data"
  ],
  "_get_client_requested_model_for_streaming": [
    "request_data"
  ],
  "_restamp_streaming_chunk_model": [],
  "async_data_generator": [
    "response",
    "user_api_key_dict",
    "request_data"
  ],
  "select_data_generator": [
    "response",
    "user_api_key_dict",
    "request_data"
  ],
  "get_litellm_model_info": [
    "model"
  ],
  "giveup": [
    "e"
  ],
  "ProxyStartupEvent": {
    "_initialize_startup_logging": [
      "cls",
      "llm_router",
      "proxy_logging_obj",
      "redis_usage_cache"
    ],
    "_initialize_semantic_tool_filter": [
      "cls",
      "llm_router",
      "litellm_settings"
    ],
    "_initialize_jwt_auth": [
      "cls",
      "general_settings",
      "prisma_client",
      "user_api_key_cache"
    ],
    "_add_proxy_budget_to_db": [
      "cls",
      "litellm_proxy_budget_name"
    ],
    "_warm_global_spend_cache": [
      "cls",
      "litellm_proxy_admin_name",
      "user_api_key_cache",
      "prisma_client"
    ],
    "_update_default_team_member_budget": [
      "cls"
    ],
    "initialize_scheduled_background_jobs": [
      "cls",
      "general_settings",
      "prisma_client",
      "proxy_budget_rescheduler_min_time",
      "proxy_budget_rescheduler_max_time",
      "proxy_batch_write_at",
      "proxy_logging_obj"
    ],
    "_initialize_spend_tracking_background_jobs": [
      "cls",
      "scheduler"
    ],
    "_initialize_slack_alerting_jobs": [
      "cls",
      "scheduler",
      "general_settings",
      "proxy_logging_obj",
      "prisma_client"
    ],
    "_setup_prisma_client": [
      "cls",
      "database_url",
      "proxy_logging_obj",
      "user_api_key_cache"
    ],
    "_init_dd_tracer": [
      "cls"
    ],
    "_init_pyroscope": [
      "cls"
    ]
  },
  "model_info": [
    "model_id",
    "user_api_key_dict"
  ],
  "chat_completion": [
    "request",
    "fastapi_response",
    "model",
    "user_api_key_dict"
  ],
  "embeddings": [
    "request",
    "fastapi_response",
    "model",
    "user_api_key_dict"
  ],
  "moderations": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_audio_speech_chunk_generator": [
    "_response"
  ],
  "audio_speech": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "audio_transcriptions": [
    "request",
    "fastapi_response",
    "file",
    "user_api_key_dict"
  ],
  "vertex_ai_live_passthrough_endpoint": [
    "websocket",
    "model",
    "vertex_project",
    "vertex_location",
    "user_api_key_dict"
  ],
  "_realtime_query_params_template": [
    "model",
    "intent"
  ],
  "realtime_websocket_endpoint": [
    "websocket",
    "model",
    "intent",
    "user_api_key_dict"
  ],
  "create_assistant": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "create_threads": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "add_messages": [
    "request",
    "thread_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_get_provider_token_counter": [
    "deployment",
    "model_to_use"
  ],
  "supported_openai_params": [
    "model"
  ],
  "transform_request": [
    "request"
  ],
  "_check_if_model_is_user_added": [
    "models",
    "user_api_key_dict",
    "prisma_client"
  ],
  "_check_if_model_is_team_model": [
    "models",
    "user_row"
  ],
  "non_admin_all_models": [
    "all_models",
    "llm_router",
    "user_api_key_dict",
    "prisma_client"
  ],
  "_add_team_models_to_all_models": [
    "team_db_objects_typed",
    "llm_router"
  ],
  "get_all_team_models": [
    "user_teams",
    "prisma_client",
    "llm_router"
  ],
  "get_direct_access_models": [
    "user_db_object",
    "llm_router"
  ],
  "get_all_team_and_direct_access_models": [
    "user_api_key_dict",
    "prisma_client",
    "llm_router",
    "all_models"
  ],
  "_enrich_model_info_with_litellm_data": [
    "model",
    "debug",
    "llm_router"
  ],
  "_apply_search_filter_to_models": [
    "all_models",
    "search",
    "page",
    "size",
    "prisma_client",
    "proxy_config",
    "sort_by"
  ],
  "_normalize_datetime_for_sorting": [
    "dt"
  ],
  "_sort_models": [
    "all_models",
    "sort_by",
    "sort_order"
  ],
  "_paginate_models_response": [
    "all_models",
    "page",
    "size",
    "total_count",
    "search"
  ],
  "_filter_models_by_team_id": [
    "all_models",
    "team_id",
    "prisma_client",
    "llm_router"
  ],
  "_find_model_by_id": [
    "model_id",
    "search",
    "llm_router",
    "prisma_client",
    "proxy_config"
  ],
  "model_info_v2": [
    "user_api_key_dict",
    "model",
    "user_models_only",
    "include_team_models",
    "debug",
    "page",
    "size",
    "search",
    "modelId",
    "teamId",
    "sortBy",
    "sortOrder"
  ],
  "model_streaming_metrics": [
    "user_api_key_dict",
    "_selected_model_group",
    "startTime",
    "endTime"
  ],
  "model_metrics": [
    "user_api_key_dict",
    "_selected_model_group",
    "startTime",
    "endTime",
    "api_key",
    "customer"
  ],
  "model_metrics_slow_responses": [
    "user_api_key_dict",
    "_selected_model_group",
    "startTime",
    "endTime",
    "api_key",
    "customer"
  ],
  "model_metrics_exceptions": [
    "user_api_key_dict",
    "_selected_model_group",
    "startTime",
    "endTime",
    "api_key",
    "customer"
  ],
  "_get_proxy_model_info": [
    "model"
  ],
  "model_info_v1": [
    "user_api_key_dict",
    "litellm_model_id"
  ],
  "_get_model_group_info": [
    "llm_router",
    "all_models_str",
    "model_group"
  ],
  "model_group_info": [
    "user_api_key_dict",
    "model_group"
  ],
  "model_settings": [],
  "alerting_settings": [
    "user_api_key_dict"
  ],
  "async_queue_request": [
    "request",
    "fastapi_response",
    "model",
    "user_api_key_dict"
  ],
  "fallback_login": [
    "request"
  ],
  "login": [
    "request"
  ],
  "login_v2": [
    "request"
  ],
  "onboarding": [
    "invite_link",
    "request"
  ],
  "claim_onboarding_link": [
    "data"
  ],
  "get_logo_url": [],
  "get_image": [],
  "new_invitation": [
    "data",
    "user_api_key_dict"
  ],
  "invitation_info": [
    "invitation_id",
    "user_api_key_dict"
  ],
  "invitation_update": [
    "data",
    "user_api_key_dict"
  ],
  "invitation_delete": [
    "data",
    "user_api_key_dict"
  ],
  "update_config": [
    "config_info"
  ],
  "update_config_general_settings": [
    "data",
    "user_api_key_dict"
  ],
  "get_config_general_settings": [
    "field_name",
    "user_api_key_dict"
  ],
  "get_config_list": [
    "config_type",
    "user_api_key_dict"
  ],
  "delete_config_general_settings": [
    "data",
    "user_api_key_dict"
  ],
  "delete_callback": [
    "data",
    "user_api_key_dict"
  ],
  "get_config": [],
  "config_yaml_endpoint": [
    "config_info"
  ],
  "reload_model_cost_map": [
    "user_api_key_dict"
  ],
  "schedule_model_cost_map_reload": [
    "hours",
    "user_api_key_dict"
  ],
  "cancel_model_cost_map_reload": [
    "user_api_key_dict"
  ],
  "get_model_cost_map_reload_status": [
    "user_api_key_dict"
  ],
  "reload_anthropic_beta_headers": [
    "user_api_key_dict"
  ],
  "schedule_anthropic_beta_headers_reload": [
    "hours",
    "user_api_key_dict"
  ],
  "cancel_anthropic_beta_headers_reload": [
    "user_api_key_dict"
  ],
  "get_anthropic_beta_headers_reload_status": [
    "user_api_key_dict"
  ],
  "home": [
    "request"
  ],
  "get_routes": [],
  "dynamic_mcp_route": [
    "mcp_server_name",
    "request"
  ],
  "_route_user_config_request": [
    "data",
    "route_type"
  ],
  "_is_a2a_agent_model": [
    "model_name"
  ],
  "ROUTE_ENDPOINT_MAPPING": [],
  "ProxyModelNotFoundError": {
    "__init__": [
      "self",
      "route",
      "model_name"
    ]
  },
  "get_team_id_from_data": [
    "data"
  ],
  "add_shared_session_to_data": [
    "data"
  ],
  "route_request": [
    "data",
    "llm_router",
    "user_model",
    "route_type"
  ],
  "config_filename": [],
  "LiteLLMDatabaseConnectionPool": {
    "database_connection_pool_limit": [],
    "database_connection_pool_timeout": []
  },
  "append_query_params": [
    "url",
    "params"
  ],
  "ProxyInitializationHelpers": {
    "_echo_litellm_version": [],
    "_run_health_check": [
      "host",
      "port"
    ],
    "_run_test_chat_completion": [
      "host",
      "port",
      "model",
      "test"
    ],
    "_get_default_unvicorn_init_args": [
      "host",
      "port",
      "log_config",
      "keepalive_timeout"
    ],
    "_init_hypercorn_server": [
      "app",
      "host",
      "port",
      "ssl_certfile_path",
      "ssl_keyfile_path",
      "ciphers"
    ],
    "_run_gunicorn_server": [
      "host",
      "port",
      "app",
      "num_workers",
      "ssl_certfile_path",
      "ssl_keyfile_path",
      "max_requests_before_restart"
    ],
    "_run_ollama_serve": [],
    "_is_port_in_use": [
      "port"
    ],
    "_get_loop_type": []
  },
  "run_server": [
    "host",
    "port",
    "api_base",
    "api_version",
    "model",
    "alias",
    "add_key",
    "headers",
    "save",
    "debug",
    "detailed_debug",
    "temperature",
    "max_tokens",
    "request_timeout",
    "drop_params",
    "add_function_to_prompt",
    "config",
    "max_budget",
    "telemetry",
    "test",
    "local",
    "num_workers",
    "test_async",
    "iam_token_db_auth",
    "num_requests",
    "use_queue",
    "health",
    "version",
    "run_gunicorn",
    "run_hypercorn",
    "ssl_keyfile_path",
    "ssl_certfile_path",
    "ciphers",
    "log_config",
    "use_prisma_db_push",
    "skip_server_startup",
    "keepalive_timeout",
    "max_requests_before_restart"
  ],
  "user_api_key_auth": [
    "request",
    "api_key"
  ],
  "ComplianceChecker": {
    "__init__": [
      "self",
      "data"
    ],
    "_get_guardrails_by_mode": [
      "self",
      "mode"
    ],
    "_has_guardrail_intervention": [
      "self",
      "guardrails"
    ],
    "_all_guardrails_passed": [
      "self",
      "guardrails"
    ],
    "_check_art_9_guardrails_applied": [
      "self"
    ],
    "_check_art_5_content_screened": [
      "self"
    ],
    "_check_art_12_audit_complete": [
      "self"
    ],
    "_check_art_32_data_protection": [
      "self"
    ],
    "_check_art_5_1c_sensitive_data_protected": [
      "self"
    ],
    "_check_art_30_audit_complete": [
      "self"
    ],
    "check_eu_ai_act": [
      "self"
    ],
    "check_gdpr": [
      "self"
    ]
  },
  "CustomDB": {
    "__init__": [
      "self"
    ],
    "get_data": [
      "self",
      "key",
      "table_name"
    ],
    "insert_data": [
      "self",
      "value",
      "table_name"
    ],
    "update_data": [
      "self",
      "key",
      "value",
      "table_name"
    ],
    "delete_data": [
      "self",
      "keys",
      "table_name"
    ],
    "connect": [
      "self"
    ],
    "disconnect": [
      "self"
    ]
  },
  "_db": [],
  "create_missing_views": [
    "db"
  ],
  "should_create_missing_views": [
    "db"
  ],
  "extract_sql_commands": [
    "diff_output"
  ],
  "check_prisma_schema_diff_helper": [
    "db_url"
  ],
  "check_prisma_schema_diff": [
    "db_url"
  ],
  "PrismaWrapper": {
    "TOKEN_REFRESH_BUFFER_SECONDS": [],
    "FALLBACK_REFRESH_INTERVAL_SECONDS": [],
    "__init__": [
      "self",
      "original_prisma",
      "iam_token_db_auth"
    ],
    "_extract_token_from_db_url": [
      "self",
      "db_url"
    ],
    "_parse_token_expiration": [
      "self",
      "token"
    ],
    "_calculate_seconds_until_refresh": [
      "self"
    ],
    "is_token_expired": [
      "self",
      "token_url"
    ],
    "get_rds_iam_token": [
      "self"
    ],
    "recreate_prisma_client": [
      "self",
      "new_db_url",
      "http_client"
    ],
    "start_token_refresh_task": [
      "self"
    ],
    "stop_token_refresh_task": [
      "self"
    ],
    "_token_refresh_loop": [
      "self"
    ],
    "_safe_refresh_token": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "PrismaManager": {
    "_get_prisma_dir": [],
    "setup_database": [
      "use_migrate"
    ]
  },
  "should_update_prisma_schema": [
    "disable_updates"
  ],
  "log_db_metrics": [
    "func"
  ],
  "_is_exception_related_to_db": [
    "e"
  ],
  "_handle_logging_db_exception": [
    "e",
    "func",
    "kwargs",
    "args",
    "start_time",
    "end_time"
  ],
  "PrismaDBExceptionHandler": {
    "should_allow_request_on_db_unavailable": [],
    "is_database_connection_error": [
      "e"
    ],
    "is_database_transport_error": [
      "e"
    ],
    "handle_db_exception": [
      "e"
    ]
  },
  "DynamoDBWrapper": {
    "__init__": [
      "self",
      "database_arguments"
    ],
    "set_env_vars_based_on_arn": [
      "self"
    ]
  },
  "DBSpendUpdateWriter": {
    "__init__": [
      "self",
      "redis_cache"
    ],
    "update_database": [
      "self",
      "token",
      "user_id",
      "end_user_id",
      "team_id",
      "org_id",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time",
      "response_cost"
    ],
    "_update_key_db": [
      "self",
      "response_cost",
      "hashed_token",
      "prisma_client"
    ],
    "_update_user_db": [
      "self",
      "response_cost",
      "user_id",
      "prisma_client",
      "user_api_key_cache",
      "litellm_proxy_budget_name",
      "end_user_id"
    ],
    "_update_team_db": [
      "self",
      "response_cost",
      "team_id",
      "user_id",
      "prisma_client"
    ],
    "_update_org_db": [
      "self",
      "response_cost",
      "org_id",
      "prisma_client"
    ],
    "_update_tag_db": [
      "self",
      "response_cost",
      "request_tags",
      "prisma_client"
    ],
    "_insert_spend_log_to_db": [
      "self",
      "payload",
      "prisma_client",
      "spend_logs_url"
    ],
    "db_update_spend_transaction_handler": [
      "self",
      "prisma_client",
      "n_retry_times",
      "proxy_logging_obj"
    ],
    "_commit_spend_updates_to_db_with_redis": [
      "self",
      "prisma_client",
      "n_retry_times",
      "proxy_logging_obj"
    ],
    "_commit_spend_updates_to_db_without_redis_buffer": [
      "self",
      "prisma_client",
      "n_retry_times",
      "proxy_logging_obj"
    ],
    "_commit_spend_updates_to_db": [
      "self",
      "prisma_client",
      "n_retry_times",
      "proxy_logging_obj",
      "db_spend_update_transactions"
    ],
    "_update_entity_spend_in_db": [
      "entity_name",
      "transactions",
      "table_accessor",
      "where_field",
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj"
    ],
    "_update_daily_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions",
      "entity_type",
      "entity_id_field",
      "table_name",
      "unique_constraint_name"
    ],
    "update_daily_user_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions"
    ],
    "update_daily_team_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions"
    ],
    "update_daily_org_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions"
    ],
    "update_daily_end_user_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions"
    ],
    "update_daily_agent_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions"
    ],
    "update_daily_tag_spend": [
      "n_retry_times",
      "prisma_client",
      "proxy_logging_obj",
      "daily_spend_transactions"
    ],
    "_common_add_spend_log_transaction_to_daily_transaction": [
      "self",
      "payload",
      "prisma_client",
      "type"
    ],
    "add_spend_log_transaction_to_daily_user_transaction": [
      "self",
      "payload",
      "prisma_client"
    ],
    "add_spend_log_transaction_to_daily_team_transaction": [
      "self",
      "payload",
      "prisma_client"
    ],
    "add_spend_log_transaction_to_daily_org_transaction": [
      "self",
      "payload",
      "prisma_client",
      "org_id"
    ],
    "add_spend_log_transaction_to_daily_end_user_transaction": [
      "self",
      "payload",
      "prisma_client"
    ],
    "add_spend_log_transaction_to_daily_agent_transaction": [
      "self",
      "payload",
      "prisma_client"
    ],
    "add_spend_log_transaction_to_daily_tag_transaction": [
      "self",
      "payload",
      "prisma_client"
    ]
  },
  "PodLockManager": {
    "__init__": [
      "self",
      "redis_cache"
    ],
    "get_redis_lock_key": [
      "cronjob_id"
    ],
    "acquire_lock": [
      "self",
      "cronjob_id"
    ],
    "release_lock": [
      "self",
      "cronjob_id"
    ],
    "_emit_acquired_lock_event": [
      "cronjob_id",
      "pod_id"
    ],
    "_emit_released_lock_event": [
      "cronjob_id",
      "pod_id"
    ]
  },
  "SpendLogCleanup": {
    "__init__": [
      "self",
      "general_settings",
      "redis_cache"
    ],
    "_should_delete_spend_logs": [
      "self"
    ],
    "_delete_old_logs": [
      "self",
      "prisma_client",
      "cutoff_date"
    ],
    "cleanup_old_spend_logs": [
      "self",
      "prisma_client"
    ]
  },
  "RedisUpdateBuffer": {
    "__init__": [
      "self",
      "redis_cache"
    ],
    "_should_commit_spend_updates_to_redis": [],
    "_store_transactions_in_redis": [
      "self",
      "transactions",
      "redis_key",
      "service_type"
    ],
    "store_in_memory_spend_updates_in_redis": [
      "self",
      "spend_update_queue",
      "daily_spend_update_queue",
      "daily_team_spend_update_queue",
      "daily_org_spend_update_queue",
      "daily_end_user_spend_update_queue",
      "daily_agent_spend_update_queue",
      "daily_tag_spend_update_queue"
    ],
    "_number_of_transactions_to_store_in_redis": [
      "db_spend_update_transactions"
    ],
    "_remove_prefix_from_keys": [
      "data",
      "prefix"
    ],
    "get_all_update_transactions_from_redis_buffer": [
      "self"
    ],
    "get_all_daily_spend_update_transactions_from_redis_buffer": [
      "self"
    ],
    "get_all_daily_team_spend_update_transactions_from_redis_buffer": [
      "self"
    ],
    "get_all_daily_org_spend_update_transactions_from_redis_buffer": [
      "self"
    ],
    "get_all_daily_end_user_spend_update_transactions_from_redis_buffer": [
      "self"
    ],
    "get_all_daily_agent_spend_update_transactions_from_redis_buffer": [
      "self"
    ],
    "get_all_daily_tag_spend_update_transactions_from_redis_buffer": [
      "self"
    ],
    "_parse_list_of_transactions": [
      "list_of_transactions"
    ],
    "_combine_list_of_transactions": [
      "list_of_transactions"
    ],
    "_emit_new_item_added_to_redis_buffer_event": [
      "self",
      "service",
      "queue_size"
    ]
  },
  "BaseUpdateQueue": {
    "__init__": [
      "self"
    ],
    "add_update": [
      "self",
      "update"
    ],
    "flush_all_updates_from_in_memory_queue": [
      "self"
    ],
    "_emit_new_item_added_to_queue_event": [
      "self",
      "queue_size"
    ]
  },
  "DailySpendUpdateQueue": {
    "__init__": [
      "self"
    ],
    "add_update": [
      "self",
      "update"
    ],
    "aggregate_queue_updates": [
      "self"
    ],
    "flush_and_get_aggregated_daily_spend_update_transactions": [
      "self"
    ],
    "get_aggregated_daily_spend_update_transactions": [
      "updates"
    ],
    "_emit_new_item_added_to_queue_event": [
      "self",
      "queue_size"
    ]
  },
  "SpendUpdateQueue": {
    "__init__": [
      "self"
    ],
    "flush_and_get_aggregated_db_spend_update_transactions": [
      "self"
    ],
    "add_update": [
      "self",
      "update"
    ],
    "aggregate_queue_updates": [
      "self"
    ],
    "_get_aggregated_spend_update_queue_item": [
      "self",
      "updates"
    ],
    "get_aggregated_db_spend_update_transactions": [
      "self",
      "updates"
    ],
    "_emit_new_item_added_to_queue_event": [
      "self",
      "queue_size"
    ]
  },
  "AgentRegistry": {
    "__init__": [
      "self"
    ],
    "reset_agent_list": [
      "self"
    ],
    "register_agent": [
      "self",
      "agent_config"
    ],
    "deregister_agent": [
      "self",
      "agent_name"
    ],
    "get_agent_list": [
      "self",
      "agent_names"
    ],
    "get_public_agent_list": [
      "self"
    ],
    "_create_agent_id": [
      "self",
      "agent_config"
    ],
    "load_agents_from_config": [
      "self",
      "agent_config"
    ],
    "load_agents_from_db_and_config": [
      "self",
      "agent_config",
      "db_agents"
    ],
    "add_agent_to_db": [
      "self",
      "agent",
      "prisma_client",
      "created_by"
    ],
    "delete_agent_from_db": [
      "self",
      "agent_id",
      "prisma_client"
    ],
    "patch_agent_in_db": [
      "self",
      "agent_id",
      "agent",
      "prisma_client",
      "updated_by"
    ],
    "update_agent_in_db": [
      "self",
      "agent_id",
      "agent",
      "prisma_client",
      "updated_by"
    ],
    "get_all_agents_from_db": [
      "prisma_client"
    ],
    "get_agent_by_id": [
      "self",
      "agent_id"
    ],
    "get_agent_by_name": [
      "self",
      "agent_name"
    ]
  },
  "global_agent_registry": [],
  "get_agents": [
    "request",
    "user_api_key_dict"
  ],
  "create_agent": [
    "request",
    "user_api_key_dict"
  ],
  "get_agent_by_id": [
    "agent_id"
  ],
  "update_agent": [
    "agent_id",
    "request",
    "user_api_key_dict"
  ],
  "patch_agent": [
    "agent_id",
    "request",
    "user_api_key_dict"
  ],
  "delete_agent": [
    "agent_id"
  ],
  "make_agent_public": [
    "agent_id",
    "user_api_key_dict"
  ],
  "make_agents_public": [
    "request",
    "user_api_key_dict"
  ],
  "get_agent_daily_activity": [
    "agent_ids",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "page",
    "page_size",
    "exclude_agent_ids",
    "user_api_key_dict"
  ],
  "append_agents_to_model_group": [
    "model_groups",
    "user_api_key_dict"
  ],
  "append_agents_to_model_info": [
    "models",
    "user_api_key_dict"
  ],
  "_jsonrpc_error": [
    "request_id",
    "code",
    "message",
    "status_code"
  ],
  "_get_agent": [
    "agent_id"
  ],
  "_handle_stream_message": [
    "api_base",
    "request_id",
    "params",
    "litellm_params",
    "agent_id",
    "metadata",
    "proxy_server_request"
  ],
  "get_agent_card": [
    "agent_id",
    "request",
    "user_api_key_dict"
  ],
  "invoke_agent_a2a": [
    "agent_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "route_a2a_agent_request": [
    "data",
    "route_type"
  ],
  "AgentRequestHandler": {
    "get_allowed_agents": [
      "user_api_key_auth"
    ],
    "is_agent_allowed": [
      "agent_id",
      "user_api_key_auth"
    ],
    "_get_key_object_permission": [
      "user_api_key_auth"
    ],
    "_get_team_object_permission": [
      "user_api_key_auth"
    ],
    "_get_allowed_agents_for_key": [
      "user_api_key_auth"
    ],
    "_get_allowed_agents_for_team": [
      "user_api_key_auth"
    ],
    "_get_config_agent_ids_for_access_groups": [
      "config_agents",
      "access_groups"
    ],
    "_get_db_agent_ids_for_access_groups": [
      "prisma_client",
      "access_groups"
    ],
    "_get_agents_from_access_groups": [
      "access_groups"
    ],
    "get_agent_access_groups": [
      "user_api_key_auth"
    ],
    "_get_agent_access_groups_for_key": [
      "user_api_key_auth"
    ],
    "_get_agent_access_groups_for_team": [
      "user_api_key_auth"
    ]
  },
  "PassThroughGuardrailsConfigInput": [],
  "PassthroughGuardrailHandler": {
    "normalize_config": [
      "guardrails_config"
    ],
    "is_enabled": [
      "guardrails_config"
    ],
    "get_guardrail_names": [
      "guardrails_config"
    ],
    "get_settings": [
      "guardrails_config",
      "guardrail_name"
    ],
    "prepare_input": [
      "request_data",
      "guardrail_settings"
    ],
    "prepare_output": [
      "response_data",
      "guardrail_settings"
    ],
    "execute": [
      "request_data",
      "user_api_key_dict",
      "guardrails_config",
      "event_type"
    ],
    "collect_guardrails": [
      "user_api_key_dict",
      "passthrough_guardrails_config"
    ],
    "get_field_targeted_text": [
      "data",
      "guardrail_name",
      "is_request"
    ]
  },
  "JsonPathExtractor": {
    "extract_fields": [
      "data",
      "jsonpath_expressions"
    ],
    "evaluate": [
      "data",
      "expr"
    ]
  },
  "vertex_llm_base": [],
  "default_vertex_config": [],
  "passthrough_endpoint_router": [],
  "create_request_copy": [
    "request"
  ],
  "is_passthrough_request_using_router_model": [
    "request_body",
    "llm_router"
  ],
  "is_passthrough_request_streaming": [
    "request_body"
  ],
  "llm_passthrough_factory_proxy_route": [
    "custom_llm_provider",
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "gemini_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response"
  ],
  "cohere_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vllm_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "mistral_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "milvus_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "is_streaming_request_fn": [
    "request"
  ],
  "anthropic_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "BEDROCK_ENDPOINT_ACTIONS": [],
  "BEDROCK_STREAMING_ACTIONS": [],
  "_extract_model_from_bedrock_endpoint": [
    "endpoint"
  ],
  "handle_bedrock_passthrough_router_model": [
    "model",
    "endpoint",
    "request",
    "request_body",
    "llm_router",
    "user_api_key_dict",
    "proxy_logging_obj",
    "general_settings",
    "proxy_config",
    "select_data_generator",
    "user_model",
    "user_temperature",
    "user_request_timeout",
    "user_max_tokens",
    "user_api_base",
    "version"
  ],
  "handle_bedrock_count_tokens": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "request_body"
  ],
  "bedrock_llm_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "bedrock_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_resolve_vertex_model_from_router": [
    "model_id",
    "llm_router",
    "encoded_endpoint",
    "endpoint",
    "vertex_project",
    "vertex_location"
  ],
  "_is_bedrock_agent_runtime_route": [
    "endpoint"
  ],
  "assemblyai_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "azure_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "BaseVertexAIPassThroughHandler": {
    "get_default_base_target_url": [
      "vertex_location"
    ],
    "update_base_target_url_with_credential_location": [
      "base_target_url",
      "vertex_location"
    ]
  },
  "VertexAIDiscoveryPassThroughHandler": {
    "get_default_base_target_url": [
      "vertex_location"
    ],
    "update_base_target_url_with_credential_location": [
      "base_target_url",
      "vertex_location"
    ]
  },
  "VertexAIPassThroughHandler": {
    "get_default_base_target_url": [
      "vertex_location"
    ],
    "update_base_target_url_with_credential_location": [
      "base_target_url",
      "vertex_location"
    ]
  },
  "get_vertex_base_url": [
    "vertex_location"
  ],
  "get_vertex_ai_allowed_incoming_headers": [
    "request"
  ],
  "get_vertex_pass_through_handler": [
    "call_type"
  ],
  "_override_vertex_params_from_router_credentials": [
    "router_credentials",
    "vertex_project",
    "vertex_location"
  ],
  "_prepare_vertex_auth_headers": [
    "request",
    "vertex_credentials",
    "router_credentials",
    "vertex_project",
    "vertex_location",
    "base_target_url",
    "get_vertex_pass_through_handler"
  ],
  "_base_vertex_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "get_vertex_pass_through_handler",
    "user_api_key_dict",
    "router_credentials"
  ],
  "vertex_discovery_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response"
  ],
  "vertex_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "openai_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "BaseOpenAIPassThroughHandler": {
    "_base_openai_pass_through_handler": [
      "endpoint",
      "request",
      "fastapi_response",
      "user_api_key_dict",
      "base_target_url",
      "api_key",
      "custom_llm_provider",
      "extra_headers"
    ],
    "_append_openai_beta_header": [
      "headers",
      "request"
    ],
    "_assemble_headers": [
      "api_key",
      "request",
      "extra_headers"
    ],
    "_join_url_paths": [
      "base_url",
      "path",
      "custom_llm_provider"
    ]
  },
  "vertex_ai_live_websocket_passthrough": [
    "websocket",
    "model",
    "vertex_project",
    "vertex_location",
    "user_api_key_dict"
  ],
  "create_vertex_ai_live_websocket_endpoint": [],
  "create_generic_websocket_passthrough_endpoint": [
    "provider",
    "target_url",
    "custom_headers",
    "forward_headers",
    "cost_per_request"
  ],
  "PassthroughEndpointRouter": {
    "__init__": [
      "self"
    ],
    "set_pass_through_credentials": [
      "self",
      "custom_llm_provider",
      "api_base",
      "api_key"
    ],
    "get_credentials": [
      "self",
      "custom_llm_provider",
      "region_name"
    ],
    "_get_vertex_env_vars": [
      "self"
    ],
    "set_default_vertex_config": [
      "self",
      "config"
    ],
    "add_vertex_credentials": [
      "self",
      "project_id",
      "location",
      "vertex_credentials"
    ],
    "_get_deployment_key": [
      "self",
      "project_id",
      "location"
    ],
    "get_vector_store_credentials": [
      "self",
      "vector_store_id"
    ],
    "get_vertex_credentials": [
      "self",
      "project_id",
      "location"
    ],
    "_get_credential_name_for_provider": [
      "self",
      "custom_llm_provider",
      "region_name"
    ],
    "_get_region_name_from_api_base": [
      "self",
      "custom_llm_provider",
      "api_base"
    ],
    "_get_default_env_variable_name_passthrough_endpoint": [
      "custom_llm_provider"
    ]
  },
  "cohere_passthrough_logging_handler": [],
  "PassThroughEndpointLogging": {
    "__init__": [
      "self"
    ],
    "_handle_logging": [
      "self",
      "logging_obj",
      "standard_logging_response_object",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "normalize_llm_passthrough_logging_payload": [
      "self",
      "httpx_response",
      "response_body",
      "request_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "custom_llm_provider"
    ],
    "pass_through_async_success_handler": [
      "self",
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body",
      "passthrough_logging_payload",
      "custom_llm_provider"
    ],
    "is_vertex_route": [
      "self",
      "url_route"
    ],
    "is_anthropic_route": [
      "self",
      "url_route"
    ],
    "is_cohere_route": [
      "self",
      "url_route"
    ],
    "is_assemblyai_route": [
      "self",
      "url_route"
    ],
    "is_langfuse_route": [
      "self",
      "url_route"
    ],
    "is_vertex_ai_live_route": [
      "self",
      "url_route"
    ],
    "is_openai_route": [
      "self",
      "url_route"
    ],
    "is_gemini_route": [
      "self",
      "url_route",
      "custom_llm_provider"
    ],
    "_is_supported_openai_endpoint": [
      "self",
      "url_route"
    ],
    "_set_cost_per_request": [
      "self",
      "logging_obj",
      "passthrough_logging_payload",
      "kwargs"
    ]
  },
  "PassThroughStreamingHandler": {
    "chunk_processor": [
      "response",
      "request_body",
      "litellm_logging_obj",
      "endpoint_type",
      "start_time",
      "passthrough_success_handler_obj",
      "url_route"
    ],
    "_route_streaming_logging_to_handler": [
      "litellm_logging_obj",
      "passthrough_success_handler_obj",
      "url_route",
      "request_body",
      "endpoint_type",
      "start_time",
      "raw_bytes",
      "end_time",
      "model"
    ],
    "_extract_model_for_cost_injection": [
      "request_body",
      "url_route",
      "endpoint_type",
      "litellm_logging_obj"
    ],
    "_convert_raw_bytes_to_str_lines": [
      "raw_bytes"
    ]
  },
  "get_litellm_virtual_key": [
    "request"
  ],
  "pass_through_endpoint_logging": [],
  "get_response_body": [
    "response"
  ],
  "set_env_variables_in_header": [
    "custom_headers"
  ],
  "chat_completion_pass_through_endpoint": [
    "fastapi_response",
    "request",
    "adapter_id",
    "user_api_key_dict"
  ],
  "HttpPassThroughEndpointHelpers": {
    "get_response_headers": [
      "headers",
      "litellm_call_id",
      "custom_headers"
    ],
    "get_endpoint_type": [
      "url"
    ],
    "_make_non_streaming_http_request": [
      "request",
      "async_client",
      "url",
      "headers",
      "requested_query_params",
      "custom_body"
    ],
    "non_streaming_http_request_handler": [
      "request",
      "async_client",
      "url",
      "headers",
      "requested_query_params",
      "_parsed_body"
    ],
    "is_multipart": [
      "request"
    ],
    "_build_request_files_from_upload_file": [
      "upload_file"
    ],
    "make_multipart_http_request": [
      "request",
      "async_client",
      "url",
      "headers",
      "requested_query_params"
    ],
    "_init_kwargs_for_pass_through_endpoint": [
      "request",
      "user_api_key_dict",
      "passthrough_logging_payload",
      "logging_obj",
      "_parsed_body",
      "litellm_call_id"
    ],
    "construct_target_url_with_subpath": [
      "base_target",
      "subpath",
      "include_subpath"
    ],
    "_update_stream_param_based_on_request_body": [
      "parsed_body",
      "stream"
    ]
  },
  "pass_through_request": [
    "request",
    "target",
    "custom_headers",
    "user_api_key_dict",
    "custom_body",
    "forward_headers",
    "merge_query_params",
    "query_params",
    "default_query_params",
    "stream",
    "cost_per_request",
    "custom_llm_provider",
    "guardrails_config"
  ],
  "_update_metadata_with_tags_in_header": [
    "request",
    "metadata"
  ],
  "_parse_request_data_by_content_type": [
    "request"
  ],
  "create_pass_through_route": [
    "endpoint",
    "target",
    "custom_headers",
    "_forward_headers",
    "_merge_query_params",
    "dependencies",
    "include_subpath",
    "cost_per_request",
    "custom_llm_provider",
    "is_streaming_request",
    "query_params",
    "default_query_params",
    "guardrails"
  ],
  "create_websocket_passthrough_route": [
    "endpoint",
    "target",
    "custom_headers",
    "_forward_headers",
    "dependencies",
    "cost_per_request"
  ],
  "websocket_passthrough_request": [
    "websocket",
    "target",
    "custom_headers",
    "user_api_key_dict",
    "forward_headers",
    "endpoint",
    "cost_per_request",
    "accept_websocket"
  ],
  "_is_streaming_response": [
    "response"
  ],
  "_extract_model_from_vertex_ai_setup": [
    "setup_response"
  ],
  "SafeRouteAdder": {
    "_is_path_registered": [
      "app",
      "path",
      "methods"
    ],
    "add_api_route_if_not_exists": [
      "app",
      "path",
      "endpoint",
      "methods",
      "dependencies"
    ]
  },
  "InitPassThroughEndpointHelpers": {
    "add_exact_path_route": [
      "app",
      "path",
      "target",
      "custom_headers",
      "forward_headers",
      "merge_query_params",
      "dependencies",
      "cost_per_request",
      "endpoint_id",
      "guardrails",
      "methods",
      "default_query_params"
    ],
    "add_subpath_route": [
      "app",
      "path",
      "target",
      "custom_headers",
      "forward_headers",
      "merge_query_params",
      "dependencies",
      "cost_per_request",
      "endpoint_id",
      "guardrails",
      "methods",
      "default_query_params"
    ],
    "remove_endpoint_routes": [
      "endpoint_id"
    ],
    "clear_all_pass_through_routes": [],
    "get_all_registered_pass_through_routes": [],
    "_build_full_path_with_root": [
      "path"
    ],
    "is_registered_pass_through_route": [
      "route"
    ],
    "get_registered_pass_through_route": [
      "route",
      "method"
    ]
  },
  "_get_combined_pass_through_endpoints": [
    "pass_through_endpoints",
    "config_pass_through_endpoints"
  ],
  "initialize_pass_through_endpoints": [
    "pass_through_endpoints"
  ],
  "_get_pass_through_endpoints_from_config": [],
  "_get_pass_through_endpoints_from_db": [
    "endpoint_id",
    "user_api_key_dict"
  ],
  "_filter_endpoints_by_team_allowed_routes": [
    "team_id",
    "pass_through_endpoints",
    "prisma_client"
  ],
  "get_pass_through_endpoints": [
    "endpoint_id",
    "user_api_key_dict",
    "team_id"
  ],
  "update_pass_through_endpoints": [
    "endpoint_id",
    "data",
    "request",
    "user_api_key_dict"
  ],
  "create_pass_through_endpoints": [
    "data",
    "request",
    "user_api_key_dict"
  ],
  "delete_pass_through_endpoints": [
    "endpoint_id",
    "user_api_key_dict"
  ],
  "_find_endpoint_by_id": [
    "endpoints_data",
    "endpoint_id"
  ],
  "initialize_pass_through_endpoints_in_db": [],
  "AnthropicPassthroughLoggingHandler": {
    "anthropic_passthrough_handler": [
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ],
    "_get_user_from_metadata": [
      "passthrough_logging_payload"
    ],
    "_create_anthropic_response_logging_payload": [
      "litellm_model_response",
      "model",
      "kwargs",
      "start_time",
      "end_time",
      "logging_obj"
    ],
    "_handle_logging_anthropic_collected_chunks": [
      "litellm_logging_obj",
      "passthrough_success_handler_obj",
      "url_route",
      "request_body",
      "endpoint_type",
      "start_time",
      "all_chunks",
      "end_time"
    ],
    "_split_sse_chunk_into_events": [
      "chunk"
    ],
    "_build_complete_streaming_response": [
      "all_chunks",
      "litellm_logging_obj",
      "model"
    ],
    "batch_creation_handler": [
      "httpx_response",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ],
    "_store_batch_managed_object": [
      "unified_object_id",
      "batch_object",
      "model_object_id",
      "logging_obj"
    ],
    "get_actual_model_id_from_router": [
      "model_name"
    ]
  },
  "AssemblyAITranscriptResponse": {},
  "AssemblyAIPassthroughLoggingHandler": {
    "__init__": [
      "self"
    ],
    "assemblyai_passthrough_logging_handler": [
      "self",
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "_handle_assemblyai_passthrough_logging": [
      "self",
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "_get_response_to_log": [
      "self",
      "transcript_response"
    ],
    "_get_assembly_transcript": [
      "self",
      "transcript_id",
      "request_region"
    ],
    "_poll_assembly_for_transcript_response": [
      "self",
      "transcript_id",
      "url_route"
    ],
    "get_cost_for_assembly_transcript": [
      "transcript_response",
      "speech_model"
    ],
    "get_cost_per_second_for_assembly_model": [
      "speech_model"
    ],
    "_should_log_request": [
      "request_method"
    ],
    "_get_assembly_region_from_url": [
      "url"
    ],
    "_get_assembly_base_url_from_region": [
      "region"
    ]
  },
  "vertex_search_api_config": [],
  "VertexPassthroughLoggingHandler": {
    "vertex_passthrough_handler": [
      "httpx_response",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ],
    "_handle_predict_response": [
      "httpx_response",
      "logging_obj",
      "url_route",
      "kwargs"
    ],
    "_handle_logging_vertex_collected_chunks": [
      "litellm_logging_obj",
      "passthrough_success_handler_obj",
      "url_route",
      "request_body",
      "endpoint_type",
      "start_time",
      "all_chunks",
      "model",
      "end_time"
    ],
    "_build_complete_streaming_response": [
      "all_chunks",
      "litellm_logging_obj",
      "model",
      "url_route"
    ],
    "extract_model_from_url": [
      "url"
    ],
    "extract_model_name_from_vertex_path": [
      "vertex_model_path"
    ],
    "_get_vertex_publisher_or_api_spec_from_url": [
      "url"
    ],
    "_get_custom_llm_provider_from_url": [
      "url"
    ],
    "_is_multimodal_embedding_response": [
      "json_response"
    ],
    "_create_vertex_response_logging_payload_for_generate_content": [
      "litellm_model_response",
      "model",
      "kwargs",
      "start_time",
      "end_time",
      "logging_obj",
      "custom_llm_provider"
    ],
    "batch_prediction_jobs_handler": [
      "httpx_response",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "_store_batch_managed_object": [
      "unified_object_id",
      "batch_object",
      "model_object_id",
      "logging_obj"
    ],
    "get_actual_model_id_from_router": [
      "model_name"
    ]
  },
  "OpenAIPassthroughLoggingHandler": {
    "llm_provider_name": [
      "self"
    ],
    "get_provider_config": [
      "self",
      "model"
    ],
    "is_openai_chat_completions_route": [
      "url_route"
    ],
    "is_openai_image_generation_route": [
      "url_route"
    ],
    "is_openai_image_editing_route": [
      "url_route"
    ],
    "is_openai_responses_route": [
      "url_route"
    ],
    "_get_user_from_metadata": [
      "self",
      "passthrough_logging_payload"
    ],
    "_calculate_image_generation_cost": [
      "model",
      "response_body",
      "request_body"
    ],
    "_calculate_image_editing_cost": [
      "model",
      "response_body",
      "request_body"
    ],
    "openai_passthrough_handler": [
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ],
    "_build_complete_streaming_response": [
      "self",
      "all_chunks",
      "litellm_logging_obj",
      "model"
    ],
    "_handle_logging_openai_collected_chunks": [
      "litellm_logging_obj",
      "passthrough_success_handler_obj",
      "url_route",
      "request_body",
      "endpoint_type",
      "start_time",
      "all_chunks",
      "end_time"
    ]
  },
  "VertexAILivePassthroughLoggingHandler": {
    "_build_complete_streaming_response": [
      "self"
    ],
    "get_provider_config": [
      "self",
      "model"
    ],
    "llm_provider_name": [
      "self"
    ],
    "_extract_usage_metadata_from_websocket_messages": [
      "websocket_messages"
    ],
    "_calculate_live_api_cost": [
      "model",
      "usage_metadata",
      "custom_llm_provider"
    ],
    "_create_usage_object_from_metadata": [
      "usage_metadata",
      "model"
    ],
    "vertex_ai_live_passthrough_handler": [
      "self",
      "websocket_messages",
      "logging_obj",
      "url_route",
      "start_time",
      "end_time",
      "request_body"
    ]
  },
  "GeminiPassthroughLoggingHandler": {
    "gemini_passthrough_handler": [
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ],
    "_handle_logging_gemini_collected_chunks": [
      "litellm_logging_obj",
      "passthrough_success_handler_obj",
      "url_route",
      "request_body",
      "endpoint_type",
      "start_time",
      "all_chunks",
      "model",
      "end_time"
    ],
    "_build_complete_streaming_response": [
      "all_chunks",
      "litellm_logging_obj",
      "model",
      "url_route"
    ],
    "extract_model_from_url": [
      "url"
    ],
    "_create_gemini_response_logging_payload_for_generate_content": [
      "litellm_model_response",
      "model",
      "kwargs",
      "start_time",
      "end_time",
      "logging_obj",
      "custom_llm_provider"
    ]
  },
  "CoherePassthroughLoggingHandler": {
    "llm_provider_name": [
      "self"
    ],
    "get_provider_config": [
      "self",
      "model"
    ],
    "_build_complete_streaming_response": [
      "self",
      "all_chunks",
      "litellm_logging_obj",
      "model"
    ],
    "cohere_passthrough_handler": [
      "self",
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ]
  },
  "BasePassthroughLoggingHandler": {
    "llm_provider_name": [
      "self"
    ],
    "get_provider_config": [
      "self",
      "model"
    ],
    "passthrough_chat_handler": [
      "self",
      "httpx_response",
      "response_body",
      "logging_obj",
      "url_route",
      "result",
      "start_time",
      "end_time",
      "cache_hit",
      "request_body"
    ],
    "_get_user_from_metadata": [
      "self",
      "passthrough_logging_payload"
    ],
    "_create_response_logging_payload": [
      "self",
      "litellm_model_response",
      "model",
      "kwargs",
      "start_time",
      "end_time",
      "logging_obj"
    ],
    "_build_complete_streaming_response": [
      "self",
      "all_chunks",
      "litellm_logging_obj",
      "model"
    ],
    "_handle_logging_llm_collected_chunks": [
      "self",
      "litellm_logging_obj",
      "passthrough_success_handler_obj",
      "url_route",
      "request_body",
      "endpoint_type",
      "start_time",
      "all_chunks",
      "end_time"
    ]
  },
  "CustomSSOLoginHandler": {
    "handle_custom_ui_sso_sign_in": [
      "self",
      "request"
    ]
  },
  "custom_ui_sso_sign_in_handler": [],
  "google_generate_content": [
    "request",
    "model_name",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "google_stream_generate_content": [
    "request",
    "model_name",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "google_count_tokens": [
    "request",
    "model_name"
  ],
  "create_interaction": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "get_interaction": [
    "request",
    "interaction_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "delete_interaction": [
    "request",
    "interaction_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "cancel_interaction": [
    "request",
    "interaction_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_AUTHORIZATION_HEADER": [],
  "PrometheusAuthMiddleware": {
    "__init__": [
      "self",
      "app"
    ],
    "__call__": [
      "self",
      "scope",
      "receive",
      "send"
    ]
  },
  "fine_tuning_config": [],
  "set_fine_tuning_config": [
    "config"
  ],
  "get_fine_tuning_provider_config": [
    "custom_llm_provider"
  ],
  "create_fine_tuning_job": [
    "request",
    "fastapi_response",
    "fine_tuning_request",
    "user_api_key_dict"
  ],
  "retrieve_fine_tuning_job": [
    "request",
    "fastapi_response",
    "fine_tuning_job_id",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "list_fine_tuning_jobs": [
    "request",
    "fastapi_response",
    "custom_llm_provider",
    "target_model_names",
    "after",
    "limit",
    "user_api_key_dict"
  ],
  "cancel_fine_tuning_job": [
    "request",
    "fastapi_response",
    "fine_tuning_job_id",
    "user_api_key_dict"
  ],
  "public_model_hub": [],
  "get_mcp_servers": [],
  "public_model_hub_info": [],
  "get_supported_providers": [],
  "get_litellm_model_cost_map": [],
  "get_agent_fields": [],
  "CredentialHelperUtils": {
    "encrypt_credential_values": [
      "credential",
      "new_encryption_key"
    ]
  },
  "create_credential": [
    "request",
    "fastapi_response",
    "credential",
    "user_api_key_dict"
  ],
  "get_credentials": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "get_credential": [
    "request",
    "fastapi_response",
    "credential_name",
    "model_id",
    "user_api_key_dict"
  ],
  "delete_credential": [
    "request",
    "fastapi_response",
    "credential_name",
    "user_api_key_dict"
  ],
  "update_db_credential": [
    "db_credential",
    "updated_patch",
    "new_encryption_key"
  ],
  "update_credential": [
    "request",
    "fastapi_response",
    "credential",
    "credential_name",
    "user_api_key_dict"
  ],
  "_update_request_data_with_managed_file_id": [
    "data",
    "file_id",
    "request",
    "llm_router"
  ],
  "_replace_file_id_in_response": [
    "response",
    "original_file_id"
  ],
  "_update_request_data_with_litellm_managed_vector_store_registry": [
    "data",
    "vector_store_id",
    "llm_router"
  ],
  "_resolve_provider": [],
  "_maybe_check_permissions": [],
  "vector_store_file_create": [
    "vector_store_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vector_store_file_list": [
    "vector_store_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vector_store_file_retrieve": [
    "vector_store_id",
    "file_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vector_store_file_content": [
    "vector_store_id",
    "file_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vector_store_file_update": [
    "vector_store_id",
    "file_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vector_store_file_delete": [
    "vector_store_id",
    "file_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "create_container": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "list_containers": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "retrieve_container": [
    "request",
    "container_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "delete_container": [
    "request",
    "container_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_load_endpoints_config": [],
  "get_all_route_types": [],
  "_get_container_provider_config": [
    "custom_llm_provider"
  ],
  "_create_handler_for_path_params": [
    "path_params",
    "route_type",
    "returns_binary",
    "is_multipart"
  ],
  "_process_binary_request": [
    "request",
    "container_id",
    "file_id",
    "user_api_key_dict"
  ],
  "_process_multipart_upload_request": [
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "route_type",
    "container_id"
  ],
  "_process_request": [
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "route_type",
    "path_params"
  ],
  "register_container_file_endpoints": [
    "router"
  ],
  "UsersManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "list_users": [
      "self",
      "params"
    ],
    "get_user": [
      "self",
      "user_id"
    ],
    "create_user": [
      "self",
      "user_data"
    ],
    "delete_user": [
      "self",
      "user_ids"
    ]
  },
  "KeysManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "list": [
      "self",
      "page",
      "size",
      "user_id",
      "team_id",
      "organization_id",
      "key_hash",
      "key_alias",
      "return_full_object",
      "include_team_keys",
      "return_request"
    ],
    "generate": [
      "self",
      "models",
      "aliases",
      "spend",
      "duration",
      "key_alias",
      "team_id",
      "user_id",
      "budget_id",
      "config",
      "return_request"
    ],
    "delete": [
      "self",
      "keys",
      "key_aliases",
      "return_request"
    ],
    "update": [
      "self",
      "key",
      "models",
      "aliases",
      "spend",
      "duration",
      "key_alias",
      "team_id",
      "user_id"
    ],
    "info": [
      "self",
      "key",
      "return_request"
    ]
  },
  "TeamsManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "list": [
      "self",
      "user_id",
      "organization_id"
    ],
    "list_v2": [
      "self",
      "user_id",
      "organization_id",
      "team_id",
      "team_alias",
      "page",
      "page_size",
      "sort_by",
      "sort_order"
    ],
    "get_available": [
      "self"
    ]
  },
  "ChatClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "completions": [
      "self",
      "model",
      "messages",
      "temperature",
      "top_p",
      "n",
      "max_tokens",
      "presence_penalty",
      "frequency_penalty",
      "user",
      "return_request"
    ],
    "completions_stream": [
      "self",
      "model",
      "messages",
      "temperature",
      "top_p",
      "n",
      "max_tokens",
      "presence_penalty",
      "frequency_penalty",
      "user"
    ]
  },
  "UnauthorizedError": {
    "__init__": [
      "self",
      "orig_exception"
    ]
  },
  "CredentialsManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "list": [
      "self",
      "return_request"
    ],
    "create": [
      "self",
      "credential_name",
      "credential_info",
      "credential_values",
      "return_request"
    ],
    "delete": [
      "self",
      "credential_name",
      "return_request"
    ],
    "get": [
      "self",
      "credential_name",
      "return_request"
    ]
  },
  "HTTPClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key",
      "timeout"
    ],
    "request": [
      "self",
      "method",
      "uri"
    ]
  },
  "Client": {
    "__init__": [
      "self",
      "base_url",
      "api_key",
      "timeout"
    ]
  },
  "ModelGroupsManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "info": [
      "self",
      "return_request"
    ]
  },
  "HealthManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key",
      "timeout"
    ],
    "get_readiness": [
      "self"
    ],
    "get_server_version": [
      "self"
    ]
  },
  "ModelsManagementClient": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "_get_headers": [
      "self"
    ],
    "list": [
      "self",
      "return_request"
    ],
    "new": [
      "self",
      "model_name",
      "model_params",
      "model_info",
      "return_request"
    ],
    "delete": [
      "self",
      "model_id",
      "return_request"
    ],
    "get": [
      "self",
      "model_id",
      "model_name",
      "return_request"
    ],
    "info": [
      "self",
      "return_request"
    ],
    "update": [
      "self",
      "model_id",
      "model_params",
      "model_info",
      "return_request"
    ]
  },
  "print_version": [
    "base_url",
    "api_key"
  ],
  "cli": [
    "ctx",
    "base_url",
    "api_key"
  ],
  "version": [
    "ctx"
  ],
  "styled_prompt": [],
  "show_commands": [],
  "setup_shell": [
    "ctx"
  ],
  "handle_special_commands": [
    "user_input"
  ],
  "execute_command": [
    "user_input",
    "ctx"
  ],
  "interactive_shell": [
    "ctx"
  ],
  "users": [],
  "list_users": [
    "ctx"
  ],
  "get_user": [
    "ctx",
    "user_id"
  ],
  "create_user": [
    "ctx",
    "email",
    "role",
    "alias",
    "team",
    "max_budget"
  ],
  "delete_user": [
    "ctx",
    "user_ids"
  ],
  "keys": [],
  "list": [
    "ctx",
    "page",
    "size",
    "user_id",
    "team_id",
    "organization_id",
    "key_hash",
    "key_alias",
    "include_team_keys",
    "output_format",
    "return_full_object"
  ],
  "generate": [
    "ctx",
    "models",
    "aliases",
    "spend",
    "duration",
    "key_alias",
    "team_id",
    "user_id",
    "budget_id",
    "config"
  ],
  "_parse_created_since_filter": [
    "created_since"
  ],
  "_fetch_all_keys_with_pagination": [
    "source_client",
    "source_base_url"
  ],
  "_filter_keys_by_created_since": [
    "source_keys",
    "created_since_dt",
    "created_since"
  ],
  "_display_dry_run_table": [
    "source_keys"
  ],
  "_prepare_key_import_data": [
    "key"
  ],
  "_import_keys_to_destination": [
    "source_keys",
    "dest_client"
  ],
  "import_keys": [
    "ctx",
    "source_base_url",
    "source_api_key",
    "dry_run",
    "created_since"
  ],
  "get_token_file_path": [],
  "save_token": [
    "token_data"
  ],
  "load_token": [],
  "clear_token": [],
  "get_stored_api_key": [],
  "display_teams_table": [
    "teams"
  ],
  "get_key_input": [],
  "display_interactive_team_selection": [
    "teams",
    "selected_index"
  ],
  "prompt_team_selection": [
    "teams"
  ],
  "prompt_team_selection_fallback": [
    "teams"
  ],
  "_poll_for_ready_data": [
    "url"
  ],
  "_normalize_teams": [
    "teams",
    "team_details"
  ],
  "_poll_for_authentication": [
    "base_url",
    "key_id"
  ],
  "_handle_team_selection_during_polling": [
    "base_url",
    "key_id",
    "teams"
  ],
  "_render_and_prompt_for_team_selection": [
    "teams"
  ],
  "logout": [],
  "whoami": [],
  "teams": [],
  "available": [
    "ctx"
  ],
  "assign_key": [
    "ctx",
    "team_id"
  ],
  "_get_available_models": [
    "ctx"
  ],
  "_select_model": [
    "console",
    "available_models"
  ],
  "chat": [
    "ctx",
    "model",
    "temperature",
    "max_tokens",
    "system"
  ],
  "_show_help": [
    "console"
  ],
  "_show_history": [
    "console",
    "messages"
  ],
  "_save_conversation": [
    "console",
    "messages",
    "command"
  ],
  "_load_conversation": [
    "console",
    "command",
    "system"
  ],
  "_handle_special_commands": [
    "console",
    "user_input",
    "messages",
    "system",
    "ctx"
  ],
  "_stream_response": [
    "console",
    "client",
    "model",
    "messages",
    "temperature",
    "max_tokens"
  ],
  "credentials": [],
  "http": [],
  "request": [
    "ctx",
    "method",
    "uri",
    "data",
    "json",
    "header"
  ],
  "ModelYamlInfo": {
    "access_groups_str": [
      "self"
    ]
  },
  "_get_model_info_obj_from_yaml": [
    "model"
  ],
  "format_iso_datetime_str": [
    "iso_datetime_str"
  ],
  "format_timestamp": [
    "timestamp"
  ],
  "format_cost_per_1k_tokens": [
    "cost"
  ],
  "create_client": [
    "ctx"
  ],
  "models": [],
  "list_models": [
    "ctx",
    "output_format"
  ],
  "add_model": [
    "ctx",
    "model_name",
    "param",
    "info"
  ],
  "delete_model": [
    "ctx",
    "model_id"
  ],
  "get_model": [
    "ctx",
    "model_id",
    "model_name"
  ],
  "get_models_info": [
    "ctx",
    "output_format",
    "columns"
  ],
  "update_model": [
    "ctx",
    "model_id",
    "param",
    "info"
  ],
  "_filter_model": [
    "model",
    "model_regex",
    "access_group_regex"
  ],
  "_print_models_table": [
    "added_models",
    "table_title"
  ],
  "_print_summary_table": [
    "provider_counts"
  ],
  "get_model_list_from_yaml_file": [
    "yaml_file"
  ],
  "_get_filtered_model_list": [
    "model_list",
    "only_models_matching_regex",
    "only_access_groups_matching_regex"
  ],
  "_import_models_get_table_title": [
    "dry_run"
  ],
  "import_models": [
    "ctx",
    "yaml_file",
    "dry_run",
    "only_models_matching_regex",
    "only_access_groups_matching_regex"
  ],
  "my_custom_rule": [
    "input"
  ],
  "SseServerTransport": {
    "__init__": [
      "self",
      "endpoint"
    ],
    "connect_sse": [
      "self",
      "request"
    ],
    "handle_post_message": [
      "self",
      "scope",
      "receive",
      "send"
    ]
  },
  "_SESSION_MANAGERS_INITIALIZED": [],
  "_INITIALIZATION_LOCK": [],
  "LITELLM_MCP_SERVER_NAME": [],
  "LITELLM_MCP_SERVER_VERSION": [],
  "LITELLM_MCP_SERVER_DESCRIPTION": [],
  "MCP_TOOL_PREFIX_SEPARATOR": [],
  "MCP_TOOL_PREFIX_FORMAT": [],
  "is_mcp_available": [],
  "normalize_server_name": [
    "server_name"
  ],
  "validate_and_normalize_mcp_server_payload": [
    "payload"
  ],
  "add_server_prefix_to_name": [
    "name",
    "server_name"
  ],
  "get_server_prefix": [
    "server"
  ],
  "split_server_prefix_from_name": [
    "prefixed_name"
  ],
  "is_tool_name_prefixed": [
    "tool_name"
  ],
  "validate_mcp_server_name": [
    "server_name",
    "raise_http_exception"
  ],
  "merge_mcp_headers": [],
  "MCPCostCalculator": {
    "calculate_mcp_tool_call_cost": [
      "litellm_logging_obj"
    ]
  },
  "get_request_base_url": [
    "request"
  ],
  "encode_state_with_base_url": [
    "base_url",
    "original_state",
    "code_challenge",
    "code_challenge_method",
    "client_redirect_uri"
  ],
  "decode_state_hash": [
    "encrypted_state"
  ],
  "_resolve_oauth2_server_for_root_endpoints": [
    "client_ip"
  ],
  "authorize_with_server": [
    "request",
    "mcp_server",
    "client_id",
    "redirect_uri",
    "state",
    "code_challenge",
    "code_challenge_method",
    "response_type",
    "scope"
  ],
  "exchange_token_with_server": [
    "request",
    "mcp_server",
    "grant_type",
    "code",
    "redirect_uri",
    "client_id",
    "client_secret",
    "code_verifier"
  ],
  "register_client_with_server": [
    "request",
    "mcp_server",
    "client_name",
    "grant_types",
    "response_types",
    "token_endpoint_auth_method",
    "fallback_client_id"
  ],
  "authorize": [
    "request",
    "client_id",
    "redirect_uri",
    "state",
    "mcp_server_name",
    "code_challenge",
    "code_challenge_method",
    "response_type",
    "scope"
  ],
  "token_endpoint": [
    "request",
    "grant_type",
    "code",
    "redirect_uri",
    "client_id",
    "client_secret",
    "code_verifier",
    "mcp_server_name"
  ],
  "callback": [
    "code",
    "state"
  ],
  "_build_oauth_protected_resource_response": [
    "request",
    "mcp_server_name",
    "use_standard_pattern"
  ],
  "oauth_protected_resource_mcp_standard": [
    "request",
    "mcp_server_name"
  ],
  "oauth_protected_resource_mcp": [
    "request",
    "mcp_server_name"
  ],
  "_build_oauth_authorization_server_response": [
    "request",
    "mcp_server_name"
  ],
  "oauth_authorization_server_mcp_standard": [
    "request",
    "mcp_server_name"
  ],
  "oauth_authorization_server_mcp": [
    "request",
    "mcp_server_name"
  ],
  "openid_configuration": [
    "request"
  ],
  "oauth_authorization_server_legacy": [
    "request",
    "mcp_server_name"
  ],
  "register_client": [
    "request",
    "mcp_server_name"
  ],
  "clone_user_api_key_auth_with_team": [
    "user_api_key_auth",
    "team_id"
  ],
  "resolve_ui_session_team_ids": [
    "user_api_key_auth"
  ],
  "build_effective_auth_contexts": [
    "user_api_key_auth"
  ],
  "MCPOAuth2TokenCache": {
    "__init__": [
      "self"
    ],
    "_get_lock": [
      "self",
      "server_id"
    ],
    "async_get_token": [
      "self",
      "server"
    ],
    "_fetch_token": [
      "self",
      "server"
    ],
    "invalidate": [
      "self",
      "server_id"
    ]
  },
  "mcp_oauth2_token_cache": [],
  "resolve_mcp_auth": [
    "server",
    "mcp_auth_header"
  ],
  "BASE_URL": [],
  "_sanitize_path_parameter_value": [
    "param_value",
    "param_name"
  ],
  "load_openapi_spec": [
    "filepath"
  ],
  "load_openapi_spec_async": [
    "filepath"
  ],
  "get_base_url": [
    "spec",
    "spec_path"
  ],
  "extract_parameters": [
    "operation"
  ],
  "build_input_schema": [
    "operation"
  ],
  "create_tool_function": [
    "path",
    "method",
    "operation",
    "base_url",
    "headers"
  ],
  "register_tools_from_openapi": [
    "spec",
    "base_url"
  ],
  "MCP_DEBUG_REQUEST_HEADER": [],
  "_RESPONSE_HEADER_PREFIX": [],
  "MCPDebug": {
    "_masker": [],
    "_mask": [
      "value"
    ],
    "is_debug_enabled": [
      "headers"
    ],
    "resolve_auth_resolution": [
      "server",
      "mcp_auth_header",
      "mcp_server_auth_headers",
      "oauth2_headers"
    ],
    "build_debug_headers": [],
    "wrap_send_with_debug_headers": [
      "send",
      "debug_headers"
    ],
    "maybe_build_debug_headers": []
  },
  "MCPToolRegistry": {
    "__init__": [
      "self"
    ],
    "register_tool": [
      "self",
      "name",
      "description",
      "input_schema",
      "handler"
    ],
    "get_tool": [
      "self",
      "name"
    ],
    "list_tools": [
      "self",
      "tool_prefix"
    ],
    "convert_tools_to_mcp_sdk_tool_type": [
      "self",
      "tools"
    ],
    "load_tools_from_config": [
      "self",
      "mcp_tools_config"
    ]
  },
  "global_mcp_tool_registry": [],
  "SemanticMCPToolFilter": {
    "__init__": [
      "self",
      "embedding_model",
      "litellm_router_instance",
      "top_k",
      "similarity_threshold",
      "enabled"
    ],
    "build_router_from_mcp_registry": [
      "self"
    ],
    "_extract_tool_info": [
      "self",
      "tool"
    ],
    "_build_router": [
      "self",
      "tools"
    ],
    "filter_tools": [
      "self",
      "query",
      "available_tools",
      "top_k"
    ],
    "_extract_tool_names_from_matches": [
      "self",
      "matches"
    ],
    "_get_tools_by_names": [
      "self",
      "tool_names",
      "available_tools"
    ],
    "extract_user_query": [
      "self",
      "messages"
    ]
  },
  "_prepare_mcp_server_data": [
    "data"
  ],
  "encrypt_credentials": [
    "credentials",
    "encryption_key"
  ],
  "get_all_mcp_servers": [
    "prisma_client"
  ],
  "get_mcp_server": [
    "prisma_client",
    "server_id"
  ],
  "get_mcp_servers_by_verificationtoken": [
    "prisma_client",
    "token"
  ],
  "get_mcp_servers_by_team": [
    "prisma_client",
    "team_id"
  ],
  "get_all_mcp_servers_for_user": [
    "prisma_client",
    "user"
  ],
  "get_objectpermissions_for_mcp_server": [
    "prisma_client",
    "mcp_server_id"
  ],
  "get_virtualkeys_for_mcp_server": [
    "prisma_client",
    "server_id"
  ],
  "delete_mcp_server_from_team": [
    "prisma_client",
    "server_id"
  ],
  "delete_mcp_server_from_virtualkey": [],
  "delete_mcp_server": [
    "prisma_client",
    "server_id"
  ],
  "create_mcp_server": [
    "prisma_client",
    "data",
    "touched_by"
  ],
  "update_mcp_server": [
    "prisma_client",
    "data",
    "touched_by"
  ],
  "rotate_mcp_server_credentials_master_key": [
    "prisma_client",
    "touched_by",
    "new_master_key"
  ],
  "_separator_probe_tool_name": [],
  "_separator_probe": [],
  "_warn_on_server_name_fields": [],
  "_deserialize_json_dict": [
    "data"
  ],
  "MCPServerManager": {
    "_STDIO_ENV_TEMPLATE_PATTERN": [],
    "__init__": [
      "self"
    ],
    "get_registry": [
      "self"
    ],
    "load_servers_from_config": [
      "self",
      "mcp_servers_config",
      "mcp_aliases"
    ],
    "_register_openapi_tools": [
      "self",
      "spec_path",
      "server",
      "base_url"
    ],
    "remove_server": [
      "self",
      "mcp_server"
    ],
    "build_mcp_server_from_table": [
      "self",
      "mcp_server"
    ],
    "_maybe_register_openapi_tools": [
      "self",
      "server"
    ],
    "add_server": [
      "self",
      "mcp_server"
    ],
    "update_server": [
      "self",
      "mcp_server"
    ],
    "get_all_mcp_server_ids": [
      "self"
    ],
    "get_allow_all_keys_server_ids": [
      "self"
    ],
    "get_allowed_mcp_servers": [
      "self",
      "user_api_key_auth"
    ],
    "filter_server_ids_by_ip": [
      "self",
      "server_ids",
      "client_ip"
    ],
    "get_tools_for_server": [
      "self",
      "server_id"
    ],
    "list_tools": [
      "self",
      "user_api_key_auth",
      "mcp_auth_header",
      "mcp_server_auth_headers"
    ],
    "_build_stdio_env": [
      "self",
      "server",
      "raw_headers"
    ],
    "_create_mcp_client": [
      "self",
      "server",
      "mcp_auth_header",
      "extra_headers",
      "stdio_env"
    ],
    "_get_tools_from_server": [
      "self",
      "server",
      "mcp_auth_header",
      "extra_headers",
      "add_prefix",
      "raw_headers"
    ],
    "get_prompts_from_server": [
      "self",
      "server",
      "mcp_auth_header",
      "extra_headers",
      "add_prefix",
      "raw_headers"
    ],
    "get_resources_from_server": [
      "self",
      "server",
      "mcp_auth_header",
      "extra_headers",
      "add_prefix",
      "raw_headers"
    ],
    "get_resource_templates_from_server": [
      "self",
      "server",
      "mcp_auth_header",
      "extra_headers",
      "add_prefix",
      "raw_headers"
    ],
    "read_resource_from_server": [
      "self",
      "server",
      "url",
      "mcp_auth_header",
      "extra_headers",
      "raw_headers"
    ],
    "get_prompt_from_server": [
      "self",
      "server",
      "prompt_name",
      "arguments",
      "mcp_auth_header",
      "extra_headers",
      "raw_headers"
    ],
    "_descovery_metadata": [
      "self",
      "server_url"
    ],
    "_parse_www_authenticate_header": [
      "self",
      "header_value"
    ],
    "_fetch_oauth_metadata_from_resource": [
      "self",
      "resource_metadata_url"
    ],
    "_attempt_well_known_discovery": [
      "self",
      "server_url"
    ],
    "_fetch_authorization_server_metadata": [
      "self",
      "authorization_servers"
    ],
    "_fetch_single_authorization_server_metadata": [
      "self",
      "issuer_url"
    ],
    "_extract_scopes": [
      "self",
      "scopes_value"
    ],
    "_fetch_tools_with_timeout": [
      "self",
      "client",
      "server_name"
    ],
    "_create_prefixed_tools": [
      "self",
      "tools",
      "server",
      "add_prefix"
    ],
    "_create_prefixed_prompts": [
      "self",
      "prompts",
      "server",
      "add_prefix"
    ],
    "_create_prefixed_resources": [
      "self",
      "resources",
      "server",
      "add_prefix"
    ],
    "_create_prefixed_resource_templates": [
      "self",
      "resource_templates",
      "server",
      "add_prefix"
    ],
    "check_allowed_or_banned_tools": [
      "self",
      "tool_name",
      "server"
    ],
    "validate_allowed_params": [
      "self",
      "tool_name",
      "arguments",
      "server"
    ],
    "check_tool_permission_for_key_team": [
      "self",
      "tool_name",
      "server",
      "user_api_key_auth"
    ],
    "_call_openapi_tool_handler": [
      "self",
      "server",
      "tool_name",
      "arguments"
    ],
    "pre_call_tool_check": [
      "self",
      "name",
      "arguments",
      "server_name",
      "user_api_key_auth",
      "proxy_logging_obj",
      "server"
    ],
    "_create_during_hook_task": [
      "self",
      "name",
      "arguments",
      "server_name_from_prefix",
      "user_api_key_auth",
      "proxy_logging_obj",
      "start_time"
    ],
    "_call_regular_mcp_tool": [
      "self",
      "mcp_server",
      "original_tool_name",
      "arguments",
      "tasks",
      "mcp_auth_header",
      "mcp_server_auth_headers",
      "oauth2_headers",
      "raw_headers",
      "proxy_logging_obj",
      "host_progress_callback"
    ],
    "call_tool": [
      "self",
      "server_name",
      "name",
      "arguments",
      "user_api_key_auth",
      "mcp_auth_header",
      "mcp_server_auth_headers",
      "proxy_logging_obj",
      "oauth2_headers",
      "raw_headers",
      "host_progress_callback"
    ],
    "initialize_tool_name_to_mcp_server_name_mapping": [
      "self"
    ],
    "_initialize_tool_name_to_mcp_server_name_mapping": [
      "self"
    ],
    "_get_mcp_server_from_tool_name": [
      "self",
      "tool_name"
    ],
    "reload_servers_from_database": [
      "self"
    ],
    "get_mcp_servers_from_ids": [
      "self",
      "server_ids"
    ],
    "_get_general_settings": [
      "self"
    ],
    "_is_server_accessible_from_ip": [
      "self",
      "server",
      "client_ip"
    ],
    "get_mcp_server_by_id": [
      "self",
      "server_id"
    ],
    "get_public_mcp_servers": [
      "self"
    ],
    "get_mcp_server_by_name": [
      "self",
      "server_name",
      "client_ip"
    ],
    "get_filtered_registry": [
      "self",
      "client_ip"
    ],
    "_generate_stable_server_id": [
      "self",
      "server_name",
      "url",
      "transport",
      "auth_type",
      "alias"
    ],
    "health_check_server": [
      "self",
      "server_id",
      "mcp_auth_header"
    ],
    "get_all_mcp_servers_with_health_and_teams": [
      "self",
      "user_api_key_auth",
      "server_ids"
    ],
    "get_all_allowed_mcp_servers": [
      "self",
      "user_api_key_auth"
    ],
    "_build_mcp_server_table": [
      "self",
      "server"
    ],
    "get_all_mcp_servers_unfiltered": [
      "self"
    ],
    "get_all_mcp_servers_with_health_unfiltered": [
      "self",
      "server_ids"
    ],
    "_run_health_checks": [
      "self",
      "target_server_ids"
    ]
  },
  "MCPRequestHandler": {
    "LITELLM_API_KEY_HEADER_NAME_PRIMARY": [],
    "LITELLM_API_KEY_HEADER_NAME_SECONDARY": [],
    "LITELLM_MCP_AUTH_HEADER_NAME": [],
    "LITELLM_MCP_SERVERS_HEADER_NAME": [],
    "LITELLM_MCP_ACCESS_GROUPS_HEADER_NAME": [],
    "process_mcp_request": [
      "scope"
    ],
    "_get_mcp_auth_header_from_headers": [
      "headers"
    ],
    "_get_mcp_server_auth_headers_from_headers": [
      "headers"
    ],
    "_get_oauth2_headers_from_headers": [
      "headers"
    ],
    "_get_mcp_client_side_auth_header_name": [],
    "get_litellm_api_key_from_headers": [
      "headers"
    ],
    "_safe_get_headers_from_scope": [
      "scope"
    ],
    "get_allowed_mcp_servers": [
      "user_api_key_auth"
    ],
    "_get_key_object_permission": [
      "user_api_key_auth"
    ],
    "_get_team_object_permission": [
      "user_api_key_auth"
    ],
    "get_allowed_tools_for_server": [
      "server_id",
      "user_api_key_auth"
    ],
    "is_tool_allowed_for_server": [
      "tool_name",
      "server_id",
      "user_api_key_auth"
    ],
    "is_tool_allowed": [
      "allowed_mcp_servers",
      "server_name"
    ],
    "_get_allowed_mcp_servers_for_key": [
      "user_api_key_auth"
    ],
    "_get_allowed_mcp_servers_for_team": [
      "user_api_key_auth"
    ],
    "_get_allowed_mcp_servers_for_end_user": [
      "user_api_key_auth"
    ],
    "_get_config_server_ids_for_access_groups": [
      "config_mcp_servers",
      "access_groups"
    ],
    "_get_db_server_ids_for_access_groups": [
      "prisma_client",
      "access_groups"
    ],
    "_get_mcp_servers_from_access_groups": [
      "access_groups"
    ],
    "get_mcp_access_groups": [
      "user_api_key_auth"
    ],
    "_get_mcp_access_groups_for_key": [
      "user_api_key_auth"
    ],
    "_get_mcp_access_groups_for_team": [
      "user_api_key_auth"
    ],
    "get_mcp_access_groups_from_headers": [
      "headers"
    ],
    "get_mcp_access_groups_from_scope": [
      "scope"
    ]
  },
  "MCPAuthenticatedUser": {
    "__init__": [
      "self",
      "user_api_key_auth",
      "mcp_auth_header",
      "mcp_servers",
      "mcp_server_auth_headers",
      "oauth2_headers",
      "mcp_protocol_version",
      "raw_headers",
      "client_ip"
    ]
  },
  "MCPGuardrailTranslationHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "guardrail_translation_mappings": [],
  "SearchToolRegistry": {
    "__init__": [
      "self"
    ],
    "_convert_prisma_to_dict": [
      "prisma_obj"
    ],
    "add_search_tool_to_db": [
      "self",
      "search_tool",
      "prisma_client"
    ],
    "delete_search_tool_from_db": [
      "self",
      "search_tool_id",
      "prisma_client"
    ],
    "update_search_tool_in_db": [
      "self",
      "search_tool_id",
      "search_tool",
      "prisma_client"
    ],
    "get_all_search_tools_from_db": [
      "prisma_client"
    ],
    "get_search_tool_by_id_from_db": [
      "self",
      "search_tool_id",
      "prisma_client"
    ],
    "get_search_tool_by_name_from_db": [
      "self",
      "search_tool_name",
      "prisma_client"
    ]
  },
  "SEARCH_TOOL_REGISTRY": [],
  "_convert_datetime_to_str": [
    "value"
  ],
  "list_search_tools": [],
  "CreateSearchToolRequest": {},
  "create_search_tool": [
    "request"
  ],
  "UpdateSearchToolRequest": {},
  "update_search_tool": [
    "search_tool_id",
    "request"
  ],
  "delete_search_tool": [
    "search_tool_id"
  ],
  "get_search_tool_info": [
    "search_tool_id"
  ],
  "TestSearchToolConnectionRequest": {},
  "test_search_tool_connection": [
    "request"
  ],
  "get_available_search_providers": [],
  "convert_priority_to_percent": [
    "value",
    "model_info"
  ],
  "BatchFileUsage": {},
  "_PROXY_BatchRateLimiter": {
    "__init__": [
      "self",
      "internal_usage_cache",
      "parallel_request_limiter"
    ],
    "_raise_rate_limit_error": [
      "self",
      "status",
      "descriptors",
      "batch_usage",
      "limit_type"
    ],
    "_check_and_increment_batch_counters": [
      "self",
      "user_api_key_dict",
      "data",
      "batch_usage"
    ],
    "count_input_file_usage": [
      "self",
      "file_id",
      "custom_llm_provider",
      "user_api_key_dict"
    ],
    "_fetch_managed_file_content": [
      "self",
      "file_id",
      "user_api_key_dict"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "_PROXY_BatchRedisRequests": {
    "__init__": [
      "self"
    ],
    "print_verbose": [
      "self",
      "print_statement",
      "debug_level"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_get_cache": [
      "self"
    ]
  },
  "ResponsesIDSecurity": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "check_user_access_to_response_id": [
      "self",
      "response_id_user_id",
      "response_id_team_id",
      "user_api_key_dict"
    ],
    "_is_encrypted_response_id": [
      "self",
      "response_id"
    ],
    "_decrypt_response_id": [
      "self",
      "response_id"
    ],
    "_get_signing_key": [
      "self"
    ],
    "_encrypt_response_id": [
      "self",
      "response",
      "user_api_key_dict"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ]
  },
  "LITELLM_PREFIX_STORED_VIRTUAL_KEYS": [],
  "KeyManagementEventHooks": {
    "async_key_generated_hook": [
      "data",
      "response",
      "user_api_key_dict",
      "litellm_changed_by"
    ],
    "async_key_updated_hook": [
      "data",
      "existing_key_row",
      "response",
      "user_api_key_dict",
      "litellm_changed_by"
    ],
    "async_key_rotated_hook": [
      "data",
      "existing_key_row",
      "response",
      "user_api_key_dict",
      "litellm_changed_by"
    ],
    "async_key_deleted_hook": [
      "data",
      "keys_being_deleted",
      "response",
      "user_api_key_dict",
      "litellm_changed_by"
    ],
    "_store_virtual_key_in_secret_manager": [
      "secret_name",
      "secret_token",
      "team_id"
    ],
    "_rotate_virtual_key_in_secret_manager": [
      "current_secret_name",
      "new_secret_name",
      "new_secret_value",
      "team_id"
    ],
    "_get_secret_name": [
      "secret_name"
    ],
    "_delete_virtual_keys_from_secret_manager": [
      "keys_being_deleted"
    ],
    "_get_secret_manager_optional_params": [
      "team_id"
    ],
    "_is_email_sending_enabled": [],
    "_send_key_created_email": [
      "response"
    ],
    "_send_key_rotated_email": [
      "response",
      "existing_key_alias"
    ]
  },
  "BATCH_RATE_LIMITER_SCRIPT": [],
  "TOKEN_INCREMENT_SCRIPT": [],
  "REDIS_CLUSTER_SLOTS": [],
  "REDIS_NODE_HASHTAG_NAME": [],
  "RateLimitDescriptorRateLimitObject": {},
  "RateLimitDescriptor": {},
  "RateLimitStatus": {},
  "RateLimitResponse": {},
  "RateLimitResponseWithDescriptors": {},
  "_PROXY_MaxParallelRequestsHandler_v3": {
    "__init__": [
      "self",
      "internal_usage_cache",
      "time_provider"
    ],
    "_get_batch_rate_limiter": [
      "self"
    ],
    "_get_current_time": [
      "self"
    ],
    "_is_redis_cluster": [
      "self"
    ],
    "in_memory_cache_sliding_window": [
      "self",
      "keys",
      "now_int",
      "window_size"
    ],
    "create_rate_limit_keys": [
      "self",
      "key",
      "value",
      "rate_limit_type"
    ],
    "is_cache_list_over_limit": [
      "self",
      "keys_to_fetch",
      "cache_values",
      "key_metadata"
    ],
    "keyslot_for_redis_cluster": [
      "self",
      "key"
    ],
    "_group_keys_by_hash_tag": [
      "self",
      "keys"
    ],
    "_execute_redis_batch_rate_limiter_script": [
      "self",
      "keys_to_fetch",
      "now_int"
    ],
    "should_rate_limit": [
      "self",
      "descriptors",
      "parent_otel_span",
      "read_only"
    ],
    "create_organization_rate_limit_descriptor": [
      "self",
      "user_api_key_dict",
      "requested_model"
    ],
    "_add_model_per_key_rate_limit_descriptor": [
      "self",
      "user_api_key_dict",
      "requested_model",
      "descriptors"
    ],
    "_should_enforce_rate_limit": [
      "self",
      "limit_type",
      "model_has_failures"
    ],
    "_get_enforced_limit": [
      "self",
      "limit_value",
      "limit_type",
      "model_has_failures"
    ],
    "_is_dynamic_rate_limiting_enabled": [
      "self",
      "rpm_limit_type",
      "tpm_limit_type"
    ],
    "_create_rate_limit_descriptors": [
      "self",
      "user_api_key_dict",
      "data",
      "rpm_limit_type",
      "tpm_limit_type",
      "model_has_failures"
    ],
    "_check_model_has_recent_failures": [
      "self",
      "model",
      "parent_otel_span"
    ],
    "get_rate_limiter_for_call_type": [
      "self",
      "call_type"
    ],
    "_add_team_model_rate_limit_descriptor_from_metadata": [
      "self",
      "user_api_key_dict",
      "requested_model",
      "descriptors"
    ],
    "_handle_rate_limit_error": [
      "self",
      "response",
      "descriptors"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "_create_pipeline_operations": [
      "self",
      "key",
      "value",
      "rate_limit_type",
      "total_tokens"
    ],
    "_get_total_tokens_from_usage": [
      "self",
      "usage",
      "rate_limit_type"
    ],
    "_execute_token_increment_script": [
      "self",
      "pipeline_operations"
    ],
    "async_increment_tokens_with_ttl_preservation": [
      "self",
      "pipeline_operations",
      "parent_otel_span"
    ],
    "get_rate_limit_type": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ]
  },
  "DynamicRateLimiterCache": {
    "__init__": [
      "self",
      "cache"
    ],
    "async_get_cache": [
      "self",
      "model"
    ],
    "async_set_cache_sadd": [
      "self",
      "model",
      "value"
    ]
  },
  "_PROXY_DynamicRateLimitHandler": {
    "__init__": [
      "self",
      "internal_usage_cache"
    ],
    "update_variables": [
      "self",
      "llm_router"
    ],
    "check_available_usage": [
      "self",
      "model",
      "priority"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ]
  },
  "VIRTUAL_KEY_SPEND_CACHE_KEY_PREFIX": [],
  "_PROXY_VirtualKeyModelMaxBudgetLimiter": {
    "__init__": [
      "self",
      "dual_cache"
    ],
    "is_key_within_model_budget": [
      "self",
      "user_api_key_dict",
      "model"
    ],
    "_get_virtual_key_spend_for_model": [
      "self",
      "user_api_key_hash",
      "model",
      "key_budget_config"
    ],
    "_get_request_model_budget_config": [
      "self",
      "model",
      "internal_model_max_budget"
    ],
    "_get_model_without_custom_llm_provider": [
      "self",
      "model"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs",
      "parent_otel_span"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "_PROXY_AzureContentSafety": {
    "__init__": [
      "self",
      "endpoint",
      "api_key",
      "thresholds"
    ],
    "_configure_thresholds": [
      "self",
      "thresholds"
    ],
    "_compute_result": [
      "self",
      "response"
    ],
    "test_violation": [
      "self",
      "content",
      "source"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ]
  },
  "_PROXY_CacheControlCheck": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "_PROXY_MaxBudgetLimiter": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "CacheObject": {},
  "_PROXY_MaxParallelRequestsHandler": {
    "__init__": [
      "self",
      "internal_usage_cache"
    ],
    "print_verbose": [
      "self",
      "print_statement"
    ],
    "check_key_in_limits": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type",
      "max_parallel_requests",
      "tpm_limit",
      "rpm_limit",
      "current",
      "request_count_api_key",
      "rate_limit_type",
      "values_to_update_in_cache"
    ],
    "time_to_next_minute": [
      "self"
    ],
    "raise_rate_limit_error": [
      "self",
      "additional_details"
    ],
    "get_all_cache_objects": [
      "self",
      "current_global_requests",
      "request_count_api_key",
      "request_count_api_key_model",
      "request_count_user_id",
      "request_count_team_id",
      "request_count_end_user_id",
      "parent_otel_span"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "get_internal_user_object": [
      "self",
      "user_id",
      "user_api_key_dict"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ]
  },
  "_OPTIONAL_PromptInjectionDetection": {
    "__init__": [
      "self",
      "prompt_injection_params"
    ],
    "print_verbose": [
      "self",
      "print_statement",
      "level"
    ],
    "update_environment": [
      "self",
      "router"
    ],
    "generate_injection_keywords": [
      "self"
    ],
    "check_user_input_similarity": [
      "self",
      "user_input",
      "similarity_threshold"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ]
  },
  "UserManagementEventHooks": {
    "async_user_created_hook": [
      "data",
      "response",
      "user_api_key_dict"
    ],
    "async_send_user_invitation_email": [
      "data",
      "response",
      "user_api_key_dict"
    ],
    "send_legacy_v1_user_invitation_email": [
      "data",
      "response",
      "user_api_key_dict",
      "event"
    ],
    "create_internal_user_audit_log": [
      "user_id",
      "action",
      "litellm_changed_by",
      "user_api_key_dict",
      "litellm_proxy_admin_name",
      "before_value",
      "after_value"
    ]
  },
  "_get_priority_settings": [],
  "_PROXY_DynamicRateLimitHandlerV3": {
    "__init__": [
      "self",
      "internal_usage_cache",
      "time_provider"
    ],
    "update_variables": [
      "self",
      "llm_router"
    ],
    "_get_saturation_check_cache_ttl": [
      "self"
    ],
    "_get_saturation_value_from_cache": [
      "self",
      "counter_key"
    ],
    "_get_priority_weight": [
      "self",
      "priority",
      "model_info"
    ],
    "_get_priority_from_user_api_key_dict": [
      "self",
      "user_api_key_dict"
    ],
    "_normalize_priority_weights": [
      "self",
      "model_info"
    ],
    "_get_priority_allocation": [
      "self",
      "model",
      "priority",
      "normalized_weights",
      "model_info"
    ],
    "_check_model_saturation": [
      "self",
      "model",
      "model_group_info"
    ],
    "_create_priority_based_descriptors": [
      "self",
      "model",
      "user_api_key_dict",
      "priority"
    ],
    "_create_model_tracking_descriptor": [
      "self",
      "model",
      "model_group_info",
      "high_limit_multiplier"
    ],
    "_check_rate_limits": [
      "self",
      "model",
      "model_group_info",
      "user_api_key_dict",
      "priority",
      "saturation",
      "data"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "_ProxyDBLogger": {
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "_PROXY_track_cost_callback": [
      "self",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time"
    ],
    "_should_track_errors_in_db": []
  },
  "_should_track_cost_callback": [
    "user_api_key",
    "user_id",
    "team_id",
    "end_user_id"
  ],
  "PROXY_HOOKS": [],
  "get_proxy_hook": [
    "hook_name"
  ],
  "SkillsInjectionHook": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "_process_for_messages_api": [
      "self",
      "data",
      "litellm_skills",
      "use_anthropic_format"
    ],
    "_process_non_anthropic_model": [
      "self",
      "data",
      "litellm_skills"
    ],
    "_fetch_skill_from_db": [
      "self",
      "skill_id"
    ],
    "_is_anthropic_model": [
      "self",
      "model"
    ],
    "async_post_call_success_deployment_hook": [
      "self",
      "request_data",
      "response",
      "call_type"
    ],
    "_extract_tool_calls": [
      "self",
      "response"
    ],
    "_execute_code_loop_messages_api": [
      "self",
      "data",
      "response",
      "skill_files"
    ],
    "_execute_code": [
      "self",
      "code",
      "skill_files",
      "executor",
      "generated_files"
    ],
    "_execute_skill_tool": [
      "self",
      "tool_name",
      "tool_input",
      "skill_files",
      "executor",
      "generated_files"
    ],
    "_execute_code_loop": [
      "self",
      "data",
      "response",
      "skill_files"
    ],
    "_execute_code_tool": [
      "self",
      "tool_call",
      "skill_files",
      "executor",
      "generated_files"
    ],
    "_attach_files_to_response": [
      "self",
      "response",
      "generated_files"
    ]
  },
  "skills_injection_hook": [],
  "SemanticToolFilterHook": {
    "__init__": [
      "self",
      "semantic_filter"
    ],
    "_should_expand_mcp_tools": [
      "self",
      "tools"
    ],
    "_expand_mcp_tools": [
      "self",
      "tools",
      "user_api_key_dict"
    ],
    "_get_metadata_variable_name": [
      "self",
      "data"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_response_headers_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response",
      "request_headers"
    ],
    "_get_tool_names_csv": [
      "self",
      "tools"
    ],
    "initialize_from_config": [
      "config",
      "llm_router"
    ]
  },
  "handle_nested_budget_structure_in_organization_update_request": [
    "raw_data"
  ],
  "new_organization": [
    "data",
    "user_api_key_dict"
  ],
  "get_organization_daily_activity": [
    "organization_ids",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "page",
    "page_size",
    "exclude_organization_ids",
    "user_api_key_dict"
  ],
  "_set_object_permission": [
    "data",
    "prisma_client"
  ],
  "update_organization": [
    "request",
    "user_api_key_dict"
  ],
  "handle_update_object_permission": [
    "data_json",
    "existing_organization_row"
  ],
  "delete_organization": [
    "data",
    "user_api_key_dict"
  ],
  "list_organization": [
    "org_id",
    "org_alias",
    "user_api_key_dict"
  ],
  "info_organization": [
    "organization_id"
  ],
  "deprecated_info_organization": [
    "data"
  ],
  "organization_member_add": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "find_member_if_email": [
    "user_email",
    "prisma_client"
  ],
  "organization_member_update": [
    "data",
    "user_api_key_dict"
  ],
  "organization_member_delete": [
    "data",
    "user_api_key_dict"
  ],
  "add_member_to_organization": [
    "member",
    "organization_id",
    "prisma_client"
  ],
  "_check_user_permission_for_project": [
    "user_api_key_dict",
    "team_id",
    "prisma_client",
    "require_admin",
    "team_object"
  ],
  "_validate_team_exists": [
    "team_id",
    "prisma_client"
  ],
  "_check_team_project_limits": [
    "team_object",
    "data"
  ],
  "_create_budget_for_project": [
    "data",
    "user_id",
    "litellm_proxy_admin_name",
    "prisma_client"
  ],
  "_set_project_object_permission": [
    "data",
    "prisma_client"
  ],
  "_remove_budget_fields_from_project_data": [
    "project_data"
  ],
  "new_project": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "update_project": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "delete_project": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "project_info": [
    "project_id",
    "user_api_key_dict"
  ],
  "list_projects": [
    "user_api_key_dict"
  ],
  "_resolve_model_for_cost_lookup": [
    "model"
  ],
  "_calculate_period_costs": [
    "num_requests",
    "cost_per_request",
    "input_cost",
    "output_cost",
    "margin_cost"
  ],
  "get_cost_discount_config": [
    "user_api_key_dict"
  ],
  "update_cost_discount_config": [
    "cost_discount_config",
    "user_api_key_dict"
  ],
  "get_cost_margin_config": [
    "user_api_key_dict"
  ],
  "update_cost_margin_config": [
    "cost_margin_config",
    "user_api_key_dict"
  ],
  "estimate_cost": [
    "request",
    "user_api_key_dict"
  ],
  "_require_proxy_admin": [
    "user_api_key_dict"
  ],
  "_record_to_response": [
    "record"
  ],
  "_record_to_access_group_table": [
    "record"
  ],
  "_cache_access_group_record": [
    "record"
  ],
  "_invalidate_cache_access_group": [
    "access_group_id"
  ],
  "create_access_group": [
    "data",
    "user_api_key_dict"
  ],
  "list_access_groups": [
    "user_api_key_dict"
  ],
  "get_access_group": [
    "access_group_id",
    "user_api_key_dict"
  ],
  "update_access_group": [
    "access_group_id",
    "data",
    "user_api_key_dict"
  ],
  "delete_access_group": [
    "access_group_id",
    "user_api_key_dict"
  ],
  "validate_models_exist": [
    "model_names",
    "llm_router"
  ],
  "add_access_group_to_deployment": [
    "model_info",
    "access_group"
  ],
  "update_deployments_with_access_group": [
    "model_names",
    "access_group",
    "prisma_client"
  ],
  "remove_access_group_from_deployment": [
    "model_info",
    "access_group"
  ],
  "get_all_access_groups_from_db": [
    "prisma_client"
  ],
  "create_model_group": [
    "data",
    "user_api_key_dict"
  ],
  "get_access_group_info": [
    "access_group",
    "user_api_key_dict"
  ],
  "check_is_admin_only_access": [
    "ui_access_mode"
  ],
  "has_admin_ui_access": [
    "user_role"
  ],
  "is_valid_litellm_user_role": [
    "role_str"
  ],
  "get_litellm_user_role": [
    "role_str"
  ],
  "CustomOpenID": {},
  "check_eu_ai_act_compliance": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "check_gdpr_compliance": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "update_metrics": [
    "existing_metrics",
    "record"
  ],
  "_is_user_agent_tag": [
    "tag"
  ],
  "compute_tag_metadata_totals": [
    "records"
  ],
  "update_breakdown_metrics": [
    "breakdown",
    "record",
    "model_metadata",
    "provider_metadata",
    "api_key_metadata",
    "entity_id_field",
    "entity_metadata_field"
  ],
  "get_api_key_metadata": [
    "prisma_client",
    "api_keys"
  ],
  "_adjust_dates_for_timezone": [
    "start_date",
    "end_date",
    "timezone_offset_minutes"
  ],
  "_build_where_conditions": [],
  "_build_aggregated_sql_query": [],
  "_aggregate_spend_records": [],
  "get_daily_activity": [
    "prisma_client",
    "table_name",
    "entity_id_field",
    "entity_id",
    "entity_metadata_field",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "page",
    "page_size",
    "exclude_entity_ids",
    "metadata_metrics_func",
    "timezone_offset_minutes"
  ],
  "get_daily_activity_aggregated": [
    "prisma_client",
    "table_name",
    "entity_id_field",
    "entity_id",
    "entity_metadata_field",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "exclude_entity_ids",
    "timezone_offset_minutes"
  ],
  "CacheSettingsManager": {
    "_cache_params_equal": [
      "params1",
      "params2"
    ],
    "init_cache_settings_in_db": [
      "prisma_client",
      "proxy_config"
    ],
    "update_cache_params": [
      "cache_params"
    ]
  },
  "CacheSettingsResponse": {},
  "CacheTestRequest": {},
  "CacheTestResponse": {},
  "CacheSettingsUpdateRequest": {},
  "get_cache_settings": [
    "user_api_key_dict"
  ],
  "test_cache_connection": [
    "request",
    "user_api_key_dict"
  ],
  "update_cache_settings": [
    "request",
    "user_api_key_dict"
  ],
  "new_budget": [
    "budget_obj",
    "user_api_key_dict"
  ],
  "update_budget": [
    "budget_obj",
    "user_api_key_dict"
  ],
  "info_budget": [
    "data"
  ],
  "budget_settings": [
    "budget_id",
    "user_api_key_dict"
  ],
  "list_budget": [
    "user_api_key_dict"
  ],
  "delete_budget": [
    "data",
    "user_api_key_dict"
  ],
  "TEMPORARY_MCP_SERVER_TTL_SECONDS": [],
  "DEFAULT_MCP_REGISTRY_VERSION": [],
  "add_team_callbacks": [
    "data",
    "http_request",
    "team_id",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "disable_team_logging": [
    "http_request",
    "team_id",
    "user_api_key_dict"
  ],
  "get_team_callbacks": [
    "http_request",
    "team_id",
    "user_api_key_dict"
  ],
  "block_user": [
    "data"
  ],
  "unblock_user": [
    "data"
  ],
  "new_budget_request": [
    "data"
  ],
  "_handle_customer_object_permission_update": [
    "non_default_values",
    "end_user_table_data_typed",
    "update_end_user_table_data",
    "prisma_client"
  ],
  "new_end_user": [
    "data",
    "user_api_key_dict"
  ],
  "end_user_info": [
    "end_user_id"
  ],
  "update_end_user": [
    "data",
    "user_api_key_dict"
  ],
  "delete_end_user": [
    "data",
    "user_api_key_dict"
  ],
  "list_end_user": [
    "http_request",
    "user_api_key_dict"
  ],
  "get_customer_daily_activity": [
    "end_user_ids",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "page",
    "page_size",
    "exclude_end_user_ids",
    "user_api_key_dict"
  ],
  "create_fallback": [
    "data",
    "user_api_key_dict"
  ],
  "get_fallback": [
    "model",
    "fallback_type",
    "user_api_key_dict"
  ],
  "delete_fallback": [
    "model",
    "fallback_type",
    "user_api_key_dict"
  ],
  "UpdatePublicModelGroupsRequest": {
    "model_config": []
  },
  "get_db_model": [
    "model_id",
    "prisma_client"
  ],
  "update_db_model": [
    "db_model",
    "updated_patch"
  ],
  "patch_model": [
    "model_id",
    "patch_data",
    "user_api_key_dict"
  ],
  "_add_model_to_db": [
    "model_params",
    "user_api_key_dict",
    "prisma_client",
    "new_encryption_key",
    "should_create_model_in_db"
  ],
  "_add_team_model_to_db": [
    "model_params",
    "user_api_key_dict",
    "prisma_client"
  ],
  "_update_team_model_in_db": [
    "db_model",
    "patch_data",
    "user_api_key_dict",
    "prisma_client"
  ],
  "_get_public_model_name": [
    "patch_data",
    "db_model"
  ],
  "_setup_new_team_model_assignment": [
    "team_id",
    "public_model_name",
    "patch_data",
    "user_api_key_dict"
  ],
  "_update_existing_team_model_assignment": [
    "team_id",
    "public_model_name",
    "db_model",
    "patch_data",
    "user_api_key_dict"
  ],
  "ModelManagementAuthChecks": {
    "can_user_make_team_model_call": [
      "team_id",
      "user_api_key_dict",
      "team_obj",
      "premium_user"
    ],
    "allow_team_model_action": [
      "model_params",
      "user_api_key_dict",
      "prisma_client",
      "premium_user"
    ],
    "can_user_make_model_call": [
      "model_params",
      "user_api_key_dict",
      "prisma_client",
      "premium_user"
    ]
  },
  "delete_team_model_alias": [
    "public_model_name",
    "prisma_client"
  ],
  "add_new_model": [
    "model_params",
    "user_api_key_dict"
  ],
  "update_public_model_groups": [
    "request",
    "user_api_key_dict"
  ],
  "update_useful_links": [
    "request",
    "user_api_key_dict"
  ],
  "_deduplicate_litellm_router_models": [
    "models"
  ],
  "clear_cache": [],
  "_get_model_names": [
    "prisma_client",
    "model_ids"
  ],
  "get_deployments_by_model": [
    "model",
    "llm_router"
  ],
  "new_tag": [
    "tag",
    "user_api_key_dict"
  ],
  "_add_tag_to_deployment": [
    "deployment",
    "tag"
  ],
  "update_tag": [
    "tag",
    "user_api_key_dict"
  ],
  "info_tag": [
    "data",
    "user_api_key_dict"
  ],
  "list_tags": [
    "user_api_key_dict"
  ],
  "delete_tag": [
    "data",
    "user_api_key_dict"
  ],
  "get_tag_daily_activity": [
    "tags",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "page",
    "page_size"
  ],
  "_update_internal_new_user_params": [
    "data_json",
    "data"
  ],
  "_check_duplicate_user_field": [
    "field_name",
    "field_value",
    "prisma_client"
  ],
  "_check_duplicate_user_email": [
    "user_email",
    "prisma_client"
  ],
  "_check_duplicate_user_id": [
    "user_id",
    "prisma_client"
  ],
  "_add_user_to_organizations": [
    "user_id",
    "organizations",
    "prisma_client",
    "user_api_key_dict"
  ],
  "_add_user_to_team": [
    "user_id",
    "team_id",
    "user_api_key_dict",
    "user_email",
    "max_budget_in_team",
    "user_role"
  ],
  "check_if_default_team_set": [],
  "add_new_user_to_default_team": [
    "user_id",
    "user_email",
    "user_api_key_dict",
    "teams",
    "prisma_client"
  ],
  "new_user": [
    "data",
    "user_api_key_dict"
  ],
  "ui_get_available_role": [
    "user_api_key_dict"
  ],
  "get_team_from_list": [
    "team_list",
    "team_id"
  ],
  "get_user_id_from_request": [
    "request"
  ],
  "user_info": [
    "request",
    "user_id",
    "user_api_key_dict"
  ],
  "_get_user_info_for_proxy_admin": [],
  "_process_keys_for_user_info": [
    "keys",
    "all_teams"
  ],
  "_update_internal_user_params": [
    "data_json",
    "data"
  ],
  "_update_single_user_helper": [
    "user_request",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "can_user_call_user_update": [
    "user_api_key_dict",
    "user_info"
  ],
  "user_update": [
    "data",
    "user_api_key_dict"
  ],
  "bulk_update_processed_users": [
    "users_to_update",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "bulk_user_update": [
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "get_user_key_counts": [
    "prisma_client",
    "user_ids"
  ],
  "_validate_sort_params": [
    "sort_by",
    "sort_order"
  ],
  "get_users": [
    "role",
    "user_ids",
    "sso_user_ids",
    "user_email",
    "team",
    "page",
    "page_size",
    "sort_by",
    "sort_order"
  ],
  "add_internal_user_to_organization": [
    "user_id",
    "organization_id",
    "user_role"
  ],
  "ui_view_users": [
    "user_id",
    "user_email",
    "page",
    "page_size",
    "user_api_key_dict"
  ],
  "get_user_daily_activity": [
    "start_date",
    "end_date",
    "model",
    "api_key",
    "user_id",
    "page",
    "page_size",
    "timezone",
    "user_api_key_dict"
  ],
  "get_user_daily_activity_aggregated": [
    "start_date",
    "end_date",
    "model",
    "api_key",
    "user_id",
    "timezone",
    "user_api_key_dict"
  ],
  "TeamMemberBudgetHandler": {
    "should_create_budget": [
      "team_member_budget",
      "team_member_rpm_limit",
      "team_member_tpm_limit",
      "team_member_budget_duration"
    ],
    "create_team_member_budget_table": [
      "data",
      "new_team_data_json",
      "user_api_key_dict",
      "team_member_budget",
      "team_member_rpm_limit",
      "team_member_tpm_limit",
      "team_member_budget_duration"
    ],
    "upsert_team_member_budget_table": [
      "team_table",
      "user_api_key_dict",
      "updated_kv",
      "team_member_budget",
      "team_member_rpm_limit",
      "team_member_tpm_limit",
      "team_member_budget_duration"
    ],
    "_clean_team_member_fields": [
      "data_dict"
    ]
  },
  "_is_available_team": [
    "team_id",
    "user_api_key_dict"
  ],
  "get_all_team_memberships": [
    "prisma_client",
    "team_ids",
    "user_id"
  ],
  "_check_team_model_specific_limits": [
    "teams",
    "data",
    "entity_rpm_limit",
    "entity_tpm_limit",
    "entity_model_rpm_limit_dict",
    "entity_model_tpm_limit_dict",
    "entity_type"
  ],
  "_check_team_rpm_tpm_limits": [
    "teams",
    "data",
    "entity_rpm_limit",
    "entity_tpm_limit",
    "entity_type"
  ],
  "check_org_team_model_specific_limits": [
    "teams",
    "org_table",
    "data"
  ],
  "check_org_team_rpm_tpm_limits": [
    "teams",
    "org_table",
    "data"
  ],
  "_check_org_team_limits": [
    "org_table",
    "data",
    "prisma_client"
  ],
  "_check_user_team_limits": [
    "data",
    "user_api_key_dict",
    "prisma_client",
    "user_api_key_cache"
  ],
  "new_team": [
    "data",
    "http_request",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_create_team_update_audit_log": [
    "existing_team_row",
    "updated_kv",
    "team_id",
    "litellm_changed_by",
    "user_api_key_dict",
    "litellm_proxy_admin_name"
  ],
  "_update_model_table": [
    "data",
    "model_id",
    "prisma_client",
    "user_api_key_dict",
    "litellm_proxy_admin_name"
  ],
  "fetch_and_validate_organization": [
    "organization_id",
    "existing_team_row",
    "llm_router",
    "prisma_client"
  ],
  "validate_team_org_change": [
    "team",
    "organization",
    "llm_router"
  ],
  "update_team": [
    "data",
    "http_request",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_set_budget_reset_at": [
    "data",
    "updated_kv"
  ],
  "_check_team_member_admin_add": [
    "member",
    "premium_user"
  ],
  "team_call_validation_checks": [
    "prisma_client",
    "data",
    "premium_user"
  ],
  "team_member_add_duplication_check": [
    "data",
    "existing_team_row"
  ],
  "_validate_team_member_add_permissions": [
    "user_api_key_dict",
    "complete_team_data"
  ],
  "_process_team_members": [
    "data",
    "complete_team_data",
    "prisma_client",
    "user_api_key_dict",
    "litellm_proxy_admin_name"
  ],
  "_update_team_members_list": [
    "data",
    "complete_team_data",
    "updated_users"
  ],
  "_add_team_members_to_team": [
    "data",
    "complete_team_data",
    "prisma_client",
    "user_api_key_dict",
    "litellm_proxy_admin_name"
  ],
  "_validate_and_populate_member_user_info": [
    "member",
    "prisma_client"
  ],
  "team_member_add": [
    "data",
    "user_api_key_dict"
  ],
  "_cleanup_members_with_roles": [
    "existing_team_row",
    "data"
  ],
  "team_member_delete": [
    "data",
    "user_api_key_dict"
  ],
  "team_member_update": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "_create_results_from_response": [
    "members",
    "response"
  ],
  "bulk_team_member_add": [
    "data",
    "user_api_key_dict"
  ],
  "delete_team": [
    "data",
    "http_request",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_transform_teams_to_deleted_records": [
    "teams",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_save_deleted_team_records": [
    "records",
    "prisma_client"
  ],
  "_persist_deleted_team_records": [
    "teams",
    "prisma_client",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "validate_membership": [
    "user_api_key_dict",
    "team_table"
  ],
  "_unfurl_all_proxy_models": [
    "team_info",
    "llm_router"
  ],
  "_add_team_member_budget_table": [
    "team_member_budget_id",
    "prisma_client",
    "team_info_response_object"
  ],
  "team_info": [
    "http_request",
    "team_id",
    "user_api_key_dict"
  ],
  "block_team": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "unblock_team": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "list_available_teams": [
    "http_request",
    "user_api_key_dict",
    "response_model"
  ],
  "_build_team_list_where_conditions": [
    "prisma_client",
    "team_id",
    "team_alias",
    "organization_id",
    "user_id",
    "use_deleted_table"
  ],
  "_convert_teams_to_response": [
    "teams",
    "use_deleted_table"
  ],
  "list_team_v2": [
    "http_request",
    "user_id",
    "organization_id",
    "team_id",
    "team_alias",
    "page",
    "page_size",
    "sort_by",
    "sort_order",
    "status",
    "user_api_key_dict"
  ],
  "list_team": [
    "http_request",
    "user_id",
    "organization_id",
    "user_api_key_dict"
  ],
  "get_paginated_teams": [
    "prisma_client",
    "page_size",
    "page"
  ],
  "ui_view_teams": [
    "team_id",
    "team_alias",
    "page",
    "page_size",
    "user_api_key_dict"
  ],
  "add_new_models_to_team": [
    "team_obj",
    "new_models"
  ],
  "team_model_add": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "team_model_delete": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "team_member_permissions": [
    "team_id",
    "user_api_key_dict"
  ],
  "update_team_member_permissions": [
    "data",
    "http_request",
    "user_api_key_dict"
  ],
  "get_team_daily_activity": [
    "team_ids",
    "start_date",
    "end_date",
    "model",
    "api_key",
    "page",
    "page_size",
    "exclude_team_ids",
    "user_api_key_dict"
  ],
  "MAX_DAYS": [],
  "MAX_WEEKS": [],
  "MAX_MONTHS": [],
  "MAX_TAGS": [],
  "TagActiveUsersResponse": {},
  "ActiveUsersAnalyticsResponse": {},
  "TagSummaryMetrics": {},
  "TagSummaryResponse": {},
  "DistinctTagResponse": {},
  "DistinctTagsResponse": {},
  "PerUserMetrics": {},
  "PerUserAnalyticsResponse": {},
  "get_distinct_user_agent_tags": [
    "user_api_key_dict"
  ],
  "get_daily_active_users": [
    "tag_filter",
    "tag_filters",
    "user_api_key_dict"
  ],
  "get_weekly_active_users": [
    "tag_filter",
    "tag_filters",
    "user_api_key_dict"
  ],
  "get_monthly_active_users": [
    "tag_filter",
    "tag_filters",
    "user_api_key_dict"
  ],
  "get_tag_summary": [
    "start_date",
    "end_date",
    "tag_filter",
    "tag_filters",
    "user_api_key_dict"
  ],
  "get_per_user_analytics": [
    "tag_filter",
    "tag_filters",
    "page",
    "page_size",
    "user_api_key_dict"
  ],
  "_is_team_key": [
    "data"
  ],
  "_get_user_in_team": [
    "team_table",
    "user_id"
  ],
  "_calculate_key_rotation_time": [
    "rotation_interval"
  ],
  "_set_key_rotation_fields": [
    "data",
    "auto_rotate",
    "rotation_interval"
  ],
  "_is_allowed_to_make_key_request": [
    "user_api_key_dict",
    "user_id",
    "team_id"
  ],
  "_team_key_operation_team_member_check": [
    "assigned_user_id",
    "team_table",
    "user_api_key_dict",
    "team_key_generation",
    "route"
  ],
  "_key_generation_required_param_check": [
    "data",
    "required_params"
  ],
  "_team_key_generation_check": [
    "team_table",
    "user_api_key_dict",
    "data",
    "route"
  ],
  "_personal_key_membership_check": [
    "user_api_key_dict",
    "personal_key_generation"
  ],
  "_personal_key_generation_check": [
    "user_api_key_dict",
    "data"
  ],
  "key_generation_check": [
    "team_table",
    "user_api_key_dict",
    "data",
    "route"
  ],
  "common_key_access_checks": [
    "user_api_key_dict",
    "data",
    "llm_router",
    "premium_user",
    "user_id"
  ],
  "handle_key_type": [
    "data",
    "data_json"
  ],
  "validate_team_id_used_in_service_account_request": [
    "team_id",
    "prisma_client"
  ],
  "_common_key_generation_helper": [
    "data",
    "user_api_key_dict",
    "litellm_changed_by",
    "team_table"
  ],
  "_check_key_model_specific_limits": [
    "keys",
    "data",
    "entity_rpm_limit",
    "entity_tpm_limit",
    "entity_model_rpm_limit_dict",
    "entity_model_tpm_limit_dict",
    "entity_type"
  ],
  "_check_key_rpm_tpm_limits": [
    "keys",
    "data",
    "entity_rpm_limit",
    "entity_tpm_limit",
    "entity_type"
  ],
  "check_team_key_model_specific_limits": [
    "keys",
    "team_table",
    "data"
  ],
  "check_team_key_rpm_tpm_limits": [
    "keys",
    "team_table",
    "data"
  ],
  "_check_team_key_limits": [
    "team_table",
    "data",
    "prisma_client"
  ],
  "_check_project_key_limits": [
    "project_id",
    "data",
    "prisma_client",
    "user_api_key_cache"
  ],
  "check_org_key_model_specific_limits": [
    "keys",
    "org_table",
    "data"
  ],
  "check_org_key_rpm_tpm_limits": [
    "keys",
    "org_table",
    "data"
  ],
  "_check_org_key_limits": [
    "org_table",
    "data",
    "prisma_client"
  ],
  "generate_key_fn": [
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "generate_service_account_key_fn": [
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "prepare_metadata_fields": [
    "data",
    "non_default_values",
    "existing_metadata"
  ],
  "prepare_key_update_data": [
    "data",
    "existing_key_row"
  ],
  "_handle_update_object_permission": [
    "data_json",
    "existing_key_row"
  ],
  "is_different_team": [
    "data",
    "existing_key_row"
  ],
  "_validate_max_budget": [
    "max_budget"
  ],
  "_get_and_validate_existing_key": [
    "token",
    "prisma_client"
  ],
  "_process_single_key_update": [
    "key_update_item",
    "user_api_key_dict",
    "litellm_changed_by",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj",
    "llm_router"
  ],
  "update_key_fn": [
    "request",
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "bulk_update_keys": [
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "validate_key_team_change": [
    "key",
    "team",
    "change_initiated_by",
    "llm_router"
  ],
  "delete_key_fn": [
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "info_key_fn_v2": [
    "data",
    "user_api_key_dict"
  ],
  "info_key_fn": [
    "key",
    "user_api_key_dict"
  ],
  "_check_model_access_group": [
    "models",
    "llm_router",
    "premium_user"
  ],
  "generate_key_helper_fn": [
    "request_type",
    "duration",
    "models",
    "aliases",
    "config",
    "spend",
    "key_max_budget",
    "key_budget_duration",
    "budget_id",
    "soft_budget",
    "max_budget",
    "blocked",
    "budget_duration",
    "token",
    "key",
    "user_id",
    "user_alias",
    "team_id",
    "user_email",
    "user_role",
    "max_parallel_requests",
    "metadata",
    "tpm_limit",
    "rpm_limit",
    "query_type",
    "update_key_values",
    "key_alias",
    "allowed_cache_controls",
    "permissions",
    "model_max_budget",
    "model_rpm_limit",
    "model_tpm_limit",
    "guardrails",
    "policies",
    "prompts",
    "teams",
    "organization_id",
    "project_id",
    "table_name",
    "send_invite_email",
    "created_by",
    "updated_by",
    "allowed_routes",
    "sso_user_id",
    "object_permission_id",
    "object_permission",
    "auto_rotate",
    "rotation_interval",
    "router_settings",
    "access_group_ids"
  ],
  "_team_key_deletion_check": [
    "user_api_key_dict",
    "key_info",
    "prisma_client",
    "user_api_key_cache"
  ],
  "can_modify_verification_token": [
    "key_info",
    "user_api_key_cache",
    "user_api_key_dict",
    "prisma_client"
  ],
  "delete_verification_tokens": [
    "tokens",
    "user_api_key_cache",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_transform_verification_tokens_to_deleted_records": [
    "keys",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_save_deleted_verification_token_records": [
    "records",
    "prisma_client"
  ],
  "_persist_deleted_verification_tokens": [
    "keys",
    "prisma_client",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "delete_key_aliases": [
    "key_aliases",
    "user_api_key_cache",
    "prisma_client",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_rotate_master_key": [
    "prisma_client",
    "user_api_key_dict",
    "current_master_key",
    "new_master_key"
  ],
  "get_new_token": [
    "data"
  ],
  "_insert_deprecated_key": [
    "prisma_client",
    "old_token_hash",
    "new_token_hash",
    "grace_period"
  ],
  "_execute_virtual_key_regeneration": [],
  "regenerate_key_fn": [
    "key",
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "_check_proxy_or_team_admin_for_key": [
    "key_in_db",
    "user_api_key_dict",
    "prisma_client",
    "user_api_key_cache"
  ],
  "_validate_reset_spend_value": [
    "reset_to",
    "key_in_db"
  ],
  "reset_key_spend_fn": [
    "key",
    "data",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "validate_key_list_check": [
    "user_api_key_dict",
    "user_id",
    "team_id",
    "organization_id",
    "key_alias",
    "key_hash",
    "prisma_client"
  ],
  "_fetch_user_team_objects": [
    "complete_user_info",
    "prisma_client"
  ],
  "_get_admin_team_ids_from_objects": [
    "user_api_key_dict",
    "team_objects"
  ],
  "_get_member_team_ids_from_objects": [
    "user_api_key_dict",
    "team_objects"
  ],
  "get_admin_team_ids": [
    "complete_user_info",
    "user_api_key_dict",
    "prisma_client"
  ],
  "get_member_team_ids": [
    "complete_user_info",
    "user_api_key_dict",
    "prisma_client"
  ],
  "list_keys": [
    "request",
    "user_api_key_dict",
    "page",
    "size",
    "user_id",
    "team_id",
    "organization_id",
    "key_hash",
    "key_alias",
    "return_full_object",
    "include_team_keys",
    "include_created_by_keys",
    "sort_by",
    "sort_order",
    "expand",
    "status"
  ],
  "key_aliases": [],
  "_build_key_filter_conditions": [
    "user_id",
    "team_id",
    "organization_id",
    "key_alias",
    "key_hash",
    "exclude_team_id",
    "admin_team_ids",
    "member_team_ids",
    "include_created_by_keys"
  ],
  "_list_key_helper": [
    "prisma_client",
    "page",
    "size",
    "user_id",
    "team_id",
    "organization_id",
    "key_alias",
    "key_hash",
    "exclude_team_id",
    "return_full_object",
    "admin_team_ids",
    "member_team_ids",
    "include_created_by_keys",
    "sort_by",
    "sort_order",
    "expand",
    "status"
  ],
  "_get_condition_to_filter_out_ui_session_tokens": [],
  "block_key": [
    "data",
    "http_request",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "unblock_key": [
    "data",
    "http_request",
    "user_api_key_dict",
    "litellm_changed_by"
  ],
  "key_health": [
    "request",
    "user_api_key_dict"
  ],
  "_can_user_query_key_info": [
    "user_api_key_dict",
    "key",
    "key_info"
  ],
  "test_key_logging": [
    "user_api_key_dict",
    "request",
    "key_logging"
  ],
  "_enforce_unique_key_alias": [
    "key_alias",
    "prisma_client",
    "existing_key_token"
  ],
  "validate_model_max_budget": [
    "model_max_budget"
  ],
  "list_callbacks": [],
  "get_callback_configs": [],
  "normalize_email": [
    "email"
  ],
  "determine_role_from_groups": [
    "user_groups",
    "role_mappings"
  ],
  "process_sso_jwt_access_token": [
    "access_token_str",
    "sso_jwt_handler",
    "result",
    "role_mappings"
  ],
  "google_login": [
    "request",
    "source",
    "key",
    "existing_key"
  ],
  "generic_response_convertor": [
    "response",
    "jwt_handler",
    "sso_jwt_handler",
    "role_mappings",
    "team_mappings"
  ],
  "_setup_generic_sso_env_vars": [
    "generic_client_id",
    "redirect_url"
  ],
  "_setup_team_mappings": [],
  "_setup_role_mappings": [],
  "get_generic_sso_response": [
    "request",
    "jwt_handler",
    "sso_jwt_handler",
    "generic_client_id",
    "redirect_url"
  ],
  "create_team_member_add_task": [
    "team_id",
    "user_info"
  ],
  "add_missing_team_member": [
    "user_info",
    "sso_teams"
  ],
  "get_disabled_non_admin_personal_key_creation": [],
  "get_existing_user_info_from_db": [
    "user_id",
    "user_email",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "get_user_info_from_db": [
    "result",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj",
    "user_email",
    "user_defined_values",
    "alternate_user_id"
  ],
  "_should_use_role_from_sso_response": [
    "sso_role"
  ],
  "_build_sso_user_update_data": [
    "result",
    "user_email",
    "user_id"
  ],
  "apply_user_info_values_to_sso_user_defined_values": [
    "user_info",
    "user_defined_values"
  ],
  "check_and_update_if_proxy_admin_id": [
    "user_role",
    "user_id",
    "prisma_client"
  ],
  "auth_callback": [
    "request",
    "state"
  ],
  "cli_sso_callback": [
    "request",
    "key",
    "existing_key",
    "result"
  ],
  "cli_poll_key": [
    "key_id",
    "team_id"
  ],
  "insert_sso_user": [
    "result_openid",
    "user_defined_values"
  ],
  "get_ui_settings": [
    "request"
  ],
  "sso_readiness": [],
  "SSOAuthenticationHandler": {
    "get_sso_login_redirect": [
      "redirect_url",
      "google_client_id",
      "microsoft_client_id",
      "generic_client_id",
      "state"
    ],
    "get_generic_sso_redirect_response": [
      "generic_sso",
      "state",
      "generic_authorization_endpoint"
    ],
    "_get_generic_sso_redirect_params": [
      "state",
      "generic_authorization_endpoint"
    ],
    "should_use_sso_handler": [
      "google_client_id",
      "microsoft_client_id",
      "generic_client_id"
    ],
    "get_redirect_url_for_sso": [
      "request",
      "sso_callback_route",
      "existing_key"
    ],
    "upsert_sso_user": [
      "result",
      "user_info",
      "user_email",
      "user_defined_values",
      "prisma_client"
    ],
    "add_user_to_teams_from_sso_response": [
      "result",
      "user_info"
    ],
    "verify_user_in_restricted_sso_group": [
      "general_settings",
      "result",
      "received_response"
    ],
    "create_litellm_team_from_sso_group": [
      "litellm_team_id",
      "litellm_team_name"
    ],
    "_cast_and_deepcopy_litellm_default_team_params": [
      "default_team_params",
      "team_request",
      "litellm_team_id",
      "litellm_team_name"
    ],
    "_get_cli_state": [
      "source",
      "key",
      "existing_key"
    ],
    "_get_user_email_and_id_from_result": [
      "result",
      "generic_client_id"
    ],
    "get_redirect_response_from_openid": [
      "result",
      "request",
      "received_response",
      "generic_client_id",
      "ui_access_mode"
    ],
    "prepare_token_exchange_parameters": [
      "request",
      "generic_include_client_id"
    ],
    "generate_pkce_params": []
  },
  "MicrosoftSSOHandler": {
    "graph_api_base_url": [],
    "graph_api_user_groups_endpoint": [],
    "MAX_GRAPH_API_PAGES": [],
    "GRAPH_API_RESPONSE_KEY": [],
    "get_microsoft_callback_response": [
      "request",
      "microsoft_client_id",
      "redirect_url",
      "return_raw_sso_response"
    ],
    "openid_from_response": [
      "response",
      "team_ids",
      "user_role"
    ],
    "get_app_roles_from_id_token": [
      "id_token"
    ],
    "get_user_groups_from_graph_api": [
      "access_token"
    ],
    "fetch_and_parse_groups": [
      "url",
      "headers",
      "async_client"
    ],
    "_get_group_ids_from_graph_api_response": [
      "response"
    ],
    "_cast_graph_api_response_dict": [
      "response"
    ],
    "get_group_ids_from_service_principal": [
      "service_principal_id",
      "async_client",
      "access_token"
    ],
    "create_litellm_teams_from_service_principal_team_ids": [
      "service_principal_teams"
    ]
  },
  "GoogleSSOHandler": {
    "get_google_callback_response": [
      "request",
      "google_client_id",
      "redirect_url",
      "return_raw_sso_response"
    ]
  },
  "debug_sso_login": [
    "request"
  ],
  "debug_sso_callback": [
    "request"
  ],
  "RouterSettingsResponse": {},
  "RouterFieldsResponse": {},
  "_get_routing_strategies_from_router_class": [],
  "get_router_settings": [
    "user_api_key_dict"
  ],
  "get_router_fields": [
    "user_api_key_dict"
  ],
  "_user_has_admin_view": [
    "user_api_key_dict"
  ],
  "_is_user_team_admin": [
    "user_api_key_dict",
    "team_obj"
  ],
  "_team_member_has_permission": [
    "user_api_key_dict",
    "team_obj",
    "permission"
  ],
  "_user_has_admin_privileges": [
    "user_api_key_dict",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_org_admin_can_invite_user": [
    "admin_user_obj",
    "target_user_obj"
  ],
  "_team_admin_can_invite_user": [
    "user_api_key_dict",
    "admin_user_obj",
    "target_user_obj",
    "prisma_client"
  ],
  "admin_can_invite_user": [
    "target_user_id",
    "user_api_key_dict",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_set_object_metadata_field": [
    "object_data",
    "field_name",
    "value"
  ],
  "_upsert_budget_and_membership": [
    "tx"
  ],
  "_update_metadata_field": [
    "updated_kv",
    "field_name"
  ],
  "_has_non_empty_value": [
    "value"
  ],
  "_update_metadata_fields": [
    "updated_kv"
  ],
  "CustomMicrosoftSSO": {
    "__init__": [
      "self",
      "client_id",
      "client_secret",
      "redirect_uri",
      "allow_insecure_http",
      "scope",
      "tenant"
    ],
    "get_discovery_document": [
      "self"
    ]
  },
  "ScimTransformations": {
    "DEFAULT_SCIM_NAME": [],
    "DEFAULT_SCIM_FAMILY_NAME": [],
    "DEFAULT_SCIM_DISPLAY_NAME": [],
    "DEFAULT_SCIM_MEMBER_VALUE": [],
    "transform_litellm_user_to_scim_user": [
      "user"
    ],
    "_get_scim_user_name": [
      "user"
    ],
    "_get_scim_family_name": [
      "user"
    ],
    "_get_scim_given_name": [
      "user"
    ],
    "transform_litellm_team_to_scim_group": [
      "team"
    ],
    "_get_scim_member_value": [
      "member"
    ],
    "_get_scim_member_display": [
      "member"
    ]
  },
  "UserProvisionerHelpers": {
    "handle_existing_user_by_email": [
      "prisma_client",
      "new_user_request"
    ]
  },
  "ScimUserData": {},
  "GroupMemberExtractionResult": {},
  "scim_router": [],
  "_get_prisma_client_or_raise_exception": [],
  "_check_user_exists": [
    "user_id"
  ],
  "_check_team_exists": [
    "team_id"
  ],
  "_extract_scim_user_data": [
    "user"
  ],
  "_build_scim_metadata": [
    "given_name",
    "family_name",
    "active"
  ],
  "_get_scim_upsert_user_setting": [],
  "_extract_group_member_ids": [
    "group"
  ],
  "_get_team_members_display": [
    "member_ids"
  ],
  "_handle_team_membership_changes": [
    "user_id",
    "existing_teams",
    "new_teams"
  ],
  "_create_user_if_not_exists": [
    "user_id",
    "created_via"
  ],
  "_get_team_member_user_ids_from_team": [
    "team"
  ],
  "set_scim_content_type": [
    "response"
  ],
  "_get_resource_types": [
    "base_url"
  ],
  "_get_schemas": [],
  "get_scim_base": [
    "request"
  ],
  "get_resource_types": [
    "request"
  ],
  "get_resource_type": [
    "request",
    "resource_type_id"
  ],
  "get_schemas": [
    "request"
  ],
  "get_schema": [
    "request",
    "schema_id"
  ],
  "get_service_provider_config": [
    "request"
  ],
  "update_user": [
    "user_id",
    "user"
  ],
  "_extract_group_values": [
    "value"
  ],
  "_handle_displayname_update": [
    "op_type",
    "value",
    "update_data"
  ],
  "_handle_externalid_update": [
    "op_type",
    "value",
    "update_data"
  ],
  "_handle_active_update": [
    "op_type",
    "value",
    "metadata"
  ],
  "_handle_name_update": [
    "path",
    "op_type",
    "value",
    "scim_metadata"
  ],
  "_handle_group_operations": [
    "op_type",
    "value",
    "teams_set"
  ],
  "_handle_generic_metadata": [
    "path",
    "op_type",
    "value",
    "metadata"
  ],
  "_apply_patch_ops": [
    "existing_user",
    "patch_ops"
  ],
  "patch_team_membership": [
    "user_id",
    "teams_ids_to_add_user_to",
    "teams_ids_to_remove_user_from"
  ],
  "patch_user": [
    "user_id",
    "patch_ops"
  ],
  "get_groups": [
    "startIndex",
    "count",
    "filter"
  ],
  "get_group": [
    "group_id"
  ],
  "create_group": [
    "group"
  ],
  "update_group": [
    "group_id",
    "group"
  ],
  "delete_group": [
    "group_id"
  ],
  "_process_group_patch_operations": [
    "patch_ops",
    "existing_team",
    "prisma_client"
  ],
  "_apply_group_patch_updates": [
    "group_id",
    "update_data",
    "final_members",
    "prisma_client"
  ],
  "_handle_group_membership_changes": [
    "group_id",
    "current_members",
    "final_members"
  ],
  "patch_group": [
    "group_id",
    "patch_ops"
  ],
  "GuardrailApplyError": {
    "__init__": [
      "self",
      "guardrail_name",
      "message"
    ]
  },
  "GuardrailErrorEntry": {},
  "_ApplyPoliciesResultBase": {},
  "ApplyPoliciesResult": {},
  "_ApplyPoliciesPerItemResultBase": {},
  "ApplyPoliciesPerItemResult": {},
  "ApplyPoliciesListResult": {},
  "apply_policies": [
    "policy_names",
    "inputs",
    "request_data",
    "input_type",
    "proxy_logging_obj",
    "guardrail_names"
  ],
  "_chat_body_from_inputs": [
    "inputs",
    "agent_id",
    "request_data"
  ],
  "_request_with_json_body": [
    "body"
  ],
  "TestPoliciesAndGuardrailsRequest": {},
  "test_policies_and_guardrails": [
    "request",
    "data",
    "user_api_key_dict"
  ],
  "validate_policy": [
    "request",
    "data",
    "user_api_key_dict"
  ],
  "list_policies": [
    "request",
    "user_api_key_dict"
  ],
  "get_policy_info": [
    "request",
    "policy_name",
    "user_api_key_dict"
  ],
  "test_policy_matching": [
    "request",
    "context",
    "user_api_key_dict"
  ],
  "POLICY_TEMPLATES_GITHUB_URL": [],
  "_load_policy_templates_from_local_backup": [],
  "get_policy_templates": [
    "request",
    "user_api_key_dict"
  ],
  "EnrichTemplateRequest": {},
  "_validate_enrichment_request": [
    "data"
  ],
  "enrich_policy_template": [
    "data",
    "request",
    "user_api_key_dict"
  ],
  "_build_refinement_prompt": [
    "instruction",
    "existing_competitors",
    "brand_name"
  ],
  "_stream_llm_competitor_names": [
    "prompt",
    "model",
    "existing"
  ],
  "_stream_competitor_events": [
    "data",
    "template",
    "llm_enrichment",
    "brand_name",
    "model"
  ],
  "enrich_policy_template_stream": [
    "data",
    "request",
    "user_api_key_dict"
  ],
  "_clean_competitor_line": [
    "line"
  ],
  "_generate_competitor_variations": [
    "competitors",
    "model"
  ],
  "_parse_variations_response": [
    "raw",
    "competitors"
  ],
  "_discover_competitors_via_llm": [
    "prompt",
    "model"
  ],
  "_build_all_names_per_competitor": [
    "competitors",
    "variations_map"
  ],
  "_build_competitor_guardrail_definitions": [
    "definitions",
    "competitors",
    "brand_name",
    "variations_map"
  ],
  "_build_name_blocked_words": [
    "competitors",
    "all_names"
  ],
  "_build_recommendation_blocked_words": [
    "competitors",
    "all_names"
  ],
  "_build_comparison_blocked_words": [
    "competitors",
    "all_names",
    "brand_name"
  ],
  "SuggestTemplatesRequest": {},
  "suggest_policy_templates": [
    "data",
    "request",
    "user_api_key_dict"
  ],
  "GuardrailTestResultEntry": {},
  "TestPolicyTemplateRequest": {},
  "TestPolicyTemplateResponse": {},
  "test_policy_template": [
    "data",
    "request",
    "user_api_key_dict"
  ],
  "_test_guardrail_definitions": [
    "guardrail_definitions",
    "text"
  ],
  "_compute_overall_action": [
    "results"
  ],
  "SUGGEST_TOOL": [],
  "AiPolicySuggester": {
    "suggest": [
      "self",
      "templates",
      "attack_examples",
      "description",
      "model"
    ],
    "_build_system_prompt": [
      "self",
      "templates"
    ],
    "_build_user_prompt": [
      "self",
      "attack_examples",
      "description"
    ]
  },
  "SharedHealthCheckManager": {
    "__init__": [
      "self",
      "redis_cache",
      "health_check_ttl",
      "lock_ttl"
    ],
    "get_health_check_lock_key": [],
    "get_health_check_cache_key": [],
    "get_model_health_check_lock_key": [
      "model_name"
    ],
    "get_model_health_check_cache_key": [
      "model_name"
    ],
    "acquire_health_check_lock": [
      "self"
    ],
    "release_health_check_lock": [
      "self"
    ],
    "get_cached_health_check_results": [
      "self"
    ],
    "cache_health_check_results": [
      "self",
      "healthy_endpoints",
      "unhealthy_endpoints"
    ],
    "perform_shared_health_check": [
      "self",
      "model_list",
      "details"
    ],
    "is_health_check_in_progress": [
      "self"
    ],
    "get_health_check_status": [
      "self"
    ]
  },
  "get_ui_config": [],
  "handle_oauth2_proxy_request": [
    "request"
  ],
  "JWTHandler": {
    "__init__": [
      "self"
    ],
    "update_environment": [
      "self",
      "prisma_client",
      "user_api_key_cache",
      "litellm_jwtauth",
      "leeway"
    ],
    "is_jwt": [
      "token"
    ],
    "_rbac_role_from_role_mapping": [
      "self",
      "token"
    ],
    "get_rbac_role": [
      "self",
      "token"
    ],
    "is_admin": [
      "self",
      "scopes"
    ],
    "get_team_ids_from_jwt": [
      "self",
      "token"
    ],
    "get_end_user_id": [
      "self",
      "token",
      "default_value"
    ],
    "is_required_team_id": [
      "self"
    ],
    "is_enforced_email_domain": [
      "self"
    ],
    "get_team_id": [
      "self",
      "token",
      "default_value"
    ],
    "get_team_alias": [
      "self",
      "token",
      "default_value"
    ],
    "is_upsert_user_id": [
      "self",
      "valid_user_email"
    ],
    "get_user_id": [
      "self",
      "token",
      "default_value"
    ],
    "get_user_roles": [
      "self",
      "token",
      "default_value"
    ],
    "map_jwt_role_to_litellm_role": [
      "self",
      "token"
    ],
    "get_jwt_role": [
      "self",
      "token",
      "default_value"
    ],
    "is_allowed_user_role": [
      "self",
      "user_roles"
    ],
    "get_user_email": [
      "self",
      "token",
      "default_value"
    ],
    "get_object_id": [
      "self",
      "token",
      "default_value"
    ],
    "get_org_id": [
      "self",
      "token",
      "default_value"
    ],
    "get_org_alias": [
      "self",
      "token",
      "default_value"
    ],
    "get_scopes": [
      "self",
      "token"
    ],
    "get_public_key": [
      "self",
      "kid"
    ],
    "parse_keys": [
      "self",
      "keys",
      "kid"
    ],
    "is_allowed_domain": [
      "self",
      "user_email"
    ],
    "get_oidc_userinfo": [
      "self",
      "token"
    ],
    "auth_jwt": [
      "self",
      "token"
    ],
    "close": [
      "self"
    ]
  },
  "JWTAuthManager": {
    "can_rbac_role_call_route": [
      "rbac_role",
      "general_settings",
      "route"
    ],
    "can_rbac_role_call_model": [
      "rbac_role",
      "general_settings",
      "model"
    ],
    "check_scope_based_access": [
      "scope_mappings",
      "scopes",
      "request_data",
      "general_settings"
    ],
    "check_rbac_role": [
      "jwt_handler",
      "jwt_valid_token",
      "general_settings",
      "request_data",
      "route",
      "rbac_role"
    ],
    "check_admin_access": [
      "jwt_handler",
      "scopes",
      "route",
      "user_id",
      "org_id",
      "api_key"
    ],
    "find_and_validate_specific_team_id": [
      "jwt_handler",
      "jwt_valid_token",
      "prisma_client",
      "user_api_key_cache",
      "parent_otel_span",
      "proxy_logging_obj"
    ],
    "get_all_team_ids": [
      "jwt_handler",
      "jwt_valid_token"
    ],
    "find_team_with_model_access": [
      "team_ids",
      "requested_model",
      "route",
      "jwt_handler",
      "prisma_client",
      "user_api_key_cache",
      "parent_otel_span",
      "proxy_logging_obj"
    ],
    "get_user_info": [
      "jwt_handler",
      "jwt_valid_token"
    ],
    "get_objects": [
      "user_id",
      "user_email",
      "org_id",
      "end_user_id",
      "team_id",
      "valid_user_email",
      "jwt_handler",
      "prisma_client",
      "user_api_key_cache",
      "parent_otel_span",
      "proxy_logging_obj",
      "route",
      "org_alias"
    ],
    "validate_object_id": [
      "user_id",
      "team_id",
      "enforce_rbac",
      "is_proxy_admin"
    ],
    "get_team_id_from_header": [
      "request_headers",
      "allowed_team_ids"
    ],
    "map_user_to_teams": [
      "user_object",
      "team_object"
    ],
    "sync_user_role_and_teams": [
      "jwt_handler",
      "jwt_valid_token",
      "user_object",
      "prisma_client"
    ],
    "auth_builder": [
      "api_key",
      "jwt_handler",
      "request_data",
      "general_settings",
      "route",
      "prisma_client",
      "user_api_key_cache",
      "parent_otel_span",
      "proxy_logging_obj",
      "request_headers"
    ]
  },
  "get_ui_credentials": [
    "master_key"
  ],
  "LoginResult": {
    "__init__": [
      "self",
      "user_id",
      "key",
      "user_email",
      "user_role",
      "login_method"
    ]
  },
  "authenticate_user": [
    "username",
    "password",
    "master_key",
    "prisma_client"
  ],
  "create_ui_token_object": [
    "login_result",
    "general_settings",
    "premium_user"
  ],
  "Oauth2Handler": {
    "_is_introspection_endpoint": [
      "token_info_endpoint",
      "oauth_client_id",
      "oauth_client_secret"
    ],
    "_prepare_introspection_request": [
      "token",
      "oauth_client_id",
      "oauth_client_secret"
    ],
    "_prepare_token_info_request": [
      "token"
    ],
    "_extract_user_info": [
      "response_data",
      "user_id_field_name",
      "user_role_field_name",
      "user_team_id_field_name"
    ],
    "check_oauth2_token": [
      "token"
    ]
  },
  "organization_role_based_access_check": [
    "request_body",
    "user_object",
    "route"
  ],
  "get_user_organization_info": [
    "user_object"
  ],
  "_user_is_org_admin": [
    "request_data",
    "user_object"
  ],
  "UserAPIKeyAuthExceptionHandler": {
    "_handle_authentication_error": [
      "e",
      "request",
      "request_data",
      "route",
      "parent_otel_span",
      "api_key"
    ]
  },
  "LicenseCheck": {
    "base_url": [],
    "__init__": [
      "self"
    ],
    "read_public_key": [
      "self"
    ],
    "_verify": [
      "self",
      "license_str"
    ],
    "is_premium": [
      "self"
    ],
    "is_over_limit": [
      "self",
      "total_users"
    ],
    "is_team_count_over_limit": [
      "self",
      "team_count"
    ],
    "verify_license_without_api_request": [
      "self",
      "public_key",
      "license_key"
    ]
  },
  "last_db_access_time": [],
  "db_cache_expiry": [],
  "all_routes": [],
  "_log_budget_lookup_failure": [
    "entity",
    "error"
  ],
  "_is_model_cost_zero": [
    "model",
    "llm_router"
  ],
  "_run_project_checks": [
    "project_object",
    "_model",
    "llm_router",
    "skip_budget_checks",
    "valid_token",
    "proxy_logging_obj"
  ],
  "common_checks": [
    "request_body",
    "team_object",
    "user_object",
    "end_user_object",
    "global_proxy_spend",
    "general_settings",
    "route",
    "llm_router",
    "proxy_logging_obj",
    "valid_token",
    "request",
    "skip_budget_checks",
    "project_object"
  ],
  "_is_ui_route": [
    "route",
    "user_obj"
  ],
  "_get_user_role": [
    "user_obj"
  ],
  "_is_api_route_allowed": [
    "route",
    "request",
    "request_data",
    "valid_token",
    "user_obj"
  ],
  "_is_user_proxy_admin": [
    "user_obj"
  ],
  "_is_allowed_route": [
    "route",
    "token_type",
    "request",
    "request_data",
    "valid_token",
    "user_obj"
  ],
  "_allowed_routes_check": [
    "user_route",
    "allowed_routes"
  ],
  "allowed_routes_check": [
    "user_role",
    "user_route",
    "litellm_proxy_roles"
  ],
  "allowed_route_check_inside_route": [
    "user_api_key_dict",
    "requested_user_id"
  ],
  "get_actual_routes": [
    "allowed_routes"
  ],
  "get_default_end_user_budget": [
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span"
  ],
  "_apply_default_budget_to_end_user": [
    "end_user_obj",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span"
  ],
  "_check_end_user_budget": [
    "end_user_obj",
    "route"
  ],
  "get_end_user_object": [
    "end_user_id",
    "prisma_client",
    "user_api_key_cache",
    "route",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "get_tag_objects_batch": [
    "tag_names",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "get_tag_object": [
    "tag_name",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "get_team_membership": [
    "user_id",
    "team_id",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "model_in_access_group": [
    "model",
    "team_models",
    "llm_router"
  ],
  "_should_check_db": [
    "key",
    "last_db_access_time",
    "db_cache_expiry"
  ],
  "_update_last_db_access_time": [
    "key",
    "value",
    "last_db_access_time"
  ],
  "_get_role_based_permissions": [
    "rbac_role",
    "general_settings",
    "key"
  ],
  "get_role_based_models": [
    "rbac_role",
    "general_settings"
  ],
  "get_role_based_routes": [
    "rbac_role",
    "general_settings"
  ],
  "_get_fuzzy_user_object": [
    "prisma_client",
    "sso_user_id",
    "user_email"
  ],
  "get_user_object": [
    "user_id",
    "prisma_client",
    "user_api_key_cache",
    "user_id_upsert",
    "parent_otel_span",
    "proxy_logging_obj",
    "sso_user_id",
    "user_email",
    "check_db_only"
  ],
  "_cache_management_object": [
    "key",
    "value",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_cache_team_object": [
    "team_id",
    "team_table",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_cache_key_object": [
    "hashed_token",
    "user_api_key_obj",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_delete_cache_key_object": [
    "hashed_token",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_get_team_db_check": [
    "team_id",
    "prisma_client",
    "team_id_upsert"
  ],
  "_get_team_object_from_db": [
    "team_id",
    "prisma_client"
  ],
  "_get_team_object_from_user_api_key_cache": [
    "team_id",
    "prisma_client",
    "user_api_key_cache",
    "last_db_access_time",
    "db_cache_expiry",
    "proxy_logging_obj",
    "key",
    "team_id_upsert"
  ],
  "_get_team_object_from_cache": [
    "key",
    "proxy_logging_obj",
    "user_api_key_cache",
    "parent_otel_span"
  ],
  "get_team_object": [
    "team_id",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj",
    "check_cache_only",
    "check_db_only",
    "team_id_upsert"
  ],
  "_cache_access_object": [
    "access_group_id",
    "access_group_table",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_delete_cache_access_object": [
    "access_group_id",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "get_access_object": [
    "access_group_id",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "get_team_object_by_alias": [
    "team_alias",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "get_org_object_by_alias": [
    "org_alias",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "ExperimentalUIJWTToken": {
    "get_experimental_ui_login_jwt_auth_token": [
      "user_info"
    ],
    "get_cli_jwt_auth_token": [
      "user_info",
      "team_id"
    ],
    "get_key_object_from_ui_hash_key": [
      "hashed_token"
    ]
  },
  "_fetch_key_object_from_db_with_reconnect": [
    "hashed_token",
    "prisma_client",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "get_key_object": [
    "hashed_token",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj",
    "check_cache_only"
  ],
  "get_object_permission": [
    "object_permission_id",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj"
  ],
  "get_org_object": [
    "org_id",
    "prisma_client",
    "user_api_key_cache",
    "parent_otel_span",
    "proxy_logging_obj",
    "include_budget_table"
  ],
  "_get_resources_from_access_groups": [
    "access_group_ids",
    "resource_field",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_get_models_from_access_groups": [
    "access_group_ids",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_get_mcp_server_ids_from_access_groups": [
    "access_group_ids",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_get_agent_ids_from_access_groups": [
    "access_group_ids",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_check_model_access_helper": [
    "model",
    "llm_router",
    "models",
    "team_model_aliases",
    "team_id"
  ],
  "_can_object_call_model": [
    "model",
    "llm_router",
    "models",
    "team_model_aliases",
    "team_id",
    "object_type",
    "fallback_depth"
  ],
  "_model_in_team_aliases": [
    "model",
    "team_model_aliases"
  ],
  "can_key_call_model": [
    "model",
    "llm_model_list",
    "valid_token",
    "llm_router"
  ],
  "can_org_access_model": [
    "model",
    "org_object",
    "llm_router",
    "team_model_aliases"
  ],
  "can_team_access_model": [
    "model",
    "team_object",
    "llm_router",
    "team_model_aliases"
  ],
  "can_project_access_model": [
    "model",
    "project_object",
    "llm_router"
  ],
  "can_user_call_model": [
    "model",
    "llm_router",
    "user_object"
  ],
  "is_valid_fallback_model": [
    "model",
    "llm_router",
    "user_model"
  ],
  "_virtual_key_max_budget_check": [
    "valid_token",
    "proxy_logging_obj",
    "user_obj"
  ],
  "_virtual_key_soft_budget_check": [
    "valid_token",
    "proxy_logging_obj",
    "user_obj"
  ],
  "_virtual_key_max_budget_alert_check": [
    "valid_token",
    "proxy_logging_obj",
    "user_obj"
  ],
  "_check_team_member_budget": [
    "team_object",
    "user_object",
    "valid_token",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_team_max_budget_check": [
    "team_object",
    "valid_token",
    "proxy_logging_obj"
  ],
  "_team_soft_budget_check": [
    "team_object",
    "valid_token",
    "proxy_logging_obj"
  ],
  "_project_max_budget_check": [
    "project_object",
    "valid_token",
    "proxy_logging_obj"
  ],
  "_project_soft_budget_check": [
    "project_object",
    "valid_token",
    "proxy_logging_obj"
  ],
  "get_project_object": [
    "project_id",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_organization_max_budget_check": [
    "valid_token",
    "team_object",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj"
  ],
  "_tag_max_budget_check": [
    "request_body",
    "prisma_client",
    "user_api_key_cache",
    "proxy_logging_obj",
    "valid_token"
  ],
  "is_model_allowed_by_pattern": [
    "model",
    "allowed_model_pattern"
  ],
  "_model_matches_any_wildcard_pattern_in_list": [
    "model",
    "allowed_model_list"
  ],
  "_model_custom_llm_provider_matches_wildcard_pattern": [
    "model",
    "allowed_model_pattern"
  ],
  "_is_wildcard_pattern": [
    "allowed_model_pattern"
  ],
  "vector_store_access_check": [
    "request_body",
    "team_object",
    "valid_token"
  ],
  "_can_object_call_vector_stores": [
    "object_type",
    "vector_store_ids_to_run",
    "object_permissions"
  ],
  "_check_wildcard_routing": [
    "model"
  ],
  "get_provider_models": [
    "provider",
    "litellm_params"
  ],
  "get_mcp_server_ids": [
    "user_api_key_dict"
  ],
  "get_key_models": [
    "user_api_key_dict",
    "proxy_model_list",
    "model_access_groups",
    "include_model_access_groups",
    "only_model_access_groups"
  ],
  "get_team_models": [
    "team_models",
    "proxy_model_list",
    "model_access_groups",
    "include_model_access_groups"
  ],
  "get_complete_model_list": [
    "key_models",
    "team_models",
    "proxy_model_list",
    "user_model",
    "infer_model_from_keys",
    "return_wildcard_routes",
    "llm_router",
    "model_access_groups",
    "include_model_access_groups",
    "only_model_access_groups"
  ],
  "get_known_models_from_wildcard": [
    "wildcard_model",
    "litellm_params"
  ],
  "_get_wildcard_models": [
    "unique_models",
    "return_wildcard_routes",
    "llm_router"
  ],
  "get_all_fallbacks": [
    "model",
    "llm_router",
    "fallback_type"
  ],
  "init_rds_client": [
    "aws_access_key_id",
    "aws_secret_access_key",
    "aws_region_name",
    "aws_session_name",
    "aws_profile_name",
    "aws_role_name",
    "aws_web_identity_token",
    "timeout"
  ],
  "generate_iam_auth_token": [
    "db_host",
    "db_port",
    "db_user",
    "client"
  ],
  "IPAddressUtils": {
    "_DEFAULT_INTERNAL_NETWORKS": [],
    "parse_internal_networks": [
      "configured_ranges"
    ],
    "parse_trusted_proxy_networks": [
      "configured_ranges"
    ],
    "is_trusted_proxy": [
      "proxy_ip",
      "trusted_networks"
    ],
    "is_internal_ip": [
      "client_ip",
      "internal_networks"
    ],
    "get_mcp_client_ip": [
      "request",
      "general_settings"
    ]
  },
  "RouteChecks": {
    "should_call_route": [
      "route",
      "valid_token"
    ],
    "is_virtual_key_allowed_to_call_route": [
      "route",
      "valid_token"
    ],
    "_mask_user_id": [
      "user_id"
    ],
    "_raise_admin_only_route_exception": [
      "user_obj",
      "route"
    ],
    "non_proxy_admin_allowed_routes_check": [
      "user_obj",
      "_user_role",
      "route",
      "request",
      "valid_token",
      "request_data"
    ],
    "custom_admin_only_route_check": [
      "route"
    ],
    "is_llm_api_route": [
      "route"
    ],
    "is_management_route": [
      "route"
    ],
    "_is_azure_openai_route": [
      "route"
    ],
    "_route_matches_pattern": [
      "route",
      "pattern"
    ],
    "_is_wildcard_pattern": [
      "pattern"
    ],
    "_route_matches_wildcard_pattern": [
      "route",
      "pattern"
    ],
    "_route_matches_allowed_route": [
      "route",
      "allowed_route"
    ],
    "check_route_access": [
      "route",
      "allowed_routes"
    ],
    "check_passthrough_route_access": [
      "route",
      "user_api_key_dict"
    ],
    "_is_assistants_api_request": [
      "request"
    ],
    "is_generate_content_route": [
      "route"
    ],
    "_check_proxy_admin_viewer_access": [
      "route",
      "_user_role",
      "request_data"
    ]
  },
  "_get_request_ip_address": [
    "request",
    "use_x_forwarded_for"
  ],
  "_check_valid_ip": [
    "allowed_ips",
    "request",
    "use_x_forwarded_for"
  ],
  "check_complete_credentials": [
    "request_body"
  ],
  "check_regex_or_str_match": [
    "request_body_value",
    "regex_str"
  ],
  "_is_param_allowed": [
    "param",
    "request_body_value",
    "configurable_clientside_auth_params"
  ],
  "_allow_model_level_clientside_configurable_parameters": [
    "model",
    "param",
    "request_body_value",
    "llm_router"
  ],
  "is_request_body_safe": [
    "request_body",
    "general_settings",
    "llm_router",
    "model"
  ],
  "pre_db_read_auth_checks": [
    "request",
    "request_data",
    "route"
  ],
  "route_in_additonal_public_routes": [
    "current_route"
  ],
  "get_request_route": [
    "request"
  ],
  "normalize_request_route": [
    "route"
  ],
  "check_if_request_size_is_safe": [
    "request"
  ],
  "check_response_size_is_safe": [
    "response"
  ],
  "bytes_to_mb": [
    "bytes_value"
  ],
  "get_key_model_rpm_limit": [
    "user_api_key_dict"
  ],
  "get_key_model_tpm_limit": [
    "user_api_key_dict"
  ],
  "get_model_rate_limit_from_metadata": [
    "user_api_key_dict",
    "metadata_accessor_key",
    "rate_limit_key"
  ],
  "get_team_model_rpm_limit": [
    "user_api_key_dict"
  ],
  "get_team_model_tpm_limit": [
    "user_api_key_dict"
  ],
  "is_pass_through_provider_route": [
    "route"
  ],
  "_has_user_setup_sso": [],
  "get_customer_user_header_from_mapping": [
    "user_id_mapping"
  ],
  "_get_customer_id_from_standard_headers": [
    "request_headers"
  ],
  "get_end_user_id_from_request_body": [
    "request_body",
    "request_headers"
  ],
  "get_model_from_request": [
    "request_data",
    "route"
  ],
  "abbreviate_api_key": [
    "api_key"
  ],
  "user_api_key_service_logger_obj": [],
  "custom_litellm_key_header": [],
  "api_key_header": [],
  "azure_api_key_header": [],
  "anthropic_api_key_header": [],
  "google_ai_studio_api_key_header": [],
  "azure_apim_header": [],
  "_get_bearer_token_or_received_api_key": [
    "api_key"
  ],
  "_get_bearer_token": [
    "api_key"
  ],
  "_apply_budget_limits_to_end_user_params": [
    "end_user_params",
    "budget_info",
    "end_user_id"
  ],
  "user_api_key_auth_websocket": [
    "websocket"
  ],
  "update_valid_token_with_end_user_params": [
    "valid_token",
    "end_user_params"
  ],
  "_global_spend_coordinator": [],
  "_fetch_global_spend_with_event_coordination": [
    "cache_key",
    "user_api_key_cache",
    "prisma_client"
  ],
  "get_global_proxy_spend": [
    "litellm_proxy_admin_name",
    "user_api_key_cache",
    "prisma_client",
    "token",
    "proxy_logging_obj"
  ],
  "get_rbac_role": [
    "jwt_handler",
    "scopes"
  ],
  "check_api_key_for_custom_headers_or_pass_through_endpoints": [
    "request",
    "route",
    "pass_through_endpoints",
    "api_key"
  ],
  "_user_api_key_auth_builder": [
    "request",
    "api_key",
    "azure_api_key_header",
    "anthropic_api_key_header",
    "google_ai_studio_api_key_header",
    "azure_apim_header",
    "request_data",
    "custom_litellm_key_header"
  ],
  "_return_user_api_key_auth_obj": [
    "user_obj",
    "api_key",
    "parent_otel_span",
    "valid_token_dict",
    "route",
    "start_time",
    "user_role"
  ],
  "get_api_key_from_custom_header": [
    "request",
    "custom_litellm_key_header_name"
  ],
  "_get_temp_budget_increase": [
    "valid_token"
  ],
  "_update_key_budget_with_temp_budget_increase": [
    "valid_token"
  ],
  "ocr": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_build_file_metadata_entry": [
    "response",
    "file_data",
    "file_url"
  ],
  "_save_vector_store_to_db_from_rag_ingest": [
    "response",
    "ingest_options",
    "prisma_client",
    "user_api_key_dict",
    "file_data",
    "file_url"
  ],
  "parse_rag_ingest_request": [
    "request"
  ],
  "rag_ingest": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "rag_query": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_is_master_key": [
    "api_key",
    "_master_key"
  ],
  "_get_spend_logs_metadata": [
    "metadata",
    "applied_guardrails",
    "batch_models",
    "mcp_tool_call_metadata",
    "vector_store_request_metadata",
    "guardrail_information",
    "usage_object",
    "model_map_information",
    "cold_storage_object_key",
    "litellm_overhead_time_ms",
    "cost_breakdown"
  ],
  "generate_hash_from_response": [
    "response_obj"
  ],
  "get_spend_logs_id": [
    "call_type",
    "response_obj",
    "kwargs"
  ],
  "_extract_usage_for_ocr_call": [
    "response_obj",
    "response_obj_dict"
  ],
  "get_logging_payload": [
    "kwargs",
    "response_obj",
    "start_time",
    "end_time"
  ],
  "_get_session_id_for_spend_log": [
    "kwargs",
    "standard_logging_payload"
  ],
  "_ensure_datetime_utc": [
    "timestamp"
  ],
  "get_spend_by_team_and_customer": [
    "start_date",
    "end_date",
    "team_id",
    "customer_id",
    "prisma_client"
  ],
  "_get_messages_for_spend_logs_payload": [
    "standard_logging_payload",
    "metadata"
  ],
  "_sanitize_request_body_for_spend_logs_payload": [
    "request_body",
    "visited"
  ],
  "_convert_to_json_serializable_dict": [
    "obj",
    "visited",
    "max_depth"
  ],
  "_get_proxy_server_request_for_spend_logs_payload": [
    "metadata",
    "litellm_params",
    "kwargs"
  ],
  "_get_vector_store_request_for_spend_logs_payload": [
    "vector_store_request_metadata"
  ],
  "_get_response_for_spend_logs_payload": [
    "payload",
    "kwargs"
  ],
  "_should_store_prompts_and_responses_in_spend_logs": [],
  "_get_status_for_spend_log": [
    "metadata"
  ],
  "_sensitive_masker": [],
  "_set_cloudzero_settings": [
    "api_key",
    "connection_id",
    "timezone"
  ],
  "_get_cloudzero_settings": [],
  "get_cloudzero_settings": [
    "user_api_key_dict"
  ],
  "update_cloudzero_settings": [
    "request",
    "user_api_key_dict"
  ],
  "_cloudzero_background_job_initialized": [],
  "is_cloudzero_setup_in_db": [],
  "is_cloudzero_setup_in_config": [],
  "is_cloudzero_setup": [],
  "init_cloudzero_settings": [
    "request",
    "user_api_key_dict"
  ],
  "cloudzero_dry_run_export": [
    "request",
    "user_api_key_dict"
  ],
  "cloudzero_export": [
    "request",
    "user_api_key_dict"
  ],
  "delete_cloudzero_settings": [
    "user_api_key_dict"
  ],
  "spend_key_fn": [],
  "spend_user_fn": [
    "user_id"
  ],
  "view_spend_tags": [
    "start_date",
    "end_date"
  ],
  "get_global_activity_internal_user": [
    "user_api_key_dict",
    "start_date",
    "end_date"
  ],
  "get_global_activity": [
    "start_date",
    "end_date",
    "user_api_key_dict"
  ],
  "get_global_activity_model_internal_user": [
    "user_api_key_dict",
    "start_date",
    "end_date"
  ],
  "get_global_activity_model": [
    "start_date",
    "end_date",
    "user_api_key_dict"
  ],
  "get_global_activity_exceptions_per_deployment": [
    "model_group",
    "start_date",
    "end_date"
  ],
  "get_global_activity_exceptions": [
    "model_group",
    "start_date",
    "end_date"
  ],
  "get_global_spend_provider": [
    "start_date",
    "end_date",
    "user_api_key_dict"
  ],
  "get_global_spend_report": [
    "start_date",
    "end_date",
    "group_by",
    "api_key",
    "internal_user_id",
    "team_id",
    "customer_id"
  ],
  "global_get_all_tag_names": [],
  "global_view_spend_tags": [
    "start_date",
    "end_date",
    "tags"
  ],
  "_get_spend_report_for_time_range": [
    "start_date",
    "end_date"
  ],
  "calculate_spend": [
    "request"
  ],
  "ui_view_spend_logs": [
    "request",
    "api_key",
    "user_id",
    "request_id",
    "team_id",
    "min_spend",
    "max_spend",
    "start_date",
    "end_date",
    "page",
    "page_size",
    "user_api_key_dict",
    "status_filter",
    "model",
    "model_id",
    "key_alias",
    "end_user",
    "error_code",
    "error_message",
    "sort_by",
    "sort_order"
  ],
  "ui_view_request_response_for_request_id": [
    "request_id",
    "start_date",
    "end_date"
  ],
  "view_spend_logs": [
    "api_key",
    "user_id",
    "request_id",
    "start_date",
    "end_date",
    "summarize",
    "user_api_key_dict"
  ],
  "global_spend_reset": [],
  "global_spend_refresh": [],
  "global_spend_for_internal_user": [
    "api_key",
    "user_api_key_dict"
  ],
  "global_spend_logs": [
    "api_key",
    "user_api_key_dict"
  ],
  "global_spend": [],
  "global_spend_key_internal_user": [
    "user_api_key_dict",
    "limit"
  ],
  "global_spend_keys": [
    "limit",
    "user_api_key_dict"
  ],
  "global_spend_per_team": [],
  "global_view_all_end_users": [],
  "global_spend_end_users": [
    "data"
  ],
  "global_spend_models_internal_user": [
    "user_api_key_dict",
    "limit"
  ],
  "global_spend_models": [
    "limit",
    "user_api_key_dict"
  ],
  "provider_budgets": [],
  "get_spend_by_tags": [
    "prisma_client",
    "start_date",
    "end_date"
  ],
  "ui_get_spend_by_tags": [
    "start_date",
    "end_date",
    "prisma_client",
    "tags_str"
  ],
  "ui_view_session_spend_logs": [
    "session_id",
    "page",
    "page_size",
    "user_api_key_dict"
  ],
  "_build_ui_spend_logs_response": [
    "prisma_client",
    "data",
    "total_records",
    "page",
    "page_size",
    "total_pages",
    "enrich_session_counts"
  ],
  "_build_status_filter_condition": [
    "status_filter"
  ],
  "_is_admin_view_safe": [
    "user_api_key_dict"
  ],
  "_can_team_member_view_log": [
    "prisma_client",
    "user_api_key_dict",
    "team_id"
  ],
  "_can_user_view_spend_log": [
    "user_api_key_dict"
  ],
  "ColdStorageHandler": {
    "get_proxy_server_request_from_cold_storage_with_object_key": [
      "self",
      "object_key"
    ],
    "_select_custom_logger_for_cold_storage": [
      "self"
    ]
  },
  "get_instance_fn": [
    "value",
    "config_file_path"
  ],
  "_load_instance_from_remote_storage": [
    "remote_url",
    "config_file_path"
  ],
  "_download_gcs_file_wrapper": [
    "bucket_name",
    "object_key",
    "local_file_path"
  ],
  "validate_custom_validate_return_type": [
    "fn"
  ],
  "uploadfile_to_bytesio": [
    "upload"
  ],
  "batch_to_bytesio": [
    "uploads"
  ],
  "image_generation": [
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "model"
  ],
  "image_edit_api": [
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "image",
    "image_array",
    "mask",
    "mask_array",
    "model"
  ],
  "create_eval": [
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "list_evals": [
    "fastapi_response",
    "request",
    "limit",
    "after",
    "before",
    "order",
    "order_by",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "get_eval": [
    "eval_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "update_eval": [
    "eval_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "delete_eval": [
    "eval_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "cancel_eval": [
    "eval_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "create_run": [
    "eval_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "list_runs": [
    "eval_id",
    "fastapi_response",
    "request",
    "limit",
    "after",
    "before",
    "order",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "get_run": [
    "eval_id",
    "run_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "cancel_run": [
    "eval_id",
    "run_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "delete_run": [
    "eval_id",
    "run_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "create_invitation_for_user": [
    "data",
    "user_api_key_dict"
  ],
  "get_new_internal_user_defaults": [
    "user_id",
    "user_email"
  ],
  "handle_budget_for_entity": [
    "data",
    "existing_budget_id",
    "user_api_key_dict",
    "prisma_client",
    "litellm_proxy_admin_name"
  ],
  "add_new_member": [
    "new_member",
    "max_budget_in_team",
    "prisma_client",
    "team_id",
    "user_api_key_dict",
    "litellm_proxy_admin_name",
    "default_team_budget_id"
  ],
  "_delete_user_id_from_cache": [
    "kwargs"
  ],
  "_delete_api_key_from_cache": [
    "kwargs"
  ],
  "_delete_team_id_from_cache": [
    "kwargs"
  ],
  "_delete_customer_id_from_cache": [
    "kwargs"
  ],
  "send_management_endpoint_alert": [
    "request_kwargs",
    "user_api_key_dict",
    "function_name"
  ],
  "management_endpoint_wrapper": [
    "func"
  ],
  "create_object_audit_log": [
    "object_id",
    "action",
    "litellm_changed_by",
    "user_api_key_dict",
    "litellm_proxy_admin_name",
    "table_name",
    "before_value",
    "after_value"
  ],
  "create_audit_log_for_update": [
    "request_data"
  ],
  "DEFAULT_TEAM_MEMBER_PERMISSIONS": [],
  "TeamMemberPermissionChecks": {
    "get_permissions_for_team_member": [
      "team_member_object",
      "team_table"
    ],
    "_get_list_of_route_enum_as_str": [
      "route_enum"
    ],
    "can_team_member_execute_key_management_endpoint": [
      "user_api_key_dict",
      "route",
      "prisma_client",
      "user_api_key_cache",
      "existing_key_row"
    ],
    "does_team_member_have_permissions_for_endpoint": [
      "team_member_object",
      "team_table",
      "route"
    ],
    "user_belongs_to_keys_team": [
      "user_api_key_dict",
      "existing_key_row"
    ],
    "get_all_available_team_member_permissions": [],
    "default_team_member_permissions": []
  },
  "attach_object_permission_to_dict": [
    "data_dict",
    "prisma_client"
  ],
  "handle_update_object_permission_common": [
    "data_json",
    "existing_object_permission_id",
    "prisma_client"
  ],
  "PolicyRegistry": {
    "__init__": [
      "self"
    ],
    "load_policies": [
      "self",
      "policies_config"
    ],
    "_parse_policy": [
      "self",
      "policy_name",
      "policy_data"
    ],
    "_parse_pipeline": [
      "pipeline_data"
    ],
    "get_policy": [
      "self",
      "policy_name"
    ],
    "get_all_policies": [
      "self"
    ],
    "get_policy_names": [
      "self"
    ],
    "has_policy": [
      "self",
      "policy_name"
    ],
    "is_initialized": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "add_policy": [
      "self",
      "policy_name",
      "policy"
    ],
    "remove_policy": [
      "self",
      "policy_name"
    ],
    "add_policy_to_db": [
      "self",
      "policy_request",
      "prisma_client",
      "created_by"
    ],
    "update_policy_in_db": [
      "self",
      "policy_id",
      "policy_request",
      "prisma_client",
      "updated_by"
    ],
    "delete_policy_from_db": [
      "self",
      "policy_id",
      "prisma_client"
    ],
    "get_policy_by_id_from_db": [
      "self",
      "policy_id",
      "prisma_client"
    ],
    "get_all_policies_from_db": [
      "self",
      "prisma_client"
    ],
    "sync_policies_from_db": [
      "self",
      "prisma_client"
    ],
    "resolve_guardrails_from_db": [
      "self",
      "policy_name",
      "prisma_client"
    ]
  },
  "get_policy_registry": [],
  "PipelineExecutor": {
    "execute_steps": [
      "steps",
      "mode",
      "data",
      "user_api_key_dict",
      "call_type",
      "policy_name"
    ],
    "_run_step": [
      "step",
      "mode",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "_find_guardrail_callback": [
      "guardrail_name"
    ]
  },
  "_extract_error_message": [
    "e"
  ],
  "create_policy": [
    "request",
    "user_api_key_dict"
  ],
  "get_policy": [
    "policy_id"
  ],
  "update_policy": [
    "policy_id",
    "request",
    "user_api_key_dict"
  ],
  "delete_policy": [
    "policy_id"
  ],
  "get_resolved_guardrails": [
    "policy_id"
  ],
  "test_pipeline": [
    "request",
    "user_api_key_dict"
  ],
  "list_policy_attachments": [],
  "create_policy_attachment": [
    "request",
    "user_api_key_dict"
  ],
  "get_policy_attachment": [
    "attachment_id"
  ],
  "delete_policy_attachment": [
    "attachment_id"
  ],
  "ConditionEvaluator": {
    "evaluate": [
      "condition",
      "context"
    ],
    "_evaluate_model_condition": [
      "condition",
      "model"
    ],
    "_matches_pattern": [
      "pattern",
      "value"
    ]
  },
  "PolicyResolver": {
    "resolve_inheritance_chain": [
      "policy_name",
      "policies",
      "visited"
    ],
    "resolve_policy_guardrails": [
      "policy_name",
      "policies",
      "context"
    ],
    "resolve_guardrails_for_context": [
      "context",
      "policies"
    ],
    "resolve_pipelines_for_context": [
      "context",
      "policies"
    ],
    "get_pipeline_managed_guardrails": [
      "pipelines"
    ],
    "get_all_resolved_policies": [
      "policies",
      "context"
    ]
  },
  "PolicyValidator": {
    "__init__": [
      "self",
      "prisma_client",
      "llm_router"
    ],
    "is_wildcard_pattern": [
      "pattern"
    ],
    "get_available_guardrails": [
      "self"
    ],
    "check_team_alias_exists": [
      "self",
      "team_alias"
    ],
    "check_key_alias_exists": [
      "self",
      "key_alias"
    ],
    "check_model_exists": [
      "self",
      "model"
    ],
    "_validate_inheritance_chain": [
      "self",
      "policy_name",
      "policies",
      "visited",
      "max_depth"
    ],
    "validate_policies": [
      "self",
      "policies",
      "validate_db"
    ],
    "_validate_pipeline": [
      "policy_name",
      "policy",
      "available_guardrails"
    ],
    "validate_policy_config": [
      "self",
      "policy_config",
      "validate_db"
    ]
  },
  "_green_color_code": [],
  "_blue_color_code": [],
  "_yellow_color_code": [],
  "_reset_color_code": [],
  "_print_policies_on_startup": [
    "policies_config",
    "policy_attachments_config"
  ],
  "init_policies": [
    "policies_config",
    "policy_attachments_config",
    "prisma_client",
    "validate_db",
    "fail_on_error"
  ],
  "init_policies_sync": [
    "policies_config",
    "policy_attachments_config",
    "fail_on_error"
  ],
  "get_policies_summary": [],
  "_build_alias_where": [
    "field",
    "patterns"
  ],
  "_parse_metadata": [
    "raw_metadata"
  ],
  "_get_tags_from_metadata": [
    "metadata",
    "json_metadata"
  ],
  "_fetch_all_teams": [
    "prisma_client"
  ],
  "_filter_keys_by_tags": [
    "keys",
    "tag_patterns"
  ],
  "_filter_teams_by_tags": [
    "teams",
    "tag_patterns"
  ],
  "_find_affected_by_team_patterns": [
    "prisma_client",
    "all_teams",
    "team_patterns",
    "existing_teams",
    "existing_keys"
  ],
  "_find_affected_keys_by_alias": [
    "prisma_client",
    "key_patterns",
    "existing_keys"
  ],
  "resolve_policies_for_context": [
    "request",
    "force_sync",
    "user_api_key_dict"
  ],
  "estimate_attachment_impact": [
    "request",
    "user_api_key_dict"
  ],
  "AttachmentRegistry": {
    "__init__": [
      "self"
    ],
    "load_attachments": [
      "self",
      "attachments_config"
    ],
    "_parse_attachment": [
      "self",
      "attachment_data"
    ],
    "get_attached_policies": [
      "self",
      "context"
    ],
    "get_attached_policies_with_reasons": [
      "self",
      "context"
    ],
    "_describe_match_reason": [
      "attachment",
      "context"
    ],
    "is_policy_attached": [
      "self",
      "policy_name",
      "context"
    ],
    "get_all_attachments": [
      "self"
    ],
    "get_attachments_for_policy": [
      "self",
      "policy_name"
    ],
    "is_initialized": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "add_attachment": [
      "self",
      "attachment"
    ],
    "remove_attachments_for_policy": [
      "self",
      "policy_name"
    ],
    "remove_attachment_by_id": [
      "self",
      "attachment_id"
    ],
    "add_attachment_to_db": [
      "self",
      "attachment_request",
      "prisma_client",
      "created_by"
    ],
    "delete_attachment_from_db": [
      "self",
      "attachment_id",
      "prisma_client"
    ],
    "get_attachment_by_id_from_db": [
      "self",
      "attachment_id",
      "prisma_client"
    ],
    "get_all_attachments_from_db": [
      "self",
      "prisma_client"
    ],
    "sync_attachments_from_db": [
      "self",
      "prisma_client"
    ]
  },
  "get_attachment_registry": [],
  "PolicyMatcher": {
    "matches_pattern": [
      "value",
      "patterns"
    ],
    "scope_matches": [
      "scope",
      "context"
    ],
    "get_matching_policies": [
      "context"
    ],
    "get_matching_policies_from_registry": [
      "context"
    ],
    "get_policies_with_matching_conditions": [
      "policy_names",
      "context",
      "policies"
    ]
  },
  "build_health_app": [],
  "_resolve_os_environ_variables": [
    "params"
  ],
  "get_callback_identifier": [
    "callback"
  ],
  "services": [],
  "test_endpoint": [
    "request"
  ],
  "health_services_endpoint": [
    "user_api_key_dict",
    "service"
  ],
  "_convert_health_check_to_dict": [
    "check"
  ],
  "_check_prisma_client": [],
  "_save_health_check_to_db": [
    "prisma_client",
    "model_name",
    "healthy_endpoints",
    "unhealthy_endpoints",
    "start_time",
    "user_id",
    "model_id"
  ],
  "_build_model_param_to_info_mapping": [
    "model_list"
  ],
  "_aggregate_health_check_results": [
    "model_param_to_info",
    "healthy_endpoints",
    "unhealthy_endpoints"
  ],
  "_save_health_check_results_if_changed": [
    "prisma_client",
    "model_results",
    "latest_checks_map",
    "start_time",
    "checked_by"
  ],
  "_save_background_health_checks_to_db": [
    "prisma_client",
    "model_list",
    "healthy_endpoints",
    "unhealthy_endpoints",
    "start_time",
    "checked_by"
  ],
  "_perform_health_check_and_save": [
    "model_list",
    "target_model",
    "cli_model",
    "details",
    "prisma_client",
    "start_time",
    "user_id",
    "model_id"
  ],
  "health_endpoint": [
    "user_api_key_dict",
    "model",
    "model_id"
  ],
  "health_check_history_endpoint": [
    "user_api_key_dict",
    "model",
    "status_filter",
    "limit",
    "offset"
  ],
  "latest_health_checks_endpoint": [
    "user_api_key_dict"
  ],
  "shared_health_check_status_endpoint": [
    "user_api_key_dict"
  ],
  "_read_license_data": [],
  "_read_allowed_features": [
    "license_data"
  ],
  "health_license_endpoint": [
    "user_api_key_dict"
  ],
  "db_health_cache": [],
  "_db_health_readiness_check": [],
  "active_callbacks": [],
  "callback_name": [
    "callback"
  ],
  "health_readiness": [],
  "health_liveliness": [],
  "health_readiness_options": [],
  "health_liveliness_options": [],
  "test_model_connection": [
    "request",
    "mode",
    "litellm_params",
    "model_info",
    "user_api_key_dict"
  ],
  "prompt_initializer_registry": [],
  "get_prompt_initializer_from_integrations": [],
  "InMemoryPromptRegistry": {
    "__init__": [
      "self"
    ],
    "initialize_prompt": [
      "self",
      "prompt",
      "config_file_path"
    ],
    "get_prompt_by_id": [
      "self",
      "prompt_id"
    ],
    "get_prompt_callback_by_id": [
      "self",
      "prompt_id"
    ],
    "delete_prompts_by_base_id": [
      "self",
      "base_prompt_id"
    ]
  },
  "IN_MEMORY_PROMPT_REGISTRY": [],
  "get_base_prompt_id": [
    "prompt_id"
  ],
  "get_version_number": [
    "prompt_id"
  ],
  "construct_versioned_prompt_id": [
    "prompt_id",
    "version"
  ],
  "get_latest_version_prompt_id": [
    "prompt_id",
    "all_prompt_ids"
  ],
  "get_latest_prompt_versions": [
    "prompts"
  ],
  "get_next_version_for_prompt": [
    "prisma_client",
    "prompt_id"
  ],
  "create_versioned_prompt_spec": [
    "db_prompt"
  ],
  "Prompt": {},
  "PatchPromptRequest": {},
  "list_prompts": [
    "user_api_key_dict"
  ],
  "get_prompt_versions": [
    "prompt_id",
    "user_api_key_dict"
  ],
  "get_prompt_info": [
    "prompt_id",
    "user_api_key_dict"
  ],
  "create_prompt": [
    "request",
    "user_api_key_dict"
  ],
  "update_prompt": [
    "prompt_id",
    "request",
    "user_api_key_dict"
  ],
  "delete_prompt": [
    "prompt_id",
    "user_api_key_dict"
  ],
  "patch_prompt": [
    "prompt_id",
    "request",
    "user_api_key_dict"
  ],
  "test_prompt": [
    "request",
    "fastapi_request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "convert_prompt_file_to_json": [
    "file",
    "user_api_key_dict"
  ],
  "init_prompts": [
    "all_prompts",
    "config_file_path"
  ],
  "background_streaming_task": [
    "polling_id",
    "data",
    "polling_handler",
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "general_settings",
    "llm_router",
    "proxy_config",
    "proxy_logging_obj",
    "select_data_generator",
    "user_model",
    "user_temperature",
    "user_request_timeout",
    "user_max_tokens",
    "user_api_base",
    "version"
  ],
  "ResponsePollingHandler": {
    "CACHE_KEY_PREFIX": [],
    "POLLING_ID_PREFIX": [],
    "__init__": [
      "self",
      "redis_cache",
      "ttl"
    ],
    "generate_polling_id": [
      "cls"
    ],
    "is_polling_id": [
      "cls",
      "response_id"
    ],
    "get_cache_key": [
      "cls",
      "polling_id"
    ],
    "create_initial_state": [
      "self",
      "polling_id",
      "request_data"
    ],
    "update_state": [
      "self",
      "polling_id",
      "status",
      "usage",
      "error",
      "incomplete_details",
      "reasoning",
      "tool_choice",
      "tools",
      "output",
      "model",
      "instructions",
      "temperature",
      "top_p",
      "max_output_tokens",
      "previous_response_id",
      "text",
      "truncation",
      "parallel_tool_calls",
      "user",
      "store"
    ],
    "get_state": [
      "self",
      "polling_id"
    ],
    "cancel_polling": [
      "self",
      "polling_id"
    ],
    "delete_polling": [
      "self",
      "polling_id"
    ]
  },
  "should_use_polling_for_request": [
    "background_mode",
    "polling_via_cache_enabled",
    "redis_cache",
    "model",
    "llm_router",
    "native_background_mode"
  ],
  "IPAddress": {},
  "UIThemeConfig": {},
  "SettingsResponse": {},
  "SSOSettingsResponse": {},
  "InternalUserSettingsResponse": {},
  "DefaultTeamSettingsResponse": {},
  "UIThemeSettingsResponse": {},
  "UISettings": {},
  "UISettingsResponse": {},
  "ALLOWED_UI_SETTINGS_FIELDS": [],
  "MCPSemanticFilterSettings": {},
  "MCPSemanticFilterSettingsResponse": {},
  "get_allowed_ips": [],
  "add_allowed_ip": [
    "ip_address"
  ],
  "delete_allowed_ip": [
    "ip_address"
  ],
  "_get_settings_with_schema": [
    "settings_key",
    "settings_class",
    "config"
  ],
  "get_internal_user_settings": [],
  "get_default_team_settings": [],
  "update_default_team_member_budget": [
    "teams",
    "user_api_key_dict"
  ],
  "_update_litellm_setting": [
    "settings",
    "settings_key",
    "in_memory_var",
    "success_message"
  ],
  "update_internal_user_settings": [
    "settings",
    "user_api_key_dict"
  ],
  "update_default_team_settings": [
    "settings"
  ],
  "get_sso_settings": [],
  "update_sso_settings": [
    "sso_config"
  ],
  "get_ui_theme_settings": [],
  "update_ui_theme_settings": [
    "theme_config"
  ],
  "get_mcp_semantic_filter_settings": [
    "user_api_key_dict"
  ],
  "update_mcp_semantic_filter_settings": [
    "settings",
    "user_api_key_dict"
  ],
  "get_in_product_nudges": [],
  "update_ui_settings": [
    "settings",
    "user_api_key_dict"
  ],
  "upload_logo": [
    "file"
  ],
  "langfuse_proxy_route": [
    "endpoint",
    "request",
    "fastapi_response"
  ],
  "responses_api": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "cursor_chat_completions": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "get_response": [
    "response_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "delete_response": [
    "response_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "get_response_input_items": [
    "response_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "compact_response": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "cancel_response": [
    "response_id",
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "files_config": [],
  "set_files_config": [
    "config"
  ],
  "get_files_provider_config": [
    "custom_llm_provider"
  ],
  "get_first_json_object": [
    "file_content_bytes"
  ],
  "get_model_from_json_obj": [
    "json_object"
  ],
  "_deprecated_loadbalanced_create_file": [
    "llm_router",
    "router_model",
    "_create_file_request"
  ],
  "route_create_file": [
    "llm_router",
    "_create_file_request",
    "purpose",
    "proxy_logging_obj",
    "user_api_key_dict",
    "target_model_names_list",
    "is_router_model",
    "router_model",
    "custom_llm_provider",
    "model",
    "target_storage"
  ],
  "create_file": [
    "request",
    "fastapi_response",
    "purpose",
    "target_model_names",
    "target_storage",
    "provider",
    "custom_llm_provider",
    "file",
    "litellm_metadata",
    "user_api_key_dict"
  ],
  "get_file_content": [
    "request",
    "fastapi_response",
    "file_id",
    "provider",
    "user_api_key_dict"
  ],
  "get_file": [
    "request",
    "fastapi_response",
    "file_id",
    "provider",
    "user_api_key_dict"
  ],
  "delete_file": [
    "request",
    "fastapi_response",
    "file_id",
    "provider",
    "user_api_key_dict"
  ],
  "list_files": [
    "request",
    "fastapi_response",
    "user_api_key_dict",
    "provider",
    "target_model_names",
    "purpose"
  ],
  "StorageBackendFileService": {
    "upload_file_to_storage_backend": [
      "file_data",
      "target_storage",
      "target_model_names",
      "purpose",
      "proxy_logging_obj",
      "user_api_key_dict"
    ],
    "_create_file_object_with_storage_metadata": [
      "file_content",
      "filename",
      "purpose",
      "target_storage",
      "storage_url"
    ],
    "_create_unified_file_id": [
      "file_type",
      "target_model_names",
      "file_id"
    ],
    "_store_in_managed_files": [
      "file_object",
      "file_data",
      "target_model_names",
      "target_storage",
      "storage_url",
      "proxy_logging_obj",
      "user_api_key_dict"
    ]
  },
  "_is_base64_encoded_unified_file_id": [
    "b64_uid"
  ],
  "convert_b64_uid_to_unified_uid": [
    "b64_uid"
  ],
  "get_models_from_unified_file_id": [
    "unified_file_id"
  ],
  "get_model_id_from_unified_batch_id": [
    "file_id"
  ],
  "get_batch_id_from_unified_batch_id": [
    "file_id"
  ],
  "encode_file_id_with_model": [
    "file_id",
    "model",
    "id_type"
  ],
  "decode_model_from_file_id": [
    "encoded_id"
  ],
  "get_original_file_id": [
    "encoded_id"
  ],
  "is_model_embedded_id": [
    "file_id"
  ],
  "extract_model_from_sources": [
    "file_id",
    "request",
    "data"
  ],
  "get_credentials_for_model": [
    "llm_router",
    "model_id",
    "operation_context"
  ],
  "prepare_data_with_credentials": [
    "data",
    "credentials",
    "file_id"
  ],
  "handle_model_based_routing": [
    "file_id",
    "request",
    "llm_router",
    "data",
    "check_file_id_encoding"
  ],
  "GEMINI_SUPPORTED_IMAGE_TYPES": [],
  "GEMINI_SUPPORTED_VIDEO_TYPES": [],
  "GEMINI_SUPPORTED_AUDIO_TYPES": [],
  "GEMINI_SUPPORTED_DOCUMENT_TYPES": [],
  "EXTENSION_TO_MIME_TYPE": [],
  "detect_content_type_from_filename": [
    "filename"
  ],
  "normalize_mime_type_for_provider": [
    "mime_type",
    "provider"
  ],
  "is_gemini_supported_mime_type": [
    "mime_type"
  ],
  "get_content_type_from_file_object": [
    "file_object"
  ],
  "FileCreationParams": {
    "__post_init__": [
      "self"
    ]
  },
  "extract_file_creation_params": [
    "request",
    "request_body",
    "target_model_names_form",
    "target_storage_form"
  ],
  "_extract_target_storage_simple": [
    "target_storage_form"
  ],
  "_extract_target_model_names_simple": [
    "target_model_names_form"
  ],
  "_extract_model_param": [
    "request",
    "request_body"
  ],
  "resolve_input_file_id_to_unified": [
    "response",
    "prisma_client"
  ],
  "get_batch_from_database": [
    "batch_id",
    "unified_batch_id",
    "managed_files_obj",
    "prisma_client",
    "verbose_proxy_logger"
  ],
  "update_batch_in_database": [
    "batch_id",
    "unified_batch_id",
    "response",
    "managed_files_obj",
    "prisma_client",
    "verbose_proxy_logger",
    "db_batch_object",
    "operation"
  ],
  "_does_endpoint_match": [
    "endpoint_path",
    "request_path"
  ],
  "check_vector_store_permission": [
    "index_name",
    "permission",
    "key_metadata",
    "team_metadata"
  ],
  "is_allowed_to_call_vector_store_endpoint": [
    "provider",
    "index_name",
    "request",
    "user_api_key_dict"
  ],
  "is_allowed_to_call_vector_store_files_endpoint": [
    "provider",
    "vector_store_id",
    "request",
    "user_api_key_dict"
  ],
  "_check_vector_store_access": [
    "vector_store",
    "user_api_key_dict"
  ],
  "vector_store_search": [
    "request",
    "vector_store_id",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "vector_store_create": [
    "request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "index_create": [
    "request",
    "index_create_request",
    "fastapi_response",
    "user_api_key_dict"
  ],
  "_resolve_embedding_config_from_router": [
    "embedding_model",
    "llm_router"
  ],
  "_resolve_embedding_config_from_db": [
    "embedding_model",
    "prisma_client"
  ],
  "_resolve_embedding_config": [
    "embedding_model",
    "prisma_client",
    "llm_router"
  ],
  "create_vector_store_in_db": [
    "vector_store_id",
    "custom_llm_provider",
    "prisma_client",
    "vector_store_name",
    "vector_store_description",
    "vector_store_metadata",
    "litellm_params",
    "litellm_credential_name",
    "team_id",
    "user_id"
  ],
  "new_vector_store": [
    "vector_store",
    "user_api_key_dict"
  ],
  "list_vector_stores": [
    "user_api_key_dict",
    "page",
    "page_size"
  ],
  "delete_vector_store": [
    "data",
    "user_api_key_dict"
  ],
  "get_vector_store_info": [
    "data",
    "user_api_key_dict"
  ],
  "update_vector_store": [
    "data",
    "user_api_key_dict"
  ],
  "LITELLM_BANNER": [],
  "show_banner": [],
  "AsyncCacheProtocol": {
    "async_get_cache": [
      "self",
      "key"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ]
  },
  "EventDrivenCacheCoordinator": {
    "__init__": [
      "self",
      "log_prefix"
    ],
    "_get_cached": [
      "self",
      "cache_key",
      "cache"
    ],
    "_log_cache_hit": [
      "self",
      "value"
    ],
    "_log_cache_miss": [
      "self"
    ],
    "_claim_role": [
      "self"
    ],
    "_wait_for_signal_and_get": [
      "self",
      "event",
      "cache_key",
      "cache"
    ],
    "_load_and_cache": [
      "self",
      "cache_key",
      "cache",
      "load_fn"
    ],
    "_signal_done": [
      "self"
    ],
    "get_or_load": [
      "self",
      "cache_key",
      "cache",
      "load_fn"
    ]
  },
  "remove_sensitive_info_from_deployment": [
    "deployment_dict",
    "excluded_keys"
  ],
  "get_custom_llm_provider_from_request_body": [
    "request"
  ],
  "get_custom_llm_provider_from_request_query": [
    "request"
  ],
  "get_custom_llm_provider_from_request_headers": [
    "request"
  ],
  "CustomOpenAPISpec": {
    "CHAT_COMPLETION_PATHS": [],
    "EMBEDDING_PATHS": [],
    "RESPONSES_API_PATHS": [],
    "get_pydantic_schema": [
      "model_class"
    ],
    "add_schema_to_components": [
      "openapi_schema",
      "schema_name",
      "schema_def"
    ],
    "add_request_body_to_paths": [
      "openapi_schema",
      "paths",
      "schema_ref"
    ],
    "_move_defs_to_components": [
      "openapi_schema",
      "defs"
    ],
    "_rewrite_defs_refs": [
      "schema"
    ],
    "_extract_field_schema": [
      "field_def"
    ],
    "_expand_field_definition": [
      "field_def"
    ],
    "add_request_schema": [
      "openapi_schema",
      "model_class",
      "schema_name",
      "paths",
      "operation_name"
    ],
    "add_chat_completion_request_schema": [
      "openapi_schema"
    ],
    "add_embedding_request_schema": [
      "openapi_schema"
    ],
    "add_responses_api_request_schema": [
      "openapi_schema"
    ],
    "add_llm_api_request_schema_body": [
      "openapi_schema"
    ]
  },
  "_profile_lock": [],
  "_profiler": [],
  "_last_profile_file_path": [],
  "_sample_counter": [],
  "_sample_counter_lock": [],
  "_line_profiler_lock": [],
  "_should_sample": [
    "profile_sampling_rate"
  ],
  "_start_profiling": [
    "profile_sampling_rate"
  ],
  "_start_profiling_for_request": [
    "profile_sampling_rate"
  ],
  "_save_stats": [
    "profile_file"
  ],
  "profile_endpoint": [
    "sampling_rate"
  ],
  "enable_line_profiler": [],
  "wrap_function_with_line_profiler": [
    "module",
    "function_name"
  ],
  "wrap_function_directly": [
    "func"
  ],
  "collect_line_profiler_stats": [
    "output_file"
  ],
  "register_shutdown_handler": [
    "output_file"
  ],
  "ResetBudgetJob": {
    "__init__": [
      "self",
      "proxy_logging_obj",
      "prisma_client"
    ],
    "reset_budget": [
      "self"
    ],
    "reset_budget_for_litellm_team_members": [
      "self",
      "budgets_to_reset"
    ],
    "reset_budget_for_litellm_budget_table": [
      "self"
    ],
    "reset_budget_for_litellm_keys": [
      "self"
    ],
    "reset_budget_for_litellm_users": [
      "self"
    ],
    "reset_budget_for_litellm_teams": [
      "self"
    ],
    "_reset_budget_common": [
      "item",
      "current_time",
      "item_type"
    ],
    "_reset_budget_for_team": [
      "team",
      "current_time"
    ],
    "_reset_budget_for_user": [
      "user",
      "current_time"
    ],
    "_reset_budget_for_enduser": [
      "enduser"
    ],
    "_reset_budget_reset_at_date": [
      "budget",
      "current_time"
    ],
    "_reset_budget_for_key": [
      "key",
      "current_time"
    ]
  },
  "_read_request_body": [
    "request"
  ],
  "_safe_get_request_parsed_body": [
    "request"
  ],
  "_safe_get_request_query_params": [
    "request"
  ],
  "_safe_set_request_parsed_body": [
    "request",
    "parsed_body"
  ],
  "_safe_get_request_headers": [
    "request"
  ],
  "check_file_size_under_limit": [
    "request_data",
    "file",
    "router_model_names"
  ],
  "get_form_data": [
    "request"
  ],
  "convert_upload_files_to_file_data": [
    "form_data"
  ],
  "get_request_body": [
    "request"
  ],
  "extract_nested_form_metadata": [
    "form_data",
    "prefix"
  ],
  "get_tags_from_request_body": [
    "request_body"
  ],
  "populate_request_with_path_params": [
    "request_data",
    "request"
  ],
  "_add_vector_store_id_from_path": [
    "request_data",
    "request"
  ],
  "KeyRotationManager": {
    "__init__": [
      "self",
      "prisma_client"
    ],
    "process_rotations": [
      "self"
    ],
    "_find_keys_needing_rotation": [
      "self"
    ],
    "_cleanup_expired_deprecated_keys": [
      "self"
    ],
    "_should_rotate_key": [
      "self",
      "key",
      "now"
    ],
    "_rotate_key": [
      "self",
      "key"
    ]
  },
  "_get_salt_key": [],
  "encrypt_value_helper": [
    "value",
    "new_encryption_key"
  ],
  "decrypt_value_helper": [
    "value",
    "key",
    "exception_type",
    "return_original_value"
  ],
  "encrypt_value": [
    "value",
    "signing_key"
  ],
  "decrypt_value": [
    "value",
    "signing_key"
  ],
  "show_missing_vars_in_env": [],
  "missing_keys_form": [
    "missing_key_names"
  ],
  "admin_ui_disabled": [],
  "blue_color_code": [],
  "reset_color_code": [],
  "initialize_callbacks_on_proxy": [
    "value",
    "premium_user",
    "config_file_path",
    "litellm_settings",
    "callback_specific_params"
  ],
  "get_model_group_from_litellm_kwargs": [
    "kwargs"
  ],
  "get_model_group_from_request_data": [
    "data"
  ],
  "get_remaining_tokens_and_requests_from_request_data": [
    "data"
  ],
  "get_logging_caching_headers": [
    "request_data"
  ],
  "add_guardrail_to_applied_guardrails_header": [
    "request_data",
    "guardrail_name"
  ],
  "add_policy_to_applied_policies_header": [
    "request_data",
    "policy_name"
  ],
  "add_policy_sources_to_metadata": [
    "request_data",
    "policy_sources"
  ],
  "add_guardrail_response_to_standard_logging_object": [
    "litellm_logging_obj",
    "guardrail_response"
  ],
  "process_callback": [
    "_callback",
    "callback_type",
    "environment_variables"
  ],
  "normalize_callback_names": [
    "callbacks"
  ],
  "get_file_contents_from_s3": [
    "bucket_name",
    "object_key"
  ],
  "get_config_file_contents_from_gcs": [
    "bucket_name",
    "object_key"
  ],
  "download_python_file_from_s3": [
    "bucket_name",
    "object_key",
    "local_file_path"
  ],
  "download_python_file_from_gcs": [
    "bucket_name",
    "object_key",
    "local_file_path"
  ],
  "GetRoutes": {
    "get_app_routes": [
      "route",
      "endpoint_route"
    ],
    "get_routes_for_mounted_app": [
      "route"
    ],
    "_safe_get_endpoint_name": [
      "endpoint_function"
    ]
  },
  "ErrorResponse": {},
  "get_status_code": [
    "exception"
  ],
  "ERROR_RESPONSES": [],
  "ProxyState": {
    "valid_keys_literal": [],
    "__init__": [
      "self"
    ],
    "get_proxy_state_variable": [
      "self",
      "variable_name"
    ],
    "set_proxy_state_variable": [
      "self",
      "variable_name",
      "value"
    ]
  },
  "get_budget_reset_timezone": [],
  "get_budget_reset_time": [
    "budget_duration"
  ],
  "configure_gc_thresholds": [],
  "get_active_tasks_stats": [],
  "memory_usage_in_mem_cache": [
    "_"
  ],
  "memory_usage_in_mem_cache_items": [
    "_"
  ],
  "get_memory_summary": [
    "_"
  ],
  "_get_gc_statistics": [],
  "_get_object_type_counts": [
    "top_n"
  ],
  "_get_uncollectable_objects_info": [],
  "_get_cache_memory_stats": [
    "user_api_key_cache",
    "llm_router",
    "proxy_logging_obj",
    "redis_usage_cache"
  ],
  "_get_router_memory_stats": [
    "llm_router"
  ],
  "_get_process_memory_info": [
    "worker_pid",
    "include_process_info"
  ],
  "get_memory_details": [
    "_",
    "top_n",
    "include_process_info"
  ],
  "configure_gc_thresholds_endpoint": [
    "_",
    "generation_0",
    "generation_1",
    "generation_2"
  ],
  "get_otel_spans": [],
  "init_verbose_loggers": [],
  "get_openapi_schema_with_compat": [
    "get_openapi_func",
    "title",
    "version",
    "description",
    "routes"
  ],
  "_realtime_request_body": [
    "model"
  ],
  "url_to_redirect_to": [],
  "new_ui_login_url": [],
  "build_ui_login_form": [
    "show_deprecation_banner"
  ],
  "html_form": [],
  "render_cli_sso_success_page": [],
  "jwt_display_template": [],
  "GuardrailForLBTestingA": {
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "GuardrailForLBTestingB": {
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "myCustomGuardrail": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ]
  },
  "MyCustomLLM": {
    "completion": [
      "self"
    ],
    "acompletion": [
      "self"
    ]
  },
  "my_custom_llm": [],
  "MyCustomHandler": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_streaming_hook": [
      "self",
      "user_api_key_dict",
      "response"
    ]
  },
  "proxy_handler_instance": [],
  "StrictFilter": {
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "PermissiveFilter": {
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "AlwaysBlockFilter": {
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ]
  },
  "create_skill": [
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "list_skills": [
    "fastapi_response",
    "request",
    "limit",
    "after_id",
    "before_id",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "get_skill": [
    "skill_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "delete_skill": [
    "skill_id",
    "fastapi_response",
    "request",
    "custom_llm_provider",
    "user_api_key_dict"
  ],
  "anthropic_response": [
    "fastapi_response",
    "request",
    "user_api_key_dict"
  ],
  "count_tokens": [
    "request",
    "user_api_key_dict"
  ],
  "event_logging_batch": [
    "request"
  ],
  "_get_prisma_client": [],
  "get_marketplace": [],
  "register_plugin": [
    "request",
    "user_api_key_dict"
  ],
  "list_plugins": [
    "enabled_only",
    "user_api_key_dict"
  ],
  "get_plugin": [
    "plugin_name",
    "user_api_key_dict"
  ],
  "enable_plugin": [
    "plugin_name",
    "user_api_key_dict"
  ],
  "disable_plugin": [
    "plugin_name",
    "user_api_key_dict"
  ],
  "delete_plugin": [
    "plugin_name",
    "user_api_key_dict"
  ],
  "guardrail_initializer_registry": [],
  "get_guardrail_initializer_from_hooks": [],
  "get_guardrail_class_from_hooks": [],
  "_discovered_initializers": [],
  "GuardrailRegistry": {
    "__init__": [
      "self"
    ],
    "get_initialized_guardrail_callback": [
      "self",
      "guardrail_name"
    ],
    "add_guardrail_to_db": [
      "self",
      "guardrail",
      "prisma_client"
    ],
    "delete_guardrail_from_db": [
      "self",
      "guardrail_id",
      "prisma_client"
    ],
    "update_guardrail_in_db": [
      "self",
      "guardrail_id",
      "guardrail",
      "prisma_client"
    ],
    "get_all_guardrails_from_db": [
      "prisma_client"
    ],
    "get_guardrail_by_id_from_db": [
      "self",
      "guardrail_id",
      "prisma_client"
    ],
    "get_guardrail_by_name_from_db": [
      "self",
      "guardrail_name",
      "prisma_client"
    ]
  },
  "InMemoryGuardrailHandler": {
    "__init__": [
      "self"
    ],
    "initialize_guardrail": [
      "self",
      "guardrail",
      "config_file_path",
      "llm_router"
    ],
    "initialize_custom_guardrail": [
      "self",
      "guardrail",
      "guardrail_type",
      "litellm_params",
      "config_file_path"
    ],
    "update_in_memory_guardrail": [
      "self",
      "guardrail_id",
      "guardrail"
    ],
    "delete_in_memory_guardrail": [
      "self",
      "guardrail_id"
    ],
    "list_in_memory_guardrails": [
      "self"
    ],
    "get_guardrail_by_id": [
      "self",
      "guardrail_id"
    ],
    "_has_guardrail_params_changed": [
      "self",
      "guardrail_id",
      "new_guardrail"
    ],
    "reinitialize_guardrail": [
      "self",
      "guardrail",
      "config_file_path"
    ],
    "sync_guardrail_from_db": [
      "self",
      "guardrail",
      "config_file_path"
    ]
  },
  "IN_MEMORY_GUARDRAIL_HANDLER": [],
  "can_modify_guardrails": [
    "team_obj"
  ],
  "should_proceed_based_on_metadata": [
    "data",
    "guardrail_name"
  ],
  "should_proceed_based_on_api_key": [
    "user_api_key_dict",
    "guardrail_name"
  ],
  "GUARDRAIL_REGISTRY": [],
  "_get_guardrails_list_response": [
    "guardrails_config"
  ],
  "list_guardrails": [],
  "list_guardrails_v2": [],
  "CreateGuardrailRequest": {},
  "create_guardrail": [
    "request"
  ],
  "UpdateGuardrailRequest": {},
  "update_guardrail": [
    "guardrail_id",
    "request"
  ],
  "delete_guardrail": [
    "guardrail_id"
  ],
  "patch_guardrail": [
    "guardrail_id",
    "request"
  ],
  "get_guardrail_info": [
    "guardrail_id"
  ],
  "get_guardrail_ui_settings": [],
  "get_category_yaml": [
    "category_name"
  ],
  "get_major_airlines": [],
  "validate_blocked_words_file": [
    "request"
  ],
  "_get_field_type_from_annotation": [
    "field_annotation"
  ],
  "_extract_literal_values": [
    "annotation"
  ],
  "_get_dict_key_options": [
    "field_annotation"
  ],
  "_get_dict_value_type": [
    "field_annotation"
  ],
  "_get_list_element_options": [
    "field_annotation"
  ],
  "_should_skip_optional_params": [
    "field_name",
    "field_annotation"
  ],
  "_unwrap_optional_type": [
    "field_annotation"
  ],
  "_build_field_dict": [
    "field",
    "field_annotation",
    "description",
    "required"
  ],
  "_extract_fields_recursive": [
    "model",
    "depth"
  ],
  "_get_fields_from_model": [
    "model_class"
  ],
  "get_provider_specific_params": [],
  "TestCustomCodeGuardrailRequest": {},
  "TestCustomCodeGuardrailResponse": {},
  "test_custom_code_guardrail": [
    "request"
  ],
  "apply_guardrail": [
    "request",
    "user_api_key_dict"
  ],
  "init_guardrails_v2": [
    "all_guardrails",
    "config_file_path",
    "llm_router"
  ],
  "_populate_router_guardrail_list": [
    "guardrail_list"
  ],
  "initialize_guardrails": [
    "guardrails_config",
    "premium_user",
    "config_file_path",
    "litellm_settings"
  ],
  "initialize_bedrock": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_lakera": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_lakera_v2": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_presidio": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_hide_secrets": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_tool_permission": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_lasso": [
    "litellm_params",
    "guardrail"
  ],
  "initialize_panw_prisma_airs": [
    "litellm_params",
    "guardrail"
  ],
  "GUARDRAIL_NAME": [],
  "ToolPermissionGuardrail": {
    "__init__": [
      "self",
      "rules",
      "default_action",
      "on_disallowed_action"
    ],
    "get_config_model": [],
    "_matches_regex": [
      "self",
      "pattern",
      "value"
    ],
    "_rule_matches_tool": [
      "self",
      "rule"
    ],
    "_check_tool_permission": [
      "self",
      "tool_name",
      "tool_type"
    ],
    "_parse_tool_call_arguments": [
      "self",
      "tool_call"
    ],
    "_collect_argument_paths": [
      "self",
      "value",
      "current_path",
      "collected",
      "depth"
    ],
    "_patterns_match_for_rule": [
      "self"
    ],
    "_get_permission_for_tool_call": [
      "self",
      "tool_call"
    ],
    "_extract_tool_calls_from_response": [
      "self",
      "response"
    ],
    "_modify_request_with_permission_errors": [
      "self",
      "data",
      "denied_tool_names"
    ],
    "_create_permission_error_result": [
      "self",
      "tool_call",
      "error"
    ],
    "_modify_response_with_permission_errors": [
      "self",
      "response",
      "denied_tools"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ]
  },
  "INPUT_POSITIONING_MAP": [],
  "lakeraAI_Moderation": {
    "__init__": [
      "self",
      "moderation_check",
      "category_thresholds",
      "api_base",
      "api_key"
    ],
    "_check_response_flagged": [
      "self",
      "response"
    ],
    "_check": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ]
  },
  "GuardrailMessageFilterResult": {},
  "_redact_pii_matches": [
    "response_json"
  ],
  "BedrockGuardrail": {
    "__init__": [
      "self",
      "guardrailIdentifier",
      "guardrailVersion",
      "disable_exception_on_block"
    ],
    "_create_bedrock_input_content_request": [
      "self",
      "messages"
    ],
    "_create_bedrock_output_content_request": [
      "self",
      "response"
    ],
    "convert_to_bedrock_format": [
      "self",
      "source",
      "messages",
      "response"
    ],
    "_prepare_guardrail_messages_for_role": [
      "self",
      "messages"
    ],
    "_find_latest_message_index": [
      "self",
      "messages",
      "target_role"
    ],
    "_merge_filtered_messages": [
      "self",
      "original_messages",
      "updated_target_messages",
      "target_indices"
    ],
    "_load_credentials": [
      "self"
    ],
    "_prepare_request": [
      "self",
      "credentials",
      "data",
      "optional_params",
      "aws_region_name",
      "api_key",
      "extra_headers"
    ],
    "make_bedrock_api_request": [
      "self",
      "source",
      "messages",
      "response",
      "request_data"
    ],
    "_check_bedrock_response_for_exception": [
      "self",
      "response"
    ],
    "_get_bedrock_guardrail_response_status": [
      "self",
      "response"
    ],
    "_parse_bedrock_guardrail_error_response": [
      "self",
      "response"
    ],
    "_get_http_exception_for_blocked_guardrail": [
      "self",
      "response"
    ],
    "_should_raise_guardrail_blocked_exception": [
      "self",
      "response"
    ],
    "create_guardrail_blocked_response": [
      "self",
      "response"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "_update_messages_with_updated_bedrock_guardrail_response": [
      "self",
      "messages",
      "bedrock_guardrail_response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "_extract_masked_texts_from_response": [
      "self",
      "bedrock_guardrail_response"
    ],
    "_apply_masking_to_messages": [
      "self",
      "messages",
      "masked_texts"
    ],
    "_mask_content_list": [
      "self",
      "content_list",
      "masked_texts",
      "masking_index"
    ],
    "get_content_for_message": [
      "self",
      "message"
    ],
    "_apply_masking_to_response": [
      "self",
      "response",
      "bedrock_guardrail_response"
    ],
    "_apply_masking_to_model_response": [
      "self",
      "response",
      "masked_texts"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ]
  },
  "LakeraAIGuardrail": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "project_id",
      "payload",
      "breakdown",
      "metadata",
      "dev_info",
      "on_flagged"
    ],
    "call_v2_guard": [
      "self",
      "messages",
      "request_data",
      "event_type"
    ],
    "_mask_pii_in_messages": [
      "self",
      "messages",
      "lakera_response",
      "masked_entity_count"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "_is_only_pii_violation": [
      "self",
      "lakera_response"
    ],
    "_get_http_exception_for_blocked_guardrail": [
      "self",
      "lakera_response"
    ]
  },
  "_OPTIONAL_PresidioPIIMasking": {
    "user_api_key_cache": [],
    "ad_hoc_recognizers": [],
    "__init__": [
      "self",
      "mock_testing",
      "mock_redacted_text",
      "presidio_analyzer_api_base",
      "presidio_anonymizer_api_base",
      "output_parse_pii",
      "apply_to_output",
      "presidio_ad_hoc_recognizers",
      "logging_only",
      "pii_entities_config",
      "presidio_language",
      "presidio_score_thresholds"
    ],
    "validate_environment": [
      "self",
      "presidio_analyzer_api_base",
      "presidio_anonymizer_api_base"
    ],
    "_get_session_iterator": [
      "self"
    ],
    "_close_http_session": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "_has_block_action": [
      "self"
    ],
    "_get_presidio_analyze_request_payload": [
      "self",
      "text",
      "presidio_config",
      "request_data"
    ],
    "analyze_text": [
      "self",
      "text",
      "presidio_config",
      "request_data"
    ],
    "anonymize_text": [
      "self",
      "text",
      "analyze_results",
      "output_parse_pii",
      "masked_entity_count"
    ],
    "filter_analyze_results_by_score": [
      "self",
      "analyze_results"
    ],
    "raise_exception_if_blocked_entities_detected": [
      "self",
      "analyze_results"
    ],
    "check_pii": [
      "self",
      "text",
      "output_parse_pii",
      "presidio_config",
      "request_data"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "logging_hook": [
      "self",
      "kwargs",
      "result",
      "call_type"
    ],
    "async_logging_hook": [
      "self",
      "kwargs",
      "result",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "_mask_output_response": [
      "self",
      "response",
      "request_data"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_presidio_settings_from_request_data": [
      "self",
      "data"
    ],
    "print_verbose": [
      "self",
      "print_statement"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "update_in_memory_litellm_params": [
      "self",
      "litellm_params"
    ]
  },
  "A2A_CALL_TYPES": [],
  "_get_a2a_request_id": [
    "responses_so_far",
    "request_data"
  ],
  "endpoint_guardrail_translation_mappings": [],
  "UnifiedLLMGuardrails": {
    "__init__": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ]
  },
  "endpoint_translation_mappings": [],
  "GRAYSWAN_BLOCK_ERROR_MSG": [],
  "GraySwanGuardrailMissingSecrets": {},
  "GraySwanGuardrailAPIError": {
    "__init__": [
      "self",
      "message",
      "status_code"
    ]
  },
  "GraySwanGuardrail": {
    "SUPPORTED_ON_FLAGGED_ACTIONS": [],
    "DEFAULT_ON_FLAGGED_ACTION": [],
    "BASE_API_URL": [],
    "MONITOR_PATH": [],
    "SUPPORTED_REASONING_MODES": [],
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base",
      "on_flagged_action",
      "violation_threshold",
      "reasoning_mode",
      "categories",
      "policy_id",
      "streaming_end_of_stream_only",
      "streaming_sampling_rate",
      "fail_open",
      "guardrail_timeout"
    ],
    "should_run_guardrail": [
      "self",
      "data",
      "event_type"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "_is_grayswan_exception": [
      "self",
      "exc"
    ],
    "run_grayswan_guardrail": [
      "self",
      "payload"
    ],
    "_process_grayswan_response": [
      "self",
      "response_json",
      "data",
      "hook_type"
    ],
    "_call_grayswan_api": [
      "self",
      "payload"
    ],
    "_process_response_internal": [
      "self",
      "response_json",
      "request_data",
      "inputs",
      "is_output"
    ],
    "_prepare_headers": [
      "self"
    ],
    "_prepare_payload": [
      "self",
      "messages",
      "dynamic_body",
      "request_data"
    ],
    "_format_violation_message": [
      "self",
      "detection_info",
      "is_output"
    ],
    "_format_violated_rules": [
      "self",
      "violated_rules"
    ],
    "_resolve_threshold": [
      "self",
      "value"
    ],
    "_resolve_reasoning_mode": [
      "self",
      "value"
    ],
    "_log_guardrail_failure": [
      "self",
      "exc",
      "request_data",
      "start_time",
      "end_time",
      "status_code"
    ]
  },
  "initialize_guardrail": [
    "litellm_params",
    "guardrail"
  ],
  "_get_config_value": [
    "litellm_params",
    "optional_params",
    "attribute_name"
  ],
  "guardrail_class_registry": [],
  "_HEADER_VALUE_ALLOWLIST": [],
  "_HEADER_PRESENT_PLACEHOLDER": [],
  "_header_value_allowed": [
    "header_name"
  ],
  "_sanitize_inbound_headers": [
    "headers"
  ],
  "_extract_inbound_headers": [
    "request_data",
    "logging_obj"
  ],
  "GenericGuardrailAPI": {
    "__init__": [
      "self",
      "headers",
      "api_base",
      "api_key",
      "additional_provider_specific_params",
      "unreachable_fallback"
    ],
    "_extract_user_api_key_metadata": [
      "self",
      "request_data"
    ],
    "_fail_open_passthrough": [
      "self"
    ],
    "_build_guardrail_return_inputs": [
      "self"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ]
  },
  "DynamoAIGuardrails": {
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base",
      "model_id",
      "policy_ids"
    ],
    "_call_dynamoai_guardrails": [
      "self",
      "messages",
      "event_type",
      "text_type",
      "request_data"
    ],
    "_process_dynamoai_guardrails_response": [
      "self",
      "response"
    ],
    "_determine_guardrail_status": [
      "self",
      "response_json"
    ],
    "_create_error_message": [
      "self",
      "processed_result"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_config_model": []
  },
  "GuardrailsAIResponse": {},
  "InferenceData": {},
  "GuardrailsAIResponsePreCall": {},
  "GuardrailsAI": {
    "__init__": [
      "self",
      "guard_name",
      "api_base",
      "guardrails_ai_api_input_format"
    ],
    "make_guardrails_ai_api_request": [
      "self",
      "llm_output",
      "request_data"
    ],
    "make_guardrails_ai_api_request_pre_call_request": [
      "self",
      "text_input",
      "request_data"
    ],
    "process_input": [
      "self",
      "data",
      "call_type"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_logging_hook": [
      "self",
      "kwargs",
      "result",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "get_config_model": []
  },
  "MCPSecurityGuardrail": {
    "__init__": [
      "self",
      "on_violation"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "_extract_mcp_server_names_from_tools": [
      "tools"
    ],
    "_find_unregistered_mcp_servers": [
      "data"
    ]
  },
  "PromptSecurityGuardrailMissingSecrets": {},
  "PromptSecurityGuardrail": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "user",
      "system_prompt",
      "check_tool_results"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "_apply_guardrail_on_request": [
      "self",
      "inputs",
      "texts",
      "images",
      "structured_messages",
      "request_data",
      "user_api_key_alias"
    ],
    "_apply_guardrail_on_response": [
      "self",
      "inputs",
      "texts",
      "user_api_key_alias"
    ],
    "_extract_texts_from_messages": [
      "self",
      "messages"
    ],
    "_process_standalone_images": [
      "self",
      "images",
      "user_api_key_alias"
    ],
    "_resolve_key_alias_from_request_data": [
      "request_data"
    ],
    "sanitize_file_content": [
      "self",
      "file_data",
      "filename",
      "user_api_key_alias"
    ],
    "_process_image_url_item": [
      "self",
      "item",
      "user_api_key_alias"
    ],
    "_process_document_item": [
      "self",
      "item",
      "user_api_key_alias"
    ],
    "process_message_files": [
      "self",
      "messages",
      "user_api_key_alias"
    ],
    "filter_messages_by_role": [
      "self",
      "messages"
    ],
    "_build_headers": [
      "self",
      "user_api_key_alias"
    ],
    "_redact_headers": [
      "headers"
    ],
    "_log_api_request": [
      "self",
      "method",
      "url",
      "headers",
      "payload"
    ],
    "_log_api_response": [
      "self",
      "url",
      "status_code",
      "payload"
    ],
    "get_config_model": []
  },
  "SemanticGuardrail": {
    "__init__": [
      "self",
      "guardrail_name",
      "llm_router",
      "embedding_model",
      "similarity_threshold",
      "route_templates",
      "custom_routes_file",
      "custom_routes",
      "on_flagged_action",
      "event_hook",
      "default_on"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ]
  },
  "_get_top_route_choice": [
    "result"
  ],
  "_extract_user_text": [
    "messages"
  ],
  "_extract_response_text": [
    "response"
  ],
  "_handle_match": [
    "guardrail",
    "route_name",
    "similarity_score",
    "user_text",
    "data"
  ],
  "ROUTE_TEMPLATES_DIR": [],
  "SemanticGuardRouteLoader": {
    "load_builtin_template": [
      "template_name"
    ],
    "list_builtin_templates": [],
    "load_custom_routes_file": [
      "file_path"
    ],
    "build_routes": [
      "cls",
      "route_templates",
      "custom_routes_file",
      "custom_routes",
      "global_threshold"
    ],
    "build_semantic_router": [
      "cls",
      "routes",
      "litellm_router",
      "embedding_model",
      "global_threshold"
    ]
  },
  "AimGuardrailMissingSecrets": {},
  "AimGuardrail": {
    "__init__": [
      "self",
      "api_key",
      "api_base"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "call_aim_guardrail": [
      "self",
      "data",
      "hook",
      "key_alias"
    ],
    "_handle_block_action": [
      "self",
      "analysis_result",
      "required_action"
    ],
    "_anonymize_request": [
      "self",
      "res",
      "data"
    ],
    "call_aim_guardrail_on_output": [
      "self",
      "request_data",
      "output",
      "hook",
      "key_alias"
    ],
    "_handle_block_action_on_output": [
      "self",
      "analysis_result",
      "required_action"
    ],
    "_build_aim_headers": [
      "self"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "forward_the_stream_to_aim": [
      "self",
      "websocket",
      "response_iter"
    ],
    "get_config_model": []
  },
  "OpenAIModerationGuardrail": {
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base",
      "model"
    ],
    "_get_api_key": [
      "self"
    ],
    "async_make_request": [
      "self",
      "input_text"
    ],
    "_check_moderation_result": [
      "self",
      "moderation_response"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "get_config_model": []
  },
  "OpenAIGuardrailBase": {
    "get_user_prompt": [
      "self",
      "messages"
    ]
  },
  "ModelArmorGuardrail": {
    "__init__": [
      "self",
      "template_id",
      "project_id",
      "location",
      "credentials",
      "api_endpoint"
    ],
    "_get_api_endpoint": [
      "self"
    ],
    "_create_sanitize_request": [
      "self",
      "content",
      "source"
    ],
    "_extract_content_from_response": [
      "self",
      "response"
    ],
    "make_model_armor_request": [
      "self",
      "content",
      "source",
      "request_data",
      "file_bytes",
      "file_type"
    ],
    "sanitize_file_prompt": [
      "self",
      "file_bytes",
      "file_type",
      "source"
    ],
    "_should_block_content": [
      "self",
      "armor_response",
      "allow_sanitization"
    ],
    "_get_sanitized_content": [
      "self",
      "armor_response"
    ],
    "_process_response": [
      "self",
      "response",
      "request_data",
      "start_time",
      "end_time",
      "duration",
      "event_type",
      "original_inputs"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_config_model": []
  },
  "MAX_PILLAR_HEADER_VALUE_BYTES": [],
  "_encode_json_for_header": [
    "data"
  ],
  "_truncate_evidence_payload": [
    "evidence",
    "max_bytes"
  ],
  "build_pillar_response_headers": [
    "metadata_store"
  ],
  "PillarGuardrailMissingSecrets": {},
  "PillarGuardrailAPIError": {},
  "PillarGuardrail": {
    "SUPPORTED_ON_FLAGGED_ACTIONS": [],
    "DEFAULT_ON_FLAGGED_ACTION": [],
    "SUPPORTED_FALLBACK_ACTIONS": [],
    "DEFAULT_FALLBACK_ACTION": [],
    "BASE_API_URL": [],
    "DEFAULT_TIMEOUT": [],
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base",
      "on_flagged_action",
      "async_mode",
      "persist_session",
      "include_scanners",
      "include_evidence",
      "fallback_on_error",
      "timeout"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "run_pillar_guardrail": [
      "self",
      "data",
      "user_api_key_dict"
    ],
    "_handle_api_error": [
      "self",
      "error",
      "data"
    ],
    "_prepare_headers": [
      "self",
      "user_api_key_dict"
    ],
    "_set_bool_header": [
      "self",
      "headers",
      "header_name",
      "value"
    ],
    "_resolve_bool_config": [
      "self",
      "provided_value",
      "env_var",
      "default",
      "setting_name"
    ],
    "_parse_bool_value": [
      "value"
    ],
    "_extract_model_and_provider": [
      "self",
      "data"
    ],
    "_prepare_payload": [
      "self",
      "data"
    ],
    "_call_pillar_api": [
      "self",
      "headers",
      "payload"
    ],
    "_process_pillar_response": [
      "self",
      "pillar_response",
      "original_data"
    ],
    "_raise_pillar_detection_exception": [
      "self",
      "pillar_response"
    ],
    "get_config_model": []
  },
  "LassoResponse": {},
  "LassoGuardrailMissingSecrets": {},
  "LassoGuardrailAPIError": {},
  "LassoGuardrail": {
    "__init__": [
      "self",
      "lasso_api_key",
      "api_key",
      "api_base",
      "user_id",
      "conversation_id",
      "mask"
    ],
    "_generate_ulid": [
      "self"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type",
      "cache"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "_get_or_generate_conversation_id": [
      "self",
      "data",
      "cache"
    ],
    "_run_lasso_guardrail": [
      "self",
      "data",
      "cache",
      "message_type"
    ],
    "_handle_classification": [
      "self",
      "data",
      "cache",
      "message_type",
      "messages"
    ],
    "_handle_masking": [
      "self",
      "data",
      "cache",
      "message_type",
      "messages"
    ],
    "_handle_api_error": [
      "self",
      "error",
      "message_type"
    ],
    "_log_masking_applied": [
      "self",
      "message_type",
      "response"
    ],
    "_prepare_headers": [
      "self",
      "data",
      "cache"
    ],
    "_prepare_payload": [
      "self",
      "messages",
      "data",
      "cache",
      "message_type"
    ],
    "_call_lasso_api": [
      "self",
      "headers",
      "payload",
      "api_url"
    ],
    "_process_lasso_response": [
      "self",
      "response"
    ],
    "_check_for_blocking_actions": [
      "self",
      "response"
    ],
    "_parse_violated_deputies": [
      "self",
      "response"
    ],
    "_apply_masking_to_model_response": [
      "self",
      "model_response",
      "masked_messages"
    ],
    "get_config_model": []
  },
  "AzureContentSafetyPromptShieldGuardrail": {
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base"
    ],
    "async_make_request": [
      "self",
      "user_prompt"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "get_config_model": []
  },
  "AzureContentSafetyTextModerationGuardrail": {
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base",
      "severity_threshold",
      "severity_threshold_by_category"
    ],
    "get_config_model": [],
    "async_make_request": [
      "self",
      "text"
    ],
    "check_severity_threshold": [
      "self",
      "response"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_hook": [
      "self",
      "user_api_key_dict",
      "response"
    ]
  },
  "AzureGuardrailBase": {
    "get_user_prompt": [
      "self",
      "messages"
    ]
  },
  "is_saas": [
    "host"
  ],
  "_get_jwt": [
    "auth_url",
    "api_id",
    "api_key"
  ],
  "HiddenlayerGuardrail": {
    "__init__": [
      "self",
      "api_id",
      "api_key",
      "api_base",
      "auth_url"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "_call_hiddenlayer": [
      "self",
      "project_id",
      "metadata",
      "payload",
      "input_type"
    ],
    "get_config_model": []
  },
  "allow": [],
  "block": [
    "reason",
    "detection_info"
  ],
  "modify": [
    "texts",
    "images",
    "tool_calls"
  ],
  "regex_match": [
    "text",
    "pattern",
    "flags"
  ],
  "regex_match_all": [
    "text",
    "pattern",
    "flags"
  ],
  "regex_replace": [
    "text",
    "pattern",
    "replacement",
    "flags"
  ],
  "regex_find_all": [
    "text",
    "pattern",
    "flags"
  ],
  "json_parse": [
    "text"
  ],
  "json_stringify": [
    "obj"
  ],
  "json_schema_valid": [
    "obj",
    "schema"
  ],
  "_basic_json_schema_validate": [
    "obj",
    "schema",
    "max_depth"
  ],
  "_URL_PATTERN": [],
  "extract_urls": [
    "text"
  ],
  "is_valid_url": [
    "url"
  ],
  "all_urls_valid": [
    "text"
  ],
  "get_url_domain": [
    "url"
  ],
  "_HTTP_DEFAULT_TIMEOUT": [],
  "_HTTP_MAX_TIMEOUT": [],
  "_http_error_response": [
    "error"
  ],
  "_http_success_response": [
    "response"
  ],
  "_prepare_http_body": [
    "body"
  ],
  "http_request": [
    "url",
    "method",
    "headers",
    "body",
    "timeout"
  ],
  "_execute_http_request": [
    "client",
    "method",
    "url",
    "headers",
    "body",
    "timeout"
  ],
  "http_get": [
    "url",
    "headers",
    "timeout"
  ],
  "http_post": [
    "url",
    "body",
    "headers",
    "timeout"
  ],
  "_CODE_PATTERNS": [],
  "detect_code": [
    "text"
  ],
  "detect_code_languages": [
    "text"
  ],
  "contains_code_language": [
    "text",
    "languages"
  ],
  "contains": [
    "text",
    "substring"
  ],
  "contains_any": [
    "text",
    "substrings"
  ],
  "contains_all": [
    "text",
    "substrings"
  ],
  "word_count": [
    "text"
  ],
  "char_count": [
    "text"
  ],
  "lower": [
    "text"
  ],
  "upper": [
    "text"
  ],
  "trim": [
    "text"
  ],
  "get_custom_code_primitives": [],
  "DEFAULT_REJECTION_PHRASES": [],
  "RESPONSE_REJECTION_GUARDRAIL_CODE": [],
  "CustomCodeGuardrailError": {
    "__init__": [
      "self",
      "message",
      "details"
    ]
  },
  "CustomCodeCompilationError": {},
  "CustomCodeExecutionError": {},
  "CustomCodeGuardrailConfigModel": {},
  "CustomCodeGuardrail": {
    "__init__": [
      "self",
      "custom_code",
      "guardrail_name"
    ],
    "get_config_model": [],
    "_compile_custom_code": [
      "self"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "_prepare_safe_request_data": [
      "self",
      "request_data"
    ],
    "_process_result": [
      "self",
      "result",
      "inputs",
      "request_data",
      "input_type"
    ],
    "update_custom_code": [
      "self",
      "new_code"
    ]
  },
  "EnkryptAIGuardrails": {
    "__init__": [
      "self",
      "guardrail_name",
      "api_key",
      "api_base",
      "policy_name"
    ],
    "_call_enkryptai_guardrails": [
      "self",
      "prompt",
      "request_data"
    ],
    "_process_enkryptai_guardrails_response": [
      "self",
      "response"
    ],
    "_determine_guardrail_status": [
      "self",
      "response_json"
    ],
    "_create_error_message": [
      "self",
      "processed_result"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_config_model": []
  },
  "PanwPrismaAirsHandler": {
    "__init__": [
      "self",
      "guardrail_name",
      "profile_name",
      "api_key",
      "api_base",
      "default_on",
      "mask_on_block",
      "mask_request_content",
      "mask_response_content",
      "app_name",
      "fallback_on_error",
      "timeout",
      "violation_message_template"
    ],
    "_extract_text_from_messages": [
      "self",
      "messages"
    ],
    "_extract_text_from_content_list": [
      "self",
      "content_list"
    ],
    "_extract_response_text": [
      "self",
      "response"
    ],
    "_call_panw_api": [
      "self",
      "content",
      "is_response",
      "metadata",
      "call_id"
    ],
    "_get_masked_text": [
      "self",
      "scan_result",
      "is_response"
    ],
    "_apply_masking_to_messages": [
      "self",
      "messages",
      "masked_text"
    ],
    "_apply_masking_to_response": [
      "self",
      "response",
      "masked_text"
    ],
    "_build_error_detail": [
      "self",
      "scan_result",
      "is_response"
    ],
    "_handle_api_error_with_logging": [
      "self",
      "scan_result",
      "data",
      "start_time",
      "event_type",
      "is_response"
    ],
    "_prepare_metadata_from_request": [
      "self",
      "data"
    ],
    "_check_and_mark_scanned": [
      "self",
      "data",
      "scan_type"
    ],
    "_extract_prompt_from_request": [
      "self",
      "data"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "_scan_and_process_streaming_response": [
      "self",
      "assembled_model_response",
      "request_data",
      "start_time"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_config_model": []
  },
  "AporiaGuardrail": {
    "__init__": [
      "self",
      "api_key",
      "api_base"
    ],
    "transform_messages": [
      "self",
      "messages"
    ],
    "prepare_aporia_request": [
      "self",
      "new_messages",
      "response_string"
    ],
    "make_aporia_api_request": [
      "self",
      "request_data",
      "new_messages",
      "response_string"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "get_config_model": []
  },
  "MCPEndUserPermissionGuardrail": {
    "__init__": [
      "self"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "_check_request_tools": [
      "self",
      "inputs",
      "object_permission"
    ],
    "_resolve_end_user_object_permission": [
      "request_data"
    ],
    "_get_end_user_id_from_request_data": [
      "request_data"
    ],
    "_fetch_end_user_object": [
      "end_user_id"
    ],
    "_get_allowed_mcp_servers_from_object_permission": [
      "object_permission"
    ],
    "get_config_model": [],
    "_extract_mcp_server_name": [
      "tool_name"
    ],
    "_get_tool_name_from_definition": [
      "tool"
    ]
  },
  "IBMGuardrailDetector": {
    "__init__": [
      "self",
      "guardrail_name",
      "auth_token",
      "base_url",
      "detector_id",
      "is_detector_server",
      "detector_params",
      "extra_headers",
      "score_threshold",
      "block_on_detection",
      "verify_ssl"
    ],
    "_call_detector_server": [
      "self",
      "contents",
      "event_type",
      "request_data"
    ],
    "_call_orchestrator": [
      "self",
      "content",
      "event_type",
      "request_data"
    ],
    "_filter_detections_by_threshold": [
      "self",
      "detections"
    ],
    "_determine_guardrail_status_detector_server": [
      "self",
      "response_json"
    ],
    "_determine_guardrail_status_orchestrator": [
      "self",
      "response_json"
    ],
    "_create_error_message_detector_server": [
      "self",
      "detections_list"
    ],
    "_create_error_message_orchestrator": [
      "self",
      "detections"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_config_model": []
  },
  "GUARDRAIL_TIMEOUT": [],
  "ZscalerAIGuard": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "policy_id",
      "send_user_api_key_alias",
      "send_user_api_key_user_id",
      "send_user_api_key_team_id"
    ],
    "_resolve_metadata_value": [
      "request_data",
      "key"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "extract_blocking_info": [
      "self",
      "response"
    ],
    "_create_user_facing_error": [
      "self",
      "reason"
    ],
    "_prepare_headers": [
      "self",
      "api_key"
    ],
    "_send_request": [
      "self",
      "url",
      "headers",
      "data"
    ],
    "_handle_response": [
      "self",
      "response",
      "direction"
    ],
    "make_zscaler_ai_guard_api_call": [
      "self",
      "zscaler_ai_guard_url",
      "api_key",
      "policy_id",
      "direction",
      "content"
    ],
    "get_config_model": []
  },
  "OnyxGuardrail": {
    "__init__": [
      "self",
      "api_base",
      "api_key",
      "timeout"
    ],
    "_validate_with_guard_server": [
      "self",
      "payload",
      "input_type",
      "conversation_id"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "get_config_model": []
  },
  "MAX_KEYWORD_VALUE_GAP_WORDS": [],
  "GAP_WORD_TOKENIZER": [],
  "WORD_NUMBER_MAP": [],
  "WORD_NUMBER_TOKEN_REGEX": [],
  "WORD_NUMBER_SEQUENCE_PATTERN": [],
  "WORD_NUMBER_TOKEN_FINDER": [],
  "CategoryConfig": {
    "__init__": [
      "self",
      "category_name",
      "description",
      "default_action",
      "keywords",
      "exceptions",
      "identifier_words",
      "always_block_keywords",
      "inherit_from",
      "additional_block_words",
      "phrase_patterns"
    ]
  },
  "ContentFilterGuardrail": {
    "PATTERN_REDACTION_FORMAT": [],
    "KEYWORD_REDACTION_STR": [],
    "__init__": [
      "self",
      "guardrail_name",
      "guardrail_id",
      "policy_template",
      "patterns",
      "blocked_words",
      "blocked_words_file",
      "event_hook",
      "default_on",
      "pattern_redaction_format",
      "keyword_redaction_tag",
      "categories",
      "severity_threshold",
      "llm_router",
      "image_model",
      "competitor_intent_config"
    ],
    "_init_competitor_intent_checker": [
      "self",
      "competitor_intent_config"
    ],
    "_normalize_patterns": [
      "patterns"
    ],
    "_normalize_blocked_words": [
      "blocked_words"
    ],
    "_resolve_category_file_path": [
      "file_path"
    ],
    "_load_categories": [
      "self",
      "categories"
    ],
    "_load_conditional_category": [
      "self",
      "category_name",
      "category_config_obj",
      "category_action",
      "severity_threshold",
      "categories_dir"
    ],
    "_load_category_file": [
      "self",
      "file_path"
    ],
    "_load_category_file_json": [
      "self",
      "file_path"
    ],
    "_should_apply_severity": [
      "self",
      "severity",
      "threshold"
    ],
    "_add_pattern": [
      "self",
      "pattern_config"
    ],
    "_load_blocked_words_file": [
      "self",
      "file_path"
    ],
    "_find_pattern_spans": [
      "self",
      "text",
      "pattern_entry"
    ],
    "_match_near_keyword": [
      "self",
      "value_start",
      "value_end",
      "keyword_matches",
      "text"
    ],
    "_gap_text_allowed": [
      "self",
      "gap_text"
    ],
    "_merge_spans": [
      "self",
      "spans"
    ],
    "_mask_spans": [
      "self",
      "text",
      "spans",
      "redaction"
    ],
    "_convert_word_number_sequence": [
      "self",
      "sequence"
    ],
    "_check_patterns": [
      "self",
      "text"
    ],
    "_check_conditional_categories": [
      "self",
      "text",
      "exceptions"
    ],
    "_check_phrase_patterns": [
      "self",
      "text",
      "exceptions"
    ],
    "_check_category_keywords": [
      "self",
      "text",
      "exceptions"
    ],
    "_check_blocked_words": [
      "self",
      "text"
    ],
    "_handle_conditional_match": [
      "self",
      "matched_phrase",
      "category_name",
      "severity",
      "action",
      "detections"
    ],
    "_handle_category_keyword_match": [
      "self",
      "keyword",
      "category_name",
      "severity",
      "action",
      "text",
      "detections"
    ],
    "_handle_pattern_match": [
      "self",
      "pattern_name",
      "action",
      "text",
      "spans",
      "detections"
    ],
    "_handle_blocked_word_match": [
      "self",
      "keyword",
      "action",
      "description",
      "text",
      "detections"
    ],
    "_filter_single_text": [
      "self",
      "text",
      "detections"
    ],
    "_keyword_to_regex_pattern": [
      "keyword"
    ],
    "_mask_content": [
      "self",
      "text",
      "pattern_name"
    ],
    "_process_images": [
      "self",
      "images",
      "detections"
    ],
    "_count_masked_entities": [
      "self",
      "detections",
      "masked_entity_count"
    ],
    "_build_match_details": [
      "self",
      "detections"
    ],
    "_get_detection_methods": [
      "self",
      "detections"
    ],
    "_get_patterns_checked_count": [
      "self"
    ],
    "_get_policy_templates": [
      "self"
    ],
    "_compute_risk_score": [
      "self",
      "detections",
      "masked_entity_count",
      "status"
    ],
    "_apply_competitor_intent_policy": [
      "self",
      "intent_result",
      "request_data",
      "detections"
    ],
    "_log_guardrail_information": [
      "self",
      "request_data",
      "detections",
      "status",
      "start_time",
      "masked_entity_count",
      "exception_str"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "get_config_model": []
  },
  "_load_patterns_from_json": [],
  "_PATTERNS_DATA": [],
  "PrebuiltPatternName": {},
  "KNOWN_PATTERN_KEYS": [],
  "get_compiled_pattern": [
    "pattern_name"
  ],
  "get_all_pattern_names": [],
  "get_pattern_metadata": [],
  "get_available_content_categories": [],
  "EVAL_DIR": [],
  "RESULTS_DIR": [],
  "_load_jsonl": [
    "filename"
  ],
  "_run": [
    "checker",
    "text"
  ],
  "_print_confusion_report": [
    "label",
    "metrics",
    "wrong"
  ],
  "_save_confusion_results": [
    "label",
    "metrics",
    "wrong",
    "rows"
  ],
  "_confusion_matrix": [
    "checker",
    "cases",
    "label"
  ],
  "_ContentFilterChecker": {
    "__init__": [
      "self",
      "guardrail"
    ],
    "check": [
      "self",
      "text"
    ]
  },
  "_content_filter": [
    "category"
  ],
  "TestInsultsContentFilter": {
    "blocker": [
      "self"
    ],
    "cases": [
      "self"
    ],
    "test_confusion_matrix": [
      "self",
      "blocker",
      "cases"
    ]
  },
  "TestInvestmentContentFilter": {
    "blocker": [
      "self"
    ],
    "cases": [
      "self"
    ],
    "test_confusion_matrix": [
      "self",
      "blocker",
      "cases"
    ]
  },
  "LLM_JUDGE_SYSTEM_PROMPT": [],
  "_LlmJudgeChecker": {
    "__init__": [
      "self",
      "model"
    ],
    "check": [
      "self",
      "text"
    ]
  },
  "_llm_judge": [
    "model"
  ],
  "TestInvestmentLlmJudgeGpt4oMini": {
    "blocker": [
      "self"
    ],
    "cases": [
      "self"
    ],
    "test_confusion_matrix": [
      "self",
      "blocker",
      "cases"
    ]
  },
  "TestInvestmentLlmJudgeClaude": {
    "blocker": [
      "self"
    ],
    "cases": [
      "self"
    ],
    "test_confusion_matrix": [
      "self",
      "blocker",
      "cases"
    ]
  },
  "AIRLINE_OTHER_MEANING_SIGNALS": [],
  "AIRLINE_COMPETITOR_SIGNALS": [],
  "AIRLINE_OPERATIONAL_SIGNALS": [],
  "AIRLINE_COMPARISON_SIGNALS": [],
  "AIRLINE_EXPLICIT_COMPETITOR_MARKER": [],
  "AIRLINE_EXPLICIT_OTHER_MEANING_MARKER": [],
  "_MAJOR_AIRLINES_PATH": [],
  "_load_competitors_excluding_brand": [
    "brand_self"
  ],
  "AirlineCompetitorIntentChecker": {
    "__init__": [
      "self",
      "config"
    ],
    "_classify_ambiguous": [
      "self",
      "text",
      "token"
    ]
  },
  "ZERO_WIDTH": [],
  "LEET": [],
  "OTHER_MEANING_DEFAULT_THRESHOLD": [],
  "normalize": [
    "text"
  ],
  "_word_boundary_match": [
    "text",
    "token"
  ],
  "_count_signals": [
    "text",
    "patterns"
  ],
  "_compile_marker": [
    "pattern"
  ],
  "text_for_entity_matching": [
    "text"
  ],
  "BaseCompetitorIntentChecker": {
    "__init__": [
      "self",
      "config"
    ],
    "_classify_ambiguous": [
      "self",
      "text",
      "token"
    ],
    "_find_matches": [
      "self",
      "text"
    ],
    "run": [
      "self",
      "text"
    ]
  },
  "MessageRole": [],
  "LLMResponse": [],
  "NomaBlockedMessage": {
    "__init__": [
      "self",
      "classification_response"
    ],
    "_is_result_true": [
      "self",
      "result_obj"
    ]
  },
  "NomaGuardrail": {
    "_DEFAULT_API_BASE": [],
    "_AIDR_ENDPOINT": [],
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "application_id",
      "monitor_mode",
      "block_failures",
      "anonymize_input"
    ],
    "_create_background_noma_check": [
      "self",
      "coro"
    ],
    "_process_user_message_check": [
      "self",
      "request_data",
      "user_auth",
      "event_type"
    ],
    "_process_llm_response_check": [
      "self",
      "request_data",
      "response",
      "user_auth",
      "event_type"
    ],
    "_determine_guardrail_status": [
      "self",
      "response_json"
    ],
    "_should_only_sensitive_data_failed": [
      "self",
      "classification_obj"
    ],
    "_extract_anonymized_content": [
      "self",
      "response_json",
      "message_type"
    ],
    "_should_anonymize": [
      "self",
      "response_json",
      "message_type"
    ],
    "_is_result_true": [
      "self",
      "result_obj"
    ],
    "_replace_user_message_content": [
      "self",
      "request_data",
      "anonymized_content"
    ],
    "_replace_llm_response_content": [
      "self",
      "response",
      "anonymized_content"
    ],
    "_check_user_message_background": [
      "self",
      "request_data",
      "user_auth"
    ],
    "_check_llm_response_background": [
      "self",
      "request_data",
      "response",
      "user_auth"
    ],
    "_handle_verdict_background": [
      "self",
      "type",
      "message",
      "response_json"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "_check_user_message": [
      "self",
      "request_data",
      "user_auth",
      "event_type"
    ],
    "_check_llm_response": [
      "self",
      "request_data",
      "response",
      "user_auth",
      "event_type"
    ],
    "_call_noma_api": [
      "self",
      "payload",
      "llm_request_id",
      "request_data",
      "user_auth",
      "extra_data"
    ],
    "_check_verdict": [
      "self",
      "type",
      "message",
      "response_json"
    ],
    "get_config_model": [],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ]
  },
  "PangeaGuardrailMissingSecrets": {},
  "_TextCompletionRequest": {
    "__init__": [
      "self",
      "body"
    ],
    "get_messages": [
      "self"
    ],
    "update_original_body": [
      "self",
      "prompt_messages"
    ]
  },
  "PangeaHandler": {
    "__init__": [
      "self",
      "guardrail_name",
      "pangea_input_recipe",
      "pangea_output_recipe",
      "api_key",
      "api_base"
    ],
    "_call_pangea_ai_guard": [
      "self",
      "api",
      "payload",
      "hook_name"
    ],
    "_async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "_async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "get_config_model": []
  },
  "JavelinGuardrail": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "default_on",
      "guardrail_name",
      "javelin_guard_name",
      "api_version",
      "metadata",
      "config",
      "application"
    ],
    "call_javelin_guard": [
      "self",
      "request",
      "event_type"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "get_config_model": []
  },
  "DEFAULT_QUALIFIRE_API_BASE": [],
  "QualifireGuardrail": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "evaluation_id",
      "prompt_injections",
      "hallucinations_check",
      "grounding_check",
      "pii_check",
      "content_moderation_check",
      "tool_selection_quality_check",
      "assertions",
      "on_flagged"
    ],
    "_has_any_check_enabled": [
      "self"
    ],
    "_convert_messages_to_api_format": [
      "self",
      "messages"
    ],
    "_convert_tools_to_api_format": [
      "self",
      "tools"
    ],
    "_check_if_flagged": [
      "self",
      "result"
    ],
    "_build_evaluate_payload": [
      "self",
      "api_messages",
      "output",
      "assertions",
      "available_tools"
    ],
    "_run_qualifire_check": [
      "self",
      "messages",
      "output",
      "dynamic_params",
      "available_tools"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "get_config_model": []
  },
  "AnthropicExceptionMapping": {
    "get_error_type": [
      "status_code"
    ],
    "create_error_response": [
      "status_code",
      "message",
      "request_id"
    ],
    "extract_error_message": [
      "raw_message"
    ],
    "_is_anthropic_error_dict": [
      "parsed"
    ],
    "_extract_message_from_dict": [
      "parsed",
      "raw_message"
    ],
    "transform_to_anthropic_error": [
      "status_code",
      "raw_message",
      "request_id"
    ]
  },
  "AnthropicErrorType": [],
  "AnthropicErrorDetail": {},
  "AnthropicErrorResponse": {},
  "BaseCache": {
    "__init__": [
      "self",
      "default_ttl"
    ],
    "get_ttl": [
      "self"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "batch_cache_write": [
      "self",
      "key",
      "value"
    ],
    "disconnect": [
      "self"
    ],
    "test_connection": [
      "self"
    ]
  },
  "GCSCache": {
    "__init__": [
      "self",
      "bucket_name",
      "path_service_account",
      "gcs_path"
    ],
    "_construct_headers": [
      "self"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "flush_cache": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ]
  },
  "RedisSemanticCache": {
    "__init__": [
      "self",
      "host",
      "port",
      "password",
      "redis_url",
      "similarity_threshold",
      "embedding_model",
      "index_name"
    ],
    "_get_ttl": [
      "self"
    ],
    "_get_embedding": [
      "self",
      "prompt"
    ],
    "_get_cache_logic": [
      "self",
      "cached_response"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "_get_async_embedding": [
      "self",
      "prompt"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "_index_info": [
      "self"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ]
  },
  "QdrantSemanticCache": {
    "__init__": [
      "self",
      "qdrant_api_base",
      "qdrant_api_key",
      "collection_name",
      "similarity_threshold",
      "quantization_config",
      "embedding_model",
      "host_type"
    ],
    "_get_cache_logic": [
      "self",
      "cached_response"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "_collection_info": [
      "self"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ]
  },
  "DiskCache": {
    "__init__": [
      "self",
      "disk_cache_dir"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "batch_get_cache": [
      "self",
      "keys"
    ],
    "increment_cache": [
      "self",
      "key",
      "value"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "async_batch_get_cache": [
      "self",
      "keys"
    ],
    "async_increment": [
      "self",
      "key",
      "value"
    ],
    "flush_cache": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "delete_cache": [
      "self",
      "key"
    ]
  },
  "LLMClientCache": {
    "_remove_key": [
      "self",
      "key"
    ],
    "update_cache_key_with_event_loop": [
      "self",
      "key"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "async_get_cache": [
      "self",
      "key"
    ]
  },
  "CachingHandlerResponse": {},
  "in_memory_cache_obj": [],
  "LLMCachingHandler": {
    "__init__": [
      "self",
      "original_function",
      "request_kwargs",
      "start_time"
    ],
    "_async_get_cache": [
      "self",
      "model",
      "original_function",
      "logging_obj",
      "start_time",
      "call_type",
      "kwargs",
      "args"
    ],
    "_sync_get_cache": [
      "self",
      "model",
      "original_function",
      "logging_obj",
      "start_time",
      "call_type",
      "kwargs",
      "args"
    ],
    "handle_kwargs_input_list_or_str": [
      "self",
      "kwargs"
    ],
    "_extract_model_from_cached_results": [
      "self",
      "non_null_list"
    ],
    "_process_async_embedding_cached_response": [
      "self",
      "final_embedding_cached_response",
      "cached_result",
      "kwargs",
      "logging_obj",
      "start_time",
      "model"
    ],
    "combine_usage": [
      "self",
      "usage1",
      "usage2"
    ],
    "_combine_cached_embedding_response_with_api_result": [
      "self",
      "_caching_handler_response",
      "embedding_response",
      "start_time",
      "end_time"
    ],
    "_async_log_cache_hit_on_callbacks": [
      "self",
      "logging_obj",
      "cached_result",
      "start_time",
      "end_time",
      "cache_hit"
    ],
    "_retrieve_from_cache": [
      "self",
      "call_type",
      "kwargs",
      "args"
    ],
    "_convert_cached_result_to_model_response": [
      "self",
      "cached_result",
      "call_type",
      "kwargs",
      "logging_obj",
      "model",
      "args",
      "custom_llm_provider"
    ],
    "_convert_cached_stream_response": [
      "self",
      "cached_result",
      "call_type",
      "logging_obj",
      "model"
    ],
    "async_set_cache": [
      "self",
      "result",
      "original_function",
      "kwargs",
      "args"
    ],
    "sync_set_cache": [
      "self",
      "result",
      "kwargs",
      "args"
    ],
    "_should_store_result_in_cache": [
      "self",
      "original_function",
      "kwargs"
    ],
    "_is_call_type_supported_by_cache": [
      "self",
      "original_function"
    ],
    "_add_streaming_response_to_cache": [
      "self",
      "processed_chunk"
    ],
    "_sync_add_streaming_response_to_cache": [
      "self",
      "processed_chunk"
    ],
    "_update_litellm_logging_obj_environment": [
      "self",
      "logging_obj",
      "model",
      "kwargs",
      "cached_result",
      "is_async",
      "is_embedding",
      "custom_llm_provider",
      "cache_duration_ms"
    ]
  },
  "convert_args_to_kwargs": [
    "original_function",
    "args"
  ],
  "AzureBlobCache": {
    "__init__": [
      "self",
      "account_url",
      "container"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "flush_cache": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ]
  },
  "CacheMode": {
    "default_on": [],
    "default_off": []
  },
  "Cache": {
    "__init__": [
      "self",
      "type",
      "mode",
      "host",
      "port",
      "password",
      "namespace",
      "ttl",
      "default_in_memory_ttl",
      "default_in_redis_ttl",
      "similarity_threshold",
      "supported_call_types",
      "azure_account_url",
      "azure_blob_container",
      "s3_bucket_name",
      "s3_region_name",
      "s3_api_version",
      "s3_use_ssl",
      "s3_verify",
      "s3_endpoint_url",
      "s3_aws_access_key_id",
      "s3_aws_secret_access_key",
      "s3_aws_session_token",
      "s3_config",
      "s3_path",
      "gcs_bucket_name",
      "gcs_path_service_account",
      "gcs_path",
      "redis_semantic_cache_embedding_model",
      "redis_semantic_cache_index_name",
      "redis_flush_size",
      "redis_startup_nodes",
      "disk_cache_dir",
      "qdrant_api_base",
      "qdrant_api_key",
      "qdrant_collection_name",
      "qdrant_quantization_config",
      "qdrant_semantic_cache_embedding_model",
      "gcp_service_account",
      "gcp_ssl_ca_certs"
    ],
    "get_cache_key": [
      "self"
    ],
    "_get_param_value": [
      "self",
      "param",
      "kwargs"
    ],
    "_get_model_param_value": [
      "self",
      "kwargs"
    ],
    "_get_caching_group": [
      "self",
      "metadata",
      "model_group"
    ],
    "_get_file_param_value": [
      "self",
      "kwargs"
    ],
    "_get_preset_cache_key_from_kwargs": [
      "self"
    ],
    "_set_preset_cache_key_in_kwargs": [
      "self",
      "preset_cache_key"
    ],
    "_get_hashed_cache_key": [
      "cache_key"
    ],
    "_add_namespace_to_cache_key": [
      "self",
      "hash_hex"
    ],
    "generate_streaming_content": [
      "self",
      "content"
    ],
    "_get_cache_logic": [
      "self",
      "cached_result",
      "max_age"
    ],
    "get_cache": [
      "self",
      "dynamic_cache_object"
    ],
    "async_get_cache": [
      "self",
      "dynamic_cache_object"
    ],
    "_add_cache_logic": [
      "self",
      "result"
    ],
    "add_cache": [
      "self",
      "result"
    ],
    "async_add_cache": [
      "self",
      "result",
      "dynamic_cache_object"
    ],
    "_convert_to_cached_embedding": [
      "self",
      "embedding_response",
      "model"
    ],
    "add_embedding_response_to_cache": [
      "self",
      "result",
      "input",
      "kwargs",
      "idx_in_result_data"
    ],
    "async_add_cache_pipeline": [
      "self",
      "result",
      "dynamic_cache_object"
    ],
    "should_use_cache": [
      "self"
    ],
    "batch_cache_write": [
      "self",
      "result"
    ],
    "ping": [
      "self"
    ],
    "delete_cache_keys": [
      "self",
      "keys"
    ],
    "disconnect": [
      "self"
    ],
    "_supports_async": [
      "self"
    ]
  },
  "enable_cache": [
    "type",
    "host",
    "port",
    "password",
    "supported_call_types"
  ],
  "disable_cache": [],
  "RedisClusterCache": {
    "__init__": [
      "self"
    ],
    "init_async_client": [
      "self"
    ],
    "_run_redis_mget_operation": [
      "self",
      "keys"
    ],
    "_async_run_redis_mget_operation": [
      "self",
      "keys"
    ],
    "test_connection": [
      "self"
    ]
  },
  "lru_cache_wrapper": [
    "maxsize"
  ],
  "S3Cache": {
    "__init__": [
      "self",
      "s3_bucket_name",
      "s3_region_name",
      "s3_api_version",
      "s3_use_ssl",
      "s3_verify",
      "s3_endpoint_url",
      "s3_aws_access_key_id",
      "s3_aws_secret_access_key",
      "s3_aws_session_token",
      "s3_config",
      "s3_path"
    ],
    "_to_s3_key": [
      "self",
      "key"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "flush_cache": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list"
    ]
  },
  "_get_call_stack_info": [
    "num_frames"
  ],
  "RedisCache": {
    "__init__": [
      "self",
      "host",
      "port",
      "password",
      "redis_flush_size",
      "namespace",
      "startup_nodes",
      "socket_timeout"
    ],
    "_setup_health_pings": [
      "self"
    ],
    "_handle_async_ping_error": [
      "self",
      "e"
    ],
    "_handle_sync_ping_error": [
      "self",
      "e"
    ],
    "_get_async_client_cache_key": [
      "self"
    ],
    "init_async_client": [
      "self"
    ],
    "check_and_fix_namespace": [
      "self",
      "key"
    ],
    "_parse_redis_major_version": [
      "self"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "increment_cache": [
      "self",
      "key",
      "value",
      "ttl"
    ],
    "async_scan_iter": [
      "self",
      "pattern",
      "count"
    ],
    "async_register_script": [
      "self",
      "script"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "_pipeline_helper": [
      "self",
      "pipe",
      "cache_list",
      "ttl"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list",
      "ttl"
    ],
    "_set_cache_sadd_helper": [
      "self",
      "redis_client",
      "key",
      "value",
      "ttl"
    ],
    "async_set_cache_sadd": [
      "self",
      "key",
      "value",
      "ttl"
    ],
    "batch_cache_write": [
      "self",
      "key",
      "value"
    ],
    "async_increment": [
      "self",
      "key",
      "value",
      "ttl",
      "parent_otel_span"
    ],
    "flush_cache_buffer": [
      "self"
    ],
    "_get_cache_logic": [
      "self",
      "cached_response"
    ],
    "get_cache": [
      "self",
      "key",
      "parent_otel_span"
    ],
    "_run_redis_mget_operation": [
      "self",
      "keys"
    ],
    "_async_run_redis_mget_operation": [
      "self",
      "keys"
    ],
    "batch_get_cache": [
      "self",
      "key_list",
      "parent_otel_span"
    ],
    "async_get_cache": [
      "self",
      "key",
      "parent_otel_span"
    ],
    "async_batch_get_cache": [
      "self",
      "key_list",
      "parent_otel_span"
    ],
    "sync_ping": [
      "self"
    ],
    "ping": [
      "self"
    ],
    "delete_cache_keys": [
      "self",
      "keys"
    ],
    "client_list": [
      "self"
    ],
    "info": [
      "self"
    ],
    "flush_cache": [
      "self"
    ],
    "flushall": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "test_connection": [
      "self"
    ],
    "async_delete_cache": [
      "self",
      "key"
    ],
    "delete_cache": [
      "self",
      "key"
    ],
    "_pipeline_increment_helper": [
      "self",
      "pipe",
      "increment_list"
    ],
    "async_increment_pipeline": [
      "self",
      "increment_list"
    ],
    "async_get_ttl": [
      "self",
      "key"
    ],
    "async_rpush": [
      "self",
      "key",
      "values",
      "parent_otel_span"
    ],
    "handle_lpop_count_for_older_redis_versions": [
      "self",
      "pipe",
      "key",
      "count"
    ],
    "async_lpop": [
      "self",
      "key",
      "count",
      "parent_otel_span"
    ]
  },
  "LimitedSizeOrderedDict": {
    "__init__": [
      "self"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "DualCache": {
    "__init__": [
      "self",
      "in_memory_cache",
      "redis_cache",
      "default_in_memory_ttl",
      "default_redis_ttl",
      "default_redis_batch_cache_expiry",
      "default_max_redis_batch_cache_size"
    ],
    "update_cache_ttl": [
      "self",
      "default_in_memory_ttl",
      "default_redis_ttl"
    ],
    "set_cache": [
      "self",
      "key",
      "value",
      "local_only"
    ],
    "increment_cache": [
      "self",
      "key",
      "value",
      "local_only"
    ],
    "get_cache": [
      "self",
      "key",
      "parent_otel_span",
      "local_only"
    ],
    "batch_get_cache": [
      "self",
      "keys",
      "parent_otel_span",
      "local_only"
    ],
    "async_get_cache": [
      "self",
      "key",
      "parent_otel_span",
      "local_only"
    ],
    "_reserve_redis_batch_keys": [
      "self",
      "current_time",
      "keys",
      "result"
    ],
    "_rollback_redis_batch_key_reservations": [
      "self",
      "previous_access_times"
    ],
    "async_batch_get_cache": [
      "self",
      "keys",
      "parent_otel_span",
      "local_only"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value",
      "local_only"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list",
      "local_only"
    ],
    "async_increment_cache": [
      "self",
      "key",
      "value",
      "parent_otel_span",
      "local_only"
    ],
    "async_increment_cache_pipeline": [
      "self",
      "increment_list",
      "local_only",
      "parent_otel_span"
    ],
    "async_set_cache_sadd": [
      "self",
      "key",
      "value",
      "local_only"
    ],
    "flush_cache": [
      "self"
    ],
    "delete_cache": [
      "self",
      "key"
    ],
    "async_delete_cache": [
      "self",
      "key"
    ],
    "async_get_ttl": [
      "self",
      "key"
    ]
  },
  "InMemoryCache": {
    "__init__": [
      "self",
      "max_size_in_memory",
      "default_ttl",
      "max_size_per_item"
    ],
    "check_value_size": [
      "self",
      "value"
    ],
    "_is_key_expired": [
      "self",
      "key"
    ],
    "_remove_key": [
      "self",
      "key"
    ],
    "evict_cache": [
      "self"
    ],
    "allow_ttl_override": [
      "self",
      "key"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache": [
      "self",
      "key",
      "value"
    ],
    "async_set_cache_pipeline": [
      "self",
      "cache_list",
      "ttl"
    ],
    "async_set_cache_sadd": [
      "self",
      "key",
      "value",
      "ttl"
    ],
    "evict_element_if_expired": [
      "self",
      "key"
    ],
    "get_cache": [
      "self",
      "key"
    ],
    "batch_get_cache": [
      "self",
      "keys"
    ],
    "increment_cache": [
      "self",
      "key",
      "value"
    ],
    "async_get_cache": [
      "self",
      "key"
    ],
    "async_batch_get_cache": [
      "self",
      "keys"
    ],
    "async_increment": [
      "self",
      "key",
      "value"
    ],
    "async_increment_pipeline": [
      "self",
      "increment_list"
    ],
    "flush_cache": [
      "self"
    ],
    "disconnect": [
      "self"
    ],
    "delete_cache": [
      "self",
      "key"
    ],
    "async_get_ttl": [
      "self",
      "key"
    ],
    "async_get_oldest_n_keys": [
      "self",
      "n"
    ]
  },
  "AccessToken": {},
  "TokenCredential": {
    "get_token": [
      "self",
      "scope"
    ]
  },
  "AzureADCredential": {
    "__init__": [
      "self",
      "credential"
    ],
    "get_token": [
      "self",
      "scope"
    ]
  },
  "GenericOAuth2Credential": {
    "__init__": [
      "self",
      "client_id",
      "client_secret",
      "token_url"
    ],
    "get_token": [
      "self",
      "scope"
    ]
  },
  "ProxyAuthHandler": {
    "__init__": [
      "self",
      "credential",
      "scope"
    ],
    "get_token": [
      "self"
    ],
    "get_auth_headers": [
      "self"
    ]
  },
  "DEFAULT_OPENAI_API_BASE": [],
  "acreate_eval": [
    "data_source_config",
    "testing_criteria",
    "name",
    "metadata",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "alist_evals": [
    "limit",
    "after",
    "before",
    "order",
    "order_by",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "aget_eval": [
    "eval_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "aupdate_eval": [
    "eval_id",
    "name",
    "metadata",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "adelete_eval": [
    "eval_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "acancel_eval": [
    "eval_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "acreate_run": [
    "eval_id",
    "data_source",
    "name",
    "metadata",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "alist_runs": [
    "eval_id",
    "limit",
    "after",
    "before",
    "order",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "aget_run": [
    "eval_id",
    "run_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "acancel_run": [
    "eval_id",
    "run_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "adelete_run": [
    "eval_id",
    "run_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "ImageEditRequestUtils": {
    "get_optional_params_image_edit": [
      "model",
      "image_edit_provider_config",
      "image_edit_optional_params",
      "drop_params",
      "additional_drop_params"
    ],
    "get_requested_image_edit_optional_param": [
      "params"
    ],
    "get_image_content_type": [
      "image_data"
    ]
  },
  "_get_ImageEditRequestUtils": [],
  "aimage_generation": [],
  "aimage_variation": [],
  "image_variation": [
    "image",
    "model",
    "n",
    "response_format",
    "size",
    "user"
  ],
  "image_edit": [
    "image",
    "prompt",
    "model",
    "mask",
    "n",
    "quality",
    "response_format",
    "size",
    "user",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "aimage_edit": [
    "image",
    "model",
    "prompt",
    "mask",
    "n",
    "quality",
    "response_format",
    "size",
    "user",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "azure_realtime": [],
  "openai_realtime": [],
  "bedrock_realtime": [],
  "xai_realtime": [],
  "_arealtime": [
    "model",
    "websocket",
    "api_base",
    "api_key",
    "api_version",
    "azure_ad_token",
    "client",
    "timeout",
    "query_params"
  ],
  "_realtime_health_check": [
    "model",
    "custom_llm_provider",
    "api_key",
    "api_base",
    "api_version",
    "realtime_protocol"
  ],
  "search_provider_cost_per_query": [
    "model",
    "custom_llm_provider",
    "number_of_queries",
    "optional_params"
  ],
  "_build_search_optional_params": [
    "max_results",
    "search_domain_filter",
    "max_tokens_per_page",
    "country"
  ],
  "BasePassthroughUtils": {
    "get_merged_query_parameters": [
      "existing_url",
      "request_query_params",
      "default_query_params"
    ],
    "forward_headers_from_request": [
      "request_headers",
      "headers",
      "forward_headers"
    ]
  },
  "CommonUtils": {
    "encode_bedrock_runtime_modelid_arn": [
      "endpoint"
    ]
  },
  "allm_passthrough_route": [],
  "llm_passthrough_route": [],
  "_async_passthrough_request": [
    "client",
    "request",
    "is_streaming_request",
    "litellm_logging_obj",
    "provider_config"
  ],
  "_sync_streaming": [
    "response",
    "litellm_logging_obj",
    "provider_config"
  ],
  "aocr": [
    "model",
    "document",
    "api_key",
    "api_base",
    "timeout",
    "custom_llm_provider",
    "extra_headers"
  ],
  "to_basic_auth": [
    "auth_value"
  ],
  "TSessionResult": [],
  "MCPClient": {
    "__init__": [
      "self",
      "server_url",
      "transport_type",
      "auth_type",
      "auth_value",
      "timeout",
      "stdio_config",
      "extra_headers",
      "ssl_verify"
    ],
    "_create_transport_context": [
      "self"
    ],
    "_execute_session_operation": [
      "self",
      "transport_ctx",
      "operation"
    ],
    "run_with_session": [
      "self",
      "operation"
    ],
    "update_auth_value": [
      "self",
      "mcp_auth_value"
    ],
    "_get_auth_headers": [
      "self"
    ],
    "_create_httpx_client_factory": [
      "self"
    ],
    "list_tools": [
      "self"
    ],
    "call_tool": [
      "self",
      "call_tool_request_params",
      "host_progress_callback"
    ],
    "list_prompts": [
      "self"
    ],
    "get_prompt": [
      "self",
      "get_prompt_request_params"
    ],
    "list_resources": [
      "self"
    ],
    "list_resource_templates": [
      "self"
    ],
    "read_resource": [
      "self",
      "url"
    ]
  },
  "transform_mcp_tool_to_openai_tool": [
    "mcp_tool"
  ],
  "_normalize_mcp_input_schema": [
    "input_schema"
  ],
  "transform_mcp_tool_to_openai_responses_api_tool": [
    "mcp_tool"
  ],
  "load_mcp_tools": [
    "session",
    "format"
  ],
  "call_mcp_tool": [
    "session",
    "call_tool_request_params"
  ],
  "_get_function_arguments": [
    "function"
  ],
  "transform_openai_tool_call_request_to_mcp_tool_call_request": [
    "openai_tool"
  ],
  "call_openai_tool": [
    "session",
    "openai_tool"
  ],
  "FilesAPIUtils": {
    "is_batch_jsonl_file": [
      "create_file_data",
      "extracted_file_data"
    ],
    "valid_content_type": [
      "content_type"
    ]
  },
  "openai_files_instance": [],
  "azure_files_instance": [],
  "vertex_ai_files_instance": [],
  "bedrock_files_instance": [],
  "anthropic_files_instance": [],
  "acreate_file": [
    "file",
    "purpose",
    "expires_after",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "afile_retrieve": [
    "file_id",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "file_retrieve": [
    "file_id",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "afile_delete": [
    "file_id",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "file_delete": [
    "file_id",
    "model",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "afile_list": [
    "custom_llm_provider",
    "purpose",
    "extra_headers",
    "extra_body"
  ],
  "file_list": [
    "custom_llm_provider",
    "purpose",
    "extra_headers",
    "extra_body"
  ],
  "afile_content": [
    "file_id",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "file_content": [
    "file_id",
    "model",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "create_sync_endpoint_function": [
    "endpoint_config"
  ],
  "create_async_endpoint_function": [
    "sync_func",
    "endpoint_config"
  ],
  "generate_container_endpoints": [],
  "get_all_endpoint_names": [],
  "get_async_endpoint_names": [],
  "_generated_endpoints": [],
  "list_container_files": [],
  "alist_container_files": [],
  "upload_container_file": [],
  "aupload_container_file": [],
  "retrieve_container_file": [],
  "aretrieve_container_file": [],
  "delete_container_file": [],
  "adelete_container_file": [],
  "retrieve_container_file_content": [],
  "aretrieve_container_file_content": [],
  "ContainerRequestUtils": {
    "get_requested_container_create_optional_param": [
      "passed_params"
    ],
    "get_optional_params_container_create": [
      "container_provider_config",
      "container_create_optional_params"
    ],
    "get_requested_container_list_optional_param": [
      "passed_params"
    ]
  },
  "acreate_container": [
    "name",
    "expires_after",
    "file_ids",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "alist_containers": [
    "after",
    "limit",
    "order",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "aretrieve_container": [
    "container_id",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "adelete_container": [
    "container_id",
    "timeout",
    "custom_llm_provider",
    "extra_headers",
    "extra_query",
    "extra_body"
  ],
  "AthinaLogger": {
    "__init__": [
      "self"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ]
  },
  "GalileoObserve": {
    "__init__": [
      "self"
    ],
    "set_galileo_headers": [
      "self"
    ],
    "get_output_str_from_response": [
      "self",
      "response_obj",
      "kwargs"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "flush_in_memory_records": [
      "self"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "LagoLogger": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self"
    ],
    "_common_logic": [
      "self",
      "kwargs",
      "response_obj"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "is_serializable": [
    "value"
  ],
  "ArgillaLogger": {
    "__init__": [
      "self",
      "argilla_api_key",
      "argilla_dataset_name",
      "argilla_base_url"
    ],
    "validate_argilla_transformation_object": [
      "self",
      "argilla_transformation_object"
    ],
    "get_credentials_from_env": [
      "self",
      "argilla_api_key",
      "argilla_dataset_name",
      "argilla_base_url"
    ],
    "get_chat_messages": [
      "self",
      "payload"
    ],
    "get_str_response": [
      "self",
      "payload"
    ],
    "_prepare_log_data": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_send_batch": [
      "self"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ]
  },
  "LITELLM_TRACER_NAME": [],
  "LITELLM_METER_NAME": [],
  "LITELLM_LOGGER_NAME": [],
  "LITELLM_PROXY_REQUEST_SPAN_NAME": [],
  "RAW_REQUEST_SPAN_NAME": [],
  "LITELLM_REQUEST_SPAN_NAME": [],
  "OpenTelemetryConfig": {
    "__post_init__": [
      "self"
    ],
    "from_env": [
      "cls"
    ]
  },
  "OpenTelemetry": {
    "__init__": [
      "self",
      "config",
      "callback_name",
      "tracer_provider",
      "logger_provider",
      "meter_provider"
    ],
    "_get_litellm_resource": [
      "config"
    ],
    "_init_otel_logger_on_litellm_proxy": [
      "self"
    ],
    "_get_or_create_provider": [
      "self",
      "provider",
      "provider_name",
      "get_existing_provider_fn",
      "sdk_provider_class",
      "create_new_provider_fn",
      "set_provider_fn"
    ],
    "_init_tracing": [
      "self",
      "tracer_provider"
    ],
    "_init_metrics": [
      "self",
      "meter_provider"
    ],
    "_init_logs": [
      "self",
      "logger_provider"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_service_success_hook": [
      "self",
      "payload",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "async_service_failure_hook": [
      "self",
      "payload",
      "error",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "get_tracer_to_use_for_request": [
      "self",
      "kwargs"
    ],
    "_get_dynamic_otel_headers_from_kwargs": [
      "self",
      "kwargs"
    ],
    "_get_tracer_with_dynamic_headers": [
      "self",
      "dynamic_headers"
    ],
    "construct_dynamic_otel_headers": [
      "self",
      "standard_callback_dynamic_params"
    ],
    "_handle_success": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_start_primary_span": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "context"
    ],
    "_maybe_log_raw_request": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "parent_span"
    ],
    "_record_metrics": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_to_timestamp": [
      "val"
    ],
    "_record_time_to_first_token_metric": [
      "self",
      "kwargs",
      "common_attrs"
    ],
    "_record_time_per_output_token_metric": [
      "self",
      "kwargs",
      "response_obj",
      "end_time",
      "duration_s",
      "common_attrs"
    ],
    "_record_response_duration_metric": [
      "self",
      "kwargs",
      "end_time",
      "common_attrs"
    ],
    "_emit_semantic_logs": [
      "self",
      "kwargs",
      "response_obj",
      "span"
    ],
    "_create_guardrail_span": [
      "self",
      "kwargs",
      "context"
    ],
    "_handle_failure": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_record_exception_on_span": [
      "self",
      "span",
      "kwargs"
    ],
    "set_tools_attributes": [
      "self",
      "span",
      "tools"
    ],
    "cast_as_primitive_value_type": [
      "self",
      "value"
    ],
    "_tool_calls_kv_pair": [
      "tool_calls"
    ],
    "set_attributes": [
      "self",
      "span",
      "kwargs",
      "response_obj"
    ],
    "_cast_as_primitive_value_type": [
      "self",
      "value"
    ],
    "safe_set_attribute": [
      "self",
      "span",
      "key",
      "value"
    ],
    "_transform_messages_to_otel_semantic_conventions": [
      "self",
      "messages"
    ],
    "_transform_choices_to_otel_semantic_conventions": [
      "self",
      "choices"
    ],
    "set_raw_request_attributes": [
      "self",
      "span",
      "kwargs",
      "response_obj"
    ],
    "_to_ns": [
      "self",
      "dt"
    ],
    "_get_span_name": [
      "self",
      "kwargs"
    ],
    "get_traceparent_from_header": [
      "self",
      "headers"
    ],
    "_get_span_context": [
      "self",
      "kwargs",
      "default_span"
    ],
    "_get_span_processor": [
      "self",
      "dynamic_headers"
    ],
    "_get_log_exporter": [
      "self"
    ],
    "_get_metric_reader": [
      "self"
    ],
    "_normalize_otel_endpoint": [
      "self",
      "endpoint",
      "signal_type"
    ],
    "_get_headers_dictionary": [
      "headers"
    ],
    "async_management_endpoint_success_hook": [
      "self",
      "logging_payload",
      "parent_otel_span"
    ],
    "async_management_endpoint_failure_hook": [
      "self",
      "logging_payload",
      "parent_otel_span"
    ],
    "create_litellm_proxy_request_started_span": [
      "self",
      "start_time",
      "headers"
    ]
  },
  "LangsmithLogger": {
    "__init__": [
      "self",
      "langsmith_api_key",
      "langsmith_project",
      "langsmith_base_url",
      "langsmith_sampling_rate",
      "langsmith_tenant_id"
    ],
    "get_credentials_from_env": [
      "self",
      "langsmith_api_key",
      "langsmith_project",
      "langsmith_base_url",
      "langsmith_tenant_id"
    ],
    "_prepare_log_data": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "credentials"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "_add_endpoint_to_url": [
      "self",
      "url",
      "endpoint",
      "api_version"
    ],
    "_log_batch_on_langsmith": [
      "self",
      "credentials",
      "queue_objects"
    ],
    "_group_batches_by_credentials": [
      "self"
    ],
    "_get_sampling_rate_to_use_for_request": [
      "self",
      "kwargs"
    ],
    "_get_credentials_to_use_for_request": [
      "self",
      "kwargs"
    ],
    "_send_batch": [
      "self"
    ],
    "get_run_by_id": [
      "self",
      "run_id"
    ],
    "make_dot_order": [
      "self",
      "run_id"
    ]
  },
  "S3Logger": {
    "__init__": [
      "self",
      "s3_bucket_name",
      "s3_path",
      "s3_region_name",
      "s3_api_version",
      "s3_use_ssl",
      "s3_verify",
      "s3_endpoint_url",
      "s3_aws_access_key_id",
      "s3_aws_secret_access_key",
      "s3_aws_session_token",
      "s3_config"
    ],
    "_async_log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ]
  },
  "get_s3_object_key": [
    "s3_path",
    "prefix",
    "start_time",
    "s3_file_name"
  ],
  "_BASE64_INLINE_PATTERN": [],
  "SQSLogger": {
    "__init__": [
      "self",
      "sqs_queue_url",
      "sqs_region_name",
      "sqs_api_version",
      "sqs_use_ssl",
      "sqs_verify",
      "sqs_endpoint_url",
      "sqs_aws_access_key_id",
      "sqs_aws_secret_access_key",
      "sqs_aws_session_token",
      "sqs_aws_session_name",
      "sqs_aws_profile_name",
      "sqs_aws_role_name",
      "sqs_aws_web_identity_token",
      "sqs_aws_sts_endpoint",
      "sqs_flush_interval",
      "sqs_batch_size",
      "sqs_config",
      "sqs_strip_base64_files",
      "sqs_aws_use_application_level_encryption",
      "sqs_app_encryption_key_b64",
      "sqs_app_encryption_aad"
    ],
    "_init_sqs_params": [
      "self",
      "sqs_queue_url",
      "sqs_region_name",
      "sqs_api_version",
      "sqs_use_ssl",
      "sqs_verify",
      "sqs_endpoint_url",
      "sqs_aws_access_key_id",
      "sqs_aws_secret_access_key",
      "sqs_aws_session_token",
      "sqs_aws_session_name",
      "sqs_aws_profile_name",
      "sqs_aws_role_name",
      "sqs_aws_web_identity_token",
      "sqs_aws_sts_endpoint",
      "sqs_strip_base64_files",
      "sqs_aws_use_application_level_encryption",
      "sqs_app_encryption_key_b64",
      "sqs_app_encryption_aad",
      "sqs_config"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "async_send_message": [
      "self",
      "payload"
    ],
    "async_health_check": [
      "self"
    ]
  },
  "Supabase": {
    "supabase_table_name": [],
    "__init__": [
      "self"
    ],
    "input_log_event": [
      "self",
      "model",
      "messages",
      "end_user",
      "litellm_call_id",
      "print_verbose"
    ],
    "log_event": [
      "self",
      "model",
      "messages",
      "end_user",
      "response_obj",
      "start_time",
      "end_time",
      "litellm_call_id",
      "print_verbose"
    ]
  },
  "CustomLogger": {
    "__init__": [
      "self",
      "turn_off_message_logging",
      "message_logging"
    ],
    "get_callback_env_vars": [
      "callback_name"
    ],
    "log_pre_api_call": [
      "self",
      "model",
      "messages",
      "kwargs"
    ],
    "log_post_api_call": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_stream_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_stream_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_pre_api_call": [
      "self",
      "model",
      "messages",
      "kwargs"
    ],
    "async_pre_request_hook": [
      "self",
      "model",
      "messages",
      "kwargs"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "async_pre_routing_hook": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs",
      "parent_otel_span"
    ],
    "async_pre_call_deployment_hook": [
      "self",
      "kwargs",
      "call_type"
    ],
    "async_pre_call_check": [
      "self",
      "deployment",
      "parent_otel_span"
    ],
    "pre_call_check": [
      "self",
      "deployment"
    ],
    "async_post_call_success_deployment_hook": [
      "self",
      "request_data",
      "response",
      "call_type"
    ],
    "async_post_call_streaming_deployment_hook": [
      "self",
      "request_data",
      "response_chunk",
      "call_type"
    ],
    "log_model_group_rate_limit_error": [
      "self",
      "exception",
      "original_model_group",
      "kwargs"
    ],
    "log_success_fallback_event": [
      "self",
      "original_model_group",
      "kwargs",
      "original_exception"
    ],
    "log_failure_fallback_event": [
      "self",
      "original_model_group",
      "kwargs",
      "original_exception"
    ],
    "translate_completion_input_params": [
      "self",
      "kwargs"
    ],
    "translate_completion_output_params": [
      "self",
      "response"
    ],
    "translate_completion_output_params_streaming": [
      "self",
      "completion_stream"
    ],
    "async_dataset_hook": [
      "self",
      "logged_item",
      "standard_logging_payload"
    ],
    "async_pre_call_hook": [
      "self",
      "user_api_key_dict",
      "cache",
      "data",
      "call_type"
    ],
    "async_post_call_response_headers_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response",
      "request_headers"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "async_logging_hook": [
      "self",
      "kwargs",
      "result",
      "call_type"
    ],
    "logging_hook": [
      "self",
      "kwargs",
      "result",
      "call_type"
    ],
    "async_moderation_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "call_type"
    ],
    "async_post_call_streaming_hook": [
      "self",
      "user_api_key_dict",
      "response"
    ],
    "async_post_call_streaming_iterator_hook": [
      "self",
      "user_api_key_dict",
      "response",
      "request_data"
    ],
    "log_input_event": [
      "self",
      "model",
      "messages",
      "kwargs",
      "print_verbose",
      "callback_func"
    ],
    "async_log_input_event": [
      "self",
      "model",
      "messages",
      "kwargs",
      "print_verbose",
      "callback_func"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose",
      "callback_func"
    ],
    "async_log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose",
      "callback_func"
    ],
    "async_post_mcp_tool_call_hook": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_should_run_agentic_loop": [
      "self",
      "response",
      "model",
      "messages",
      "tools",
      "stream",
      "custom_llm_provider",
      "kwargs"
    ],
    "async_run_agentic_loop": [
      "self",
      "tools",
      "model",
      "messages",
      "response",
      "anthropic_messages_provider_config",
      "anthropic_messages_optional_request_params",
      "logging_obj",
      "stream",
      "kwargs"
    ],
    "async_should_run_chat_completion_agentic_loop": [
      "self",
      "response",
      "model",
      "messages",
      "tools",
      "stream",
      "custom_llm_provider",
      "kwargs"
    ],
    "async_run_chat_completion_agentic_loop": [
      "self",
      "tools",
      "model",
      "messages",
      "response",
      "optional_params",
      "logging_obj",
      "stream",
      "kwargs"
    ],
    "truncate_standard_logging_payload_content": [
      "self",
      "standard_logging_object"
    ],
    "_truncate_field": [
      "self",
      "standard_logging_object",
      "field_name",
      "max_length"
    ],
    "_truncate_text": [
      "self",
      "text",
      "max_length"
    ],
    "_select_metadata_field": [
      "self",
      "request_kwargs"
    ],
    "redact_standard_logging_payload_from_model_call_details": [
      "self",
      "model_call_details"
    ],
    "get_proxy_server_request_from_cold_storage_with_object_key": [
      "self",
      "object_key"
    ],
    "handle_callback_failure": [
      "self",
      "callback_name"
    ],
    "_strip_base64_from_messages": [
      "self",
      "payload",
      "max_depth"
    ],
    "_strip_base64_from_messages_sync": [
      "self",
      "payload",
      "max_depth"
    ],
    "_redact_base64": [
      "self",
      "value",
      "depth",
      "max_depth"
    ],
    "_should_keep_content": [
      "self",
      "content"
    ],
    "_process_messages": [
      "self",
      "messages",
      "max_depth"
    ]
  },
  "dc": [],
  "ModifyResponseException": {
    "__init__": [
      "self",
      "message",
      "model",
      "request_data",
      "guardrail_name",
      "detection_info"
    ]
  },
  "CustomGuardrail": {
    "__init__": [
      "self",
      "guardrail_name",
      "supported_event_hooks",
      "event_hook",
      "default_on",
      "mask_request_content",
      "mask_response_content",
      "violation_message_template"
    ],
    "render_violation_message": [
      "self",
      "default",
      "context"
    ],
    "raise_passthrough_exception": [
      "self",
      "violation_message",
      "request_data",
      "detection_info"
    ],
    "get_config_model": [],
    "_validate_event_hook": [
      "self",
      "event_hook",
      "supported_event_hooks"
    ],
    "get_disable_global_guardrail": [
      "self",
      "data"
    ],
    "_is_valid_response_type": [
      "self",
      "result"
    ],
    "get_guardrail_from_metadata": [
      "self",
      "data"
    ],
    "_guardrail_is_in_requested_guardrails": [
      "self",
      "requested_guardrails"
    ],
    "async_pre_call_deployment_hook": [
      "self",
      "kwargs",
      "call_type"
    ],
    "async_post_call_success_deployment_hook": [
      "self",
      "request_data",
      "response",
      "call_type"
    ],
    "should_run_guardrail": [
      "self",
      "data",
      "event_type"
    ],
    "_event_hook_is_event_type": [
      "self",
      "event_type"
    ],
    "get_guardrail_dynamic_request_body_params": [
      "self",
      "request_data"
    ],
    "_validate_premium_user": [
      "self"
    ],
    "add_standard_logging_guardrail_information_to_request_data": [
      "self",
      "guardrail_json_response",
      "request_data",
      "guardrail_status",
      "start_time",
      "end_time",
      "duration",
      "masked_entity_count",
      "guardrail_provider",
      "event_type",
      "tracing_detail"
    ],
    "apply_guardrail": [
      "self",
      "inputs",
      "request_data",
      "input_type",
      "logging_obj"
    ],
    "_process_response": [
      "self",
      "response",
      "request_data",
      "start_time",
      "end_time",
      "duration",
      "event_type",
      "original_inputs"
    ],
    "_is_guardrail_intervention": [
      "e"
    ],
    "_process_error": [
      "self",
      "e",
      "request_data",
      "start_time",
      "end_time",
      "duration",
      "event_type"
    ],
    "_inputs_were_modified": [
      "self",
      "original_inputs",
      "response"
    ],
    "mask_content_in_string": [
      "self",
      "content_string",
      "mask_string",
      "start_index",
      "end_index"
    ],
    "update_in_memory_litellm_params": [
      "self",
      "litellm_params"
    ],
    "get_guardrails_messages_for_call_type": [
      "self",
      "call_type",
      "data"
    ]
  },
  "log_guardrail_information": [
    "func"
  ],
  "parse_usage": [
    "usage"
  ],
  "parse_tool_calls": [
    "tool_calls"
  ],
  "parse_messages": [
    "input"
  ],
  "LunaryLogger": {
    "__init__": [
      "self"
    ],
    "log_event": [
      "self",
      "kwargs",
      "type",
      "event",
      "run_id",
      "model",
      "print_verbose",
      "extra",
      "input",
      "user_id",
      "response_obj",
      "start_time",
      "end_time",
      "error"
    ]
  },
  "TraceloopLogger": {
    "__init__": [
      "self"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "user_id",
      "print_verbose",
      "level",
      "status_message"
    ]
  },
  "MlflowLogger": {
    "__init__": [
      "self"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_handle_success": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_extract_and_set_chat_attributes": [
      "self",
      "span",
      "kwargs",
      "response_obj"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_handle_failure": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_handle_stream_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_add_chunk_events": [
      "self",
      "span",
      "response_obj"
    ],
    "_construct_input": [
      "self",
      "kwargs"
    ],
    "_extract_attributes": [
      "self",
      "kwargs"
    ],
    "_get_span_type": [
      "self",
      "call_type"
    ],
    "_start_span_or_trace": [
      "self",
      "kwargs",
      "start_time"
    ],
    "_transform_tag_list_to_dict": [
      "self",
      "tag_list"
    ],
    "_end_span_or_trace": [
      "self",
      "span",
      "outputs",
      "end_time_ns",
      "status"
    ]
  },
  "GreenscaleLogger": {
    "__init__": [
      "self"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ]
  },
  "HeliconeLogger": {
    "helicone_model_list": [],
    "__init__": [
      "self"
    ],
    "claude_mapping": [
      "self",
      "model",
      "messages",
      "response_obj"
    ],
    "add_metadata_from_header": [
      "litellm_params",
      "metadata"
    ],
    "log_success": [
      "self",
      "model",
      "messages",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose",
      "kwargs"
    ]
  },
  "_config": [],
  "AnthropicCacheControlHook": {
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "_process_message_injection": [
      "point",
      "messages"
    ],
    "_safe_insert_cache_control_in_message": [
      "message",
      "control"
    ],
    "integration_name": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "should_use_anthropic_cache_control_hook": [
      "non_default_params"
    ],
    "get_custom_logger_for_anthropic_cache_control_hook": [
      "non_default_params"
    ]
  },
  "CustomPromptManagement": {
    "__init__": [
      "self",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "integration_name": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ]
  },
  "CustomSecretManager": {
    "__init__": [
      "self",
      "secret_manager_name"
    ],
    "async_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "sync_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "async_write_secret": [
      "self",
      "secret_name",
      "secret_value",
      "description",
      "optional_params",
      "timeout",
      "tags"
    ],
    "async_delete_secret": [
      "self",
      "secret_name",
      "recovery_window_in_days",
      "optional_params",
      "timeout"
    ],
    "validate_environment": [
      "self"
    ],
    "async_health_check": [
      "self",
      "timeout"
    ],
    "__repr__": [
      "self"
    ]
  },
  "CustomBatchLogger": {
    "__init__": [
      "self",
      "flush_lock",
      "batch_size",
      "flush_interval"
    ],
    "periodic_flush": [
      "self"
    ],
    "flush_queue": [
      "self"
    ],
    "async_send_batch": [
      "self"
    ]
  },
  "AdditionalLoggingUtils": {
    "__init__": [
      "self"
    ],
    "async_health_check": [
      "self"
    ],
    "get_request_response_payload": [
      "self",
      "request_id",
      "start_time_utc",
      "end_time_utc"
    ]
  },
  "SpanConfig": {},
  "LogfireLevel": {
    "INFO": [],
    "ERROR": []
  },
  "LogfireLogger": {
    "__init__": [
      "self"
    ],
    "_get_span_config": [
      "self",
      "payload"
    ],
    "_async_log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose",
      "level"
    ],
    "log_event": [
      "self",
      "kwargs",
      "start_time",
      "end_time",
      "print_verbose",
      "level",
      "response_obj"
    ]
  },
  "imported_openAIResponse": [],
  "WeightsBiasesLogger": {
    "__init__": [
      "self"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ]
  },
  "LiteralAILogger": {
    "__init__": [
      "self",
      "literalai_api_key",
      "literalai_api_url",
      "env"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_send_batch": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "_prepare_log_data": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_steps_query_variables_builder": [
      "self",
      "steps"
    ],
    "_steps_ingest_steps_builder": [
      "self",
      "steps"
    ],
    "_steps_query_builder": [
      "self",
      "steps"
    ],
    "_steps_variables_builder": [
      "self",
      "steps"
    ]
  },
  "MockClientConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "MockResponse": {
    "__init__": [
      "self",
      "status_code",
      "json_data",
      "url",
      "elapsed_seconds"
    ],
    "text": [
      "self"
    ],
    "content": [
      "self"
    ],
    "json": [
      "self"
    ],
    "read": [
      "self"
    ],
    "raise_for_status": [
      "self"
    ]
  },
  "_is_url_match": [
    "url",
    "matchers"
  ],
  "create_mock_client_factory": [
    "config"
  ],
  "_original_http_handler_post": [],
  "_mocks_initialized": [],
  "_MOCK_LATENCY_SECONDS": [],
  "_is_braintrust_url": [
    "url"
  ],
  "_mock_http_handler_post": [
    "self",
    "url",
    "data",
    "json",
    "params",
    "headers",
    "timeout",
    "stream",
    "files",
    "content",
    "logging_obj"
  ],
  "create_mock_braintrust_client": [],
  "get_all_team_member_emails": [
    "team_id"
  ],
  "send_team_budget_alert": [
    "webhook_event"
  ],
  "FAILED_REQUESTS_LABELS": [],
  "PrometheusServicesLogger": {
    "litellm_service_latency": [],
    "__init__": [
      "self",
      "mock_testing"
    ],
    "_get_service_metrics_initialize": [
      "self",
      "service"
    ],
    "is_metric_registered": [
      "self",
      "metric_name"
    ],
    "_get_metric": [
      "self",
      "metric_name"
    ],
    "create_histogram": [
      "self",
      "service",
      "type_of_request"
    ],
    "create_gauge": [
      "self",
      "service",
      "type_of_request"
    ],
    "create_counter": [
      "self",
      "service",
      "type_of_request",
      "additional_labels"
    ],
    "observe_histogram": [
      "self",
      "histogram",
      "labels",
      "amount"
    ],
    "update_gauge": [
      "self",
      "gauge",
      "labels",
      "amount"
    ],
    "increment_counter": [
      "self",
      "counter",
      "labels",
      "amount",
      "additional_labels"
    ],
    "service_success_hook": [
      "self",
      "payload"
    ],
    "service_failure_hook": [
      "self",
      "payload"
    ],
    "async_service_success_hook": [
      "self",
      "payload"
    ],
    "async_service_failure_hook": [
      "self",
      "payload",
      "error"
    ]
  },
  "API_BASE": [],
  "BraintrustLogger": {
    "__init__": [
      "self",
      "api_key",
      "api_base"
    ],
    "validate_environment": [
      "self",
      "api_key"
    ],
    "get_project_id_sync": [
      "self",
      "project_name"
    ],
    "get_project_id_async": [
      "self",
      "project_name"
    ],
    "create_default_project_and_experiment": [
      "self"
    ],
    "create_sync_default_project_and_experiment": [
      "self"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "PromptManagementClient": {},
  "HumanLoopPromptManager": {
    "integration_name": [
      "self"
    ],
    "_get_prompt_from_id_cache": [
      "self",
      "humanloop_prompt_id"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_template",
      "prompt_variables"
    ],
    "_get_prompt_from_id_api": [
      "self",
      "humanloop_prompt_id",
      "humanloop_api_key"
    ],
    "_get_prompt_from_id": [
      "self",
      "humanloop_prompt_id",
      "humanloop_api_key"
    ],
    "compile_prompt": [
      "self",
      "prompt_template",
      "prompt_variables"
    ],
    "_get_model_from_prompt": [
      "self",
      "prompt_management_client",
      "model"
    ]
  },
  "prompt_manager": [],
  "HumanloopLogger": {
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ]
  },
  "PromptLayerLogger": {
    "__init__": [
      "self"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ]
  },
  "DyanmoDBLogger": {
    "__init__": [
      "self"
    ],
    "_async_log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ],
    "log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "print_verbose"
    ]
  },
  "LangtraceAttributes": {
    "set_langtrace_attributes": [
      "self",
      "span",
      "kwargs",
      "response_obj"
    ],
    "set_request_attributes": [
      "self",
      "span",
      "kwargs",
      "vendor"
    ],
    "set_response_attributes": [
      "self",
      "span",
      "response_obj"
    ],
    "set_usage_attributes": [
      "self",
      "span",
      "response_obj"
    ],
    "set_span_attributes": [
      "self",
      "span",
      "attributes"
    ]
  },
  "PostHogLogger": {
    "__init__": [
      "self"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_log_async_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "create_posthog_event_payload": [
      "self",
      "kwargs"
    ],
    "_create_posthog_properties": [
      "self",
      "standard_logging_object",
      "kwargs",
      "event_name"
    ],
    "_add_trace_properties": [
      "self",
      "properties",
      "kwargs"
    ],
    "_add_custom_metadata_properties": [
      "self",
      "properties",
      "kwargs"
    ],
    "_get_distinct_id": [
      "self",
      "standard_logging_object",
      "kwargs"
    ],
    "_get_credentials_for_request": [
      "self",
      "kwargs"
    ],
    "async_send_batch": [
      "self"
    ],
    "_ensure_async_setup": [
      "self"
    ],
    "_extract_metadata": [
      "self",
      "kwargs"
    ],
    "_safe_uuid": [
      "self"
    ],
    "_create_posthog_payload": [
      "self",
      "events",
      "api_key"
    ],
    "_safe_get": [
      "self",
      "obj",
      "key",
      "default"
    ],
    "_flush_on_exit": [
      "self"
    ]
  },
  "_get_end_user_id_for_cost_tracking": [],
  "_get_cached_end_user_id_for_cost_tracking": [],
  "PrometheusLogger": {
    "__init__": [
      "self"
    ],
    "_parse_prometheus_config": [
      "self"
    ],
    "_validate_all_configurations": [
      "self",
      "parsed_configs"
    ],
    "_validate_single_metric_name": [
      "self",
      "metric_name"
    ],
    "_validate_single_metric_labels": [
      "self",
      "metric_name",
      "labels"
    ],
    "_build_label_filters": [
      "self",
      "parsed_configs"
    ],
    "_validate_configured_metric_labels": [
      "self",
      "metric_name",
      "labels"
    ],
    "_pretty_print_validation_errors": [
      "self",
      "validation_results"
    ],
    "_pretty_print_invalid_labels_error": [
      "self",
      "metric_name",
      "invalid_labels",
      "valid_labels"
    ],
    "_pretty_print_invalid_metric_error": [
      "self",
      "invalid_metric_name",
      "valid_metrics"
    ],
    "_valid_metric_name": [
      "self",
      "metric_name"
    ],
    "_pretty_print_prometheus_config": [
      "self",
      "label_filters"
    ],
    "_is_metric_enabled": [
      "self",
      "metric_name"
    ],
    "_create_metric_factory": [
      "self",
      "metric_class"
    ],
    "get_labels_for_metric": [
      "self",
      "metric_name"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_increment_token_metrics": [
      "self",
      "standard_logging_payload",
      "end_user_id",
      "user_api_key",
      "user_api_key_alias",
      "model",
      "user_api_team",
      "user_api_team_alias",
      "user_id",
      "enum_values"
    ],
    "_increment_cache_metrics": [
      "self",
      "standard_logging_payload",
      "enum_values"
    ],
    "_increment_remaining_budget_metrics": [
      "self",
      "user_api_team",
      "user_api_team_alias",
      "user_api_key",
      "user_api_key_alias",
      "litellm_params",
      "response_cost",
      "user_id"
    ],
    "_increment_top_level_request_and_spend_metrics": [
      "self",
      "end_user_id",
      "user_api_key",
      "user_api_key_alias",
      "model",
      "user_api_team",
      "user_api_team_alias",
      "user_id",
      "response_cost",
      "enum_values"
    ],
    "_set_virtual_key_rate_limit_metrics": [
      "self",
      "user_api_key",
      "user_api_key_alias",
      "kwargs",
      "metadata",
      "model_id"
    ],
    "_set_latency_metrics": [
      "self",
      "kwargs",
      "model",
      "user_api_key",
      "user_api_key_alias",
      "user_api_team",
      "user_api_team_alias",
      "enum_values"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_extract_status_code": [
      "self",
      "kwargs",
      "enum_values",
      "exception"
    ],
    "_is_invalid_api_key_request": [
      "self",
      "status_code",
      "exception"
    ],
    "_should_skip_metrics_for_invalid_key": [
      "self",
      "kwargs",
      "user_api_key_dict",
      "enum_values",
      "standard_logging_payload",
      "exception"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "async_post_call_success_hook": [
      "self",
      "data",
      "user_api_key_dict",
      "response"
    ],
    "_safe_get": [
      "self",
      "obj",
      "key",
      "default"
    ],
    "_extract_deployment_failure_label_values": [
      "self",
      "request_kwargs"
    ],
    "set_llm_deployment_failure_metrics": [
      "self",
      "request_kwargs"
    ],
    "_set_deployment_tpm_rpm_limit_metrics": [
      "self",
      "model_info",
      "litellm_params",
      "litellm_model_name",
      "model_id",
      "api_base",
      "llm_provider"
    ],
    "set_llm_deployment_success_metrics": [
      "self",
      "request_kwargs",
      "start_time",
      "end_time",
      "enum_values",
      "output_tokens"
    ],
    "_record_guardrail_metrics": [
      "self",
      "guardrail_name",
      "latency_seconds",
      "status",
      "error_type",
      "hook_type"
    ],
    "_get_exception_class_name": [
      "exception"
    ],
    "log_success_fallback_event": [
      "self",
      "original_model_group",
      "kwargs",
      "original_exception"
    ],
    "log_failure_fallback_event": [
      "self",
      "original_model_group",
      "kwargs",
      "original_exception"
    ],
    "set_litellm_deployment_state": [
      "self",
      "state",
      "litellm_model_name",
      "model_id",
      "api_base",
      "api_provider"
    ],
    "set_deployment_healthy": [
      "self",
      "litellm_model_name",
      "model_id",
      "api_base",
      "api_provider"
    ],
    "set_deployment_partial_outage": [
      "self",
      "litellm_model_name",
      "model_id",
      "api_base",
      "api_provider"
    ],
    "set_deployment_complete_outage": [
      "self",
      "litellm_model_name",
      "model_id",
      "api_base",
      "api_provider"
    ],
    "increment_deployment_cooled_down": [
      "self",
      "litellm_model_name",
      "model_id",
      "api_base",
      "api_provider",
      "exception_status"
    ],
    "increment_callback_logging_failure": [
      "self",
      "callback_name"
    ],
    "track_provider_remaining_budget": [
      "self",
      "provider",
      "spend",
      "budget_limit"
    ],
    "_safe_get_remaining_budget": [
      "self",
      "max_budget",
      "spend"
    ],
    "_initialize_budget_metrics": [
      "self",
      "data_fetch_function",
      "set_metrics_function",
      "data_type"
    ],
    "_initialize_team_budget_metrics": [
      "self"
    ],
    "_initialize_api_key_budget_metrics": [
      "self"
    ],
    "_initialize_user_budget_metrics": [
      "self"
    ],
    "initialize_remaining_budget_metrics": [
      "self"
    ],
    "_initialize_remaining_budget_metrics": [
      "self"
    ],
    "_initialize_user_and_team_count_metrics": [
      "self"
    ],
    "_set_key_list_budget_metrics": [
      "self",
      "keys"
    ],
    "_set_team_list_budget_metrics": [
      "self",
      "teams"
    ],
    "_set_user_list_budget_metrics": [
      "self",
      "users"
    ],
    "_set_team_budget_metrics_after_api_request": [
      "self",
      "user_api_team",
      "user_api_team_alias",
      "team_spend",
      "team_max_budget",
      "response_cost"
    ],
    "_assemble_team_object": [
      "self",
      "team_id",
      "team_alias",
      "spend",
      "max_budget",
      "response_cost"
    ],
    "_set_team_budget_metrics": [
      "self",
      "team"
    ],
    "_set_key_budget_metrics": [
      "self",
      "user_api_key_dict"
    ],
    "_set_api_key_budget_metrics_after_api_request": [
      "self",
      "user_api_key",
      "user_api_key_alias",
      "response_cost",
      "key_max_budget",
      "key_spend"
    ],
    "_assemble_key_object": [
      "self",
      "user_api_key",
      "user_api_key_alias",
      "key_max_budget",
      "key_spend",
      "response_cost"
    ],
    "_set_user_budget_metrics_after_api_request": [
      "self",
      "user_id",
      "user_spend",
      "user_max_budget",
      "response_cost"
    ],
    "_assemble_user_object": [
      "self",
      "user_id",
      "spend",
      "max_budget",
      "response_cost"
    ],
    "_set_user_budget_metrics": [
      "self",
      "user"
    ],
    "_get_remaining_hours_for_budget_reset": [
      "self",
      "budget_reset_at"
    ],
    "_safe_duration_seconds": [
      "self",
      "start_time",
      "end_time"
    ],
    "initialize_budget_metrics_cron_job": [
      "scheduler"
    ],
    "_mount_metrics_endpoint": []
  },
  "prometheus_label_factory": [
    "supported_enum_labels",
    "enum_values",
    "tag"
  ],
  "get_custom_labels_from_metadata": [
    "metadata"
  ],
  "_tag_matches_wildcard_configured_pattern": [
    "tags",
    "configured_tag"
  ],
  "get_custom_labels_from_tags": [
    "tags"
  ],
  "OpenMeterLogger": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self"
    ],
    "_common_logic": [
      "self",
      "kwargs",
      "response_obj"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "PromptManagementBase": {
    "integration_name": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "merge_messages": [
      "self",
      "prompt_template",
      "client_messages"
    ],
    "compile_prompt": [
      "self",
      "prompt_id",
      "prompt_variables",
      "client_messages",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version",
      "prompt_spec"
    ],
    "async_compile_prompt": [
      "self",
      "prompt_id",
      "prompt_variables",
      "client_messages",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "_get_model_from_prompt": [
      "self",
      "prompt_management_client",
      "model"
    ],
    "post_compile_prompt_processing": [
      "self",
      "prompt_template",
      "messages",
      "non_default_params",
      "model",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ]
  },
  "GcsPubSubLogger": {
    "__init__": [
      "self",
      "project_id",
      "topic_id",
      "credentials_path"
    ],
    "construct_request_headers": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "publish_message": [
      "self",
      "message"
    ]
  },
  "LevoConfig": {
    "__init__": [
      "self",
      "otlp_auth_headers",
      "protocol",
      "endpoint"
    ]
  },
  "LevoLogger": {
    "get_levo_config": [],
    "async_health_check": [
      "self"
    ]
  },
  "KEY_ROTATED_EMAIL_TEMPLATE": [],
  "KEY_CREATED_EMAIL_TEMPLATE": [],
  "USER_INVITED_EMAIL_TEMPLATE": [],
  "SOFT_BUDGET_ALERT_EMAIL_TEMPLATE": [],
  "TEAM_SOFT_BUDGET_ALERT_EMAIL_TEMPLATE": [],
  "MAX_BUDGET_ALERT_EMAIL_TEMPLATE": [],
  "USER_INVITATION_EMAIL_TEMPLATE": [],
  "EMAIL_FOOTER": [],
  "AgentOpsConfig": {
    "from_env": [
      "cls"
    ]
  },
  "AgentOps": {
    "__init__": [
      "self",
      "config"
    ],
    "_fetch_auth_token": [
      "self",
      "api_key",
      "auth_endpoint"
    ]
  },
  "GITLAB_PREFIX": [],
  "encode_prompt_id": [
    "raw_id"
  ],
  "decode_prompt_id": [
    "encoded_id"
  ],
  "GitLabPromptTemplate": {
    "__init__": [
      "self",
      "template_id",
      "content",
      "metadata",
      "model"
    ],
    "__repr__": [
      "self"
    ]
  },
  "GitLabTemplateManager": {
    "__init__": [
      "self",
      "gitlab_config",
      "prompt_id",
      "ref",
      "gitlab_client"
    ],
    "_id_to_repo_path": [
      "self",
      "prompt_id"
    ],
    "_repo_path_to_id": [
      "self",
      "repo_path"
    ],
    "_load_prompt_from_gitlab": [
      "self",
      "prompt_id"
    ],
    "load_all_prompts": [
      "self"
    ],
    "_parse_prompt_file": [
      "self",
      "content",
      "prompt_id"
    ],
    "_parse_yaml_basic": [
      "self",
      "yaml_str"
    ],
    "render_template": [
      "self",
      "template_id",
      "variables"
    ],
    "get_template": [
      "self",
      "template_id"
    ],
    "list_templates": [
      "self"
    ]
  },
  "GitLabPromptManager": {
    "__init__": [
      "self",
      "gitlab_config",
      "prompt_id",
      "ref",
      "gitlab_client"
    ],
    "integration_name": [
      "self"
    ],
    "prompt_manager": [
      "self"
    ],
    "get_prompt_template": [
      "self",
      "prompt_id",
      "prompt_variables"
    ],
    "pre_call_hook": [
      "self",
      "user_id",
      "messages",
      "function_call",
      "litellm_params",
      "prompt_id",
      "prompt_variables",
      "prompt_version"
    ],
    "_parse_prompt_to_messages": [
      "self",
      "prompt_content"
    ],
    "post_call_hook": [
      "self",
      "user_id",
      "response",
      "input_messages",
      "function_call",
      "litellm_params",
      "prompt_id",
      "prompt_variables"
    ],
    "get_available_prompts": [
      "self"
    ],
    "reload_prompts": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ]
  },
  "GitLabPromptCache": {
    "__init__": [
      "self",
      "gitlab_config"
    ],
    "load_all": [
      "self"
    ],
    "reload": [
      "self"
    ],
    "list_files": [
      "self"
    ],
    "list_ids": [
      "self"
    ],
    "get_by_file": [
      "self",
      "file_path"
    ],
    "get_by_id": [
      "self",
      "prompt_id"
    ],
    "_template_to_json": [
      "self",
      "prompt_id",
      "tmpl"
    ]
  },
  "prompt_initializer": [
    "litellm_params",
    "prompt_spec"
  ],
  "_gitlab_prompt_initializer": [
    "litellm_params",
    "prompt"
  ],
  "GitLabClient": {
    "__init__": [
      "self",
      "config"
    ],
    "_file_raw_url": [
      "self",
      "file_path"
    ],
    "_file_json_url": [
      "self",
      "file_path"
    ],
    "_tree_url": [
      "self",
      "directory_path",
      "recursive"
    ],
    "set_ref": [
      "self",
      "ref"
    ],
    "get_file_content": [
      "self",
      "file_path"
    ],
    "_get_file_content_via_json": [
      "self",
      "file_path"
    ],
    "list_files": [
      "self",
      "directory_path",
      "file_extension",
      "recursive"
    ],
    "get_repository_info": [
      "self"
    ],
    "test_connection": [
      "self"
    ],
    "get_branches": [
      "self"
    ],
    "get_file_metadata": [
      "self",
      "file_path"
    ],
    "close": [
      "self"
    ]
  },
  "_should_skip_event": [
    "kwargs"
  ],
  "OpikLogger": {
    "__init__": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_sync_send": [
      "self",
      "url",
      "headers",
      "batch"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_submit_batch": [
      "self",
      "url",
      "headers",
      "batch"
    ],
    "_create_opik_headers": [
      "self"
    ],
    "async_send_batch": [
      "self"
    ]
  },
  "create_uuid7": [],
  "_read_opik_config_file": [],
  "_get_env_variable": [
    "key"
  ],
  "get_opik_config_variable": [
    "key",
    "user_value",
    "default_value"
  ],
  "create_usage_object": [
    "usage"
  ],
  "_remove_nulls": [
    "x"
  ],
  "get_traces_and_spans_from_payload": [
    "payload"
  ],
  "TracePayload": {},
  "SpanPayload": {},
  "PayloadItem": [],
  "TraceSpanPayloadTuple": [],
  "build_trace_payload": [
    "project_name",
    "trace_id",
    "response_obj",
    "start_time",
    "end_time",
    "input_data",
    "output_data",
    "metadata",
    "tags",
    "thread_id"
  ],
  "build_span_payload": [
    "project_name",
    "trace_id",
    "parent_span_id",
    "response_obj",
    "start_time",
    "end_time",
    "input_data",
    "output_data",
    "metadata",
    "tags",
    "usage",
    "provider",
    "cost"
  ],
  "build_opik_payload": [
    "kwargs",
    "response_obj",
    "start_time",
    "end_time",
    "project_name"
  ],
  "normalize_provider_name": [
    "provider"
  ],
  "extract_opik_metadata": [
    "litellm_metadata",
    "standard_logging_metadata"
  ],
  "extract_span_identifiers": [
    "current_span_data"
  ],
  "extract_tags": [
    "opik_metadata",
    "custom_llm_provider"
  ],
  "apply_proxy_header_overrides": [
    "project_name",
    "tags",
    "thread_id",
    "proxy_headers"
  ],
  "extract_and_build_metadata": [
    "opik_metadata",
    "standard_logging_metadata",
    "standard_logging_object",
    "litellm_kwargs"
  ],
  "WEAVE_BASE_URL": [],
  "WEAVE_OTEL_ENDPOINT": [],
  "WeaveLLMObsOTELAttributes": {
    "set_messages": [
      "span",
      "kwargs"
    ]
  },
  "_set_weave_specific_attributes": [
    "span",
    "kwargs",
    "response_obj"
  ],
  "_get_weave_authorization_header": [
    "api_key"
  ],
  "get_weave_otel_config": [],
  "set_weave_otel_attributes": [
    "span",
    "kwargs",
    "response_obj"
  ],
  "WeaveOtelLogger": {
    "__init__": [
      "self",
      "config",
      "callback_name"
    ],
    "_maybe_log_raw_request": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "parent_span"
    ],
    "_start_primary_span": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "context",
      "parent_span"
    ],
    "_handle_success": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "construct_dynamic_otel_headers": [
      "self",
      "standard_callback_dynamic_params"
    ]
  },
  "AzureBlobStorageLogger": {
    "__init__": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "async_upload_payload_to_azure_blob_storage": [
      "self",
      "payload"
    ],
    "_create_file": [
      "self",
      "client",
      "base_url"
    ],
    "_append_data": [
      "self",
      "client",
      "base_url",
      "json_payload"
    ],
    "_flush_data": [
      "self",
      "client",
      "base_url",
      "position"
    ],
    "set_valid_azure_ad_token": [
      "self"
    ],
    "get_azure_ad_token_from_azure_storage": [
      "self",
      "tenant_id",
      "client_id",
      "client_secret"
    ],
    "_azure_ad_token_is_expired": [
      "self"
    ],
    "_premium_user_check": [
      "self"
    ],
    "get_service_client": [
      "self"
    ],
    "upload_to_azure_data_lake_with_azure_account_key": [
      "self",
      "payload"
    ]
  },
  "AzureSentinelLogger": {
    "__init__": [
      "self",
      "dcr_immutable_id",
      "stream_name",
      "endpoint",
      "tenant_id",
      "client_id",
      "client_secret"
    ],
    "_get_oauth_token": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ]
  },
  "WebSearchTransformation": {
    "transform_request": [
      "response",
      "stream",
      "response_format"
    ],
    "_detect_from_non_streaming_response": [
      "response"
    ],
    "_detect_from_openai_response": [
      "response"
    ],
    "transform_response": [
      "tool_calls",
      "search_results",
      "response_format"
    ],
    "_transform_response_anthropic": [
      "tool_calls",
      "search_results"
    ],
    "_transform_response_openai": [
      "tool_calls",
      "search_results"
    ],
    "format_search_response": [
      "result"
    ]
  },
  "WebSearchInterceptionLogger": {
    "__init__": [
      "self",
      "enabled_providers",
      "search_tool_name"
    ],
    "async_pre_call_deployment_hook": [
      "self",
      "kwargs",
      "call_type"
    ],
    "from_config_yaml": [
      "cls",
      "config"
    ],
    "async_pre_request_hook": [
      "self",
      "model",
      "messages",
      "kwargs"
    ],
    "async_should_run_agentic_loop": [
      "self",
      "response",
      "model",
      "messages",
      "tools",
      "stream",
      "custom_llm_provider",
      "kwargs"
    ],
    "async_should_run_chat_completion_agentic_loop": [
      "self",
      "response",
      "model",
      "messages",
      "tools",
      "stream",
      "custom_llm_provider",
      "kwargs"
    ],
    "async_run_agentic_loop": [
      "self",
      "tools",
      "model",
      "messages",
      "response",
      "anthropic_messages_provider_config",
      "anthropic_messages_optional_request_params",
      "logging_obj",
      "stream",
      "kwargs"
    ],
    "async_run_chat_completion_agentic_loop": [
      "self",
      "tools",
      "model",
      "messages",
      "response",
      "optional_params",
      "logging_obj",
      "stream",
      "kwargs"
    ],
    "_execute_agentic_loop": [
      "self",
      "model",
      "messages",
      "tool_calls",
      "anthropic_messages_optional_request_params",
      "logging_obj",
      "stream",
      "kwargs"
    ],
    "_execute_search": [
      "self",
      "query"
    ],
    "_execute_chat_completion_agentic_loop": [
      "self",
      "model",
      "messages",
      "tool_calls",
      "optional_params",
      "logging_obj",
      "stream",
      "kwargs",
      "response_format"
    ],
    "_create_empty_search_result": [
      "self"
    ],
    "initialize_from_proxy_config": [
      "litellm_settings",
      "callback_specific_params"
    ]
  },
  "get_litellm_web_search_tool": [],
  "get_litellm_web_search_tool_openai": [],
  "is_web_search_tool_chat_completion": [
    "tool"
  ],
  "is_web_search_tool": [
    "tool"
  ],
  "async_http_handler": [],
  "get_metric_from_prometheus": [
    "metric_name"
  ],
  "get_fallback_metric_from_prometheus": [],
  "is_prometheus_connected": [],
  "get_daily_spend_from_prometheus": [
    "api_key"
  ],
  "ArizeOTELAttributes": {
    "set_messages": [
      "span",
      "kwargs"
    ],
    "set_response_output_messages": [
      "span",
      "response_obj"
    ]
  },
  "_set_response_attributes": [
    "span",
    "response_obj"
  ],
  "_set_choice_outputs": [
    "span",
    "response_obj",
    "msg_attrs",
    "span_attrs"
  ],
  "_set_image_outputs": [
    "span",
    "response_obj",
    "image_attrs",
    "span_attrs"
  ],
  "_set_audio_outputs": [
    "span",
    "response_obj",
    "audio_attrs",
    "span_attrs"
  ],
  "_set_embedding_outputs": [
    "span",
    "response_obj",
    "embedding_attrs",
    "span_attrs"
  ],
  "_set_structured_outputs": [
    "span",
    "response_obj",
    "msg_attrs",
    "span_attrs"
  ],
  "_set_usage_outputs": [
    "span",
    "response_obj",
    "span_attrs"
  ],
  "_infer_open_inference_span_kind": [
    "call_type"
  ],
  "_set_tool_attributes": [
    "span",
    "optional_tools",
    "metadata_tools"
  ],
  "set_attributes": [
    "span",
    "kwargs",
    "response_obj",
    "attributes"
  ],
  "_sanitize_optional_params": [
    "optional_params"
  ],
  "_set_metadata_attributes": [
    "span",
    "metadata",
    "span_attrs"
  ],
  "_extract_metadata_tools": [
    "metadata"
  ],
  "_extract_optional_tools": [
    "optional_params"
  ],
  "_set_request_attributes": [
    "span",
    "kwargs",
    "standard_logging_payload",
    "optional_params",
    "litellm_params",
    "response_obj",
    "span_attrs"
  ],
  "_set_model_params": [
    "span",
    "model_params",
    "span_attrs"
  ],
  "ArizePhoenixClient": {
    "__init__": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_prompt_version": [
      "self",
      "prompt_version_id"
    ],
    "test_connection": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "ArizePhoenixPromptTemplate": {
    "__init__": [
      "self",
      "template_id",
      "messages",
      "metadata",
      "model"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ArizePhoenixTemplateManager": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "prompt_id"
    ],
    "_load_prompt_from_arize": [
      "self",
      "prompt_version_id"
    ],
    "_parse_prompt_data": [
      "self",
      "data",
      "prompt_version_id"
    ],
    "render_template": [
      "self",
      "template_id",
      "variables"
    ],
    "get_template": [
      "self",
      "template_id"
    ],
    "list_templates": [
      "self"
    ]
  },
  "ArizePhoenixPromptManager": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "prompt_id"
    ],
    "integration_name": [
      "self"
    ],
    "prompt_manager": [
      "self"
    ],
    "get_prompt_template": [
      "self",
      "prompt_id",
      "prompt_variables"
    ],
    "pre_call_hook": [
      "self",
      "user_id",
      "messages",
      "function_call",
      "litellm_params",
      "prompt_id",
      "prompt_variables"
    ],
    "get_available_prompts": [
      "self"
    ],
    "reload_prompts": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ]
  },
  "ArizeLogger": {
    "_init_tracing": [
      "self",
      "tracer_provider"
    ],
    "_init_otel_logger_on_litellm_proxy": [
      "self"
    ],
    "set_attributes": [
      "self",
      "span",
      "kwargs",
      "response_obj"
    ],
    "set_arize_attributes": [
      "span",
      "kwargs",
      "response_obj"
    ],
    "get_arize_config": [],
    "async_service_success_hook": [
      "self",
      "payload",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "async_service_failure_hook": [
      "self",
      "payload",
      "error",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "async_health_check": [
      "self"
    ],
    "construct_dynamic_otel_headers": [
      "self",
      "standard_callback_dynamic_params"
    ]
  },
  "ARIZE_HOSTED_PHOENIX_ENDPOINT": [],
  "ArizePhoenixLogger": {
    "_init_tracing": [
      "self",
      "tracer_provider"
    ],
    "_init_otel_logger_on_litellm_proxy": [
      "self"
    ],
    "set_attributes": [
      "self",
      "span",
      "kwargs",
      "response_obj"
    ],
    "set_arize_phoenix_attributes": [
      "span",
      "kwargs",
      "response_obj"
    ],
    "_get_dynamic_project_name": [
      "kwargs"
    ],
    "_handle_success": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "get_arize_phoenix_config": [],
    "async_health_check": [
      "self"
    ]
  },
  "process_slack_alerting_variables": [
    "alert_to_webhook_url"
  ],
  "_add_langfuse_trace_id_to_alert": [
    "request_data"
  ],
  "AlertingHangingRequestCheck": {
    "__init__": [
      "self",
      "slack_alerting_object"
    ],
    "add_request_to_hanging_request_check": [
      "self",
      "request_data"
    ],
    "send_alerts_for_hanging_requests": [
      "self"
    ],
    "check_for_hanging_requests": [
      "self"
    ],
    "send_hanging_request_alert": [
      "self",
      "hanging_request_data"
    ]
  },
  "BaseBudgetAlertType": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "ProxyBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "SoftBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "UserBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "TeamBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "OrganizationBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "TokenBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "ProjectedLimitExceededAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "ProjectBudgetAlert": {
    "get_event_message": [
      "self"
    ],
    "get_id": [
      "self",
      "user_info"
    ]
  },
  "get_budget_alert_type": [
    "type"
  ],
  "squash_payloads": [
    "queue"
  ],
  "_print_alerting_payload_warning": [
    "payload",
    "slackAlertingInstance"
  ],
  "send_to_webhook": [
    "slackAlertingInstance",
    "item",
    "count"
  ],
  "SlackAlerting": {
    "__init__": [
      "self",
      "internal_usage_cache",
      "alerting_threshold",
      "alerting",
      "alert_types",
      "alert_to_webhook_url",
      "alerting_args",
      "default_webhook_url"
    ],
    "update_values": [
      "self",
      "alerting",
      "alerting_threshold",
      "alert_types",
      "alert_to_webhook_url",
      "alerting_args",
      "llm_router"
    ],
    "_prepare_outage_value_for_cache": [
      "self",
      "outage_value"
    ],
    "_restore_outage_value_from_cache": [
      "self",
      "outage_value"
    ],
    "deployment_in_cooldown": [
      "self"
    ],
    "deployment_removed_from_cooldown": [
      "self"
    ],
    "_all_possible_alert_types": [
      "self"
    ],
    "_response_taking_too_long_callback_helper": [
      "self",
      "kwargs",
      "start_time",
      "end_time"
    ],
    "_get_deployment_latencies_to_alert": [
      "self",
      "metadata"
    ],
    "response_taking_too_long_callback": [
      "self",
      "kwargs",
      "completion_response",
      "start_time",
      "end_time"
    ],
    "async_update_daily_reports": [
      "self",
      "deployment_metrics"
    ],
    "send_daily_reports": [
      "self",
      "router"
    ],
    "response_taking_too_long": [
      "self",
      "request_data"
    ],
    "failed_tracking_alert": [
      "self",
      "error_message",
      "failing_model"
    ],
    "budget_alerts": [
      "self",
      "type",
      "user_info"
    ],
    "_get_event_and_event_message": [
      "self",
      "user_info",
      "event",
      "event_message"
    ],
    "_get_percent_of_max_budget_left": [
      "self",
      "user_info"
    ],
    "_get_user_info_str": [
      "self",
      "user_info"
    ],
    "customer_spend_alert": [
      "self",
      "token",
      "key_alias",
      "end_user_id",
      "response_cost",
      "max_budget"
    ],
    "_count_outage_alerts": [
      "self",
      "alerts"
    ],
    "_outage_alert_msg_factory": [
      "self",
      "alert_type",
      "key",
      "key_val",
      "provider",
      "api_base",
      "outage_value"
    ],
    "region_outage_alerts": [
      "self",
      "exception",
      "deployment_id"
    ],
    "outage_alerts": [
      "self",
      "exception",
      "deployment_id"
    ],
    "model_added_alert": [
      "self",
      "model_name",
      "litellm_model_name",
      "passed_model_info"
    ],
    "model_removed_alert": [
      "self",
      "model_name"
    ],
    "send_webhook_alert": [
      "self",
      "webhook_event"
    ],
    "_check_if_using_premium_email_feature": [
      "self",
      "premium_user",
      "email_logo_url",
      "email_support_contact"
    ],
    "send_key_created_or_user_invited_email": [
      "self",
      "webhook_event"
    ],
    "send_email_alert_using_smtp": [
      "self",
      "webhook_event",
      "alert_type"
    ],
    "send_alert": [
      "self",
      "message",
      "level",
      "alert_type",
      "alerting_metadata",
      "user_info"
    ],
    "async_send_batch": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_run_scheduler_helper": [
      "self",
      "llm_router"
    ],
    "_run_scheduled_daily_report": [
      "self",
      "llm_router"
    ],
    "send_weekly_spend_report": [
      "self",
      "time_range"
    ],
    "send_monthly_spend_report": [
      "self"
    ],
    "send_fallback_stats_from_prometheus": [
      "self"
    ],
    "send_virtual_key_event_slack": [
      "self",
      "key_event",
      "alert_type",
      "event_name"
    ],
    "_request_is_completed": [
      "self",
      "request_data"
    ]
  },
  "BitBucketPromptTemplate": {
    "__init__": [
      "self",
      "template_id",
      "content",
      "metadata",
      "model"
    ],
    "__repr__": [
      "self"
    ]
  },
  "BitBucketTemplateManager": {
    "__init__": [
      "self",
      "bitbucket_config",
      "prompt_id"
    ],
    "_load_prompt_from_bitbucket": [
      "self",
      "prompt_id"
    ],
    "_parse_prompt_file": [
      "self",
      "content",
      "prompt_id"
    ],
    "_parse_yaml_basic": [
      "self",
      "yaml_str"
    ],
    "render_template": [
      "self",
      "template_id",
      "variables"
    ],
    "get_template": [
      "self",
      "template_id"
    ],
    "list_templates": [
      "self"
    ]
  },
  "BitBucketPromptManager": {
    "__init__": [
      "self",
      "bitbucket_config",
      "prompt_id"
    ],
    "integration_name": [
      "self"
    ],
    "prompt_manager": [
      "self"
    ],
    "get_prompt_template": [
      "self",
      "prompt_id",
      "prompt_variables"
    ],
    "pre_call_hook": [
      "self",
      "user_id",
      "messages",
      "function_call",
      "litellm_params",
      "prompt_id",
      "prompt_variables"
    ],
    "_parse_prompt_to_messages": [
      "self",
      "prompt_content"
    ],
    "post_call_hook": [
      "self",
      "user_id",
      "response",
      "input_messages",
      "function_call",
      "litellm_params",
      "prompt_id",
      "prompt_variables"
    ],
    "get_available_prompts": [
      "self"
    ],
    "reload_prompts": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ]
  },
  "BitBucketClient": {
    "__init__": [
      "self",
      "config"
    ],
    "get_file_content": [
      "self",
      "file_path"
    ],
    "list_files": [
      "self",
      "directory_path",
      "file_extension"
    ],
    "get_repository_info": [
      "self"
    ],
    "test_connection": [
      "self"
    ],
    "get_branches": [
      "self"
    ],
    "get_file_metadata": [
      "self",
      "file_path"
    ],
    "close": [
      "self"
    ]
  },
  "get_datadog_source": [],
  "get_datadog_service": [],
  "get_datadog_hostname": [],
  "get_datadog_base_url_from_env": [],
  "get_datadog_env": [],
  "get_datadog_pod_name": [],
  "get_datadog_tags": [
    "standard_logging_object"
  ],
  "DD_LOGGED_SUCCESS_SERVICE_TYPES": [],
  "DataDogLogger": {
    "__init__": [
      "self"
    ],
    "_get_datadog_params": [
      "self"
    ],
    "_configure_dd_agent": [
      "self",
      "dd_agent_host"
    ],
    "_configure_dd_direct_api": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_post_call_failure_hook": [
      "self",
      "request_data",
      "original_exception",
      "user_api_key_dict",
      "traceback_str"
    ],
    "async_send_batch": [
      "self"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_log_async_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_create_datadog_logging_payload_helper": [
      "self",
      "standard_logging_object",
      "status"
    ],
    "create_datadog_logging_payload": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_compressed_data": [
      "self",
      "data"
    ],
    "async_service_failure_hook": [
      "self",
      "payload",
      "error",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "async_service_success_hook": [
      "self",
      "payload",
      "error",
      "parent_otel_span",
      "start_time",
      "end_time",
      "event_metadata"
    ],
    "_create_v0_logging_payload": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_add_trace_context_to_payload": [
      "self",
      "dd_payload"
    ],
    "_get_active_trace_context": [
      "self"
    ],
    "async_health_check": [
      "self"
    ],
    "get_request_response_payload": [
      "self",
      "request_id",
      "start_time_utc",
      "end_time_utc"
    ]
  },
  "DatadogCostManagementLogger": {
    "__init__": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "_aggregate_costs": [
      "self",
      "logs"
    ],
    "_extract_tags": [
      "self",
      "log"
    ],
    "_upload_to_datadog": [
      "self",
      "payload"
    ]
  },
  "DataDogLLMObsLogger": {
    "__init__": [
      "self"
    ],
    "_configure_dd_agent": [
      "self",
      "dd_agent_host"
    ],
    "_configure_dd_direct_api": [
      "self"
    ],
    "_get_datadog_llm_obs_params": [
      "self"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "create_llm_obs_payload": [
      "self",
      "kwargs",
      "start_time",
      "end_time"
    ],
    "_get_apm_trace_id": [
      "self"
    ],
    "_assemble_error_info": [
      "self",
      "standard_logging_payload"
    ],
    "_get_time_to_first_token_seconds": [
      "self",
      "standard_logging_payload"
    ],
    "_get_response_messages": [
      "self",
      "standard_logging_payload",
      "call_type"
    ],
    "_get_datadog_span_kind": [
      "self",
      "call_type",
      "parent_id"
    ],
    "_ensure_string_content": [
      "self",
      "messages"
    ],
    "_get_dd_llm_obs_payload_metadata": [
      "self",
      "standard_logging_payload"
    ],
    "_get_latency_metrics": [
      "self",
      "standard_logging_payload"
    ],
    "_get_stream_value_from_payload": [
      "self",
      "standard_logging_payload"
    ],
    "_get_spend_metrics": [
      "self",
      "standard_logging_payload"
    ],
    "_process_input_messages_preserving_tool_calls": [
      "self",
      "messages"
    ],
    "_tool_calls_kv_pair": [
      "tool_calls"
    ],
    "_extract_tool_call_metadata": [
      "self",
      "standard_logging_payload"
    ]
  },
  "LangFuseHandler": {
    "get_langfuse_logger_for_request": [
      "standard_callback_dynamic_params",
      "in_memory_dynamic_logger_cache",
      "globalLangfuseLogger"
    ],
    "_return_global_langfuse_logger": [
      "globalLangfuseLogger",
      "in_memory_dynamic_logger_cache"
    ],
    "_create_langfuse_logger_from_credentials": [
      "credentials",
      "in_memory_dynamic_logger_cache"
    ],
    "get_dynamic_langfuse_logging_config": [
      "standard_callback_dynamic_params",
      "globalLangfuseLogger"
    ],
    "_dynamic_langfuse_credentials_are_passed": [
      "standard_callback_dynamic_params"
    ]
  },
  "langfuse_client_init": [
    "langfuse_public_key",
    "langfuse_secret",
    "langfuse_secret_key",
    "langfuse_host",
    "flush_interval"
  ],
  "LangfusePromptManagement": {
    "__init__": [
      "self",
      "langfuse_public_key",
      "langfuse_secret",
      "langfuse_host",
      "flush_interval"
    ],
    "integration_name": [
      "self"
    ],
    "_get_prompt_from_id": [
      "self",
      "langfuse_prompt_id",
      "langfuse_client",
      "prompt_label",
      "prompt_version"
    ],
    "_compile_prompt": [
      "self",
      "langfuse_prompt_client",
      "langfuse_prompt_variables",
      "call_type"
    ],
    "_get_optional_params_from_langfuse": [
      "self",
      "langfuse_prompt_client"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "get_output_content_by_type": [
    "response_obj",
    "kwargs"
  ],
  "LangfuseLLMObsOTELAttributes": {
    "set_messages": [
      "span",
      "kwargs"
    ],
    "set_response_output_messages": [
      "span",
      "response_obj"
    ]
  },
  "create_mock_langfuse_client": [],
  "LANGFUSE_CLOUD_EU_ENDPOINT": [],
  "LANGFUSE_CLOUD_US_ENDPOINT": [],
  "LangfuseOtelLogger": {
    "__init__": [
      "self",
      "config"
    ],
    "set_langfuse_otel_attributes": [
      "span",
      "kwargs",
      "response_obj"
    ],
    "_extract_langfuse_metadata": [
      "kwargs"
    ],
    "_set_metadata_attributes": [
      "span",
      "metadata"
    ],
    "_set_observation_output": [
      "span",
      "response_obj"
    ],
    "_set_langfuse_specific_attributes": [
      "span",
      "kwargs",
      "response_obj"
    ],
    "_get_langfuse_otel_host": [],
    "_create_open_telemetry_config_from_langfuse_env": [
      "self"
    ],
    "get_langfuse_otel_config": [],
    "_get_langfuse_authorization_header": [
      "public_key",
      "secret_key"
    ],
    "construct_dynamic_otel_headers": [
      "self",
      "standard_callback_dynamic_params"
    ],
    "create_litellm_proxy_request_started_span": [
      "self",
      "start_time",
      "headers"
    ],
    "async_service_success_hook": [
      "self"
    ],
    "async_service_failure_hook": [
      "self"
    ]
  },
  "_extract_cache_read_input_tokens": [
    "usage_obj"
  ],
  "LangFuseLogger": {
    "__init__": [
      "self",
      "langfuse_public_key",
      "langfuse_secret",
      "langfuse_host",
      "flush_interval"
    ],
    "safe_init_langfuse_client": [
      "self",
      "parameters"
    ],
    "add_metadata_from_header": [
      "litellm_params",
      "metadata"
    ],
    "log_event_on_langfuse": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "user_id",
      "level",
      "status_message"
    ],
    "_get_langfuse_input_output_content": [
      "self",
      "kwargs",
      "response_obj",
      "prompt",
      "level",
      "status_message"
    ],
    "_async_log_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "user_id"
    ],
    "_is_langfuse_v2": [
      "self"
    ],
    "_log_langfuse_v1": [
      "self",
      "user_id",
      "metadata",
      "output",
      "start_time",
      "end_time",
      "kwargs",
      "optional_params",
      "input",
      "response_obj"
    ],
    "_log_langfuse_v2": [
      "self",
      "user_id",
      "metadata",
      "litellm_params",
      "output",
      "start_time",
      "end_time",
      "kwargs",
      "optional_params",
      "input",
      "response_obj",
      "level",
      "litellm_call_id"
    ],
    "_get_chat_content_for_langfuse": [
      "response_obj"
    ],
    "_get_text_completion_content_for_langfuse": [
      "response_obj"
    ],
    "_get_responses_api_content_for_langfuse": [
      "response_obj"
    ],
    "_get_langfuse_tags": [
      "standard_logging_object"
    ],
    "add_default_langfuse_tags": [
      "self",
      "tags",
      "kwargs",
      "metadata"
    ],
    "_supports_tags": [
      "self"
    ],
    "_supports_prompt": [
      "self"
    ],
    "_supports_costs": [
      "self"
    ],
    "_supports_completion_start_time": [
      "self"
    ],
    "_apply_masking_function": [
      "data",
      "masking_function"
    ],
    "_get_langfuse_flush_interval": [
      "flush_interval"
    ],
    "_log_guardrail_information_as_span": [
      "self",
      "trace",
      "standard_logging_object"
    ]
  },
  "_add_prompt_to_generation_params": [
    "generation_params",
    "clean_metadata",
    "prompt_management_metadata",
    "langfuse_client"
  ],
  "log_provider_specific_information_as_span": [
    "trace",
    "clean_metadata"
  ],
  "log_requester_metadata": [
    "clean_metadata"
  ],
  "API_EVENT_TYPES": [],
  "LOG_FORMAT_TYPES": [],
  "load_compatible_callbacks": [],
  "is_callback_compatible": [
    "callback_name"
  ],
  "get_callback_config": [
    "callback_name"
  ],
  "substitute_env_variables": [
    "value"
  ],
  "GenericAPILogger": {
    "__init__": [
      "self",
      "endpoint",
      "headers",
      "event_types",
      "callback_name",
      "log_format"
    ],
    "_get_headers": [
      "self",
      "headers"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_send_batch": [
      "self"
    ],
    "_get_v1_logging_payload": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "to_zod_compatible_iso": [
    "dt"
  ],
  "DeepEvalLogger": {
    "__init__": [
      "self"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_prepare_trace_api": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "is_success"
    ],
    "_sync_event_handler": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "is_success"
    ],
    "_async_event_handler": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time",
      "is_success"
    ],
    "_create_base_api_span": [
      "self",
      "kwargs",
      "standard_logging_object",
      "start_time",
      "end_time",
      "is_success"
    ],
    "_create_trace_api": [
      "self",
      "base_api_span",
      "standard_logging_object",
      "start_time",
      "end_time",
      "litellm_environment"
    ]
  },
  "SpanApiType": {
    "BASE": [],
    "AGENT": [],
    "LLM": [],
    "RETRIEVER": [],
    "TOOL": []
  },
  "span_api_type_literals": [],
  "TraceSpanApiStatus": {
    "SUCCESS": [],
    "ERRORED": []
  },
  "BaseApiSpan": {},
  "TraceApi": {},
  "DEEPEVAL_BASE_URL": [],
  "DEEPEVAL_BASE_URL_EU": [],
  "API_BASE_URL": [],
  "API_BASE_URL_EU": [],
  "retryable_exceptions": [],
  "log_retry_error": [
    "details"
  ],
  "HttpMethods": {
    "GET": [],
    "POST": [],
    "DELETE": [],
    "PUT": []
  },
  "Endpoints": {
    "DATASET_ENDPOINT": [],
    "TEST_RUN_ENDPOINT": [],
    "TRACING_ENDPOINT": [],
    "EVENT_ENDPOINT": [],
    "FEEDBACK_ENDPOINT": [],
    "PROMPT_ENDPOINT": [],
    "RECOMMEND_ENDPOINT": [],
    "EVALUATE_ENDPOINT": [],
    "GUARD_ENDPOINT": [],
    "GUARDRAILS_ENDPOINT": [],
    "BASELINE_ATTACKS_ENDPOINT": []
  },
  "Api": {
    "__init__": [
      "self",
      "api_key",
      "base_url"
    ],
    "_http_request": [
      "self",
      "method",
      "url",
      "headers",
      "json",
      "params"
    ],
    "send_request": [
      "self",
      "method",
      "endpoint",
      "body",
      "params"
    ],
    "a_send_request": [
      "self",
      "method",
      "endpoint",
      "body",
      "params"
    ]
  },
  "MessageAttributes": {
    "MESSAGE_ROLE": [],
    "MESSAGE_CONTENT": [],
    "MESSAGE_CONTENTS": [],
    "MESSAGE_NAME": [],
    "MESSAGE_TOOL_CALLS": [],
    "MESSAGE_FUNCTION_CALL_NAME": [],
    "MESSAGE_FUNCTION_CALL_ARGUMENTS_JSON": [],
    "MESSAGE_TOOL_CALL_ID": [],
    "MESSAGE_REASONING_SUMMARY": []
  },
  "MessageContentAttributes": {
    "MESSAGE_CONTENT_TYPE": [],
    "MESSAGE_CONTENT_TEXT": [],
    "MESSAGE_CONTENT_IMAGE": []
  },
  "ImageAttributes": {
    "IMAGE_URL": []
  },
  "AudioAttributes": {
    "AUDIO_URL": [],
    "AUDIO_MIME_TYPE": [],
    "AUDIO_TRANSCRIPT": []
  },
  "DocumentAttributes": {
    "DOCUMENT_ID": [],
    "DOCUMENT_SCORE": [],
    "DOCUMENT_CONTENT": [],
    "DOCUMENT_METADATA": []
  },
  "RerankerAttributes": {
    "RERANKER_INPUT_DOCUMENTS": [],
    "RERANKER_OUTPUT_DOCUMENTS": [],
    "RERANKER_QUERY": [],
    "RERANKER_MODEL_NAME": [],
    "RERANKER_TOP_K": []
  },
  "EmbeddingAttributes": {
    "EMBEDDING_TEXT": [],
    "EMBEDDING_VECTOR": []
  },
  "ToolCallAttributes": {
    "TOOL_CALL_ID": [],
    "TOOL_CALL_FUNCTION_NAME": [],
    "TOOL_CALL_FUNCTION_ARGUMENTS_JSON": []
  },
  "ToolAttributes": {
    "TOOL_JSON_SCHEMA": []
  },
  "OpenInferenceSpanKindValues": {
    "TOOL": [],
    "CHAIN": [],
    "LLM": [],
    "RETRIEVER": [],
    "EMBEDDING": [],
    "AGENT": [],
    "RERANKER": [],
    "UNKNOWN": [],
    "GUARDRAIL": [],
    "EVALUATOR": []
  },
  "OpenInferenceMimeTypeValues": {
    "TEXT": [],
    "JSON": []
  },
  "OpenInferenceLLMSystemValues": {
    "OPENAI": [],
    "ANTHROPIC": [],
    "COHERE": [],
    "MISTRALAI": [],
    "VERTEXAI": []
  },
  "OpenInferenceLLMProviderValues": {
    "OPENAI": [],
    "ANTHROPIC": [],
    "COHERE": [],
    "MISTRALAI": [],
    "GOOGLE": [],
    "AZURE": [],
    "AWS": []
  },
  "ErrorAttributes": {
    "ERROR_TYPE": [],
    "ERROR_MESSAGE": [],
    "ERROR_CODE": [],
    "ERROR_STACK_TRACE": [],
    "ERROR_LLM_PROVIDER": []
  },
  "_original_async_handler_get": [],
  "_original_async_handler_delete": [],
  "_mock_async_handler_get": [
    "self",
    "url",
    "params",
    "headers",
    "follow_redirects"
  ],
  "_mock_async_handler_delete": [
    "self",
    "url",
    "data",
    "json",
    "params",
    "headers",
    "timeout",
    "stream",
    "content"
  ],
  "create_mock_gcs_client": [],
  "mock_vertex_auth_methods": [],
  "GCSBucketLogger": {
    "__init__": [
      "self",
      "bucket_name"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_drain_queue_batch": [
      "self"
    ],
    "_generate_batch_object_name": [
      "self",
      "date_str",
      "batch_id"
    ],
    "_get_config_key": [
      "self",
      "kwargs"
    ],
    "_sanitize_config_key": [
      "self",
      "config_key"
    ],
    "_group_items_by_config": [
      "self",
      "items"
    ],
    "_combine_payloads_to_ndjson": [
      "self",
      "items"
    ],
    "_send_grouped_batch": [
      "self",
      "items",
      "config_key"
    ],
    "_send_individual_logs": [
      "self",
      "items"
    ],
    "_send_single_log_item": [
      "self",
      "item"
    ],
    "async_send_batch": [
      "self"
    ],
    "_get_object_name": [
      "self",
      "kwargs",
      "logging_payload",
      "response_obj"
    ],
    "get_request_response_payload": [
      "self",
      "request_id",
      "start_time_utc",
      "end_time_utc"
    ],
    "_generate_success_object_name": [
      "self",
      "request_date_str",
      "response_id"
    ],
    "_generate_failure_object_name": [
      "self",
      "request_date_str"
    ],
    "_get_object_date_from_datetime": [
      "self",
      "datetime_obj"
    ],
    "flush_queue": [
      "self"
    ],
    "periodic_flush": [
      "self"
    ],
    "async_health_check": [
      "self"
    ]
  },
  "IAM_AUTH_KEY": [],
  "GCSBucketBase": {
    "__init__": [
      "self",
      "bucket_name"
    ],
    "construct_request_headers": [
      "self",
      "service_account_json",
      "vertex_instance"
    ],
    "sync_construct_request_headers": [
      "self"
    ],
    "_handle_folders_in_bucket_name": [
      "self",
      "bucket_name",
      "object_name"
    ],
    "get_gcs_logging_config": [
      "self",
      "kwargs"
    ],
    "get_or_create_vertex_instance": [
      "self",
      "credentials"
    ],
    "_get_in_memory_key_for_vertex_instance": [
      "self",
      "credentials"
    ],
    "download_gcs_object": [
      "self",
      "object_name"
    ],
    "delete_gcs_object": [
      "self",
      "object_name"
    ],
    "_log_json_data_on_gcs": [
      "self",
      "headers",
      "bucket_name",
      "object_name",
      "logging_payload"
    ]
  },
  "VectorStorePreCallHook": {
    "CONTENT_PREFIX_STRING": [],
    "__init__": [
      "self"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "_extract_query_from_messages": [
      "self",
      "messages"
    ],
    "_append_search_results_to_messages": [
      "self",
      "messages",
      "search_response"
    ],
    "async_post_call_success_deployment_hook": [
      "self",
      "request_data",
      "response",
      "call_type"
    ],
    "async_post_call_streaming_deployment_hook": [
      "self",
      "request_data",
      "response_chunk",
      "call_type"
    ]
  },
  "BaseVectorStore": {},
  "PromptTemplate": {
    "__init__": [
      "self",
      "content",
      "metadata",
      "template_id"
    ],
    "__repr__": [
      "self"
    ]
  },
  "PromptManager": {
    "__init__": [
      "self",
      "prompt_id",
      "prompt_directory",
      "prompt_data",
      "prompt_file"
    ],
    "_load_prompts": [
      "self"
    ],
    "_load_prompts_from_json": [
      "self",
      "prompt_data",
      "prompt_id"
    ],
    "_load_prompt_file": [
      "self",
      "file_path",
      "prompt_id"
    ],
    "_parse_frontmatter": [
      "self",
      "content"
    ],
    "render": [
      "self",
      "prompt_id",
      "prompt_variables",
      "version"
    ],
    "_validate_input": [
      "self",
      "variables",
      "schema"
    ],
    "_get_python_type": [
      "self",
      "schema_type"
    ],
    "get_prompt": [
      "self",
      "prompt_id",
      "version"
    ],
    "list_prompts": [
      "self"
    ],
    "get_prompt_metadata": [
      "self",
      "prompt_id"
    ],
    "reload_prompts": [
      "self"
    ],
    "add_prompt": [
      "self",
      "prompt_id",
      "content",
      "metadata"
    ],
    "prompt_file_to_json": [
      "self",
      "file_path"
    ],
    "json_to_prompt_file": [
      "self",
      "prompt_data"
    ],
    "get_all_prompts_as_json": [
      "self"
    ],
    "load_prompts_from_json_data": [
      "self",
      "prompt_data"
    ]
  },
  "DotpromptManager": {
    "__init__": [
      "self",
      "prompt_directory",
      "prompt_file",
      "prompt_data",
      "prompt_id"
    ],
    "integration_name": [
      "self"
    ],
    "prompt_manager": [
      "self"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "_convert_to_messages": [
      "self",
      "rendered_content"
    ],
    "_create_message": [
      "self",
      "role",
      "content"
    ],
    "_extract_optional_params": [
      "self",
      "template"
    ],
    "set_prompt_directory": [
      "self",
      "prompt_directory"
    ],
    "reload_prompts": [
      "self"
    ],
    "add_prompt_from_json": [
      "self",
      "prompt_id",
      "json_data"
    ],
    "load_prompts_from_json": [
      "self",
      "prompts_data"
    ],
    "get_prompts_as_json": [
      "self"
    ],
    "convert_prompt_file_to_json": [
      "self",
      "file_path"
    ]
  },
  "set_global_prompt_directory": [
    "directory"
  ],
  "_get_prompt_data_from_dotprompt_content": [
    "dotprompt_content"
  ],
  "LITELLM_AGENT_PREFIX": [],
  "LiteLLMAgentModelResolver": {
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ]
  },
  "FOCUS_USAGE_DATA_JOB_NAME": [],
  "DEFAULT_DRY_RUN_LIMIT": [],
  "FocusLogger": {
    "__init__": [
      "self"
    ],
    "_ensure_engine": [
      "self"
    ],
    "export_usage_data": [
      "self"
    ],
    "dry_run_export_usage_data": [
      "self",
      "limit"
    ],
    "initialize_focus_export_job": [
      "self"
    ],
    "init_focus_export_background_job": [
      "scheduler"
    ],
    "_build_scheduler_trigger": [
      "self"
    ],
    "_run_scheduled_export": [
      "self"
    ],
    "_export_window": [
      "self"
    ],
    "_compute_time_window": [
      "self",
      "now"
    ]
  },
  "FocusTransformer": {
    "schema": [],
    "transform": [
      "self",
      "frame"
    ]
  },
  "FocusLiteLLMDatabase": {
    "_ensure_prisma_client": [
      "self"
    ],
    "get_usage_data": [
      "self"
    ],
    "get_table_info": [
      "self"
    ]
  },
  "FocusExportEngine": {
    "__init__": [
      "self"
    ],
    "_init_serializer": [
      "self"
    ],
    "dry_run_export_usage_data": [
      "self",
      "limit"
    ],
    "export_window": [
      "self"
    ],
    "_serialize_and_upload": [
      "self",
      "frame",
      "window"
    ],
    "_build_filename": [
      "self"
    ],
    "_sum_column": [
      "frame",
      "column"
    ],
    "_count_unique": [
      "frame",
      "column"
    ]
  },
  "FOCUS_NORMALIZED_SCHEMA": [],
  "FocusDestinationFactory": {
    "create": [],
    "_resolve_config": []
  },
  "FocusS3Destination": {
    "__init__": [
      "self"
    ],
    "deliver": [
      "self"
    ],
    "_build_object_key": [
      "self"
    ],
    "_upload": [
      "self",
      "content",
      "object_key"
    ]
  },
  "FocusTimeWindow": {},
  "FocusDestination": {
    "deliver": [
      "self"
    ]
  },
  "FocusParquetSerializer": {
    "extension": [],
    "serialize": [
      "self",
      "frame"
    ]
  },
  "FocusSerializer": {
    "serialize": [
      "self",
      "frame"
    ]
  },
  "GenericPromptManager": {
    "__init__": [
      "self",
      "api_base",
      "api_key",
      "timeout",
      "prompt_id",
      "additional_provider_specific_query_params"
    ],
    "integration_name": [
      "self"
    ],
    "_get_headers": [
      "self"
    ],
    "_fetch_prompt_from_api": [
      "self",
      "prompt_id",
      "prompt_spec"
    ],
    "async_fetch_prompt_from_api": [
      "self",
      "prompt_id",
      "prompt_spec"
    ],
    "_parse_api_response": [
      "self",
      "prompt_id",
      "prompt_spec",
      "api_response"
    ],
    "should_run_prompt_management": [
      "self",
      "prompt_id",
      "prompt_spec",
      "dynamic_callback_params"
    ],
    "_get_cache_key": [
      "self",
      "prompt_id",
      "prompt_label",
      "prompt_version"
    ],
    "_common_caching_logic": [
      "self",
      "prompt_id",
      "prompt_label",
      "prompt_version",
      "prompt_variables"
    ],
    "_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_spec",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_label",
      "prompt_version"
    ],
    "async_compile_prompt_helper": [
      "self",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version"
    ],
    "_apply_variables": [
      "self",
      "prompt_client",
      "variables"
    ],
    "async_get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "litellm_logging_obj",
      "prompt_spec",
      "tools",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "get_chat_completion_prompt": [
      "self",
      "model",
      "messages",
      "non_default_params",
      "prompt_id",
      "prompt_variables",
      "dynamic_callback_params",
      "prompt_spec",
      "prompt_label",
      "prompt_version",
      "ignore_prompt_manager_model",
      "ignore_prompt_manager_optional_params"
    ],
    "clear_cache": [
      "self"
    ]
  },
  "set_global_generic_prompt_config": [
    "config"
  ],
  "CZEntityType": {
    "TEAM": []
  },
  "CZRNGenerator": {
    "CZRN_REGEX": [],
    "__init__": [
      "self"
    ],
    "create_from_litellm_data": [
      "self",
      "row"
    ],
    "create_from_components": [
      "self",
      "service_type",
      "provider",
      "region",
      "owner_account_id",
      "resource_type",
      "cloud_local_id"
    ],
    "is_valid": [
      "self",
      "czrn"
    ],
    "extract_components": [
      "self",
      "czrn"
    ],
    "_normalize_provider": [
      "self",
      "provider"
    ],
    "_normalize_component": [
      "self",
      "component",
      "allow_uppercase"
    ]
  },
  "LiteLLMDatabase": {
    "_ensure_prisma_client": [
      "self"
    ],
    "get_usage_data": [
      "self",
      "limit",
      "start_time_utc",
      "end_time_utc"
    ]
  },
  "CBFTransformer": {
    "__init__": [
      "self"
    ],
    "transform": [
      "self",
      "data"
    ],
    "_create_cbf_record": [
      "self",
      "row"
    ],
    "_parse_date": [
      "self",
      "date_str"
    ]
  },
  "CloudZeroLogger": {
    "__init__": [
      "self",
      "api_key",
      "connection_id",
      "timezone"
    ],
    "initialize_cloudzero_export_job": [
      "self"
    ],
    "_hourly_usage_data_export": [
      "self"
    ],
    "export_usage_data": [
      "self",
      "limit",
      "operation",
      "start_time_utc",
      "end_time_utc"
    ],
    "dry_run_export_usage_data": [
      "self",
      "limit"
    ],
    "_display_cbf_data_on_screen": [
      "self",
      "cbf_data"
    ],
    "init_cloudzero_background_job": [
      "scheduler"
    ]
  },
  "CloudZeroStreamer": {
    "__init__": [
      "self",
      "api_key",
      "connection_id",
      "user_timezone"
    ],
    "send_batched": [
      "self",
      "data",
      "operation"
    ],
    "_group_by_date": [
      "self",
      "data"
    ],
    "_parse_and_convert_timestamp": [
      "self",
      "timestamp_str"
    ],
    "_send_daily_batch": [
      "self",
      "batch_date",
      "batch_data",
      "operation"
    ],
    "_prepare_batch_payload": [
      "self",
      "batch_date",
      "batch_data",
      "operation"
    ],
    "_convert_cbf_to_api_format": [
      "self",
      "row"
    ],
    "_ensure_utc_timestamp": [
      "self",
      "timestamp_str"
    ]
  },
  "BaseLLMObsOTELAttributes": {
    "set_messages": [
      "span",
      "kwargs"
    ],
    "set_response_output_messages": [
      "span",
      "response_obj"
    ]
  },
  "cast_as_primitive_value_type": [
    "value"
  ],
  "safe_set_attribute": [
    "span",
    "key",
    "value"
  ],
  "get_rag_ingestion_class": [
    "custom_llm_provider"
  ],
  "get_rag_transformation_class": [
    "custom_llm_provider"
  ],
  "get_ingestion_class": [
    "provider"
  ],
  "_execute_ingest_pipeline": [
    "ingest_options",
    "file_data",
    "file_url",
    "file_id",
    "router"
  ],
  "aingest": [
    "ingest_options",
    "file_data",
    "file",
    "file_url",
    "file_id",
    "timeout"
  ],
  "_execute_query_pipeline": [
    "model",
    "messages",
    "retrieval_config",
    "rerank",
    "stream"
  ],
  "aquery": [
    "model",
    "messages",
    "retrieval_config",
    "rerank",
    "stream"
  ],
  "query": [
    "model",
    "messages",
    "retrieval_config",
    "rerank",
    "stream"
  ],
  "ingest": [
    "ingest_options",
    "file_data",
    "file",
    "file_url",
    "file_id",
    "timeout"
  ],
  "arag_ingest": [],
  "RAGQuery": {
    "CONTENT_PREFIX_STRING": [],
    "extract_query_from_messages": [
      "messages"
    ],
    "build_context_message": [
      "context_chunks"
    ],
    "add_search_results_to_response": [
      "response",
      "search_results",
      "rerank_results"
    ],
    "extract_documents_from_search": [
      "search_response"
    ],
    "get_top_chunks_from_rerank": [
      "search_response",
      "rerank_response"
    ]
  },
  "RecursiveCharacterTextSplitter": {
    "__init__": [
      "self",
      "chunk_size",
      "chunk_overlap",
      "separators"
    ],
    "split_text": [
      "self",
      "text"
    ],
    "_split_text": [
      "self",
      "text",
      "separators",
      "depth"
    ],
    "_merge_splits": [
      "self",
      "splits",
      "separator"
    ],
    "_force_split": [
      "self",
      "text"
    ]
  },
  "GeminiRAGIngestion": {
    "__init__": [
      "self",
      "ingest_options",
      "router"
    ],
    "embed": [
      "self",
      "chunks"
    ],
    "store": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "chunks",
      "embeddings"
    ],
    "_create_file_search_store": [
      "self",
      "api_key",
      "base_url",
      "display_name"
    ],
    "_upload_to_file_search_store": [
      "self",
      "api_key",
      "base_url",
      "vector_store_id",
      "filename",
      "file_content",
      "content_type"
    ],
    "_initiate_resumable_upload": [
      "self",
      "api_key",
      "base_url",
      "vector_store_id",
      "filename",
      "file_size",
      "content_type"
    ],
    "_upload_file_content": [
      "self",
      "upload_url",
      "file_content"
    ]
  },
  "S3VectorsRAGIngestion": {
    "__init__": [
      "self",
      "ingest_options",
      "router"
    ],
    "_get_dimension_from_embedding_request": [
      "self"
    ],
    "_get_dimension_from_config": [
      "self"
    ],
    "_ensure_config_initialized": [
      "self"
    ],
    "_sign_and_execute_request": [
      "self",
      "method",
      "url",
      "data",
      "headers"
    ],
    "_ensure_vector_bucket_exists": [
      "self"
    ],
    "_ensure_vector_index_exists": [
      "self"
    ],
    "_put_vectors": [
      "self",
      "vectors"
    ],
    "embed": [
      "self",
      "chunks"
    ],
    "store": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "chunks",
      "embeddings"
    ],
    "query_vector_store": [
      "self",
      "vector_store_id",
      "query",
      "top_k"
    ]
  },
  "_get_str_or_none": [
    "value"
  ],
  "_get_int": [
    "value",
    "default"
  ],
  "_normalize_principal_arn": [
    "caller_arn",
    "account_id"
  ],
  "BedrockRAGIngestion": {
    "__init__": [
      "self",
      "ingest_options",
      "router"
    ],
    "_ensure_config_initialized": [
      "self"
    ],
    "_auto_detect_config": [
      "self"
    ],
    "_create_knowledge_base_infrastructure": [
      "self"
    ],
    "_create_s3_bucket": [
      "self",
      "unique_id"
    ],
    "_create_opensearch_collection": [
      "self",
      "unique_id",
      "account_id",
      "caller_arn"
    ],
    "_create_opensearch_index": [
      "self",
      "collection_name"
    ],
    "_create_bedrock_role": [
      "self",
      "unique_id",
      "account_id",
      "collection_arn"
    ],
    "_create_knowledge_base": [
      "self",
      "kb_name",
      "role_arn",
      "collection_arn"
    ],
    "_create_data_source": [
      "self",
      "kb_name"
    ],
    "_get_boto3_client": [
      "self",
      "service_name"
    ],
    "embed": [
      "self",
      "chunks"
    ],
    "store": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "chunks",
      "embeddings"
    ]
  },
  "OpenAIRAGIngestion": {
    "__init__": [
      "self",
      "ingest_options",
      "router"
    ],
    "embed": [
      "self",
      "chunks"
    ],
    "store": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "chunks",
      "embeddings"
    ]
  },
  "VertexAIRAGIngestion": {
    "__init__": [
      "self",
      "ingest_options",
      "router"
    ],
    "embed": [
      "self",
      "chunks"
    ],
    "store": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "chunks",
      "embeddings"
    ],
    "_create_rag_corpus": [
      "self",
      "display_name",
      "description"
    ],
    "_poll_operation": [
      "self",
      "operation_name",
      "access_token",
      "max_retries",
      "retry_delay"
    ],
    "_upload_file_to_corpus": [
      "self",
      "rag_corpus_id",
      "filename",
      "file_content",
      "content_type"
    ],
    "_import_files_from_gcs": [
      "self",
      "rag_corpus_id",
      "gcs_uris"
    ]
  },
  "BaseRAGIngestion": {
    "__init__": [
      "self",
      "ingest_options",
      "router"
    ],
    "_load_credentials_from_config": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "upload": [
      "self",
      "file_data",
      "file_url",
      "file_id"
    ],
    "ocr": [
      "self",
      "file_content",
      "content_type"
    ],
    "chunk": [
      "self",
      "text",
      "file_content",
      "ocr_was_used"
    ],
    "embed": [
      "self",
      "chunks"
    ],
    "store": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "chunks",
      "embeddings"
    ],
    "ingest": [
      "self",
      "file_data",
      "file_url",
      "file_id"
    ]
  },
  "extract_text_from_pdf": [
    "file_content"
  ],
  "InitalizeCachedClient": {
    "set_max_parallel_requests_client": [
      "litellm_router_instance",
      "model"
    ]
  },
  "PatternUtils": {
    "calculate_pattern_specificity": [
      "pattern"
    ],
    "sorted_patterns": [
      "patterns"
    ]
  },
  "PatternMatchRouter": {
    "__init__": [
      "self"
    ],
    "add_pattern": [
      "self",
      "pattern",
      "llm_deployment"
    ],
    "_pattern_to_regex": [
      "self",
      "pattern"
    ],
    "_return_pattern_matched_deployments": [
      "self",
      "matched_pattern",
      "deployments"
    ],
    "route": [
      "self",
      "request",
      "filtered_model_names"
    ],
    "set_deployment_model_name": [
      "matched_pattern",
      "litellm_deployment_litellm_model"
    ],
    "get_pattern": [
      "self",
      "model",
      "custom_llm_provider"
    ],
    "get_deployments_by_pattern": [
      "self",
      "model",
      "custom_llm_provider"
    ]
  },
  "router_cooldown_event_callback": [
    "litellm_router_instance",
    "deployment_id",
    "exception_status",
    "cooldown_time"
  ],
  "_get_prometheus_logger_from_callbacks": [],
  "_check_stripped_model_group": [
    "model_group",
    "fallback_key"
  ],
  "get_fallback_model_group": [
    "fallbacks",
    "model_group"
  ],
  "run_async_fallback": [],
  "log_success_fallback_event": [
    "original_model_group",
    "kwargs",
    "original_exception"
  ],
  "log_failure_fallback_event": [
    "original_model_group",
    "kwargs",
    "original_exception"
  ],
  "_check_non_standard_fallback_format": [
    "fallbacks"
  ],
  "run_non_standard_fallback_format": [
    "fallbacks",
    "model_group"
  ],
  "_add_headers_to_response": [
    "response",
    "headers"
  ],
  "add_retry_headers_to_response": [
    "response",
    "attempted_retries",
    "max_retries"
  ],
  "add_fallback_headers_to_response": [
    "response",
    "attempted_fallbacks"
  ],
  "send_llm_exception_alert": [
    "litellm_router_instance",
    "request_kwargs",
    "error_traceback_str",
    "original_exception"
  ],
  "async_raise_no_deployment_exception": [
    "litellm_router_instance",
    "model",
    "parent_otel_span"
  ],
  "InMemoryFile": {
    "__init__": [
      "self",
      "content",
      "name",
      "content_type"
    ]
  },
  "parse_jsonl_with_embedded_newlines": [
    "content"
  ],
  "should_replace_model_in_jsonl": [
    "purpose"
  ],
  "replace_model_in_jsonl": [
    "file_content",
    "new_model_name"
  ],
  "_get_router_metadata_variable_name": [
    "function_name"
  ],
  "SearchAPIRouter": {
    "update_router_search_tools": [
      "router_instance",
      "search_tools"
    ],
    "get_matching_search_tools": [
      "router_instance",
      "search_tool_name"
    ],
    "async_search_with_fallbacks": [
      "router_instance",
      "original_function"
    ],
    "async_search_with_fallbacks_helper": [
      "router_instance",
      "model",
      "original_generic_function"
    ]
  },
  "PromptCachingCacheValue": {},
  "PromptCachingCache": {
    "__init__": [
      "self",
      "cache"
    ],
    "serialize_object": [
      "obj"
    ],
    "extract_cacheable_prefix": [
      "messages"
    ],
    "get_prompt_caching_cache_key": [
      "messages",
      "tools"
    ],
    "add_model_id": [
      "self",
      "model_id",
      "messages",
      "tools"
    ],
    "async_add_model_id": [
      "self",
      "model_id",
      "messages",
      "tools"
    ],
    "async_get_model_id": [
      "self",
      "messages",
      "tools"
    ],
    "get_model_id": [
      "self",
      "messages",
      "tools"
    ]
  },
  "clientside_credential_keys": [],
  "is_clientside_credential": [
    "request_kwargs"
  ],
  "get_dynamic_litellm_params": [
    "litellm_params",
    "request_kwargs"
  ],
  "get_num_retries_from_retry_policy": [
    "exception",
    "retry_policy",
    "model_group",
    "model_group_retry_policy"
  ],
  "reset_retry_policy": [],
  "_is_cooldown_required": [
    "litellm_router_instance",
    "model_id",
    "exception_status",
    "exception_str"
  ],
  "_should_run_cooldown_logic": [
    "litellm_router_instance",
    "deployment",
    "exception_status",
    "original_exception",
    "time_to_cooldown"
  ],
  "_should_cooldown_deployment": [
    "litellm_router_instance",
    "deployment",
    "exception_status",
    "original_exception"
  ],
  "_set_cooldown_deployments": [
    "litellm_router_instance",
    "original_exception",
    "exception_status",
    "deployment",
    "time_to_cooldown"
  ],
  "_async_get_cooldown_deployments": [
    "litellm_router_instance",
    "parent_otel_span"
  ],
  "_async_get_cooldown_deployments_with_debug_info": [
    "litellm_router_instance",
    "parent_otel_span"
  ],
  "_get_cooldown_deployments": [
    "litellm_router_instance",
    "parent_otel_span"
  ],
  "should_cooldown_based_on_allowed_fails_policy": [
    "litellm_router_instance",
    "deployment",
    "original_exception"
  ],
  "_is_allowed_fails_set_on_router": [
    "litellm_router_instance"
  ],
  "cast_exception_status_to_int": [
    "exception_status"
  ],
  "get_litellm_params_sensitive_credential_hash": [
    "litellm_params"
  ],
  "add_model_file_id_mappings": [
    "healthy_deployments",
    "responses"
  ],
  "filter_team_based_models": [
    "healthy_deployments",
    "request_kwargs"
  ],
  "_deployment_supports_web_search": [
    "deployment"
  ],
  "filter_web_search_deployments": [
    "healthy_deployments",
    "request_kwargs"
  ],
  "CooldownCacheValue": {},
  "CooldownCache": {
    "__init__": [
      "self",
      "cache",
      "default_cooldown_time"
    ],
    "_common_add_cooldown_logic": [
      "self",
      "model_id",
      "original_exception",
      "exception_status",
      "cooldown_time"
    ],
    "add_deployment_to_cooldown": [
      "self",
      "model_id",
      "original_exception",
      "exception_status",
      "cooldown_time"
    ],
    "get_cooldown_cache_key": [
      "model_id"
    ],
    "async_get_active_cooldowns": [
      "self",
      "model_ids",
      "parent_otel_span"
    ],
    "get_active_cooldowns": [
      "self",
      "model_ids",
      "parent_otel_span"
    ],
    "get_min_cooldown": [
      "self",
      "model_ids",
      "parent_otel_span"
    ]
  },
  "increment_deployment_successes_for_current_minute": [
    "litellm_router_instance",
    "deployment_id"
  ],
  "increment_deployment_failures_for_current_minute": [
    "litellm_router_instance",
    "deployment_id"
  ],
  "get_deployment_successes_for_current_minute": [
    "litellm_router_instance",
    "deployment_id"
  ],
  "get_deployment_failures_for_current_minute": [
    "litellm_router_instance",
    "deployment_id"
  ],
  "DeploymentAffinityCacheValue": {},
  "DeploymentAffinityCheck": {
    "CACHE_KEY_PREFIX": [],
    "__init__": [
      "self",
      "cache",
      "ttl_seconds",
      "enable_user_key_affinity",
      "enable_responses_api_affinity",
      "enable_session_id_affinity"
    ],
    "_looks_like_sha256_hex": [
      "value"
    ],
    "_hash_user_key": [
      "user_key"
    ],
    "_get_model_map_key_from_litellm_model_name": [
      "litellm_model_name"
    ],
    "_get_model_map_key_from_deployment": [
      "deployment"
    ],
    "_get_stable_model_map_key_from_deployments": [
      "healthy_deployments"
    ],
    "_shorten_for_logs": [
      "value",
      "keep"
    ],
    "get_affinity_cache_key": [
      "cls",
      "model_group",
      "user_key"
    ],
    "get_session_affinity_cache_key": [
      "cls",
      "model_group",
      "session_id"
    ],
    "_get_user_key_from_metadata_dict": [
      "metadata"
    ],
    "_get_session_id_from_metadata_dict": [
      "metadata"
    ],
    "_iter_metadata_dicts": [
      "request_kwargs"
    ],
    "_get_user_key_from_request_kwargs": [
      "request_kwargs"
    ],
    "_get_session_id_from_request_kwargs": [
      "request_kwargs"
    ],
    "_find_deployment_by_model_id": [
      "healthy_deployments",
      "model_id"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs",
      "parent_otel_span"
    ],
    "async_pre_call_deployment_hook": [
      "self",
      "kwargs",
      "call_type"
    ]
  },
  "ModelRateLimitingCheck": {
    "__init__": [
      "self",
      "dual_cache"
    ],
    "_get_deployment_limits": [
      "self",
      "deployment"
    ],
    "_get_cache_keys": [
      "self",
      "deployment",
      "current_minute"
    ],
    "pre_call_check": [
      "self",
      "deployment"
    ],
    "async_pre_call_check": [
      "self",
      "deployment",
      "parent_otel_span"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "PromptCachingDeploymentCheck": {
    "__init__": [
      "self",
      "cache"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs",
      "parent_otel_span"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ]
  },
  "ResponsesApiDeploymentCheck": {
    "__init__": [
      "self"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs",
      "parent_otel_span"
    ]
  },
  "openai_fine_tuning_apis_instance": [],
  "azure_fine_tuning_apis_instance": [],
  "vertex_fine_tuning_apis_instance": [],
  "acreate_fine_tuning_job": [
    "model",
    "training_file",
    "hyperparameters",
    "suffix",
    "validation_file",
    "integrations",
    "seed",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "acancel_fine_tuning_job": [
    "fine_tuning_job_id",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "alist_fine_tuning_jobs": [
    "after",
    "limit",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "aretrieve_fine_tuning_job": [
    "fine_tuning_job_id",
    "custom_llm_provider",
    "extra_headers",
    "extra_body"
  ],
  "VectorStoreFileRequestUtils": {
    "_filter_params": [
      "params",
      "model"
    ],
    "get_create_request_params": [
      "params"
    ],
    "get_list_query_params": [
      "params"
    ],
    "get_update_request_params": [
      "params"
    ]
  },
  "VectorStoreFileAttributeValue": [],
  "VectorStoreFileAttributes": [],
  "_ensure_provider": [
    "custom_llm_provider"
  ],
  "_prepare_registry_credentials": [],
  "alist": [],
  "aretrieve": [],
  "retrieve": [],
  "aretrieve_content": [],
  "retrieve_content": [],
  "aupdate": [],
  "update": [],
  "BaseRoutingStrategy": {
    "__init__": [
      "self",
      "dual_cache",
      "should_batch_redis_writes",
      "default_sync_interval"
    ],
    "setup_sync_task": [
      "self",
      "default_sync_interval"
    ],
    "cleanup": [
      "self"
    ],
    "_increment_value_list_in_current_window": [
      "self",
      "increment_list",
      "ttl"
    ],
    "_increment_value_in_current_window": [
      "self",
      "key",
      "value",
      "ttl"
    ],
    "periodic_sync_in_memory_spend_with_redis": [
      "self",
      "default_sync_interval"
    ],
    "_push_in_memory_increments_to_redis": [
      "self"
    ],
    "add_to_in_memory_keys_to_update": [
      "self",
      "key"
    ],
    "get_key_pattern_to_sync": [
      "self"
    ],
    "get_in_memory_keys_to_update": [
      "self"
    ],
    "get_and_reset_in_memory_keys_to_update": [
      "self"
    ],
    "reset_in_memory_keys_to_update": [
      "self"
    ],
    "_sync_in_memory_spend_with_redis": [
      "self"
    ]
  },
  "LowestLatencyLoggingHandler": {
    "__init__": [
      "self",
      "router_cache",
      "routing_args"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input",
      "request_kwargs",
      "request_count_dict"
    ],
    "async_get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input",
      "request_kwargs"
    ],
    "get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input",
      "request_kwargs"
    ]
  },
  "LowestTPMLoggingHandler_v2": {
    "__init__": [
      "self",
      "router_cache",
      "routing_args"
    ],
    "pre_call_check": [
      "self",
      "deployment"
    ],
    "async_pre_call_check": [
      "self",
      "deployment",
      "parent_otel_span"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_return_potential_deployments": [
      "self",
      "healthy_deployments",
      "all_deployments",
      "input_tokens",
      "rpm_dict"
    ],
    "_common_checks_available_deployment": [
      "self",
      "model_group",
      "healthy_deployments",
      "tpm_keys",
      "tpm_values",
      "rpm_keys",
      "rpm_values",
      "messages",
      "input"
    ],
    "async_get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input"
    ],
    "get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input",
      "parent_otel_span"
    ]
  },
  "LeastBusyLoggingHandler": {
    "__init__": [
      "self",
      "router_cache"
    ],
    "log_pre_api_call": [
      "self",
      "model",
      "messages",
      "kwargs"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_failure_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_get_available_deployments": [
      "self",
      "healthy_deployments",
      "all_deployments"
    ],
    "get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments"
    ],
    "async_get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments"
    ]
  },
  "_LiteLLMParamsDictView": {
    "__slots__": [],
    "__init__": [
      "self",
      "params"
    ],
    "__getattr__": [
      "self",
      "key"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "default"
    ],
    "keys": [
      "self"
    ],
    "values": [
      "self"
    ],
    "items": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "dict": [
      "self"
    ],
    "model_dump": [
      "self"
    ]
  },
  "RouterBudgetLimiting": {
    "__init__": [
      "self",
      "dual_cache",
      "provider_budget_config",
      "model_list"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "messages",
      "request_kwargs",
      "parent_otel_span"
    ],
    "_filter_out_deployments_above_budget": [
      "self",
      "potential_deployments",
      "healthy_deployments",
      "provider_configs",
      "deployment_configs",
      "deployment_providers",
      "spend_map",
      "request_tags"
    ],
    "_async_get_cache_keys_for_router_budget_limiting": [
      "self",
      "healthy_deployments",
      "request_kwargs"
    ],
    "_get_or_set_budget_start_time": [
      "self",
      "start_time_key",
      "current_time",
      "ttl_seconds"
    ],
    "_handle_new_budget_window": [
      "self",
      "spend_key",
      "start_time_key",
      "current_time",
      "response_cost",
      "ttl_seconds"
    ],
    "_increment_spend_in_current_window": [
      "self",
      "spend_key",
      "response_cost",
      "ttl"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "_increment_spend_for_key": [
      "self",
      "budget_config",
      "spend_key",
      "start_time_key",
      "response_cost"
    ],
    "periodic_sync_in_memory_spend_with_redis": [
      "self"
    ],
    "_push_in_memory_increments_to_redis": [
      "self"
    ],
    "_sync_in_memory_spend_with_redis": [
      "self"
    ],
    "_get_budget_config_for_deployment": [
      "self",
      "model_id"
    ],
    "_get_budget_config_for_provider": [
      "self",
      "provider"
    ],
    "_get_budget_config_for_tag": [
      "self",
      "tag"
    ],
    "_get_llm_provider_for_deployment": [
      "self",
      "deployment"
    ],
    "_track_provider_remaining_budget_prometheus": [
      "self",
      "provider",
      "spend",
      "budget_limit"
    ],
    "_get_current_provider_spend": [
      "self",
      "provider"
    ],
    "_get_current_provider_budget_reset_at": [
      "self",
      "provider"
    ],
    "_init_provider_budget_in_cache": [
      "self",
      "provider",
      "budget_config"
    ],
    "should_init_router_budget_limiter": [
      "provider_budget_config",
      "model_list"
    ],
    "_init_provider_budgets": [
      "self"
    ],
    "_init_deployment_budgets": [
      "self",
      "model_list"
    ],
    "_init_tag_budgets": [
      "self"
    ]
  },
  "LowestTPMLoggingHandler": {
    "__init__": [
      "self",
      "router_cache",
      "routing_args"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input"
    ]
  },
  "simple_shuffle": [
    "llm_router_instance",
    "healthy_deployments",
    "model"
  ],
  "LowestCostLoggingHandler": {
    "__init__": [
      "self",
      "router_cache",
      "routing_args"
    ],
    "log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_log_success_event": [
      "self",
      "kwargs",
      "response_obj",
      "start_time",
      "end_time"
    ],
    "async_get_available_deployments": [
      "self",
      "model_group",
      "healthy_deployments",
      "messages",
      "input",
      "request_kwargs"
    ]
  },
  "is_valid_deployment_tag": [
    "deployment_tags",
    "request_tags",
    "match_any"
  ],
  "get_deployments_for_tag": [
    "llm_router_instance",
    "model",
    "healthy_deployments",
    "request_kwargs",
    "metadata_variable_name"
  ],
  "_get_tags_from_request_kwargs": [
    "request_kwargs",
    "metadata_variable_name"
  ],
  "AutoRouter": {
    "DEFAULT_AUTO_SYNC_VALUE": [],
    "__init__": [
      "self",
      "model_name",
      "default_model",
      "embedding_model",
      "litellm_router_instance",
      "auto_router_config_path",
      "auto_router_config"
    ],
    "_load_semantic_routing_routes": [
      "self"
    ],
    "_load_auto_router_routes_from_config_json": [
      "self"
    ],
    "async_pre_routing_hook": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment"
    ]
  },
  "litellm_to_list": [
    "embeds"
  ],
  "CustomDenseEncoder": {
    "model_config": [],
    "__init__": [
      "self",
      "litellm_router_instance"
    ]
  },
  "LiteLLMRouterEncoder": {
    "__init__": [
      "self",
      "litellm_router_instance",
      "model_name",
      "score_threshold"
    ],
    "__call__": [
      "self",
      "docs"
    ],
    "acall": [
      "self",
      "docs"
    ],
    "encode_queries": [
      "self",
      "docs"
    ],
    "encode_documents": [
      "self",
      "docs"
    ],
    "aencode_queries": [
      "self",
      "docs"
    ],
    "aencode_documents": [
      "self",
      "docs"
    ]
  },
  "DimensionScore": {
    "__slots__": [],
    "__init__": [
      "self",
      "name",
      "score",
      "signal"
    ]
  },
  "ComplexityRouter": {
    "__init__": [
      "self",
      "model_name",
      "litellm_router_instance",
      "complexity_router_config",
      "default_model"
    ],
    "_estimate_tokens": [
      "self",
      "text"
    ],
    "_score_token_count": [
      "self",
      "estimated_tokens"
    ],
    "_keyword_matches": [
      "self",
      "text",
      "keyword"
    ],
    "_score_keyword_match": [
      "self",
      "text",
      "keywords",
      "name",
      "signal_label",
      "thresholds",
      "scores"
    ],
    "_score_multi_step": [
      "self",
      "text"
    ],
    "_score_question_complexity": [
      "self",
      "text"
    ],
    "classify": [
      "self",
      "prompt",
      "system_prompt"
    ],
    "get_model_for_tier": [
      "self",
      "tier"
    ],
    "async_pre_routing_hook": [
      "self",
      "model",
      "request_kwargs",
      "messages",
      "input",
      "specific_deployment"
    ]
  },
  "ComplexityTier": {
    "SIMPLE": [],
    "MEDIUM": [],
    "COMPLEX": [],
    "REASONING": []
  },
  "ComplexityRouterConfig": {
    "model_config": []
  },
  "DEFAULT_COMPLEXITY_CONFIG": [],
  "EvalCase": {},
  "run_eval": [],
  "main": [],
  "GLOBAL_PASS_THROUGH_SUCCESS_HANDLER_OBJ": [],
  "BaseGoogleGenAIGenerateContentStreamingIterator": {
    "__init__": [
      "self",
      "litellm_logging_obj",
      "request_body",
      "model"
    ],
    "_handle_async_streaming_logging": [
      "self"
    ]
  },
  "GoogleGenAIGenerateContentStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "logging_obj",
      "generate_content_provider_config",
      "litellm_metadata",
      "custom_llm_provider",
      "request_body"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "AsyncGoogleGenAIGenerateContentStreamingIterator": {
    "__init__": [
      "self",
      "response",
      "model",
      "logging_obj",
      "generate_content_provider_config",
      "litellm_metadata",
      "custom_llm_provider",
      "request_body"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "GenerateContentSetupResult": {},
  "GenerateContentHelper": {
    "mock_generate_content_response": [
      "mock_response"
    ],
    "setup_generate_content_call": [
      "model",
      "contents",
      "config",
      "custom_llm_provider",
      "tools"
    ]
  },
  "agenerate_content": [
    "model",
    "contents",
    "config",
    "tools",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "generate_content": [
    "model",
    "contents",
    "config",
    "tools",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "agenerate_content_stream": [
    "model",
    "contents",
    "config",
    "tools",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "generate_content_stream": [
    "model",
    "contents",
    "config",
    "tools",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "GoogleGenAIStreamWrapper": {
    "__init__": [
      "self",
      "completion_stream"
    ],
    "__next__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "google_genai_sse_wrapper": [
      "self"
    ],
    "async_google_genai_sse_wrapper": [
      "self"
    ]
  },
  "GoogleGenAIAdapter": {
    "__init__": [
      "self"
    ],
    "translate_generate_content_to_completion": [
      "self",
      "model",
      "contents",
      "config",
      "litellm_params"
    ],
    "_add_generic_litellm_params_to_request": [
      "self",
      "completion_request_dict",
      "litellm_params"
    ],
    "translate_completion_output_params_streaming": [
      "self",
      "completion_stream"
    ],
    "_transform_google_genai_tools_to_openai": [
      "self",
      "tools"
    ],
    "_transform_google_genai_tool_config_to_openai": [
      "self",
      "tool_config"
    ],
    "_transform_contents_to_messages": [
      "self",
      "contents",
      "system_instruction"
    ],
    "translate_completion_to_generate_content": [
      "self",
      "response"
    ],
    "translate_streaming_completion_to_generate_content": [
      "self",
      "response",
      "wrapper"
    ],
    "_transform_openai_message_to_google_genai_parts": [
      "self",
      "message"
    ],
    "_transform_openai_delta_to_google_genai_parts_with_accumulation": [
      "self",
      "delta",
      "wrapper"
    ],
    "_map_finish_reason": [
      "self",
      "finish_reason"
    ],
    "_map_usage": [
      "self",
      "usage"
    ]
  },
  "GOOGLE_GENAI_ADAPTER": [],
  "GenerateContentToCompletionHandler": {
    "_prepare_completion_kwargs": [
      "model",
      "contents",
      "config",
      "stream",
      "litellm_params",
      "extra_kwargs"
    ],
    "async_generate_content_handler": [
      "model",
      "contents",
      "litellm_params",
      "config",
      "stream"
    ],
    "generate_content_handler": [
      "model",
      "contents",
      "litellm_params",
      "config",
      "stream",
      "_is_async"
    ]
  },
  "DEFAULT_ANTHROPIC_API_BASE": [],
  "_litellm_skills_handler": [],
  "_get_litellm_skills_handler": [],
  "acreate_skill": [
    "files",
    "display_title",
    "extra_headers",
    "extra_query",
    "extra_body",
    "timeout",
    "custom_llm_provider"
  ],
  "alist_skills": [
    "limit",
    "page",
    "source",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "aget_skill": [
    "skill_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "adelete_skill": [
    "skill_id",
    "extra_headers",
    "extra_query",
    "timeout",
    "custom_llm_provider"
  ],
  "CustomLLMError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "CustomLLM": {
    "__init__": [
      "self"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "headers",
      "timeout",
      "client"
    ],
    "streaming": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "headers",
      "timeout",
      "client"
    ],
    "acompletion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "headers",
      "timeout",
      "client"
    ],
    "astreaming": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "headers",
      "timeout",
      "client"
    ],
    "image_generation": [
      "self",
      "model",
      "prompt",
      "api_key",
      "api_base",
      "model_response",
      "optional_params",
      "logging_obj",
      "timeout",
      "client"
    ],
    "aimage_generation": [
      "self",
      "model",
      "prompt",
      "model_response",
      "api_key",
      "api_base",
      "optional_params",
      "logging_obj",
      "timeout",
      "client"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "model_response",
      "print_verbose",
      "logging_obj",
      "optional_params",
      "api_key",
      "api_base",
      "timeout",
      "litellm_params"
    ],
    "aembedding": [
      "self",
      "model",
      "input",
      "model_response",
      "print_verbose",
      "logging_obj",
      "optional_params",
      "api_key",
      "api_base",
      "timeout",
      "litellm_params"
    ],
    "image_edit": [
      "self",
      "model",
      "image",
      "prompt",
      "model_response",
      "api_key",
      "api_base",
      "optional_params",
      "logging_obj",
      "timeout",
      "client"
    ],
    "aimage_edit": [
      "self",
      "model",
      "image",
      "prompt",
      "model_response",
      "api_key",
      "api_base",
      "optional_params",
      "logging_obj",
      "timeout",
      "client"
    ]
  },
  "custom_chat_llm_router": [
    "async_fn",
    "stream",
    "custom_llm"
  ],
  "MaritalkError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "MaritalkConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "presence_penalty",
      "top_p",
      "top_k",
      "temperature",
      "max_tokens",
      "n",
      "stop",
      "stream",
      "stream_options",
      "tools",
      "tool_choice"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "get_cost_for_web_search_request": [
    "custom_llm_provider",
    "usage",
    "model_info"
  ],
  "discover_guardrail_translation_mappings": [],
  "load_guardrail_translation_mappings": [],
  "get_guardrail_translation_mapping": [
    "call_type"
  ],
  "BaseLLM": {
    "process_response": [
      "self",
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "print_verbose",
      "encoding"
    ],
    "process_text_completion_response": [
      "self",
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "print_verbose",
      "encoding"
    ],
    "create_client_session": [
      "self"
    ],
    "create_aclient_session": [
      "self"
    ],
    "__exit__": [
      "self"
    ],
    "__aexit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "validate_environment": [
      "self"
    ],
    "completion": [
      "self"
    ],
    "embedding": [
      "self"
    ]
  },
  "CerebrasConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "response_format",
      "seed",
      "stop",
      "stream",
      "temperature",
      "top_p",
      "tool_choice",
      "tools",
      "user",
      "reasoning_effort"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "GRADIENT_AI_SERVERLESS_ENDPOINT": [],
  "GradientAIConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "max_tokens",
      "max_completion_tokens",
      "presence_penalty",
      "retrieval_method",
      "stop",
      "stream",
      "temperature",
      "top_p",
      "k",
      "kb_filters",
      "filter_kb_content_by_query_metadata",
      "instruction_override",
      "include_functions_info",
      "include_retrieval_info",
      "include_guardrails_info",
      "provide_citations"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "replace_max_completion_tokens_with_max_tokens"
    ]
  },
  "NscaleConfig": {
    "API_BASE_URL": [],
    "custom_llm_provider": [
      "self"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "models_without_dynamic_pricing": [],
  "cost_router": [
    "model",
    "custom_llm_provider",
    "call_type"
  ],
  "cost_per_character": [
    "model",
    "custom_llm_provider",
    "usage",
    "prompt_characters",
    "completion_characters"
  ],
  "_handle_128k_pricing": [
    "model_info",
    "usage"
  ],
  "VertexAIError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "TextStreamer": {
    "__init__": [
      "self",
      "text"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "_get_client_cache_key": [
    "model",
    "vertex_project",
    "vertex_location"
  ],
  "_get_client_from_cache": [
    "client_cache_key"
  ],
  "_set_client_in_cache": [
    "client_cache_key",
    "vertex_llm_model"
  ],
  "async_completion": [
    "llm_model",
    "mode",
    "prompt",
    "model",
    "messages",
    "model_response",
    "request_str",
    "print_verbose",
    "logging_obj",
    "encoding",
    "client_options",
    "instances",
    "vertex_project",
    "vertex_location",
    "vertex_credentials",
    "safety_settings"
  ],
  "async_streaming": [
    "llm_model",
    "mode",
    "prompt",
    "model",
    "model_response",
    "messages",
    "print_verbose",
    "logging_obj",
    "request_str",
    "encoding",
    "client_options",
    "instances",
    "vertex_project",
    "vertex_location",
    "vertex_credentials",
    "safety_settings"
  ],
  "VertexAIModelRoute": {
    "PARTNER_MODELS": [],
    "GEMINI": [],
    "GEMMA": [],
    "BGE": [],
    "MODEL_GARDEN": [],
    "NON_GEMINI": [],
    "OPENAI_COMPATIBLE": [],
    "AGENT_ENGINE": []
  },
  "VERTEX_AI_MODEL_ROUTES": [],
  "get_vertex_ai_model_route": [
    "model",
    "litellm_params"
  ],
  "get_supports_system_message": [
    "model",
    "custom_llm_provider"
  ],
  "get_supports_response_schema": [
    "model",
    "custom_llm_provider"
  ],
  "supports_response_json_schema": [
    "model"
  ],
  "all_gemini_url_modes": [],
  "get_vertex_base_model_name": [
    "model"
  ],
  "_get_embedding_url": [
    "model",
    "vertex_project",
    "vertex_location",
    "vertex_api_version"
  ],
  "_get_vertex_url": [
    "mode",
    "model",
    "stream",
    "vertex_project",
    "vertex_location",
    "vertex_api_version"
  ],
  "_get_gemini_url": [
    "mode",
    "model",
    "stream",
    "gemini_api_key"
  ],
  "_check_text_in_content": [
    "parts"
  ],
  "_fix_enum_empty_strings": [
    "schema",
    "depth"
  ],
  "_fix_enum_types": [
    "schema",
    "depth"
  ],
  "_build_vertex_schema": [
    "parameters",
    "add_property_ordering"
  ],
  "_build_json_schema": [
    "parameters"
  ],
  "_filter_anyof_fields": [
    "schema_dict"
  ],
  "process_items": [
    "schema",
    "depth"
  ],
  "set_schema_property_ordering": [
    "schema",
    "depth"
  ],
  "filter_schema_fields": [
    "schema_dict",
    "valid_fields",
    "processed"
  ],
  "convert_anyof_null_to_nullable": [
    "schema",
    "depth"
  ],
  "add_object_type": [
    "schema"
  ],
  "strip_field": [
    "schema",
    "field_name"
  ],
  "_convert_vertex_datetime_to_openai_datetime": [
    "vertex_datetime"
  ],
  "_convert_schema_types": [
    "schema",
    "depth"
  ],
  "get_vertex_project_id_from_url": [
    "url"
  ],
  "get_vertex_location_from_url": [
    "url"
  ],
  "get_vertex_model_id_from_url": [
    "url"
  ],
  "replace_project_and_location_in_route": [
    "requested_route",
    "vertex_project",
    "vertex_location"
  ],
  "construct_target_url": [
    "base_url",
    "requested_route",
    "vertex_location",
    "vertex_project"
  ],
  "is_global_only_vertex_model": [
    "model"
  ],
  "VertexAIModelInfo": {
    "get_token_counter": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_base_model": [
      "model"
    ]
  },
  "VertexAITokenCounter": {
    "should_use_token_counting_api": [
      "self",
      "custom_llm_provider"
    ],
    "count_tokens": [
      "self",
      "model_to_use",
      "messages",
      "contents",
      "deployment",
      "request_model"
    ]
  },
  "GOOGLE_IMPORT_ERROR_MESSAGE": [],
  "VertexBase": {
    "__init__": [
      "self"
    ],
    "get_vertex_region": [
      "self",
      "vertex_region",
      "model"
    ],
    "load_auth": [
      "self",
      "credentials",
      "project_id"
    ],
    "_credentials_from_identity_pool": [
      "self",
      "json_obj",
      "scopes"
    ],
    "_credentials_from_identity_pool_with_aws": [
      "self",
      "json_obj",
      "scopes"
    ],
    "_credentials_from_authorized_user": [
      "self",
      "json_obj",
      "scopes"
    ],
    "_credentials_from_service_account": [
      "self",
      "json_obj",
      "scopes"
    ],
    "_credentials_from_default_auth": [
      "self",
      "scopes"
    ],
    "get_default_vertex_location": [
      "self"
    ],
    "get_api_base": [
      "self",
      "api_base",
      "vertex_location"
    ],
    "create_vertex_url": [
      "vertex_location",
      "vertex_project",
      "partner",
      "stream",
      "model",
      "api_base"
    ],
    "get_complete_vertex_url": [
      "self",
      "custom_api_base",
      "vertex_location",
      "vertex_project",
      "project_id",
      "partner",
      "stream",
      "model"
    ],
    "refresh_auth": [
      "self",
      "credentials"
    ],
    "_ensure_access_token": [
      "self",
      "credentials",
      "project_id",
      "custom_llm_provider"
    ],
    "is_using_v1beta1_features": [
      "self",
      "optional_params"
    ],
    "_check_custom_proxy": [
      "self",
      "api_base",
      "custom_llm_provider",
      "gemini_api_key",
      "endpoint",
      "stream",
      "auth_header",
      "url",
      "model",
      "vertex_project",
      "vertex_location",
      "vertex_api_version",
      "use_psc_endpoint_format"
    ],
    "_get_token_and_url": [
      "self",
      "model",
      "auth_header",
      "gemini_api_key",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "stream",
      "custom_llm_provider",
      "api_base",
      "should_use_v1beta1_features",
      "mode",
      "use_psc_endpoint_format"
    ],
    "_handle_reauthentication": [
      "self",
      "credentials",
      "project_id",
      "credential_cache_key",
      "error"
    ],
    "get_access_token": [
      "self",
      "credentials",
      "project_id",
      "_retry_reauth"
    ],
    "_ensure_access_token_async": [
      "self",
      "credentials",
      "project_id",
      "custom_llm_provider"
    ],
    "set_headers": [
      "self",
      "auth_header",
      "extra_headers"
    ],
    "get_vertex_ai_project": [
      "litellm_params"
    ],
    "get_vertex_ai_credentials": [
      "litellm_params"
    ],
    "get_vertex_ai_location": [
      "litellm_params"
    ],
    "safe_get_vertex_ai_project": [
      "litellm_params"
    ],
    "safe_get_vertex_ai_credentials": [
      "litellm_params"
    ],
    "safe_get_vertex_ai_location": [
      "litellm_params"
    ]
  },
  "VertexAIBatchTransformation": {
    "transform_openai_batch_request_to_vertex_ai_batch_request": [
      "cls",
      "request"
    ],
    "transform_vertex_ai_batch_response_to_openai_batch_response": [
      "cls",
      "response"
    ],
    "transform_vertex_ai_batch_list_response_to_openai_list_response": [
      "cls",
      "response"
    ],
    "_get_batch_id_from_vertex_ai_batch_response": [
      "cls",
      "response"
    ],
    "_get_input_file_id_from_vertex_ai_batch_response": [
      "cls",
      "response"
    ],
    "_get_output_file_id_from_vertex_ai_batch_response": [
      "cls",
      "response"
    ],
    "_get_batch_job_status_from_vertex_ai_batch_response": [
      "cls",
      "response"
    ],
    "_get_gcs_uri_prefix_from_file": [
      "cls",
      "input_file_id"
    ],
    "_get_model_from_gcs_file": [
      "cls",
      "gcs_file_uri"
    ]
  },
  "VertexAIBatchPrediction": {
    "__init__": [
      "self",
      "gcs_bucket_name"
    ],
    "create_batch": [
      "self",
      "_is_async",
      "create_batch_data",
      "api_base",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries"
    ],
    "_async_create_batch": [
      "self",
      "vertex_batch_request",
      "api_base",
      "headers"
    ],
    "create_vertex_batch_url": [
      "self",
      "vertex_location",
      "vertex_project"
    ],
    "retrieve_batch": [
      "self",
      "_is_async",
      "batch_id",
      "api_base",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries",
      "logging_obj"
    ],
    "_async_retrieve_batch": [
      "self",
      "api_base",
      "headers",
      "logging_obj"
    ],
    "list_batches": [
      "self",
      "_is_async",
      "after",
      "limit",
      "api_base",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries"
    ],
    "_async_list_batches": [
      "self",
      "api_base",
      "headers",
      "params"
    ]
  },
  "cost_per_web_search_request": [
    "usage",
    "model_info"
  ],
  "VertexAIBaseConfig": {
    "get_mapped_special_auth_params": [
      "self"
    ],
    "map_special_auth_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "get_eu_regions": [
      "self"
    ],
    "get_us_regions": [
      "self"
    ]
  },
  "VertexGeminiConfig": {
    "__init__": [
      "self",
      "temperature",
      "max_output_tokens",
      "top_p",
      "top_k",
      "response_mime_type",
      "candidate_count",
      "stop_sequences",
      "frequency_penalty",
      "presence_penalty",
      "seed"
    ],
    "get_config": [
      "cls"
    ],
    "_is_gemini_3_or_newer": [
      "model"
    ],
    "_supports_penalty_parameters": [
      "self",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_tool_choice_values": [
      "self",
      "model",
      "tool_choice"
    ],
    "_map_web_search_options": [
      "self",
      "value"
    ],
    "_transform_computer_use_config": [
      "self",
      "computer_use_config"
    ],
    "_extract_google_maps_retrieval_config": [
      "self",
      "google_maps_config"
    ],
    "get_tool_value": [
      "self",
      "tool",
      "tool_name"
    ],
    "_map_function": [
      "self",
      "value",
      "optional_params"
    ],
    "_map_response_schema": [
      "self",
      "value"
    ],
    "apply_response_schema_transformation": [
      "self",
      "value",
      "optional_params",
      "model"
    ],
    "_map_reasoning_effort_to_thinking_budget": [
      "reasoning_effort",
      "model"
    ],
    "_map_reasoning_effort_to_thinking_level": [
      "reasoning_effort",
      "model"
    ],
    "_is_thinking_budget_zero": [
      "thinking_budget"
    ],
    "_validate_thinking_config_conflicts": [
      "optional_params",
      "param_name",
      "param_description"
    ],
    "_validate_thinking_level_conflicts": [
      "optional_params"
    ],
    "_map_thinking_param": [
      "thinking_param",
      "model"
    ],
    "map_response_modalities": [
      "self",
      "value"
    ],
    "validate_parallel_tool_calls": [
      "self",
      "value",
      "non_default_params"
    ],
    "_map_audio_params": [
      "self",
      "value"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_mapped_special_auth_params": [
      "self"
    ],
    "map_special_auth_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "get_eu_regions": [
      "self"
    ],
    "get_model_for_vertex_ai_url": [
      "model"
    ],
    "_is_model_gemini_spec_model": [
      "model"
    ],
    "_get_model_name_from_gemini_spec_model": [
      "model"
    ],
    "get_flagged_finish_reasons": [
      "self"
    ],
    "get_finish_reason_mapping": [],
    "translate_exception_str": [
      "self",
      "exception_string"
    ],
    "get_assistant_content_message": [
      "self",
      "parts"
    ],
    "_extract_thinking_blocks_from_parts": [
      "self",
      "parts"
    ],
    "_extract_thought_signatures_from_parts": [
      "self",
      "parts"
    ],
    "_extract_image_response_from_parts": [
      "self",
      "parts"
    ],
    "_extract_audio_response_from_parts": [
      "self",
      "parts"
    ],
    "_transform_parts": [
      "parts",
      "cumulative_tool_call_idx",
      "is_function_call"
    ],
    "_transform_logprobs": [
      "logprobs_result"
    ],
    "_handle_blocked_response": [
      "self",
      "model_response",
      "completion_response"
    ],
    "_handle_content_policy_violation": [
      "self",
      "model_response",
      "completion_response"
    ],
    "is_candidate_token_count_inclusive": [
      "usage_metadata"
    ],
    "_calculate_usage": [
      "completion_response"
    ],
    "_check_finish_reason": [
      "chat_completion_message",
      "finish_reason"
    ],
    "_check_prompt_level_content_filter": [
      "processed_chunk",
      "response_id"
    ],
    "_calculate_web_search_requests": [
      "grounding_metadata"
    ],
    "_create_streaming_choice": [
      "chat_completion_message",
      "candidate",
      "idx",
      "tools",
      "functions",
      "chat_completion_logprobs",
      "image_response"
    ],
    "_extract_candidate_metadata": [
      "candidate"
    ],
    "_convert_grounding_metadata_to_annotations": [
      "grounding_metadata",
      "content_text"
    ],
    "_process_candidates": [
      "_candidates",
      "model_response",
      "standard_optional_params",
      "cumulative_tool_call_index"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_transform_google_generate_content_to_openai_model_response": [
      "self",
      "completion_response",
      "model_response",
      "model",
      "logging_obj",
      "raw_response"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "make_call": [
    "client",
    "api_base",
    "headers",
    "data",
    "model",
    "messages",
    "logging_obj"
  ],
  "make_sync_call": [
    "client",
    "gemini_client",
    "api_base",
    "headers",
    "data",
    "model",
    "messages",
    "logging_obj"
  ],
  "VertexLLM": {
    "__init__": [
      "self"
    ],
    "async_streaming": [
      "self",
      "model",
      "custom_llm_provider",
      "messages",
      "model_response",
      "print_verbose",
      "data",
      "timeout",
      "encoding",
      "logging_obj",
      "stream",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "api_base",
      "client",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "gemini_api_key",
      "extra_headers"
    ],
    "async_completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "data",
      "custom_llm_provider",
      "timeout",
      "encoding",
      "logging_obj",
      "stream",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "api_base",
      "client",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "gemini_api_key",
      "extra_headers"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "custom_llm_provider",
      "encoding",
      "logging_obj",
      "optional_params",
      "acompletion",
      "timeout",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "gemini_api_key",
      "litellm_params",
      "logger_fn",
      "extra_headers",
      "client",
      "api_base"
    ]
  },
  "_convert_detail_to_media_resolution_enum": [
    "detail"
  ],
  "_apply_gemini_3_metadata": [
    "part",
    "model",
    "media_resolution_enum",
    "video_metadata"
  ],
  "_process_gemini_media": [
    "image_url",
    "format",
    "media_resolution_enum",
    "model",
    "video_metadata"
  ],
  "_snake_to_camel": [
    "snake_str"
  ],
  "_camel_to_snake": [
    "camel_str"
  ],
  "_get_equivalent_key": [
    "key",
    "available_keys"
  ],
  "check_if_part_exists_in_parts": [
    "parts",
    "part",
    "excluded_keys"
  ],
  "_gemini_convert_messages_with_history": [
    "messages",
    "model"
  ],
  "_pop_and_merge_extra_body": [
    "data",
    "optional_params"
  ],
  "_transform_request_body": [
    "messages",
    "model",
    "optional_params",
    "custom_llm_provider",
    "litellm_params",
    "cached_content"
  ],
  "sync_transform_request_body": [
    "gemini_api_key",
    "messages",
    "api_base",
    "model",
    "client",
    "timeout",
    "extra_headers",
    "optional_params",
    "logging_obj",
    "custom_llm_provider",
    "litellm_params",
    "vertex_project",
    "vertex_location",
    "vertex_auth_header"
  ],
  "async_transform_request_body": [
    "gemini_api_key",
    "messages",
    "api_base",
    "model",
    "client",
    "timeout",
    "extra_headers",
    "optional_params",
    "logging_obj",
    "custom_llm_provider",
    "litellm_params",
    "vertex_project",
    "vertex_location",
    "vertex_auth_header"
  ],
  "_default_user_message_when_system_message_passed": [],
  "_transform_system_message": [
    "supports_system_message",
    "messages"
  ],
  "VertexGemmaConfig": {
    "__init__": [
      "self"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "_handle_fake_stream_response": [
      "self",
      "model_response",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_unwrap_predictions_response": [
      "self",
      "response_json"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "api_key",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "logging_obj",
      "optional_params",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "client",
      "timeout",
      "encoding",
      "custom_llm_provider"
    ],
    "_sync_completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "api_key",
      "model_response",
      "print_verbose",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "encoding"
    ],
    "_async_completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "api_key",
      "model_response",
      "print_verbose",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "encoding"
    ]
  },
  "VertexAIGemmaModels": {
    "__init__": [
      "self"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "api_base",
      "optional_params",
      "custom_prompt_dict",
      "headers",
      "timeout",
      "litellm_params",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "logger_fn",
      "acompletion",
      "client"
    ]
  },
  "VertexAgentEngineError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "VertexAgentEngineConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_parse_model_string": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_get_auth_headers": [
      "self",
      "optional_params",
      "litellm_params"
    ],
    "_get_user_id": [
      "self",
      "optional_params"
    ],
    "_get_session_id": [
      "self",
      "optional_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_extract_text_from_response": [
      "self",
      "response_data"
    ],
    "_calculate_usage": [
      "self",
      "model",
      "messages",
      "content"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_streaming_response": [
      "self",
      "model",
      "raw_response"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ]
  },
  "VertexAgentEngineResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "VertexVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "VertexSearchAPIVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ],
    "calculate_vector_store_cost": [
      "self",
      "response"
    ]
  },
  "transform_openai_input_gemini_content": [
    "input",
    "model",
    "optional_params"
  ],
  "process_response": [
    "input",
    "model_response",
    "model",
    "_predictions"
  ],
  "GoogleBatchEmbeddings": {
    "batch_embeddings": [
      "self",
      "model",
      "input",
      "print_verbose",
      "model_response",
      "custom_llm_provider",
      "optional_params",
      "logging_obj",
      "api_key",
      "api_base",
      "encoding",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "aembedding",
      "timeout",
      "client",
      "extra_headers"
    ],
    "async_batch_embeddings": [
      "self",
      "model",
      "api_base",
      "url",
      "data",
      "model_response",
      "input",
      "timeout",
      "headers",
      "client"
    ]
  },
  "vertex_multimodal_embedding_handler": [],
  "VertexMultimodalEmbedding": {
    "__init__": [
      "self"
    ],
    "multimodal_embedding": [
      "self",
      "model",
      "input",
      "print_verbose",
      "model_response",
      "custom_llm_provider",
      "optional_params",
      "litellm_params",
      "logging_obj",
      "api_key",
      "api_base",
      "headers",
      "encoding",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "aembedding",
      "timeout",
      "client"
    ],
    "async_multimodal_embedding": [
      "self",
      "model",
      "api_base",
      "optional_params",
      "litellm_params",
      "data",
      "model_response",
      "timeout",
      "logging_obj",
      "headers",
      "client",
      "api_key"
    ]
  },
  "VertexAIMultimodalEmbeddingConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_is_gcs_uri": [
      "self",
      "input_str"
    ],
    "_is_video": [
      "self",
      "input_str"
    ],
    "_is_media_input": [
      "self",
      "input_str"
    ],
    "_create_image_instance": [
      "self",
      "input_str"
    ],
    "_create_video_instance": [
      "self",
      "input_str"
    ],
    "_process_input_element": [
      "self",
      "input_element"
    ],
    "_try_merge_text_with_media": [
      "self",
      "text_str",
      "next_elem"
    ],
    "process_openai_embedding_input": [
      "self",
      "_input"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "calculate_usage": [
      "self",
      "request_data",
      "vertex_predictions"
    ],
    "transform_embedding_response_to_openai": [
      "self",
      "predictions"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "_convert_image_to_vertex_format": [
    "image_file"
  ],
  "VertexAIVideoConfig": {
    "__init__": [
      "self"
    ],
    "extract_model_from_operation_name": [
      "operation_name"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "video_create_optional_params",
      "model",
      "drop_params"
    ],
    "_convert_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_video_create_request": [
      "self",
      "model",
      "prompt",
      "api_base",
      "video_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_video_create_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "custom_llm_provider",
      "request_data"
    ],
    "transform_video_status_retrieve_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_status_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_content_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_remix_request": [
      "self",
      "video_id",
      "prompt",
      "api_base",
      "litellm_params",
      "headers",
      "extra_body"
    ],
    "transform_video_remix_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_video_list_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_delete_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "VertexBGEConfig": {
    "is_bge_model": [
      "model"
    ],
    "transform_request": [
      "input",
      "optional_params",
      "model"
    ],
    "_create_embedding_input": [
      "prompt",
      "task_type",
      "title"
    ],
    "transform_response": [
      "response",
      "model",
      "model_response"
    ]
  },
  "TaskType": {
    "RETRIEVAL_QUERY": [],
    "RETRIEVAL_DOCUMENT": [],
    "SEMANTIC_SIMILARITY": [],
    "CLASSIFICATION": [],
    "CLUSTERING": [],
    "QUESTION_ANSWERING": [],
    "FACT_VERIFICATION": [],
    "CODE_RETRIEVAL_QUERY": []
  },
  "TextEmbeddingInput": {},
  "TextEmbeddingBGEInput": {},
  "TextEmbeddingFineTunedInput": {},
  "TextEmbeddingFineTunedParameters": {},
  "EmbeddingParameters": {},
  "VertexEmbeddingRequest": {},
  "VertexEmbedding": {
    "__init__": [
      "self"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "print_verbose",
      "model_response",
      "optional_params",
      "logging_obj",
      "custom_llm_provider",
      "timeout",
      "api_key",
      "encoding",
      "aembedding",
      "api_base",
      "client",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "gemini_api_key",
      "extra_headers"
    ],
    "async_embedding": [
      "self",
      "model",
      "input",
      "model_response",
      "logging_obj",
      "optional_params",
      "custom_llm_provider",
      "timeout",
      "api_base",
      "client",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "gemini_api_key",
      "extra_headers",
      "encoding"
    ]
  },
  "VertexAITextEmbeddingConfig": {
    "__init__": [
      "self",
      "auto_truncate",
      "task_type",
      "title"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "kwargs"
    ],
    "get_mapped_special_auth_params": [
      "self"
    ],
    "map_special_auth_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "transform_openai_request_to_vertex_embedding_request": [
      "self",
      "input",
      "optional_params",
      "model"
    ],
    "_transform_openai_request_to_fine_tuned_embedding_request": [
      "self",
      "input",
      "optional_params",
      "model"
    ],
    "create_embedding_input": [
      "self",
      "content",
      "task_type",
      "title"
    ],
    "transform_vertex_response_to_openai": [
      "self",
      "response",
      "model",
      "model_response"
    ],
    "_transform_vertex_response_to_openai_for_fine_tuned_models": [
      "self",
      "response",
      "model",
      "model_response"
    ]
  },
  "VertexAIRAGTransformation": {
    "__init__": [
      "self"
    ],
    "get_import_rag_files_url": [
      "self",
      "vertex_project",
      "vertex_location",
      "corpus_id"
    ],
    "get_retrieve_contexts_url": [
      "self",
      "vertex_project",
      "vertex_location"
    ],
    "transform_chunking_strategy_to_vertex_format": [
      "self",
      "chunking_strategy"
    ],
    "build_import_rag_files_request": [
      "self",
      "gcs_uri",
      "chunking_strategy"
    ],
    "get_auth_headers": [
      "self",
      "vertex_credentials",
      "vertex_project"
    ]
  },
  "cost_calculator": [
    "model",
    "image_response"
  ],
  "VertexAIGeminiImageGenerationConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_resolve_vertex_project": [
      "self"
    ],
    "_resolve_vertex_location": [
      "self"
    ],
    "_resolve_vertex_credentials": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_transform_image_usage": [
      "self",
      "usage"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "VertexImageGeneration": {
    "process_image_generation_response": [
      "self",
      "json_response",
      "model_response",
      "model"
    ],
    "transform_optional_params": [
      "self",
      "optional_params"
    ],
    "image_generation": [
      "self",
      "prompt",
      "api_base",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "model_response",
      "logging_obj",
      "model",
      "client",
      "optional_params",
      "timeout",
      "aimg_generation",
      "extra_headers"
    ],
    "aimage_generation": [
      "self",
      "prompt",
      "api_base",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "model_response",
      "logging_obj",
      "model",
      "client",
      "optional_params",
      "timeout",
      "extra_headers"
    ],
    "is_image_generation_response": [
      "self",
      "json_response"
    ]
  },
  "VertexAIImagenImageGenerationConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_resolve_vertex_project": [
      "self"
    ],
    "_resolve_vertex_location": [
      "self"
    ],
    "_resolve_vertex_credentials": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "get_vertex_ai_image_generation_config": [
    "model"
  ],
  "VertexAIDeepSeekOCRConfig": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params",
      "litellm_params"
    ],
    "transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "async_transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "async_transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "VertexAIOCRConfig": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params",
      "litellm_params"
    ],
    "_convert_url_to_data_uri_sync": [
      "self",
      "url"
    ],
    "_convert_url_to_data_uri_async": [
      "self",
      "url"
    ],
    "transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "async_transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ]
  },
  "get_vertex_ai_ocr_config": [
    "model"
  ],
  "VertexAIFilesConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_get_content_from_openai_file": [
      "self",
      "openai_file_content"
    ],
    "_get_gcs_object_name_from_batch_jsonl": [
      "self",
      "openai_jsonl_content"
    ],
    "get_object_name": [
      "self",
      "extracted_file_data",
      "purpose"
    ],
    "get_complete_file_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "data"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_openai_to_vertex_params": [
      "self",
      "openai_request_body"
    ],
    "_transform_openai_jsonl_content_to_vertex_ai_jsonl_content": [
      "self",
      "openai_jsonl_content"
    ],
    "transform_create_file_request": [
      "self",
      "model",
      "create_file_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_file_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_retrieve_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_delete_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_delete_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_list_files_request": [
      "self",
      "purpose",
      "optional_params",
      "litellm_params"
    ],
    "transform_list_files_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_file_content_request": [
      "self",
      "file_content_request",
      "optional_params",
      "litellm_params"
    ],
    "transform_file_content_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ]
  },
  "VertexAIJsonlFilesTransformation": {
    "transform_openai_file_content_to_vertex_ai_file_content": [
      "self",
      "openai_file_content"
    ],
    "_transform_openai_jsonl_content_to_vertex_ai_jsonl_content": [
      "self",
      "openai_jsonl_content"
    ],
    "_get_gcs_object_name": [
      "self",
      "openai_jsonl_content"
    ],
    "_map_openai_to_vertex_params": [
      "self",
      "openai_request_body"
    ],
    "_get_content_from_openai_file": [
      "self",
      "openai_file_content"
    ],
    "transform_gcs_bucket_response_to_openai_file_object": [
      "self",
      "create_file_data",
      "gcs_upload_response"
    ]
  },
  "vertex_ai_files_transformation": [],
  "VertexAIFilesHandler": {
    "__init__": [
      "self"
    ],
    "async_create_file": [
      "self",
      "create_file_data",
      "api_base",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries"
    ],
    "create_file": [
      "self",
      "_is_async",
      "create_file_data",
      "api_base",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries"
    ],
    "_extract_bucket_and_object_from_file_id": [
      "self",
      "file_id"
    ],
    "afile_content": [
      "self",
      "file_content_request",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries"
    ],
    "file_content": [
      "self",
      "_is_async",
      "file_content_request",
      "api_base",
      "vertex_credentials",
      "vertex_project",
      "vertex_location",
      "timeout",
      "max_retries"
    ]
  },
  "VertexFineTuningAPI": {
    "__init__": [
      "self"
    ],
    "convert_response_created_at": [
      "self",
      "response"
    ],
    "convert_openai_request_to_vertex": [
      "self",
      "create_fine_tuning_job_data",
      "original_hyperparameters",
      "kwargs"
    ],
    "_transform_openai_hyperparameters_to_vertex_hyperparameters": [
      "self",
      "create_fine_tuning_job_data",
      "original_hyperparameters",
      "kwargs"
    ],
    "convert_vertex_response_to_open_ai_response": [
      "self",
      "response"
    ],
    "_translate_vertex_response_hyperparameters": [
      "self",
      "vertex_hyper_parameters"
    ],
    "acreate_fine_tuning_job": [
      "self",
      "fine_tuning_url",
      "headers",
      "request_data"
    ],
    "create_fine_tuning_job": [
      "self",
      "_is_async",
      "create_fine_tuning_job_data",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "api_base",
      "timeout",
      "kwargs",
      "original_hyperparameters"
    ],
    "pass_through_vertex_ai_POST_request": [
      "self",
      "request_data",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "request_route"
    ]
  },
  "VertexAIRerankConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ]
  },
  "PartnerModelPrefixes": {
    "META_PREFIX": [],
    "DEEPSEEK_PREFIX": [],
    "MISTRAL_PREFIX": [],
    "CODERESTAL_PREFIX": [],
    "JAMBA_PREFIX": [],
    "CLAUDE_PREFIX": [],
    "QWEN_PREFIX": [],
    "GPT_OSS_PREFIX": [],
    "MINIMAX_PREFIX": [],
    "MOONSHOT_PREFIX": [],
    "ZAI_PREFIX": []
  },
  "VertexAIPartnerModels": {
    "__init__": [
      "self"
    ],
    "is_vertex_partner_model": [
      "model"
    ],
    "should_use_openai_handler": [
      "model"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "api_base",
      "optional_params",
      "custom_prompt_dict",
      "headers",
      "timeout",
      "litellm_params",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "logger_fn",
      "acompletion",
      "client"
    ],
    "count_tokens": [
      "self",
      "model",
      "messages",
      "litellm_params",
      "vertex_project",
      "vertex_location",
      "vertex_credentials"
    ]
  },
  "get_vertex_ai_partner_model_config": [
    "model",
    "vertex_publisher_or_api_spec"
  ],
  "VertexAIAnthropicConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_add_context_management_beta_headers": [
      "self",
      "beta_set",
      "context_management"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "is_supported_model": [
      "cls",
      "model",
      "custom_llm_provider"
    ]
  },
  "VertexAIPartnerModelsAnthropicMessagesConfig": {
    "validate_anthropic_messages_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_anthropic_messages_request": [
      "self",
      "model",
      "messages",
      "anthropic_messages_optional_request_params",
      "litellm_params",
      "headers"
    ]
  },
  "VertexAIAi21Config": {
    "__init__": [
      "self",
      "max_tokens"
    ],
    "get_config": [
      "cls"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "VertexAIPartnerModelsTokenCounter": {
    "_get_publisher_for_model": [
      "self",
      "model"
    ],
    "_build_count_tokens_endpoint": [
      "self",
      "model",
      "project_id",
      "vertex_location",
      "api_base"
    ],
    "handle_count_tokens_request": [
      "self",
      "model",
      "request_data",
      "litellm_params"
    ]
  },
  "VertexAIGPTOSSTransformation": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "VertexAILlama3Config": {
    "__init__": [
      "self",
      "max_tokens"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "VertexAILlama3StreamingHandler": {
    "__init__": [
      "self"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "__next__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "VertexAIGeminiImageEditConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "_resolve_vertex_project": [
      "self"
    ],
    "_resolve_vertex_location": [
      "self"
    ],
    "_resolve_vertex_credentials": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_prepare_inline_image_parts": [
      "self",
      "image"
    ],
    "_read_all_bytes": [
      "self",
      "image"
    ]
  },
  "VertexAIImagenImageEditConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "_resolve_vertex_project": [
      "self"
    ],
    "_resolve_vertex_location": [
      "self"
    ],
    "_resolve_vertex_credentials": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_prepare_reference_images": [
      "self",
      "image",
      "image_edit_optional_request_params"
    ],
    "_read_all_bytes": [
      "self",
      "image",
      "depth",
      "max_depth"
    ]
  },
  "get_vertex_ai_image_edit_config": [
    "model"
  ],
  "VertexAIGoogleGenAIConfig": {
    "HEADER_NAME": [],
    "BEARER_PREFIX": [],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "api_key",
      "headers",
      "model",
      "litellm_params"
    ],
    "_camel_to_snake": [
      "self",
      "camel_str"
    ],
    "map_generate_content_optional_params": [
      "self",
      "generate_content_config_dict",
      "model"
    ],
    "transform_generate_content_request": [
      "self",
      "model",
      "contents",
      "tools",
      "generate_content_config_dict",
      "system_instruction"
    ]
  },
  "local_cache_obj": [],
  "MAX_PAGINATION_PAGES": [],
  "ContextCachingEndpoints": {
    "__init__": [
      "self"
    ],
    "_get_token_and_url_context_caching": [
      "self",
      "gemini_api_key",
      "custom_llm_provider",
      "api_base",
      "vertex_project",
      "vertex_location",
      "vertex_auth_header"
    ],
    "check_cache": [
      "self",
      "cache_key",
      "client",
      "headers",
      "api_key",
      "api_base",
      "logging_obj",
      "custom_llm_provider",
      "vertex_project",
      "vertex_location",
      "vertex_auth_header"
    ],
    "async_check_cache": [
      "self",
      "cache_key",
      "client",
      "headers",
      "api_key",
      "api_base",
      "logging_obj",
      "custom_llm_provider",
      "vertex_project",
      "vertex_location",
      "vertex_auth_header"
    ],
    "check_and_create_cache": [
      "self",
      "messages",
      "optional_params",
      "api_key",
      "api_base",
      "model",
      "client",
      "timeout",
      "logging_obj",
      "custom_llm_provider",
      "vertex_project",
      "vertex_location",
      "vertex_auth_header",
      "extra_headers",
      "cached_content"
    ],
    "async_check_and_create_cache": [
      "self",
      "messages",
      "optional_params",
      "api_key",
      "api_base",
      "model",
      "client",
      "timeout",
      "logging_obj",
      "custom_llm_provider",
      "vertex_project",
      "vertex_location",
      "vertex_auth_header",
      "extra_headers",
      "cached_content"
    ],
    "get_cache": [
      "self"
    ],
    "async_get_cache": [
      "self"
    ]
  },
  "get_first_continuous_block_idx": [
    "filtered_messages"
  ],
  "extract_ttl_from_cached_messages": [
    "messages"
  ],
  "_is_valid_ttl_format": [
    "ttl"
  ],
  "separate_cached_messages": [
    "messages"
  ],
  "transform_openai_messages_to_gemini_context_caching": [
    "model",
    "messages",
    "custom_llm_provider",
    "cache_key",
    "vertex_project",
    "vertex_location"
  ],
  "VertexInput": {},
  "VertexVoice": {},
  "VertexAudioConfig": {},
  "VertexTextToSpeechAPI": {
    "__init__": [
      "self"
    ],
    "audio_speech": [
      "self",
      "logging_obj",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "api_base",
      "timeout",
      "model",
      "input",
      "voice",
      "_is_async",
      "optional_params",
      "kwargs"
    ],
    "async_audio_speech": [
      "self",
      "logging_obj",
      "url",
      "headers",
      "request"
    ]
  },
  "validate_vertex_input": [
    "input_data",
    "kwargs",
    "optional_params"
  ],
  "VertexAITextToSpeechConfig": {
    "DEFAULT_LANGUAGE_CODE": [],
    "DEFAULT_VOICE_NAME": [],
    "DEFAULT_AUDIO_ENCODING": [],
    "DEFAULT_SPEAKING_RATE": [],
    "TTS_API_URL": [],
    "VOICE_MAPPINGS": [],
    "FORMAT_MAPPINGS": [],
    "__init__": [
      "self"
    ],
    "_map_voice_to_vertex_format": [
      "self",
      "voice"
    ],
    "dispatch_text_to_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params_dict",
      "logging_obj",
      "timeout",
      "extra_headers",
      "base_llm_http_handler",
      "aspeech",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "_validate_vertex_input": [
      "self",
      "input_data",
      "optional_params"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "create_vertex_url": [
    "vertex_location",
    "vertex_project",
    "stream",
    "model",
    "api_base"
  ],
  "VertexAIModelGardenModels": {
    "__init__": [
      "self"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "api_base",
      "optional_params",
      "custom_prompt_dict",
      "headers",
      "timeout",
      "litellm_params",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "logger_fn",
      "acompletion",
      "client"
    ]
  },
  "OllamaError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "_convert_image": [
    "image"
  ],
  "OllamaModelInfo": {
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_base_model": [
      "model"
    ]
  },
  "OllamaConfig": {
    "__init__": [
      "self",
      "mirostat",
      "mirostat_eta",
      "mirostat_tau",
      "num_ctx",
      "num_gqa",
      "num_gpu",
      "num_thread",
      "repeat_last_n",
      "repeat_penalty",
      "temperature",
      "seed",
      "stop",
      "tfs_z",
      "num_predict",
      "top_k",
      "top_p",
      "system",
      "template"
    ],
    "get_config": [
      "cls"
    ],
    "get_required_params": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_supports_function_calling": [
      "self",
      "ollama_model_info"
    ],
    "_get_max_tokens": [
      "self",
      "ollama_model_info"
    ],
    "get_api_key": [],
    "get_model_info": [
      "self",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "OllamaTextCompletionResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "_handle_string_chunk": [
      "self",
      "str_line"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "_prepare_ollama_embedding_payload": [
    "model",
    "prompts",
    "optional_params"
  ],
  "_process_ollama_embedding_response": [
    "response_json",
    "prompts",
    "model",
    "model_response",
    "logging_obj",
    "encoding"
  ],
  "ollama_aembeddings": [
    "api_base",
    "model",
    "prompts",
    "model_response",
    "optional_params",
    "logging_obj",
    "encoding"
  ],
  "ollama_embeddings": [
    "api_base",
    "model",
    "prompts",
    "optional_params",
    "model_response",
    "logging_obj",
    "encoding"
  ],
  "OllamaChatConfig": {
    "__init__": [
      "self",
      "mirostat",
      "mirostat_eta",
      "mirostat_tau",
      "num_ctx",
      "num_gqa",
      "num_thread",
      "repeat_last_n",
      "repeat_penalty",
      "temperature",
      "seed",
      "stop",
      "tfs_z",
      "num_predict",
      "top_k",
      "top_p",
      "system",
      "template"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "OllamaChatCompletionResponseIterator": {
    "_is_function_call_complete": [
      "self",
      "function_args"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "NovitaConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "GeminiError": {},
  "GeminiModelInfo": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "api_version": [
      "self"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_base_model": [
      "model"
    ],
    "process_model_name": [
      "self",
      "models"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_token_counter": [
      "self"
    ]
  },
  "encode_unserializable_types": [
    "data",
    "depth"
  ],
  "get_api_key_from_env": [],
  "GoogleAIStudioTokenCounter": {
    "should_use_token_counting_api": [
      "self",
      "custom_llm_provider"
    ],
    "count_tokens": [
      "self",
      "model_to_use",
      "messages",
      "contents",
      "deployment",
      "request_model"
    ]
  },
  "GoogleAIStudioInteractionsConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "api_version": [
      "self"
    ],
    "get_supported_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "agent",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "agent",
      "input",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "transform_streaming_response": [
      "self",
      "model",
      "parsed_chunk",
      "logging_obj"
    ],
    "transform_get_interaction_request": [
      "self",
      "interaction_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_interaction_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_interaction_request": [
      "self",
      "interaction_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_interaction_response": [
      "self",
      "raw_response",
      "logging_obj",
      "interaction_id"
    ],
    "transform_cancel_interaction_request": [
      "self",
      "interaction_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_interaction_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "GeminiVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "_convert_image_to_gemini_format": [
    "image_file"
  ],
  "GeminiVideoConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "video_create_optional_params",
      "model",
      "drop_params"
    ],
    "_convert_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_video_create_request": [
      "self",
      "model",
      "prompt",
      "api_base",
      "video_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_video_create_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "custom_llm_provider",
      "request_data"
    ],
    "transform_video_status_retrieve_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_status_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_content_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_remix_request": [
      "self",
      "video_id",
      "prompt",
      "api_base",
      "litellm_params",
      "headers",
      "extra_body"
    ],
    "transform_video_remix_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_video_list_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_delete_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "GeminiRealtimeConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "api_key"
    ],
    "map_model_turn_event": [
      "self",
      "model_turn"
    ],
    "map_generation_complete_event": [
      "self",
      "delta_type"
    ],
    "get_audio_mime_type": [
      "self",
      "input_audio_format"
    ],
    "map_automatic_turn_detection": [
      "self",
      "value"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "optional_params",
      "non_default_params"
    ],
    "transform_realtime_request": [
      "self",
      "message",
      "model",
      "session_configuration_request"
    ],
    "transform_session_created_event": [
      "self",
      "model",
      "logging_session_id",
      "session_configuration_request"
    ],
    "_is_new_content_delta": [
      "self",
      "previous_messages"
    ],
    "return_new_content_delta_events": [
      "self",
      "response_id",
      "output_item_id",
      "conversation_id",
      "delta_type",
      "session_configuration_request"
    ],
    "transform_content_delta_events": [
      "self",
      "message",
      "output_item_id",
      "response_id",
      "delta_type"
    ],
    "transform_content_done_event": [
      "self",
      "delta_chunks",
      "current_output_item_id",
      "current_response_id",
      "delta_type"
    ],
    "return_additional_content_done_events": [
      "self",
      "current_output_item_id",
      "current_response_id",
      "delta_done_event",
      "delta_type"
    ],
    "get_nested_value": [
      "obj",
      "path"
    ],
    "update_current_delta_chunks": [
      "self",
      "transformed_message",
      "current_delta_chunks"
    ],
    "update_current_item_chunks": [
      "self",
      "transformed_message",
      "current_item_chunks"
    ],
    "transform_response_done_event": [
      "self",
      "message",
      "current_response_id",
      "current_conversation_id",
      "output_items",
      "session_configuration_request"
    ],
    "handle_openai_modality_event": [
      "self",
      "openai_event",
      "json_message",
      "realtime_response_transform_input",
      "delta_type"
    ],
    "map_openai_event": [
      "self",
      "key",
      "value",
      "current_delta_type",
      "json_message"
    ],
    "transform_realtime_response": [
      "self",
      "message",
      "model",
      "logging_obj",
      "realtime_response_transform_input"
    ],
    "requires_session_configuration": [
      "self"
    ],
    "session_configuration_request": [
      "self",
      "model"
    ]
  },
  "GoogleImageGenConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_transform_image_usage": [
      "self",
      "usage_metadata"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "get_gemini_image_generation_config": [
    "model"
  ],
  "GoogleAIStudioFilesHandler": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_create_file_request": [
      "self",
      "model",
      "create_file_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_file_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_retrieve_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_delete_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_delete_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_list_files_request": [
      "self",
      "purpose",
      "optional_params",
      "litellm_params"
    ],
    "transform_list_files_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_file_content_request": [
      "self",
      "file_content_request",
      "optional_params",
      "litellm_params"
    ],
    "transform_file_content_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ]
  },
  "GeminiImageEditConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "use_multipart_form_data": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_prepare_inline_image_parts": [
      "self",
      "image"
    ],
    "_read_all_bytes": [
      "self",
      "image"
    ]
  },
  "get_gemini_image_edit_config": [
    "model"
  ],
  "GoogleGenAIConfig": {
    "XGOOGLE_API_KEY": [],
    "custom_llm_provider": [
      "self"
    ],
    "__init__": [
      "self"
    ],
    "get_supported_generate_content_optional_params": [
      "self",
      "model"
    ],
    "map_generate_content_optional_params": [
      "self",
      "generate_content_config_dict",
      "model"
    ],
    "validate_environment": [
      "self",
      "api_key",
      "headers",
      "model",
      "litellm_params"
    ],
    "_get_google_ai_studio_api_key": [
      "self",
      "litellm_params"
    ],
    "_get_common_auth_components": [
      "self",
      "litellm_params"
    ],
    "_build_final_headers_and_url": [
      "self",
      "model",
      "auth_header",
      "vertex_project",
      "vertex_location",
      "vertex_credentials",
      "stream",
      "api_base",
      "litellm_params"
    ],
    "sync_get_auth_token_and_url": [
      "self",
      "api_base",
      "model",
      "litellm_params",
      "stream"
    ],
    "get_auth_token_and_url": [
      "self",
      "api_base",
      "model",
      "litellm_params",
      "stream"
    ],
    "transform_generate_content_request": [
      "self",
      "model",
      "contents",
      "tools",
      "generate_content_config_dict",
      "system_instruction"
    ],
    "transform_generate_content_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "convert_citation_sources_to_citations": [
      "self",
      "response"
    ]
  },
  "GoogleAIStudioGeminiConfig": {
    "__init__": [
      "self",
      "temperature",
      "max_output_tokens",
      "top_p",
      "top_k",
      "response_mime_type",
      "response_schema",
      "candidate_count",
      "stop_sequences"
    ],
    "get_config": [
      "cls"
    ],
    "is_model_gemini_audio_model": [
      "self",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model"
    ]
  },
  "_response_stream_shape_cache": [],
  "SagemakerError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "AWSEventStreamDecoder": {
    "__init__": [
      "self",
      "model",
      "is_messages_api"
    ],
    "_chunk_parser_messages_api": [
      "self",
      "chunk_data"
    ],
    "_chunk_parser": [
      "self",
      "chunk_data"
    ],
    "iter_bytes": [
      "self",
      "iterator"
    ],
    "aiter_bytes": [
      "self",
      "iterator"
    ],
    "_parse_message_from_event": [
      "self",
      "event"
    ]
  },
  "get_response_stream_shape": [],
  "SagemakerEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_model_config": [
      "cls",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "SagemakerConfig": {
    "__init__": [
      "self",
      "max_new_tokens",
      "max_completion_tokens",
      "top_p",
      "temperature",
      "return_full_text"
    ],
    "get_config": [
      "cls"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_transform_prompt": [
      "self",
      "model",
      "messages",
      "custom_prompt_dict",
      "hf_model_name"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "async_transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "sagemaker_config": [],
  "SagemakerLLM": {
    "_load_credentials": [
      "self",
      "optional_params"
    ],
    "_prepare_request": [
      "self",
      "credentials",
      "model",
      "data",
      "messages",
      "litellm_params",
      "optional_params",
      "aws_region_name",
      "extra_headers"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "custom_prompt_dict",
      "hf_model_name",
      "logger_fn",
      "acompletion",
      "headers"
    ],
    "make_async_call": [
      "self",
      "api_base",
      "headers",
      "data",
      "logging_obj",
      "client"
    ],
    "async_streaming": [
      "self",
      "messages",
      "model",
      "custom_prompt_dict",
      "hf_model_name",
      "credentials",
      "aws_region_name",
      "optional_params",
      "encoding",
      "model_response",
      "model_id",
      "logging_obj",
      "litellm_params",
      "headers"
    ],
    "async_completion": [
      "self",
      "messages",
      "model",
      "custom_prompt_dict",
      "hf_model_name",
      "credentials",
      "aws_region_name",
      "encoding",
      "model_response",
      "optional_params",
      "logging_obj",
      "model_id",
      "headers",
      "litellm_params"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "optional_params",
      "custom_prompt_dict",
      "litellm_params",
      "logger_fn"
    ]
  },
  "SagemakerChatConfig": {
    "__init__": [
      "self"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ]
  },
  "SagemakerChatHandler": {
    "_load_credentials": [
      "self",
      "optional_params"
    ],
    "_prepare_request": [
      "self",
      "credentials",
      "model",
      "data",
      "optional_params",
      "aws_region_name",
      "extra_headers"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "custom_prompt_dict",
      "logger_fn",
      "acompletion",
      "headers",
      "client"
    ]
  },
  "FeatherlessAIConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format",
      "tool_choice",
      "tools"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "convert_messages_to_prompt": [
    "messages"
  ],
  "A2AConfig": {
    "resolve_agent_config_from_registry": [
      "model",
      "api_base",
      "api_key",
      "headers",
      "optional_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "_openai_message_to_a2a_message": [
      "self",
      "message"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "A2AModelResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode",
      "model"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "_get_finish_reason": [
      "self",
      "chunk"
    ]
  },
  "A2AGuardrailHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "process_output_streaming_response": [
      "self",
      "responses_so_far",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "_extract_texts_from_result": [
      "self",
      "result",
      "texts_to_check",
      "task_mappings"
    ],
    "_extract_texts_from_parts": [
      "self",
      "parts",
      "path",
      "texts_to_check",
      "task_mappings"
    ],
    "_apply_text_to_path": [
      "self",
      "result",
      "path",
      "part_idx",
      "text"
    ]
  },
  "LlamaAPIConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "HostedVLLMAudioTranscriptionError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "HostedVLLMAudioTranscriptionConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ]
  },
  "HostedVLLMEmbeddingError": {},
  "HostedVLLMEmbeddingConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "HostedVLLMRerankError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "HostedVLLMRerankConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "_transform_response": [
      "self",
      "response"
    ]
  },
  "HostedVLLMChatConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "_is_video_file": [
      "self",
      "content_item"
    ],
    "_convert_file_to_video_url": [
      "self",
      "content_item"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ]
  },
  "MANUS_API_BASE": [],
  "ManusResponsesAPIConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "_extract_agent_profile": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_response_api_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "ManusFilesConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_create_file_request": [
      "self",
      "model",
      "create_file_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_file_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_retrieve_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_delete_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_delete_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_list_files_request": [
      "self",
      "purpose",
      "optional_params",
      "litellm_params"
    ],
    "transform_list_files_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "_parse_file_dict": [
      "self",
      "file_dict"
    ],
    "transform_file_content_request": [
      "self",
      "file_content_request",
      "optional_params",
      "litellm_params"
    ],
    "transform_file_content_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ]
  },
  "XInferenceImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "get_xinference_image_generation_config": [
    "model"
  ],
  "_is_azure_model_router": [
    "model"
  ],
  "calculate_azure_model_router_flat_cost": [
    "model",
    "prompt_tokens"
  ],
  "AzureFoundryModelInfo": {
    "__init__": [
      "self",
      "model"
    ],
    "get_azure_ai_route": [
      "model"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "api_version": [
      "self",
      "api_version"
    ],
    "get_token_counter": [
      "self"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "strip_model_router_prefix": [
      "model"
    ],
    "get_base_model": [
      "model"
    ],
    "get_azure_ai_config_for_model": [
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "AzureAnthropicMessagesConfig": {
    "validate_anthropic_messages_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "AzureAnthropicConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "AzureAnthropicChatCompletion": {
    "__init__": [
      "self"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_llm_provider",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "timeout",
      "litellm_params",
      "acompletion",
      "logger_fn",
      "headers",
      "client"
    ]
  },
  "azure_ai_anthropic_count_tokens_handler": [],
  "AzureAIAnthropicTokenCounter": {
    "should_use_token_counting_api": [
      "self",
      "custom_llm_provider"
    ],
    "count_tokens": [
      "self",
      "model_to_use",
      "messages",
      "contents",
      "deployment",
      "request_model"
    ]
  },
  "AzureAIAnthropicCountTokensConfig": {
    "get_required_headers": [
      "self",
      "api_key",
      "litellm_params"
    ],
    "get_count_tokens_endpoint": [
      "self",
      "api_base"
    ]
  },
  "AzureAIAnthropicCountTokensHandler": {
    "handle_count_tokens_request": [
      "self",
      "model",
      "messages",
      "api_key",
      "api_base",
      "litellm_params",
      "timeout"
    ]
  },
  "AzureAIVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "AzureAICohereConfig": {
    "__init__": [
      "self"
    ],
    "_map_azure_model_group": [
      "self",
      "model"
    ],
    "_transform_request_image_embeddings": [
      "self",
      "input",
      "optional_params"
    ],
    "_transform_request": [
      "self",
      "input",
      "optional_params",
      "model"
    ],
    "_transform_response": [
      "self",
      "response"
    ]
  },
  "AzureAIEmbedding": {
    "_process_response": [
      "self",
      "image_embedding_responses",
      "text_embedding_responses",
      "image_embeddings_idx",
      "model_response",
      "input"
    ],
    "async_image_embedding": [
      "self",
      "model",
      "data",
      "timeout",
      "logging_obj",
      "model_response",
      "optional_params",
      "api_key",
      "api_base",
      "client"
    ],
    "image_embedding": [
      "self",
      "model",
      "data",
      "timeout",
      "logging_obj",
      "model_response",
      "optional_params",
      "api_key",
      "api_base",
      "client"
    ],
    "async_embedding": [
      "self",
      "model",
      "input",
      "timeout",
      "logging_obj",
      "model_response",
      "optional_params",
      "api_key",
      "api_base",
      "client"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "timeout",
      "logging_obj",
      "model_response",
      "optional_params",
      "api_key",
      "api_base",
      "client",
      "aembedding",
      "max_retries",
      "shared_session"
    ]
  },
  "AzureFoundryGPTImageGenerationConfig": {},
  "AzureFoundryDallE2ImageGenerationConfig": {},
  "AzureFoundryDallE3ImageGenerationConfig": {},
  "AzureFoundryFluxImageGenerationConfig": {
    "get_flux2_image_generation_url": [
      "api_base",
      "model",
      "api_version"
    ],
    "is_flux2_model": [
      "model"
    ]
  },
  "get_azure_ai_image_generation_config": [
    "model"
  ],
  "AzureModelRouterConfig": {
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "calculate_additional_costs": [
      "self",
      "model",
      "prompt_tokens",
      "completion_tokens"
    ]
  },
  "AzureAIOCRConfig": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params",
      "litellm_params"
    ],
    "_convert_url_to_data_uri_sync": [
      "self",
      "url"
    ],
    "_convert_url_to_data_uri_async": [
      "self",
      "url"
    ],
    "transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "async_transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ]
  },
  "get_azure_ai_ocr_config": [
    "model"
  ],
  "AzureDocumentIntelligenceOCRConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_ocr_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params",
      "litellm_params"
    ],
    "_extract_base64_from_data_uri": [
      "self",
      "data_uri"
    ],
    "transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "_extract_page_markdown": [
      "self",
      "page_data"
    ],
    "_convert_dimensions": [
      "self",
      "width",
      "height",
      "unit"
    ],
    "_check_timeout": [
      "start_time",
      "timeout_secs"
    ],
    "_get_retry_after": [
      "response"
    ],
    "_check_operation_status": [
      "response"
    ],
    "_poll_operation_sync": [
      "self",
      "operation_url",
      "headers",
      "timeout_secs"
    ],
    "_poll_operation_async": [
      "self",
      "operation_url",
      "headers",
      "timeout_secs"
    ],
    "transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "async_transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "AzureAIAgentsError": {},
  "AzureAIAgentsConfig": {
    "DEFAULT_API_VERSION": [],
    "MAX_POLL_ATTEMPTS": [],
    "POLL_INTERVAL_SECONDS": [],
    "__init__": [
      "self"
    ],
    "is_azure_ai_agents_route": [
      "model"
    ],
    "get_agent_id_from_model": [
      "model"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_api_version": [
      "self",
      "optional_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_get_agent_id": [
      "self",
      "model",
      "optional_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "completion": [
      "model",
      "messages",
      "api_base",
      "api_key",
      "model_response",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "acompletion",
      "stream",
      "headers"
    ]
  },
  "AzureAIAgentsHandler": {
    "__init__": [
      "self"
    ],
    "_build_thread_url": [
      "self",
      "api_base",
      "api_version"
    ],
    "_build_messages_url": [
      "self",
      "api_base",
      "thread_id",
      "api_version"
    ],
    "_build_runs_url": [
      "self",
      "api_base",
      "thread_id",
      "api_version"
    ],
    "_build_run_status_url": [
      "self",
      "api_base",
      "thread_id",
      "run_id",
      "api_version"
    ],
    "_build_list_messages_url": [
      "self",
      "api_base",
      "thread_id",
      "api_version"
    ],
    "_build_create_thread_and_run_url": [
      "self",
      "api_base",
      "api_version"
    ],
    "_extract_content_from_messages": [
      "self",
      "messages_data"
    ],
    "_build_model_response": [
      "self",
      "model",
      "content",
      "model_response",
      "thread_id",
      "messages"
    ],
    "_prepare_completion_params": [
      "self",
      "model",
      "api_base",
      "api_key",
      "optional_params",
      "headers"
    ],
    "_check_response": [
      "self",
      "response",
      "expected_codes",
      "error_msg"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "api_key",
      "model_response",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "client",
      "headers"
    ],
    "_execute_agent_flow_sync": [
      "self",
      "make_request",
      "api_base",
      "api_version",
      "agent_id",
      "thread_id",
      "messages",
      "optional_params"
    ],
    "acompletion": [
      "self",
      "model",
      "messages",
      "api_base",
      "api_key",
      "model_response",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "client",
      "headers"
    ],
    "_execute_agent_flow_async": [
      "self",
      "make_request",
      "api_base",
      "api_version",
      "agent_id",
      "thread_id",
      "messages",
      "optional_params"
    ],
    "acompletion_stream": [
      "self",
      "model",
      "messages",
      "api_base",
      "api_key",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "headers"
    ],
    "_process_sse_stream": [
      "self",
      "response",
      "model"
    ]
  },
  "azure_ai_agents_handler": [],
  "AzureAIRerankConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "_get_base_model": [
      "self",
      "azure_model_group"
    ]
  },
  "AzureFoundryFluxImageEditConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "AzureFoundryFlux2ImageEditConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "use_multipart_form_data": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "_convert_image_to_base64": [
      "self",
      "image"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "get_azure_ai_image_edit_config": [
    "model"
  ],
  "AzureFoundryErrorStrings": {
    "SET_EXTRA_PARAMETERS_TO_PASS_THROUGH": []
  },
  "AzureAIStudioConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_supports_stop_reason": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_should_use_api_key_header": [
      "self",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_required_params": [
      "self"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model"
    ],
    "_is_azure_openai_model": [
      "self",
      "model",
      "api_base"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "model",
      "api_base",
      "api_key",
      "custom_llm_provider"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "should_retry_llm_api_inside_llm_translation_on_http_error": [
      "self",
      "e",
      "litellm_params"
    ],
    "max_retry_on_unprocessable_entity_error": [
      "self"
    ],
    "transform_request_on_unprocessable_entity_error": [
      "self",
      "e",
      "request_data"
    ],
    "_drop_extra_params_from_request_data": [
      "self",
      "request_data",
      "error_text"
    ],
    "_extract_params_to_drop_from_error_text": [
      "self",
      "error_text"
    ]
  },
  "GIGACHAT_AUTH_URL": [],
  "GIGACHAT_SCOPE": [],
  "TOKEN_EXPIRY_BUFFER_MS": [],
  "_token_cache": [],
  "GigaChatAuthError": {},
  "_get_credentials": [],
  "_get_auth_url": [],
  "_get_scope": [],
  "_get_http_client": [],
  "get_access_token": [
    "credentials",
    "scope",
    "auth_url"
  ],
  "get_access_token_async": [
    "credentials",
    "scope",
    "auth_url"
  ],
  "_request_token_sync": [
    "credentials",
    "scope",
    "auth_url"
  ],
  "_request_token_async": [
    "credentials",
    "scope",
    "auth_url"
  ],
  "_parse_token_response": [
    "response"
  ],
  "GIGACHAT_BASE_URL": [],
  "_get_url_hash": [
    "url"
  ],
  "_parse_data_url": [
    "data_url"
  ],
  "_download_image_sync": [
    "url"
  ],
  "_download_image_async": [
    "url"
  ],
  "upload_file_sync": [
    "image_url",
    "credentials",
    "api_base"
  ],
  "upload_file_async": [
    "image_url",
    "credentials",
    "api_base"
  ],
  "GigaChatEmbeddingError": {},
  "GigaChatEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "is_valid_json": [
    "value"
  ],
  "GigaChatError": {},
  "GigaChatConfig": {
    "__init__": [
      "self",
      "temperature",
      "top_p",
      "max_tokens",
      "repetition_penalty",
      "profanity_check"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_convert_tools_to_functions": [
      "self",
      "tools"
    ],
    "_map_tool_choice": [
      "self",
      "tool_choice"
    ],
    "_upload_image": [
      "self",
      "image_url"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_transform_messages": [
      "self",
      "messages"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "GigaChatModelResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "CloudflareError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "CloudflareChatConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "stream"
    ],
    "get_config": [
      "cls"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "CloudflareChatResponseIterator": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "LangGraphError": {},
  "LangGraphConfig": {
    "__init__": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_get_assistant_id": [
      "self",
      "model",
      "optional_params"
    ],
    "_convert_messages_to_langgraph_format": [
      "self",
      "messages"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_extract_content_from_response": [
      "self",
      "response_json"
    ],
    "get_streaming_response": [
      "self",
      "model",
      "raw_response"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ]
  },
  "LangGraphSSEStreamIterator": {
    "__init__": [
      "self",
      "response",
      "model"
    ],
    "__iter__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "_parse_sse_line": [
      "self",
      "line"
    ],
    "_process_data": [
      "self",
      "data"
    ],
    "_process_messages_event": [
      "self",
      "payload"
    ],
    "_process_metadata_event": [
      "self",
      "payload"
    ],
    "_create_content_chunk": [
      "self",
      "text"
    ],
    "_create_final_chunk": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "get_base_model_for_pricing": [
    "model_name"
  ],
  "FireworksAIException": {},
  "FireworksAIMixin": {
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "_get_api_key": [
      "self",
      "api_key"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "FireworksAIEmbeddingConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model"
    ],
    "is_fireworks_embedding_model": [
      "self",
      "model"
    ]
  },
  "FireworksAITextCompletionConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_text_completion_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "headers"
    ]
  },
  "FireworksAIRerankConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ]
  },
  "FireworksAIAudioTranscriptionConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "FireworksAIConfig": {
    "__init__": [
      "self",
      "tools",
      "tool_choice",
      "max_tokens",
      "temperature",
      "top_p",
      "top_k",
      "frequency_penalty",
      "presence_penalty",
      "n",
      "stop",
      "response_format",
      "user",
      "logprobs",
      "reasoning_effort",
      "prompt_truncate_length",
      "context_length_exceeded_behavior"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_add_transform_inline_image_block": [
      "self",
      "content",
      "model",
      "disable_add_transform_inline_image_block"
    ],
    "_transform_tools": [
      "self",
      "tools"
    ],
    "_transform_messages_helper": [
      "self",
      "messages",
      "model",
      "litellm_params"
    ],
    "get_provider_info": [
      "self",
      "model"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_handle_message_content_with_tool_calls": [
      "self",
      "message",
      "tool_calls"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ]
  },
  "LiteLLMProxyResponsesAPIConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ]
  },
  "LiteLLMProxyImageGenerationConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "LiteLLMProxyImageEditConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "LiteLLMProxyChatConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "_should_use_litellm_proxy_by_default": [
      "litellm_params"
    ],
    "litellm_proxy_get_custom_llm_provider_info": [
      "model",
      "api_base",
      "api_key"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "async_transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "LiteLLMInternalTools": {
    "CODE_EXECUTION": []
  },
  "get_litellm_code_execution_tool": [],
  "get_litellm_code_execution_tool_anthropic": [],
  "LITELLM_CODE_EXECUTION_TOOL": [],
  "CodeExecutionHandler": {
    "__init__": [
      "self",
      "max_iterations",
      "sandbox_timeout"
    ],
    "execute_with_code_execution": [
      "self",
      "model",
      "messages",
      "tools",
      "skill_files",
      "skill_id"
    ]
  },
  "has_code_execution_tool": [
    "tools"
  ],
  "add_code_execution_tool": [
    "tools"
  ],
  "code_execution_handler": [],
  "LiteLLMSkillsTransformationHandler": {
    "custom_llm_provider": [
      "self"
    ],
    "create_skill_handler": [
      "self",
      "display_title",
      "description",
      "instructions",
      "files",
      "file_content",
      "file_name",
      "file_type",
      "metadata",
      "user_id",
      "_is_async",
      "logging_obj",
      "litellm_call_id"
    ],
    "_async_create_skill": [
      "self",
      "display_title",
      "description",
      "instructions",
      "file_content",
      "file_name",
      "file_type",
      "metadata",
      "user_id"
    ],
    "list_skills_handler": [
      "self",
      "limit",
      "offset",
      "_is_async",
      "logging_obj",
      "litellm_call_id"
    ],
    "_async_list_skills": [
      "self",
      "limit",
      "offset"
    ],
    "get_skill_handler": [
      "self",
      "skill_id",
      "_is_async",
      "logging_obj",
      "litellm_call_id"
    ],
    "_async_get_skill": [
      "self",
      "skill_id"
    ],
    "delete_skill_handler": [
      "self",
      "skill_id",
      "_is_async",
      "logging_obj",
      "litellm_call_id"
    ],
    "_async_delete_skill": [
      "self",
      "skill_id"
    ],
    "_db_skill_to_response": [
      "self",
      "db_skill"
    ]
  },
  "SkillPromptInjectionHandler": {
    "extract_skill_content": [
      "self",
      "skill"
    ],
    "extract_all_files": [
      "self",
      "skill"
    ],
    "inject_skill_content_to_messages": [
      "self",
      "data",
      "skill_contents",
      "use_anthropic_format"
    ],
    "create_execute_code_tool": [
      "self",
      "skill_modules"
    ],
    "convert_skill_to_tool": [
      "self",
      "skill"
    ],
    "convert_skill_to_anthropic_tool": [
      "self",
      "skill"
    ]
  },
  "_prisma_skill_to_litellm": [
    "prisma_skill"
  ],
  "LiteLLMSkillsHandler": {
    "_get_prisma_client": [],
    "create_skill": [
      "data",
      "user_id"
    ],
    "list_skills": [
      "limit",
      "offset"
    ],
    "get_skill": [
      "skill_id"
    ],
    "delete_skill": [
      "skill_id"
    ],
    "fetch_skill_from_db": [
      "skill_id"
    ]
  },
  "SkillsSandboxExecutor": {
    "__init__": [
      "self",
      "timeout",
      "backend",
      "image"
    ],
    "execute": [
      "self",
      "code",
      "skill_files",
      "requirements"
    ],
    "_collect_generated_files": [
      "self",
      "session",
      "original_files"
    ],
    "_get_mime_type": [
      "self",
      "filename"
    ]
  },
  "PGVectorStoreConfig": {
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ]
  },
  "get_cost_for_anthropic_web_search": [
    "model_info",
    "usage"
  ],
  "get_anthropic_config": [
    "url_route"
  ],
  "is_anthropic_oauth_key": [
    "value"
  ],
  "optionally_handle_anthropic_oauth": [
    "headers",
    "api_key"
  ],
  "AnthropicError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "AnthropicModelInfo": {
    "is_cache_control_set": [
      "self",
      "messages"
    ],
    "is_file_id_used": [
      "self",
      "messages"
    ],
    "is_mcp_server_used": [
      "self",
      "mcp_servers"
    ],
    "is_computer_tool_used": [
      "self",
      "tools"
    ],
    "is_web_search_tool_used": [
      "self",
      "tools"
    ],
    "is_pdf_used": [
      "self",
      "messages"
    ],
    "is_tool_search_used": [
      "self",
      "tools"
    ],
    "is_programmatic_tool_calling_used": [
      "self",
      "tools"
    ],
    "is_input_examples_used": [
      "self",
      "tools"
    ],
    "is_effort_used": [
      "self",
      "optional_params",
      "model"
    ],
    "is_code_execution_tool_used": [
      "self",
      "tools"
    ],
    "is_container_with_skills_used": [
      "self",
      "optional_params"
    ],
    "_get_user_anthropic_beta_headers": [
      "self",
      "anthropic_beta_header"
    ],
    "get_computer_tool_beta_header": [
      "self",
      "computer_tool_version"
    ],
    "get_anthropic_beta_list": [
      "self",
      "model",
      "optional_params",
      "computer_tool_used",
      "prompt_caching_set",
      "file_id_used",
      "mcp_server_used"
    ],
    "get_anthropic_headers": [
      "self",
      "api_key",
      "anthropic_version",
      "computer_tool_used",
      "prompt_caching_set",
      "pdf_used",
      "file_id_used",
      "mcp_server_used",
      "web_search_tool_used",
      "tool_search_used",
      "programmatic_tool_calling_used",
      "input_examples_used",
      "effort_used",
      "is_vertex_request",
      "user_anthropic_beta_headers",
      "code_execution_tool_used",
      "container_with_skills_used"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_base_model": [
      "model"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_token_counter": [
      "self"
    ]
  },
  "process_anthropic_headers": [
    "headers"
  ],
  "AnthropicBatchesConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_batch_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "data"
    ],
    "transform_create_batch_request": [
      "self",
      "model",
      "create_batch_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_batch_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "get_retrieve_batch_url": [
      "self",
      "api_base",
      "batch_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_batch_request": [
      "self",
      "batch_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_batch_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AnthropicBatchesHandler": {
    "__init__": [
      "self"
    ],
    "aretrieve_batch": [
      "self",
      "batch_id",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "logging_obj"
    ],
    "retrieve_batch": [
      "self",
      "_is_async",
      "batch_id",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "logging_obj"
    ]
  },
  "AnthropicMessagesRequestUtils": {
    "get_requested_anthropic_messages_optional_param": [
      "params"
    ]
  },
  "mock_response": [
    "model",
    "messages",
    "max_tokens",
    "mock_response"
  ],
  "FakeAnthropicMessagesStreamIterator": {
    "__init__": [
      "self",
      "response"
    ],
    "_create_streaming_chunks": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ]
  },
  "DEFAULT_ANTHROPIC_API_VERSION": [],
  "AnthropicMessagesConfig": {
    "get_supported_anthropic_messages_params": [
      "self",
      "model"
    ],
    "_filter_billing_headers_from_system": [
      "system_param"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_anthropic_messages_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_anthropic_messages_request": [
      "self",
      "model",
      "messages",
      "anthropic_messages_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_anthropic_messages_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_async_streaming_response_iterator": [
      "self",
      "model",
      "httpx_response",
      "request_body",
      "litellm_logging_obj"
    ],
    "_update_headers_with_anthropic_beta": [
      "headers",
      "optional_params",
      "custom_llm_provider"
    ]
  },
  "BaseAnthropicMessagesStreamingIterator": {
    "__init__": [
      "self",
      "litellm_logging_obj",
      "request_body"
    ],
    "_handle_streaming_logging": [
      "self",
      "collected_chunks"
    ],
    "get_async_streaming_response_iterator": [
      "self",
      "httpx_response",
      "request_body",
      "litellm_logging_obj"
    ],
    "_convert_chunk_to_sse_format": [
      "self",
      "chunk"
    ],
    "async_sse_wrapper": [
      "self",
      "completion_stream"
    ]
  },
  "_execute_pre_request_hooks": [
    "model",
    "messages",
    "tools",
    "stream",
    "custom_llm_provider"
  ],
  "anthropic_messages": [
    "max_tokens",
    "messages",
    "model",
    "metadata",
    "stop_sequences",
    "stream",
    "system",
    "temperature",
    "thinking",
    "tool_choice",
    "tools",
    "top_k",
    "top_p",
    "api_key",
    "api_base",
    "client",
    "custom_llm_provider"
  ],
  "validate_anthropic_api_metadata": [
    "metadata"
  ],
  "anthropic_messages_handler": [
    "max_tokens",
    "messages",
    "model",
    "metadata",
    "stop_sequences",
    "stream",
    "system",
    "temperature",
    "thinking",
    "tool_choice",
    "tools",
    "top_k",
    "top_p",
    "container",
    "api_key",
    "api_base",
    "client",
    "custom_llm_provider"
  ],
  "OPENAI_MAX_TOOL_NAME_LENGTH": [],
  "TOOL_NAME_HASH_LENGTH": [],
  "TOOL_NAME_PREFIX_LENGTH": [],
  "truncate_tool_name": [
    "name"
  ],
  "create_tool_name_mapping": [
    "tools"
  ],
  "AnthropicAdapter": {
    "__init__": [
      "self"
    ],
    "translate_completion_input_params": [
      "self",
      "kwargs"
    ],
    "translate_completion_input_params_with_tool_mapping": [
      "self",
      "kwargs"
    ],
    "translate_completion_output_params": [
      "self",
      "response",
      "tool_name_mapping"
    ],
    "translate_completion_output_params_streaming": [
      "self",
      "completion_stream",
      "model",
      "tool_name_mapping"
    ]
  },
  "LiteLLMAnthropicMessagesAdapter": {
    "__init__": [
      "self"
    ],
    "_extract_signature_from_tool_call": [
      "self",
      "tool_call"
    ],
    "_extract_signature_from_tool_use_content": [
      "self",
      "content"
    ],
    "_add_cache_control_if_applicable": [
      "self",
      "source",
      "target",
      "model"
    ],
    "translatable_anthropic_params": [
      "self"
    ],
    "_is_web_search_tool": [
      "self",
      "tool"
    ],
    "translate_anthropic_messages_to_openai": [
      "self",
      "messages",
      "model"
    ],
    "translate_anthropic_thinking_to_reasoning_effort": [
      "thinking"
    ],
    "is_anthropic_claude_model": [
      "model"
    ],
    "translate_thinking_for_model": [
      "thinking",
      "model"
    ],
    "translate_anthropic_tool_choice_to_openai": [
      "self",
      "tool_choice"
    ],
    "translate_anthropic_tools_to_openai": [
      "self",
      "tools",
      "model"
    ],
    "translate_anthropic_output_format_to_openai": [
      "self",
      "output_format"
    ],
    "_add_system_message_to_messages": [
      "self",
      "new_messages",
      "anthropic_message_request"
    ],
    "translate_anthropic_to_openai": [
      "self",
      "anthropic_message_request"
    ],
    "_translate_anthropic_image_to_openai": [
      "self",
      "image_source"
    ],
    "_translate_openai_content_to_anthropic": [
      "self",
      "choices",
      "tool_name_mapping"
    ],
    "_translate_openai_finish_reason_to_anthropic": [
      "self",
      "openai_finish_reason"
    ],
    "translate_openai_response_to_anthropic": [
      "self",
      "response",
      "tool_name_mapping"
    ],
    "_translate_streaming_openai_chunk_to_anthropic_content_block": [
      "self",
      "choices"
    ],
    "_translate_streaming_openai_chunk_to_anthropic": [
      "self",
      "choices"
    ],
    "translate_streaming_openai_response_to_anthropic": [
      "self",
      "response",
      "current_content_block_index"
    ]
  },
  "AnthropicStreamWrapper": {
    "__init__": [
      "self",
      "completion_stream",
      "model",
      "tool_name_mapping"
    ],
    "_create_initial_usage_delta": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "anthropic_sse_wrapper": [
      "self"
    ],
    "async_anthropic_sse_wrapper": [
      "self"
    ],
    "_increment_content_block_index": [
      "self"
    ],
    "_should_start_new_content_block": [
      "self",
      "chunk"
    ]
  },
  "ANTHROPIC_ADAPTER": [],
  "LiteLLMMessagesToCompletionTransformationHandler": {
    "_route_openai_thinking_to_responses_api_if_needed": [
      "completion_kwargs"
    ],
    "_prepare_completion_kwargs": [],
    "async_anthropic_messages_handler": [
      "max_tokens",
      "messages",
      "model",
      "metadata",
      "stop_sequences",
      "stream",
      "system",
      "temperature",
      "thinking",
      "tool_choice",
      "tools",
      "top_k",
      "top_p",
      "output_format"
    ],
    "anthropic_messages_handler": [
      "max_tokens",
      "messages",
      "model",
      "metadata",
      "stop_sequences",
      "stream",
      "system",
      "temperature",
      "thinking",
      "tool_choice",
      "tools",
      "top_k",
      "top_p",
      "output_format",
      "_is_async"
    ]
  },
  "anthropic_count_tokens_handler": [],
  "AnthropicTokenCounter": {
    "should_use_token_counting_api": [
      "self",
      "custom_llm_provider"
    ],
    "count_tokens": [
      "self",
      "model_to_use",
      "messages",
      "contents",
      "deployment",
      "request_model"
    ]
  },
  "AnthropicCountTokensConfig": {
    "get_anthropic_count_tokens_endpoint": [
      "self"
    ],
    "transform_request_to_count_tokens": [
      "self",
      "model",
      "messages"
    ],
    "get_required_headers": [
      "self",
      "api_key"
    ],
    "validate_request": [
      "self",
      "model",
      "messages"
    ]
  },
  "AnthropicCountTokensHandler": {
    "handle_count_tokens_request": [
      "self",
      "model",
      "messages",
      "api_key",
      "api_base",
      "timeout"
    ]
  },
  "AnthropicTextError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "AnthropicTextConfig": {
    "__init__": [
      "self",
      "max_tokens_to_sample",
      "stop_sequences",
      "temperature",
      "top_p",
      "top_k",
      "metadata"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "_is_anthropic_text_model": [
      "model"
    ],
    "_get_anthropic_text_prompt_from_messages": [
      "self",
      "messages",
      "model"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "AnthropicTextCompletionResponseIterator": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "ANTHROPIC_ERROR_STATUS_CODE_MAP": [],
  "AnthropicFilesHandler": {
    "__init__": [
      "self"
    ],
    "afile_content": [
      "self",
      "file_content_request",
      "api_base",
      "api_key",
      "timeout",
      "max_retries"
    ],
    "file_content": [
      "self",
      "_is_async",
      "file_content_request",
      "api_base",
      "api_key",
      "timeout",
      "max_retries"
    ],
    "_transform_anthropic_batch_results_to_openai_format": [
      "self",
      "anthropic_content"
    ],
    "_transform_anthropic_message_to_openai_format": [
      "self",
      "anthropic_message",
      "anthropic_config"
    ]
  },
  "AnthropicConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "stop_sequences",
      "temperature",
      "top_p",
      "top_k",
      "metadata",
      "system"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_max_tokens_for_model": [
      "model"
    ],
    "convert_tool_use_to_openai_format": [
      "anthropic_tool_content",
      "index"
    ],
    "_is_claude_4_6_model": [
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "filter_anthropic_output_schema": [
      "schema"
    ],
    "get_json_schema_from_pydantic_object": [
      "self",
      "response_format"
    ],
    "get_cache_control_headers": [
      "self"
    ],
    "_map_tool_choice": [
      "self",
      "tool_choice",
      "parallel_tool_use"
    ],
    "_map_tool_helper": [
      "self",
      "tool"
    ],
    "_map_openai_mcp_server_tool": [
      "self",
      "tool"
    ],
    "_map_tools": [
      "self",
      "tools"
    ],
    "_detect_tool_search_tools": [
      "self",
      "tools"
    ],
    "_separate_deferred_tools": [
      "self",
      "tools"
    ],
    "_expand_tool_references": [
      "self",
      "content",
      "deferred_tools"
    ],
    "_map_stop_sequences": [
      "self",
      "stop"
    ],
    "_map_reasoning_effort": [
      "reasoning_effort",
      "model"
    ],
    "_extract_json_schema_from_response_format": [
      "self",
      "value"
    ],
    "map_response_format_to_anthropic_output_format": [
      "self",
      "value"
    ],
    "map_response_format_to_anthropic_tool": [
      "self",
      "value",
      "optional_params",
      "is_thinking_enabled"
    ],
    "map_web_search_tool": [
      "self",
      "value"
    ],
    "map_openai_context_management_to_anthropic": [
      "context_management"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_create_json_tool_call_for_response_format": [
      "self",
      "json_schema"
    ],
    "translate_system_message": [
      "self",
      "messages"
    ],
    "add_code_execution_tool": [
      "self",
      "messages",
      "tools"
    ],
    "_ensure_beta_header": [
      "self",
      "headers",
      "beta_value"
    ],
    "_ensure_context_management_beta_header": [
      "self",
      "headers",
      "context_management"
    ],
    "update_headers_with_optional_anthropic_beta": [
      "self",
      "headers",
      "optional_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_transform_response_for_json_mode": [
      "self",
      "json_mode",
      "tool_calls"
    ],
    "extract_response_content": [
      "self",
      "completion_response"
    ],
    "calculate_usage": [
      "self",
      "usage_object",
      "reasoning_content",
      "completion_response",
      "speed"
    ],
    "transform_parsed_response": [
      "self",
      "completion_response",
      "raw_response",
      "model_response",
      "json_mode",
      "prefix_prompt",
      "speed"
    ],
    "get_prefix_prompt": [
      "self",
      "messages"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_convert_tool_response_to_message": [
      "tool_calls"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "_valid_user_id": [
    "user_id"
  ],
  "AnthropicChatCompletion": {
    "__init__": [
      "self"
    ],
    "acompletion_stream_function": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "timeout",
      "client",
      "encoding",
      "api_key",
      "logging_obj",
      "stream",
      "_is_function_call",
      "data",
      "json_mode",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers"
    ],
    "acompletion_function": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "timeout",
      "encoding",
      "api_key",
      "logging_obj",
      "stream",
      "_is_function_call",
      "data",
      "optional_params",
      "json_mode",
      "litellm_params",
      "provider_config",
      "logger_fn",
      "headers",
      "client"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_llm_provider",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "timeout",
      "litellm_params",
      "acompletion",
      "logger_fn",
      "headers",
      "client"
    ],
    "embedding": [
      "self"
    ]
  },
  "AnthropicMessagesHandler": {
    "__init__": [
      "self"
    ],
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "_extract_input_text_and_images": [
      "self",
      "message",
      "msg_idx",
      "texts_to_check",
      "images_to_check",
      "task_mappings"
    ],
    "_extract_input_tools": [
      "self",
      "tools",
      "tools_to_check"
    ],
    "_apply_guardrail_responses_to_input": [
      "self",
      "messages",
      "responses",
      "task_mappings"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "process_output_streaming_response": [
      "self",
      "responses_so_far",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "get_streaming_string_so_far": [
      "self",
      "responses_so_far"
    ],
    "_extract_text_from_sse": [
      "self",
      "sse_bytes"
    ],
    "_check_streaming_has_ended": [
      "self",
      "responses_so_far"
    ],
    "_has_text_content": [
      "self",
      "response"
    ],
    "_extract_output_text_and_images": [
      "self",
      "content_block",
      "content_idx",
      "texts_to_check",
      "images_to_check",
      "task_mappings",
      "tool_calls_to_check"
    ],
    "_apply_guardrail_responses_to_output": [
      "self",
      "response",
      "responses",
      "task_mappings"
    ]
  },
  "AnthropicSkillsConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "endpoint",
      "skill_id"
    ],
    "transform_create_skill_request": [
      "self",
      "create_request",
      "litellm_params",
      "headers"
    ],
    "transform_create_skill_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_skills_request": [
      "self",
      "list_params",
      "litellm_params",
      "headers"
    ],
    "transform_list_skills_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_skill_request": [
      "self",
      "skill_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_skill_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_skill_request": [
      "self",
      "skill_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_skill_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "AiohttpOpenAIChatConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "TokenBreakdown": {},
  "_extract_token_breakdown": [
    "usage"
  ],
  "_calculate_tiered_cost": [
    "tokens",
    "tiered_pricing",
    "cost_key",
    "fallback_cost_key"
  ],
  "_calculate_prompt_cost": [
    "breakdown",
    "model_info",
    "tiered_pricing"
  ],
  "_calculate_completion_cost": [
    "breakdown",
    "model_info",
    "tiered_pricing"
  ],
  "DashScopeChatConfig": {
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "AI21ChatConfig": {
    "__init__": [
      "self",
      "tools",
      "response_format",
      "max_tokens",
      "temperature",
      "top_p",
      "stop",
      "n",
      "stream",
      "seed",
      "tool_choice",
      "user"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "DataForSEOSearchConfig": {
    "DATAFORSEO_API_BASE": [],
    "ui_friendly_name": [],
    "get_http_method": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params",
      "api_key"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "BaseLLMHTTPHandler": {
    "_make_common_async_call": [
      "self",
      "async_httpx_client",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "litellm_params",
      "logging_obj",
      "stream",
      "signed_json_body"
    ],
    "_make_common_sync_call": [
      "self",
      "sync_httpx_client",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "litellm_params",
      "logging_obj",
      "stream",
      "signed_json_body"
    ],
    "async_completion": [
      "self",
      "custom_llm_provider",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "model",
      "model_response",
      "logging_obj",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "client",
      "json_mode",
      "signed_json_body",
      "shared_session"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_llm_provider",
      "model_response",
      "encoding",
      "logging_obj",
      "optional_params",
      "timeout",
      "litellm_params",
      "acompletion",
      "stream",
      "fake_stream",
      "api_key",
      "headers",
      "client",
      "provider_config",
      "shared_session"
    ],
    "make_sync_call": [
      "self",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "signed_json_body",
      "original_data",
      "model",
      "messages",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "timeout",
      "fake_stream",
      "client",
      "json_mode"
    ],
    "acompletion_stream_function": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_llm_provider",
      "headers",
      "provider_config",
      "timeout",
      "logging_obj",
      "data",
      "litellm_params",
      "optional_params",
      "fake_stream",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "make_async_call_stream_helper": [
      "self",
      "model",
      "custom_llm_provider",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "messages",
      "logging_obj",
      "timeout",
      "litellm_params",
      "optional_params",
      "fake_stream",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "_add_stream_param_to_request_body": [
      "self",
      "data",
      "provider_config",
      "fake_stream"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "timeout",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "optional_params",
      "litellm_params",
      "model_response",
      "api_key",
      "client",
      "aembedding",
      "headers"
    ],
    "aembedding": [
      "self",
      "request_data",
      "api_base",
      "headers",
      "model",
      "custom_llm_provider",
      "provider_config",
      "model_response",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "api_key",
      "timeout",
      "client"
    ],
    "rerank": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "provider_config",
      "optional_rerank_params",
      "timeout",
      "model_response",
      "_is_async",
      "headers",
      "api_key",
      "api_base",
      "client"
    ],
    "arerank": [
      "self",
      "model",
      "request_data",
      "custom_llm_provider",
      "provider_config",
      "logging_obj",
      "model_response",
      "api_base",
      "headers",
      "api_key",
      "timeout",
      "client"
    ],
    "_prepare_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params",
      "logging_obj",
      "api_key",
      "api_base",
      "headers",
      "provider_config"
    ],
    "_transform_audio_transcription_response": [
      "self",
      "provider_config",
      "model",
      "response",
      "model_response",
      "logging_obj",
      "optional_params",
      "api_key"
    ],
    "audio_transcriptions": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params",
      "model_response",
      "timeout",
      "max_retries",
      "logging_obj",
      "api_key",
      "api_base",
      "custom_llm_provider",
      "client",
      "atranscription",
      "headers",
      "provider_config",
      "shared_session"
    ],
    "async_audio_transcriptions": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params",
      "model_response",
      "timeout",
      "max_retries",
      "logging_obj",
      "api_key",
      "api_base",
      "custom_llm_provider",
      "client",
      "headers",
      "provider_config",
      "shared_session"
    ],
    "_prepare_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "logging_obj",
      "api_key",
      "api_base",
      "headers",
      "provider_config",
      "litellm_params"
    ],
    "_async_prepare_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "logging_obj",
      "api_key",
      "api_base",
      "headers",
      "provider_config",
      "litellm_params"
    ],
    "_transform_ocr_response": [
      "self",
      "provider_config",
      "model",
      "response",
      "logging_obj"
    ],
    "ocr": [
      "self",
      "model",
      "document",
      "optional_params",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "custom_llm_provider",
      "client",
      "aocr",
      "headers",
      "provider_config",
      "litellm_params"
    ],
    "async_ocr": [
      "self",
      "model",
      "document",
      "optional_params",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "custom_llm_provider",
      "client",
      "headers",
      "provider_config",
      "litellm_params"
    ],
    "search": [
      "self",
      "query",
      "optional_params",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "custom_llm_provider",
      "client",
      "asearch",
      "headers",
      "provider_config"
    ],
    "async_search": [
      "self",
      "query",
      "optional_params",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "custom_llm_provider",
      "client",
      "headers",
      "provider_config"
    ],
    "async_anthropic_messages_handler": [
      "self",
      "model",
      "messages",
      "anthropic_messages_provider_config",
      "anthropic_messages_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "client",
      "extra_headers",
      "api_key",
      "api_base",
      "stream",
      "kwargs"
    ],
    "anthropic_messages_handler": [
      "self",
      "model",
      "messages",
      "anthropic_messages_provider_config",
      "anthropic_messages_optional_request_params",
      "custom_llm_provider",
      "_is_async",
      "litellm_params",
      "logging_obj",
      "client",
      "api_key",
      "api_base",
      "stream",
      "kwargs"
    ],
    "response_api_handler": [
      "self",
      "model",
      "input",
      "responses_api_provider_config",
      "response_api_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "fake_stream",
      "litellm_metadata",
      "shared_session"
    ],
    "async_response_api_handler": [
      "self",
      "model",
      "input",
      "responses_api_provider_config",
      "response_api_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "fake_stream",
      "litellm_metadata",
      "shared_session"
    ],
    "async_delete_response_api_handler": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "delete_response_api_handler": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "get_responses": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_get_responses": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "shared_session"
    ],
    "list_responses_input_items": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "after",
      "before",
      "include",
      "limit",
      "order",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_list_responses_input_items": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "after",
      "before",
      "include",
      "limit",
      "order",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "_extract_upload_url_from_response": [
      "self",
      "response",
      "upload_url_location",
      "upload_url_key"
    ],
    "create_file": [
      "self",
      "create_file_data",
      "litellm_params",
      "provider_config",
      "headers",
      "api_base",
      "api_key",
      "logging_obj",
      "_is_async",
      "client",
      "timeout"
    ],
    "async_create_file": [
      "self",
      "transformed_request",
      "litellm_params",
      "provider_config",
      "headers",
      "api_base",
      "logging_obj",
      "client",
      "timeout"
    ],
    "create_batch": [
      "self",
      "create_batch_data",
      "litellm_params",
      "provider_config",
      "headers",
      "api_base",
      "api_key",
      "logging_obj",
      "_is_async",
      "client",
      "timeout",
      "model"
    ],
    "retrieve_batch": [
      "self",
      "batch_id",
      "litellm_params",
      "provider_config",
      "headers",
      "api_base",
      "api_key",
      "logging_obj",
      "_is_async",
      "client",
      "timeout",
      "model"
    ],
    "async_create_batch": [
      "self",
      "transformed_request",
      "litellm_params",
      "provider_config",
      "headers",
      "api_base",
      "logging_obj",
      "client",
      "timeout",
      "create_batch_data",
      "model"
    ],
    "async_retrieve_batch": [
      "self",
      "transformed_request",
      "litellm_params",
      "provider_config",
      "headers",
      "api_base",
      "logging_obj",
      "client",
      "timeout",
      "batch_id",
      "model"
    ],
    "cancel_response_api_handler": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_cancel_response_api_handler": [
      "self",
      "response_id",
      "responses_api_provider_config",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "compact_response_api_handler": [
      "self",
      "model",
      "input",
      "responses_api_provider_config",
      "response_api_optional_request_params",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_compact_response_api_handler": [
      "self",
      "model",
      "input",
      "responses_api_provider_config",
      "response_api_optional_request_params",
      "litellm_params",
      "logging_obj",
      "custom_llm_provider",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "retrieve_file": [
      "self",
      "file_id",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "_is_async",
      "client",
      "timeout"
    ],
    "async_retrieve_file": [
      "self",
      "file_id",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "client",
      "timeout"
    ],
    "delete_file": [
      "self",
      "file_id",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "_is_async",
      "client",
      "timeout"
    ],
    "async_delete_file": [
      "self",
      "file_id",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "client",
      "timeout"
    ],
    "list_files": [
      "self",
      "purpose",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "_is_async",
      "client",
      "timeout"
    ],
    "async_list_files": [
      "self",
      "purpose",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "client",
      "timeout"
    ],
    "retrieve_file_content": [
      "self",
      "file_content_request",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "_is_async",
      "client",
      "timeout"
    ],
    "async_retrieve_file_content": [
      "self",
      "file_content_request",
      "provider_config",
      "litellm_params",
      "headers",
      "logging_obj",
      "client",
      "timeout"
    ],
    "_prepare_fake_stream_request": [
      "self",
      "stream",
      "data",
      "fake_stream"
    ],
    "_call_agentic_completion_hooks": [
      "self",
      "response",
      "model",
      "messages",
      "anthropic_messages_provider_config",
      "anthropic_messages_optional_request_params",
      "logging_obj",
      "stream",
      "custom_llm_provider",
      "kwargs"
    ],
    "_call_agentic_chat_completion_hooks": [
      "self",
      "response",
      "model",
      "messages",
      "optional_params",
      "logging_obj",
      "stream",
      "custom_llm_provider",
      "kwargs"
    ],
    "_handle_error": [
      "self",
      "e",
      "provider_config"
    ],
    "async_realtime": [
      "self",
      "model",
      "websocket",
      "logging_obj",
      "provider_config",
      "headers",
      "api_base",
      "api_key",
      "client",
      "timeout"
    ],
    "image_edit_handler": [
      "self",
      "model",
      "image",
      "prompt",
      "image_edit_provider_config",
      "image_edit_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "extra_body",
      "client",
      "_is_async",
      "fake_stream",
      "litellm_metadata"
    ],
    "async_image_edit_handler": [
      "self",
      "model",
      "image",
      "prompt",
      "image_edit_provider_config",
      "image_edit_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "extra_body",
      "client",
      "fake_stream",
      "litellm_metadata"
    ],
    "image_generation_handler": [
      "self",
      "model",
      "prompt",
      "image_generation_provider_config",
      "image_generation_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "extra_body",
      "client",
      "_is_async",
      "fake_stream",
      "litellm_metadata",
      "api_key"
    ],
    "async_image_generation_handler": [
      "self",
      "model",
      "prompt",
      "image_generation_provider_config",
      "image_generation_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "extra_body",
      "client",
      "fake_stream",
      "litellm_metadata",
      "api_key"
    ],
    "video_generation_handler": [
      "self",
      "model",
      "prompt",
      "video_generation_provider_config",
      "video_generation_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "extra_body",
      "client",
      "_is_async",
      "fake_stream",
      "litellm_metadata",
      "api_key"
    ],
    "async_video_generation_handler": [
      "self",
      "model",
      "prompt",
      "video_generation_provider_config",
      "video_generation_optional_request_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "extra_body",
      "client",
      "fake_stream",
      "litellm_metadata",
      "api_key"
    ],
    "video_content_handler": [
      "self",
      "video_id",
      "video_content_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "api_key",
      "client",
      "_is_async"
    ],
    "async_video_content_handler": [
      "self",
      "video_id",
      "video_content_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "api_key",
      "client"
    ],
    "video_remix_handler": [
      "self",
      "video_id",
      "prompt",
      "video_remix_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "_is_async",
      "client",
      "api_key"
    ],
    "async_video_remix_handler": [
      "self",
      "video_id",
      "prompt",
      "video_remix_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "api_key"
    ],
    "video_list_handler": [
      "self",
      "after",
      "limit",
      "order",
      "video_list_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "_is_async",
      "client",
      "api_key"
    ],
    "async_video_list_handler": [
      "self",
      "after",
      "limit",
      "order",
      "video_list_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "client",
      "api_key"
    ],
    "async_video_delete_handler": [
      "self",
      "video_id",
      "video_delete_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "api_key"
    ],
    "video_status_handler": [
      "self",
      "video_id",
      "video_status_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "_is_async",
      "client",
      "api_key"
    ],
    "async_video_status_handler": [
      "self",
      "video_id",
      "video_status_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "api_key"
    ],
    "container_create_handler": [
      "self",
      "name",
      "container_create_request_params",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "_is_async",
      "client"
    ],
    "async_container_create_handler": [
      "self",
      "name",
      "container_create_request_params",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client"
    ],
    "container_list_handler": [
      "self",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "after",
      "limit",
      "order",
      "extra_headers",
      "extra_query",
      "timeout",
      "_is_async",
      "client"
    ],
    "async_container_list_handler": [
      "self",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "after",
      "limit",
      "order",
      "extra_headers",
      "extra_query",
      "timeout",
      "client"
    ],
    "container_retrieve_handler": [
      "self",
      "container_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "_is_async",
      "client"
    ],
    "async_container_retrieve_handler": [
      "self",
      "container_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "client"
    ],
    "container_delete_handler": [
      "self",
      "container_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "_is_async",
      "client"
    ],
    "async_container_delete_handler": [
      "self",
      "container_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "client"
    ],
    "container_file_list_handler": [
      "self",
      "container_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "after",
      "limit",
      "order",
      "extra_headers",
      "extra_query",
      "timeout",
      "_is_async",
      "client"
    ],
    "async_container_file_list_handler": [
      "self",
      "container_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "after",
      "limit",
      "order",
      "extra_headers",
      "extra_query",
      "timeout",
      "client"
    ],
    "container_file_content_handler": [
      "self",
      "container_id",
      "file_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "_is_async",
      "client"
    ],
    "async_container_file_content_handler": [
      "self",
      "container_id",
      "file_id",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client"
    ],
    "async_vector_store_search_handler": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "vector_store_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async"
    ],
    "vector_store_search_handler": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "vector_store_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async"
    ],
    "async_vector_store_create_handler": [
      "self",
      "vector_store_create_optional_params",
      "vector_store_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async"
    ],
    "vector_store_create_handler": [
      "self",
      "vector_store_create_optional_params",
      "vector_store_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "_is_async"
    ],
    "async_vector_store_file_create_handler": [
      "self"
    ],
    "vector_store_file_create_handler": [
      "self"
    ],
    "async_vector_store_file_list_handler": [
      "self"
    ],
    "vector_store_file_list_handler": [
      "self"
    ],
    "async_vector_store_file_retrieve_handler": [
      "self"
    ],
    "vector_store_file_retrieve_handler": [
      "self"
    ],
    "async_vector_store_file_content_handler": [
      "self"
    ],
    "vector_store_file_content_handler": [
      "self"
    ],
    "async_vector_store_file_update_handler": [
      "self"
    ],
    "vector_store_file_update_handler": [
      "self"
    ],
    "async_vector_store_file_delete_handler": [
      "self"
    ],
    "vector_store_file_delete_handler": [
      "self"
    ],
    "generate_content_handler": [
      "self",
      "model",
      "contents",
      "generate_content_provider_config",
      "generate_content_config_dict",
      "tools",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "_is_async",
      "client",
      "stream",
      "litellm_metadata",
      "system_instruction"
    ],
    "async_generate_content_handler": [
      "self",
      "model",
      "contents",
      "generate_content_provider_config",
      "generate_content_config_dict",
      "tools",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_body",
      "timeout",
      "client",
      "stream",
      "litellm_metadata",
      "system_instruction"
    ],
    "text_to_speech_handler": [
      "self",
      "model",
      "input",
      "voice",
      "text_to_speech_provider_config",
      "text_to_speech_optional_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "client",
      "_is_async"
    ],
    "async_text_to_speech_handler": [
      "self",
      "model",
      "input",
      "voice",
      "text_to_speech_provider_config",
      "text_to_speech_optional_params",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "timeout",
      "extra_headers",
      "client"
    ],
    "_prepare_skill_multipart_request": [
      "self",
      "request_body",
      "headers"
    ],
    "create_skill_handler": [
      "self",
      "url",
      "request_body",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_create_skill_handler": [
      "self",
      "url",
      "request_body",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "list_skills_handler": [
      "self",
      "url",
      "query_params",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_list_skills_handler": [
      "self",
      "url",
      "query_params",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "get_skill_handler": [
      "self",
      "url",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_get_skill_handler": [
      "self",
      "url",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "delete_skill_handler": [
      "self",
      "url",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_delete_skill_handler": [
      "self",
      "url",
      "skills_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "create_eval_handler": [
      "self",
      "url",
      "request_body",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_create_eval_handler": [
      "self",
      "url",
      "request_body",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "list_evals_handler": [
      "self",
      "url",
      "query_params",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_list_evals_handler": [
      "self",
      "url",
      "query_params",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "get_eval_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_get_eval_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "update_eval_handler": [
      "self",
      "url",
      "request_body",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_update_eval_handler": [
      "self",
      "url",
      "request_body",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "delete_eval_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_delete_eval_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "cancel_eval_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_cancel_eval_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "create_run_handler": [
      "self",
      "url",
      "request_body",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_create_run_handler": [
      "self",
      "url",
      "request_body",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "list_runs_handler": [
      "self",
      "url",
      "query_params",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_list_runs_handler": [
      "self",
      "url",
      "query_params",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "get_run_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_get_run_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "cancel_run_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_cancel_run_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ],
    "delete_run_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "_is_async",
      "shared_session"
    ],
    "async_delete_run_handler": [
      "self",
      "url",
      "evals_api_provider_config",
      "custom_llm_provider",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "timeout",
      "client",
      "shared_session"
    ]
  },
  "_get_endpoint_config": [
    "endpoint_name"
  ],
  "_build_url": [
    "api_base",
    "path_template",
    "path_params"
  ],
  "_build_query_params": [
    "query_param_names",
    "kwargs"
  ],
  "_prepare_multipart_file_upload": [
    "file",
    "headers"
  ],
  "GenericContainerHandler": {
    "handle": [
      "self",
      "endpoint_name",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "_is_async",
      "client"
    ],
    "_sync_handle": [
      "self",
      "endpoint_name",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "client"
    ],
    "_async_handle": [
      "self",
      "endpoint_name",
      "container_provider_config",
      "litellm_params",
      "logging_obj",
      "extra_headers",
      "extra_query",
      "timeout",
      "client"
    ]
  },
  "generic_container_handler": [],
  "get_default_headers": [],
  "HTTPHandler": {
    "__init__": [
      "self",
      "concurrent_limit"
    ],
    "close": [
      "self"
    ],
    "get": [
      "self",
      "url",
      "params",
      "headers"
    ],
    "post": [
      "self",
      "url",
      "data",
      "params",
      "headers"
    ]
  },
  "map_aiohttp_exceptions": [],
  "AiohttpResponseStream": {
    "CHUNK_SIZE": [],
    "__init__": [
      "self",
      "aiohttp_response"
    ],
    "__aiter__": [
      "self"
    ],
    "aclose": [
      "self"
    ]
  },
  "AiohttpTransport": {
    "__init__": [
      "self",
      "client",
      "owns_session"
    ],
    "aclose": [
      "self"
    ]
  },
  "LiteLLMAiohttpTransport": {
    "__init__": [
      "self",
      "client",
      "ssl_verify",
      "owns_session"
    ],
    "_get_valid_client_session": [
      "self"
    ],
    "_make_aiohttp_request": [
      "self",
      "client_session",
      "request",
      "timeout",
      "proxy",
      "sni_hostname",
      "ssl_verify"
    ],
    "handle_async_request": [
      "self",
      "request"
    ],
    "_get_proxy_settings": [
      "self",
      "request"
    ],
    "_proxy_from_env": [
      "self",
      "url"
    ]
  },
  "close_litellm_async_clients": [],
  "register_async_client_cleanup": [],
  "_DEFAULT_TIMEOUT": [],
  "_prepare_request_data_and_content": [
    "data",
    "content"
  ],
  "_create_ssl_context": [
    "cafile",
    "ssl_security_level",
    "ssl_ecdh_curve"
  ],
  "get_ssl_verify": [
    "ssl_verify"
  ],
  "get_ssl_configuration": [
    "ssl_verify"
  ],
  "get_shared_realtime_ssl_context": [],
  "mask_sensitive_info": [
    "error_message"
  ],
  "MaskedHTTPStatusError": {
    "__init__": [
      "self",
      "original_error",
      "message",
      "text"
    ]
  },
  "AsyncHTTPHandler": {
    "__init__": [
      "self",
      "timeout",
      "event_hooks",
      "concurrent_limit",
      "client_alias",
      "ssl_verify",
      "shared_session"
    ],
    "create_client": [
      "self",
      "timeout",
      "event_hooks",
      "ssl_verify",
      "shared_session"
    ],
    "close": [
      "self"
    ],
    "__aenter__": [
      "self"
    ],
    "__aexit__": [
      "self"
    ],
    "get": [
      "self",
      "url",
      "params",
      "headers",
      "follow_redirects"
    ],
    "post": [
      "self",
      "url",
      "data",
      "json",
      "params",
      "headers",
      "timeout",
      "stream",
      "logging_obj",
      "files",
      "content"
    ],
    "put": [
      "self",
      "url",
      "data",
      "json",
      "params",
      "headers",
      "timeout",
      "stream",
      "content"
    ],
    "patch": [
      "self",
      "url",
      "data",
      "json",
      "params",
      "headers",
      "timeout",
      "stream",
      "content"
    ],
    "delete": [
      "self",
      "url",
      "data",
      "json",
      "params",
      "headers",
      "timeout",
      "stream",
      "content"
    ],
    "single_connection_post_request": [
      "self",
      "url",
      "client",
      "data",
      "json",
      "params",
      "headers",
      "stream",
      "content"
    ],
    "__del__": [
      "self"
    ],
    "_create_async_transport": [
      "ssl_context",
      "ssl_verify",
      "shared_session"
    ],
    "_should_use_aiohttp_transport": [],
    "_get_ssl_connector_kwargs": [
      "ssl_verify",
      "ssl_context"
    ],
    "_create_aiohttp_transport": [
      "ssl_verify",
      "ssl_context",
      "shared_session"
    ],
    "_create_httpx_transport": []
  },
  "get_async_httpx_client": [
    "llm_provider",
    "params",
    "shared_session"
  ],
  "_get_httpx_client": [
    "params"
  ],
  "DEFAULT_TIMEOUT": [],
  "BaseLLMAIOHTTPHandler": {
    "__init__": [
      "self",
      "client_session",
      "transport",
      "connector"
    ],
    "_get_or_create_transport": [
      "self"
    ],
    "_get_connector": [
      "self"
    ],
    "_create_client_session_with_transport": [
      "self"
    ],
    "_get_async_client_session": [
      "self",
      "dynamic_client_session"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "_make_common_async_call": [
      "self",
      "async_client_session",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "litellm_params",
      "form_data",
      "stream"
    ],
    "_make_common_sync_call": [
      "self",
      "sync_httpx_client",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "litellm_params",
      "stream",
      "files",
      "content",
      "params"
    ],
    "async_completion": [
      "self",
      "custom_llm_provider",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "model",
      "model_response",
      "logging_obj",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "client"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_llm_provider",
      "model_response",
      "encoding",
      "logging_obj",
      "optional_params",
      "timeout",
      "litellm_params",
      "acompletion",
      "stream",
      "fake_stream",
      "api_key",
      "headers",
      "client"
    ],
    "make_sync_call": [
      "self",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "model",
      "messages",
      "logging_obj",
      "litellm_params",
      "timeout",
      "fake_stream",
      "client"
    ],
    "async_image_variations": [
      "self",
      "client",
      "provider_config",
      "api_base",
      "headers",
      "data",
      "timeout",
      "litellm_params",
      "model_response",
      "logging_obj",
      "api_key",
      "model",
      "image",
      "optional_params"
    ],
    "image_variations": [
      "self",
      "model_response",
      "api_key",
      "model",
      "image",
      "timeout",
      "custom_llm_provider",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "print_verbose",
      "api_base",
      "aimage_variation",
      "logger_fn",
      "client",
      "organization",
      "headers"
    ],
    "_handle_error": [
      "self",
      "e",
      "provider_config"
    ]
  },
  "FalAIStableDiffusionConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_image_size": [
      "self",
      "size"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "FalAIIdeogramV3Config": {
    "_OPENAI_SIZE_TO_IMAGE_SIZE": [],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_image_size": [
      "self",
      "size"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "FalAIRecraftV3Config": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_image_size": [
      "self",
      "size"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "FalAIBaseConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "FalAIImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "FalAIFluxSchnellConfig": {
    "_OPENAI_SIZE_TO_IMAGE_SIZE": [],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_image_size": [
      "self",
      "size"
    ]
  },
  "FalAIFluxProV11UltraConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_aspect_ratio": [
      "self",
      "size"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "FalAIImagen4Config": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_aspect_ratio": [
      "self",
      "size"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "FalAIFluxProV11Config": {
    "_OPENAI_SIZE_TO_IMAGE_SIZE": [],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_image_size": [
      "self",
      "size"
    ]
  },
  "FalAIBytedanceBaseConfig": {
    "_OPENAI_SIZE_TO_IMAGE_SIZE": [],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_image_size": [
      "self",
      "size"
    ]
  },
  "FalAIBytedanceSeedreamV3Config": {},
  "FalAIBytedanceDreaminaV31Config": {},
  "get_fal_ai_image_generation_config": [
    "model"
  ],
  "FalAIBriaConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_aspect_ratio": [
      "self",
      "size"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "BytezError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "STREAMING_TIMEOUT": [],
  "BytezChatConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BytezCustomStreamWrapper": {
    "chunk_creator": [
      "self",
      "chunk"
    ]
  },
  "open_ai_to_bytez_content_item_map": [],
  "adapt_messages_to_bytez_standard": [
    "messages"
  ],
  "_adapt_string_only_content_to_lists": [
    "messages"
  ],
  "get_tokens_from_messages": [
    "messages"
  ],
  "ClarifaiConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_base_model": [
      "model"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "MorphChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "DeepgramException": {},
  "DeepgramAudioTranscriptionConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ],
    "transform_audio_transcription_response": [
      "self",
      "raw_response"
    ],
    "_reconstruct_diarized_transcript": [
      "self",
      "words"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_format_param_value": [
      "self",
      "value"
    ],
    "_build_query_params": [
      "self",
      "optional_params",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "_TavilySearchRequestRequired": {},
  "TavilySearchRequest": {},
  "TavilySearchConfig": {
    "TAVILY_API_BASE": [],
    "ui_friendly_name": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "_LinkupSearchRequestRequired": {},
  "LinkupSearchRequest": {},
  "LinkupSearchConfig": {
    "LINKUP_API_BASE": [],
    "ui_friendly_name": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "DatabricksException": {},
  "DatabricksBase": {
    "SENSITIVE_PATTERNS": [],
    "redact_sensitive_data": [
      "cls",
      "data"
    ],
    "redact_headers_for_logging": [
      "cls",
      "headers"
    ],
    "_build_user_agent": [
      "custom_user_agent"
    ],
    "_get_api_base": [
      "self",
      "api_base"
    ],
    "_get_oauth_m2m_token": [
      "self",
      "api_base",
      "client_id",
      "client_secret"
    ],
    "_get_databricks_credentials": [
      "self",
      "api_key",
      "api_base",
      "headers"
    ],
    "databricks_validate_environment": [
      "self",
      "api_key",
      "api_base",
      "endpoint_type",
      "custom_endpoint",
      "headers",
      "custom_user_agent"
    ]
  },
  "DatabricksResponsesAPIConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ]
  },
  "DatabricksEmbeddingConfig": {
    "__init__": [
      "self",
      "instruction"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ]
  },
  "DatabricksEmbeddingHandler": {
    "embedding": [
      "self",
      "model",
      "input",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "optional_params",
      "model_response",
      "client",
      "aembedding",
      "custom_endpoint",
      "headers"
    ]
  },
  "_sanitize_empty_content": [
    "message_dict"
  ],
  "DatabricksConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "temperature",
      "top_p",
      "top_k",
      "stop",
      "n"
    ],
    "get_config": [
      "cls"
    ],
    "get_required_params": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "convert_anthropic_tool_to_databricks_tool": [
      "self",
      "tool"
    ],
    "_map_openai_to_dbrx_tool": [
      "self",
      "model",
      "tools"
    ],
    "map_response_format_to_databricks_tool": [
      "self",
      "model",
      "value",
      "optional_params",
      "is_thinking_enabled"
    ],
    "remove_cache_control_flag_from_messages_and_tools": [
      "self",
      "model",
      "messages",
      "tools"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "replace_max_completion_tokens_with_max_tokens"
    ],
    "_should_fake_stream": [
      "self",
      "optional_params"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_move_cache_control_into_string_content_block": [
      "self",
      "message"
    ],
    "extract_content_str": [
      "content"
    ],
    "extract_reasoning_content": [
      "content"
    ],
    "extract_citations": [
      "content"
    ],
    "_transform_dbrx_choices": [
      "self",
      "choices",
      "json_mode"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "DatabricksChatResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "create_config_class": [
    "provider"
  ],
  "SimpleProviderConfig": {
    "__init__": [
      "self",
      "slug",
      "data"
    ]
  },
  "JSONProviderRegistry": {
    "_loaded": [],
    "load": [
      "cls"
    ],
    "get": [
      "cls",
      "slug"
    ],
    "exists": [
      "cls",
      "slug"
    ],
    "list_providers": [
      "cls"
    ]
  },
  "OpenAILikeError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "OpenAILikeBase": {
    "__init__": [
      "self"
    ],
    "_validate_environment": [
      "self",
      "api_key",
      "api_base",
      "endpoint_type",
      "headers",
      "custom_endpoint"
    ]
  },
  "OpenAILikeEmbeddingHandler": {
    "__init__": [
      "self"
    ],
    "aembedding": [
      "self",
      "input",
      "data",
      "model_response",
      "timeout",
      "api_key",
      "api_base",
      "logging_obj",
      "headers",
      "client"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "optional_params",
      "model_response",
      "client",
      "aembedding",
      "custom_endpoint",
      "headers"
    ]
  },
  "OpenAILikeChatConfig": {
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "_json_mode_convert_tool_response_to_message": [
      "message",
      "json_mode"
    ],
    "_sanitize_usage_obj": [
      "response_json"
    ],
    "_transform_response": [
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "print_verbose",
      "encoding",
      "json_mode",
      "custom_llm_provider",
      "base_model"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "replace_max_completion_tokens_with_max_tokens"
    ]
  },
  "OpenAILikeChatHandler": {
    "__init__": [
      "self"
    ],
    "acompletion_stream_function": [
      "self",
      "model",
      "messages",
      "custom_llm_provider",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "stream",
      "data",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers",
      "client",
      "streaming_decoder",
      "fake_stream"
    ],
    "acompletion_function": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "custom_llm_provider",
      "print_verbose",
      "client",
      "encoding",
      "api_key",
      "logging_obj",
      "stream",
      "data",
      "base_model",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers",
      "timeout",
      "json_mode"
    ],
    "completion": [
      "self"
    ]
  },
  "NvidiaNimEmbeddingConfig": {
    "__init__": [
      "self",
      "encoding_format",
      "user",
      "input_type",
      "truncate"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "kwargs"
    ]
  },
  "NvidiaNimQueryObject": {},
  "NvidiaNimPassageObject": {},
  "NvidiaNimRerankRequest": {},
  "NvidiaNimRankingResult": {},
  "NvidiaNimRerankResponse": {},
  "NvidiaNimRerankConfig": {
    "DEFAULT_NIM_RERANK_API_BASE": [],
    "__init__": [
      "self"
    ],
    "_get_clean_model_name": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "get_nvidia_nim_rerank_config": [
    "model"
  ],
  "NvidiaNimRankingConfig": {
    "_get_clean_model_name": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ]
  },
  "NvidiaNimConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "AUTH_ENDPOINT_SUFFIX": [],
  "CONFIG_FILE_ENV_VAR": [],
  "HOME_PATH_ENV_VAR": [],
  "PROFILE_ENV_VAR": [],
  "VCAP_SERVICES_ENV_VAR": [],
  "VCAP_AICORE_SERVICE_NAME": [],
  "SERVICE_KEY_ENV_VAR": [],
  "DEFAULT_HOME_PATH": [],
  "_get_home": [],
  "_get_nested": [
    "d",
    "path"
  ],
  "_load_json_env": [
    "var_name"
  ],
  "_load_vcap": [],
  "_get_vcap_service": [
    "label"
  ],
  "CredentialsValue": {},
  "init_conf": [
    "profile"
  ],
  "_env_name": [
    "name"
  ],
  "_resolve_value": [
    "cred"
  ],
  "fetch_credentials": [
    "service_key",
    "profile"
  ],
  "get_token_creator": [
    "service_key",
    "profile"
  ],
  "EmbeddingItem": {},
  "FinalResult": {},
  "EmbeddingsResponse": {},
  "EmbeddingModel": {},
  "EmbeddingsModules": {},
  "validate_dict": [
    "data",
    "model"
  ],
  "GenAIHubEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "headers": [
      "self"
    ],
    "deployment_url": [
      "self"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ]
  },
  "GenAIHubOrchestrationConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format",
      "tools",
      "tool_choice"
    ],
    "run_env_setup": [
      "self",
      "service_key"
    ],
    "headers": [
      "self"
    ],
    "base_url": [
      "self"
    ],
    "resource_group": [
      "self"
    ],
    "deployment_url": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "GenAIHubOrchestrationError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "_now_ts": [],
  "_is_terminal_chunk": [
    "chunk"
  ],
  "_StreamParser": {
    "_from_orchestration_result": [
      "evt"
    ],
    "to_openai_chunk": [
      "event_obj"
    ]
  },
  "SAPStreamIterator": {
    "__init__": [
      "self",
      "response",
      "event_prefix",
      "final_msg"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "_safe_close": [
      "self"
    ]
  },
  "AsyncSAPStreamIterator": {
    "sync_stream": [],
    "__init__": [
      "self",
      "response",
      "event_prefix",
      "final_msg"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ],
    "_aclose": [
      "self"
    ]
  },
  "GenAIHubOrchestration": {
    "_add_stream_param_to_request_body": [
      "self",
      "data",
      "provider_config",
      "fake_stream"
    ]
  },
  "validate_different_content": [
    "v"
  ],
  "ImageURLContent": {},
  "FunctionObj": {},
  "FunctionTool": {},
  "ChatCompletionTool": {},
  "MessageToolCall": {},
  "SAPMessage": {
    "_content_validator": []
  },
  "SAPUserMessage": {},
  "SAPAssistantMessage": {
    "_content_validator": []
  },
  "SAPToolChatMessage": {
    "_content_validator": []
  },
  "ResponseFormat": {},
  "JSONResponseSchema": {},
  "ResponseFormatJSONSchema": {},
  "DockerModelRunnerChatConfig": {
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "ReplicateError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "ReplicateConfig": {
    "__init__": [
      "self",
      "system_prompt",
      "max_new_tokens",
      "min_new_tokens",
      "temperature",
      "top_p",
      "top_k",
      "stop_sequences",
      "seed",
      "debug"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "model_to_version_id": [
      "self",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_prediction_url": [
      "self",
      "response"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "replicate_config": [],
  "handle_prediction_response_streaming": [
    "prediction_url",
    "api_token",
    "print_verbose",
    "headers",
    "http_client"
  ],
  "async_handle_prediction_response_streaming": [
    "prediction_url",
    "api_token",
    "print_verbose",
    "headers",
    "http_client"
  ],
  "ZAI_API_BASE": [],
  "ZAIChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "remove_cache_control_flag_from_messages_and_tools": [
      "self",
      "model",
      "messages",
      "tools"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "PetalsError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "PetalsConfig": {
    "__init__": [
      "self",
      "max_length",
      "max_new_tokens",
      "do_sample",
      "temperature",
      "top_k",
      "top_p",
      "repetition_penalty"
    ],
    "get_config": [
      "cls"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "TritonError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "TritonEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "split_embedding_by_shape": [
      "data",
      "shape"
    ]
  },
  "TritonConfig": {
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_get_triton_llm_type": [
      "self",
      "api_base"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "TritonGenerateConfig": {
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "TritonInferConfig": {
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "TritonResponseIterator": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "DeepinfraRerankConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "DeepInfraConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format",
      "tools",
      "tool_choice"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_transform_tool_message_content": [
      "self",
      "messages"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ]
  },
  "MILVUS_OPTIONAL_PARAMS": [],
  "MilvusVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "AimlImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "get_aiml_image_generation_config": [
    "model"
  ],
  "AIMLChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ]
  },
  "get_model_params_and_category": [
    "model_name",
    "call_type"
  ],
  "get_model_params_and_category_embeddings": [
    "model_name"
  ],
  "TogetherAIConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "TogetherAITextCompletionConfig": {
    "_transform_prompt": [
      "self",
      "messages"
    ],
    "transform_text_completion_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "headers"
    ]
  },
  "TogetherAIRerankConfig": {
    "_transform_response": [
      "self",
      "response"
    ]
  },
  "TogetherAIRerank": {
    "rerank": [
      "self",
      "model",
      "api_key",
      "query",
      "documents",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "_is_async"
    ],
    "async_rerank": [
      "self",
      "request_data_dict",
      "api_key"
    ]
  },
  "BaseTokenCounter": {
    "count_tokens": [
      "self",
      "model_to_use",
      "messages",
      "contents",
      "deployment",
      "request_model"
    ],
    "should_use_token_counting_api": [
      "self",
      "custom_llm_provider"
    ]
  },
  "BaseLLMModelInfo": {
    "get_provider_info": [
      "self",
      "model"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_base_model": [
      "model"
    ],
    "get_token_counter": [
      "self"
    ]
  },
  "_convert_tool_response_to_message": [
    "tool_calls"
  ],
  "_dict_to_response_format_helper": [
    "response_format",
    "ref_template"
  ],
  "type_to_response_format_param": [
    "response_format",
    "ref_template"
  ],
  "map_developer_role_to_system_role": [
    "messages"
  ],
  "convert_model_response_to_streaming": [
    "model_response"
  ],
  "BaseModelResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "__iter__": [
      "self"
    ],
    "_string_to_dict_parser": [
      "str_line"
    ],
    "_handle_string_chunk": [
      "self",
      "str_line"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "MockResponseIterator": {
    "__init__": [
      "self",
      "model_response",
      "json_mode"
    ],
    "__iter__": [
      "self"
    ],
    "_chunk_parser": [
      "self",
      "chunk_data"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "FakeStreamResponseIterator": {
    "__init__": [
      "self",
      "model_response",
      "json_mode"
    ],
    "__iter__": [
      "self"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "__next__": [
      "self"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "BaseBatchesConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_batch_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "data"
    ],
    "transform_create_batch_request": [
      "self",
      "model",
      "create_batch_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_batch_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_retrieve_batch_request": [
      "self",
      "batch_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_batch_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BaseImageVariationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request_image_variation": [
      "self",
      "model",
      "image",
      "optional_params",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "async_transform_response_image_variation": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "image",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key"
    ],
    "transform_response_image_variation": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "image",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "BaseInteractionsAPIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "agent",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "agent",
      "input",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "transform_streaming_response": [
      "self",
      "model",
      "parsed_chunk",
      "logging_obj"
    ],
    "transform_get_interaction_request": [
      "self",
      "interaction_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_interaction_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_interaction_request": [
      "self",
      "interaction_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_interaction_response": [
      "self",
      "raw_response",
      "logging_obj",
      "interaction_id"
    ],
    "transform_cancel_interaction_request": [
      "self",
      "interaction_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_interaction_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ]
  },
  "BaseResponsesAPIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_response_api_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "transform_streaming_response": [
      "self",
      "model",
      "parsed_chunk",
      "logging_obj"
    ],
    "transform_delete_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_input_items_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "before",
      "include",
      "limit",
      "order"
    ],
    "transform_list_input_items_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "transform_cancel_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_compact_response_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_compact_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "BaseVideoConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "video_create_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_video_create_request": [
      "self",
      "model",
      "prompt",
      "api_base",
      "video_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_video_create_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "custom_llm_provider",
      "request_data"
    ],
    "transform_video_content_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "async_transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_remix_request": [
      "self",
      "video_id",
      "prompt",
      "api_base",
      "litellm_params",
      "headers",
      "extra_body"
    ],
    "transform_video_remix_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_video_list_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_delete_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_status_retrieve_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_status_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BaseRealtimeConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "api_key"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_realtime_request": [
      "self",
      "message",
      "model",
      "session_configuration_request"
    ],
    "requires_session_configuration": [
      "self"
    ],
    "session_configuration_request": [
      "self",
      "model"
    ],
    "transform_realtime_response": [
      "self",
      "message",
      "model",
      "logging_obj",
      "realtime_response_transform_input"
    ]
  },
  "BaseEvalsAPIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "endpoint",
      "eval_id"
    ],
    "transform_create_eval_request": [
      "self",
      "create_request",
      "litellm_params",
      "headers"
    ],
    "transform_create_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_evals_request": [
      "self",
      "list_params",
      "litellm_params",
      "headers"
    ],
    "transform_list_evals_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_eval_request": [
      "self",
      "eval_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_update_eval_request": [
      "self",
      "eval_id",
      "update_request",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_update_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_eval_request": [
      "self",
      "eval_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_cancel_eval_request": [
      "self",
      "eval_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_create_run_request": [
      "self",
      "eval_id",
      "create_request",
      "litellm_params",
      "headers"
    ],
    "transform_create_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_runs_request": [
      "self",
      "eval_id",
      "list_params",
      "litellm_params",
      "headers"
    ],
    "transform_list_runs_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_run_request": [
      "self",
      "eval_id",
      "run_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_cancel_run_request": [
      "self",
      "eval_id",
      "run_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_run_request": [
      "self",
      "eval_id",
      "run_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "SearchResult": {
    "model_config": []
  },
  "SearchResponse": {
    "model_config": []
  },
  "BaseSearchConfig": {
    "__init__": [
      "self"
    ],
    "ui_friendly_name": [],
    "get_http_method": [
      "self"
    ],
    "get_supported_perplexity_optional_params": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BaseAnthropicMessagesConfig": {
    "validate_anthropic_messages_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_anthropic_messages_params": [
      "self",
      "model"
    ],
    "transform_anthropic_messages_request": [
      "self",
      "model",
      "messages",
      "anthropic_messages_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_anthropic_messages_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "get_async_streaming_response_iterator": [
      "self",
      "model",
      "httpx_response",
      "request_body",
      "litellm_logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BaseImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "use_multipart_form_data": [
      "self"
    ]
  },
  "BaseEmbeddingConfig": {
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "BasePassthroughConfig": {
    "is_streaming_request": [
      "self",
      "endpoint",
      "request_data"
    ],
    "format_url": [
      "self",
      "endpoint",
      "base_target_url",
      "request_query_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "endpoint",
      "request_query_params",
      "litellm_params"
    ],
    "sign_request": [
      "self",
      "headers",
      "litellm_params",
      "request_data",
      "api_base",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "logging_non_streaming_response": [
      "self",
      "model",
      "custom_llm_provider",
      "httpx_response",
      "request_data",
      "logging_obj",
      "endpoint"
    ],
    "handle_logging_collected_chunks": [
      "self",
      "all_chunks",
      "litellm_logging_obj",
      "model",
      "custom_llm_provider",
      "endpoint"
    ],
    "_convert_raw_bytes_to_str_lines": [
      "self",
      "raw_bytes"
    ]
  },
  "BaseTextCompletionConfig": {
    "transform_text_completion_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "DocumentType": [],
  "OCRPageDimensions": {},
  "OCRPageImage": {
    "model_config": []
  },
  "OCRPage": {
    "model_config": []
  },
  "OCRUsageInfo": {
    "model_config": []
  },
  "OCRResponse": {
    "model_config": []
  },
  "OCRRequestData": {},
  "BaseOCRConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_ocr_params": [
      "self",
      "model"
    ],
    "map_ocr_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params",
      "litellm_params"
    ],
    "transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "async_transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "async_transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "get_storage_backend": [
    "backend_type"
  ],
  "AzureBlobStorageBackend": {
    "__init__": [
      "self"
    ],
    "periodic_flush": [
      "self"
    ],
    "async_log_success_event": [
      "self"
    ],
    "async_log_failure_event": [
      "self"
    ],
    "_generate_file_name": [
      "self",
      "original_filename",
      "file_naming_strategy"
    ],
    "upload_file": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "path_prefix",
      "file_naming_strategy"
    ],
    "_upload_file_with_account_key": [
      "self",
      "file_content",
      "full_path"
    ],
    "_upload_file_with_azure_ad": [
      "self",
      "file_content",
      "full_path"
    ],
    "_append_data_bytes": [
      "self",
      "client",
      "base_url",
      "file_content"
    ],
    "download_file": [
      "self",
      "storage_url"
    ],
    "_download_file_with_account_key": [
      "self",
      "file_path"
    ],
    "_download_file_with_azure_ad": [
      "self",
      "file_path"
    ]
  },
  "BaseFileStorageBackend": {
    "upload_file": [
      "self",
      "file_content",
      "filename",
      "content_type",
      "path_prefix",
      "file_naming_strategy"
    ],
    "download_file": [
      "self",
      "storage_url"
    ],
    "delete_file": [
      "self",
      "storage_url"
    ]
  },
  "BaseFilesConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "file_upload_http_method": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_complete_file_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "data"
    ],
    "transform_create_file_request": [
      "self",
      "model",
      "create_file_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_file_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_retrieve_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_delete_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_delete_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_list_files_request": [
      "self",
      "purpose",
      "optional_params",
      "litellm_params"
    ],
    "transform_list_files_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_file_content_request": [
      "self",
      "file_content_request",
      "optional_params",
      "litellm_params"
    ],
    "transform_file_content_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "BaseFileEndpoints": {
    "acreate_file": [
      "self",
      "create_file_request",
      "llm_router",
      "target_model_names_list",
      "litellm_parent_otel_span",
      "user_api_key_dict"
    ],
    "afile_retrieve": [
      "self",
      "file_id",
      "litellm_parent_otel_span",
      "llm_router"
    ],
    "afile_list": [
      "self",
      "purpose",
      "litellm_parent_otel_span"
    ],
    "afile_delete": [
      "self",
      "file_id",
      "litellm_parent_otel_span",
      "llm_router"
    ],
    "afile_content": [
      "self",
      "file_id",
      "litellm_parent_otel_span",
      "llm_router"
    ]
  },
  "BaseTranslation": {
    "transform_user_api_key_dict_to_metadata": [
      "user_api_key_dict"
    ],
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "process_output_streaming_response": [
      "self",
      "responses_so_far",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "BaseContainerConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "container_create_optional_params",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_container_create_request": [
      "self",
      "name",
      "container_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_container_create_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_container_list_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_retrieve_request": [
      "self",
      "container_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_container_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_delete_request": [
      "self",
      "container_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_container_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_file_list_request": [
      "self",
      "container_id",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_container_file_list_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_file_content_request": [
      "self",
      "container_id",
      "file_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_container_file_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BaseVectorStoreFilesConfig": {
    "get_supported_openai_params": [
      "self",
      "operation"
    ],
    "map_openai_params": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_file_endpoints_by_type": [
      "self"
    ],
    "validate_environment": [
      "self"
    ],
    "get_complete_url": [
      "self"
    ],
    "transform_create_vector_store_file_request": [
      "self"
    ],
    "transform_create_vector_store_file_response": [
      "self"
    ],
    "transform_list_vector_store_files_request": [
      "self"
    ],
    "transform_list_vector_store_files_response": [
      "self"
    ],
    "transform_retrieve_vector_store_file_request": [
      "self"
    ],
    "transform_retrieve_vector_store_file_response": [
      "self"
    ],
    "transform_retrieve_vector_store_file_content_request": [
      "self"
    ],
    "transform_retrieve_vector_store_file_content_response": [
      "self"
    ],
    "transform_update_vector_store_file_request": [
      "self"
    ],
    "transform_update_vector_store_file_response": [
      "self"
    ],
    "transform_delete_vector_store_file_request": [
      "self"
    ],
    "transform_delete_vector_store_file_response": [
      "self"
    ],
    "get_error_class": [
      "self"
    ],
    "sign_request": [
      "self"
    ],
    "prepare_chunking_strategy": [
      "self",
      "chunking_strategy"
    ]
  },
  "BaseRerankConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "calculate_rerank_cost": [
      "self",
      "model",
      "custom_llm_provider",
      "billed_units",
      "model_info"
    ]
  },
  "BaseVectorStoreConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "drop_params"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "atransform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key"
    ],
    "calculate_vector_store_cost": [
      "self",
      "response"
    ]
  },
  "CompletionTransformationBridge": {
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers",
      "litellm_logging_obj"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "BaseImageEditConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "use_multipart_form_data": [
      "self"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BaseGoogleGenAIGenerateContentConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_generate_content_optional_params": [
      "self",
      "model"
    ],
    "map_generate_content_optional_params": [
      "self",
      "generate_content_config_dict",
      "model"
    ],
    "validate_environment": [
      "self",
      "api_key",
      "headers",
      "model",
      "litellm_params"
    ],
    "sync_get_auth_token_and_url": [
      "self",
      "api_base",
      "model",
      "litellm_params",
      "stream"
    ],
    "get_auth_token_and_url": [
      "self",
      "api_base",
      "model",
      "litellm_params",
      "stream"
    ],
    "transform_generate_content_request": [
      "self",
      "model",
      "contents",
      "tools",
      "generate_content_config_dict",
      "system_instruction"
    ],
    "transform_generate_content_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "AudioTranscriptionRequestData": {},
  "BaseAudioTranscriptionConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ],
    "transform_audio_transcription_response": [
      "self",
      "raw_response"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_provider_specific_params": [
      "self",
      "model",
      "optional_params",
      "openai_params"
    ],
    "_should_exclude_param": [
      "self",
      "param_name",
      "model"
    ]
  },
  "BaseLLMException": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers",
      "request",
      "response",
      "body"
    ]
  },
  "BaseConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_json_schema_from_pydantic_object": [
      "self",
      "response_format"
    ],
    "is_thinking_enabled": [
      "self",
      "non_default_params"
    ],
    "is_max_tokens_in_request": [
      "self",
      "non_default_params"
    ],
    "update_optional_params_with_thinking_tokens": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "_add_tools_to_optional_params": [
      "self",
      "optional_params",
      "tools"
    ],
    "translate_developer_role_to_system_role": [
      "self",
      "messages"
    ],
    "should_retry_llm_api_inside_llm_translation_on_http_error": [
      "self",
      "e",
      "litellm_params"
    ],
    "transform_request_on_unprocessable_entity_error": [
      "self",
      "e",
      "request_data"
    ],
    "max_retry_on_unprocessable_entity_error": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_add_response_format_to_tools": [
      "self",
      "optional_params",
      "value",
      "is_response_format_supported",
      "enforce_tool_choice"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "async_transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "calculate_additional_costs": [
      "self",
      "model",
      "prompt_tokens",
      "completion_tokens"
    ]
  },
  "is_base64_encoded_unified_id": [
    "resource_id",
    "prefix"
  ],
  "extract_target_model_names_from_unified_id": [
    "unified_id"
  ],
  "extract_resource_type_from_unified_id": [
    "unified_id"
  ],
  "extract_unified_uuid_from_unified_id": [
    "unified_id"
  ],
  "extract_model_id_from_unified_id": [
    "unified_id"
  ],
  "extract_provider_resource_id_from_unified_id": [
    "unified_id"
  ],
  "generate_unified_id_string": [
    "resource_type",
    "unified_uuid",
    "target_model_names",
    "provider_resource_id",
    "model_id",
    "additional_fields"
  ],
  "encode_unified_id": [
    "unified_id_string"
  ],
  "decode_unified_id": [
    "encoded_unified_id"
  ],
  "parse_unified_id": [
    "unified_id"
  ],
  "ResourceObjectType": [],
  "BaseManagedResource": {
    "__init__": [
      "self",
      "internal_usage_cache",
      "prisma_client"
    ],
    "resource_type": [
      "self"
    ],
    "table_name": [
      "self"
    ],
    "get_unified_resource_id_format": [
      "self",
      "resource_object",
      "target_model_names_list"
    ],
    "create_resource_for_model": [
      "self",
      "llm_router",
      "model",
      "request_data",
      "litellm_parent_otel_span"
    ],
    "store_unified_resource_id": [
      "self",
      "unified_resource_id",
      "resource_object",
      "litellm_parent_otel_span",
      "model_mappings",
      "user_api_key_dict",
      "additional_db_fields"
    ],
    "get_unified_resource_id": [
      "self",
      "unified_resource_id",
      "litellm_parent_otel_span"
    ],
    "delete_unified_resource_id": [
      "self",
      "unified_resource_id",
      "litellm_parent_otel_span"
    ],
    "can_user_access_unified_resource_id": [
      "self",
      "unified_resource_id",
      "user_api_key_dict",
      "litellm_parent_otel_span"
    ],
    "get_model_resource_id_mapping": [
      "self",
      "resource_ids",
      "litellm_parent_otel_span"
    ],
    "create_resource_for_each_model": [
      "self",
      "llm_router",
      "request_data",
      "target_model_names_list",
      "litellm_parent_otel_span"
    ],
    "generate_unified_resource_id": [
      "self",
      "resource_objects",
      "target_model_names_list"
    ],
    "extract_model_mappings_from_responses": [
      "self",
      "resource_objects"
    ],
    "async_filter_deployments": [
      "self",
      "model",
      "healthy_deployments",
      "request_kwargs",
      "parent_otel_span",
      "resource_id_key"
    ],
    "get_unified_id_prefix": [
      "self"
    ],
    "list_user_resources": [
      "self",
      "user_api_key_dict",
      "limit",
      "after",
      "additional_filters"
    ]
  },
  "BaseSkillsAPIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "endpoint",
      "skill_id"
    ],
    "transform_create_skill_request": [
      "self",
      "create_request",
      "litellm_params",
      "headers"
    ],
    "transform_create_skill_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_skills_request": [
      "self",
      "list_params",
      "litellm_params",
      "headers"
    ],
    "transform_list_skills_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_skill_request": [
      "self",
      "skill_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_skill_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_skill_request": [
      "self",
      "skill_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_skill_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "TextToSpeechRequestData": {},
  "BaseTextToSpeechConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "V0ChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "PalmError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "PalmConfig": {
    "__init__": [
      "self",
      "context",
      "examples",
      "temperature",
      "candidate_count",
      "top_k",
      "top_p",
      "max_output_tokens"
    ],
    "get_config": [
      "cls"
    ]
  },
  "AlephAlphaError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "AlephAlphaConfig": {
    "__init__": [
      "self",
      "maximum_tokens",
      "minimum_tokens",
      "echo",
      "temperature",
      "top_k",
      "top_p",
      "presence_penalty",
      "frequency_penalty",
      "sequence_penalty",
      "sequence_penalty_min_length",
      "repetition_penalties_include_prompt",
      "repetition_penalties_include_completion",
      "use_multiplicative_presence_penalty",
      "use_multiplicative_frequency_penalty",
      "use_multiplicative_sequence_penalty",
      "penalty_bias",
      "penalty_exceptions_include_stop_sequences",
      "best_of",
      "n",
      "logit_bias",
      "log_probs",
      "stop_sequences",
      "tokens",
      "raw_completion",
      "disable_optimizations",
      "completion_bias_inclusion",
      "completion_bias_exclusion",
      "completion_bias_inclusion_first_token_only",
      "completion_bias_exclusion_first_token_only",
      "contextual_control_threshold",
      "control_log_additive"
    ],
    "get_config": [
      "cls"
    ]
  },
  "JinaAIError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "JinaAIEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "JinaAIRerankConfig": {
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "calculate_rerank_cost": [
      "self",
      "model",
      "custom_llm_provider",
      "billed_units",
      "model_info"
    ]
  },
  "OVHCloudException": {},
  "OVHCloudEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "OVHCloudAudioTranscriptionConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ],
    "transform_audio_transcription_response": [
      "self",
      "raw_response"
    ]
  },
  "OVHCloudChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "OVHCloudChatCompletionStreamingHandler": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "S3VectorsVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "atransform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "GithubChatConfig": {},
  "_ExaAISearchRequestRequired": {},
  "ExaAISearchRequest": {},
  "ExaAISearchConfig": {
    "EXA_AI_API_BASE": [],
    "ui_friendly_name": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "OpenRouterException": {},
  "OpenRouterImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_size_to_aspect_ratio": [
      "self",
      "size"
    ],
    "_map_quality_to_image_size": [
      "self",
      "quality"
    ],
    "_set_usage_and_cost": [
      "self",
      "model_response",
      "response_json",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "get_openrouter_image_generation_config": [
    "model"
  ],
  "OpenrouterEmbeddingConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "CacheControlSupportedModels": {
    "CLAUDE": [],
    "GEMINI": [],
    "MINIMAX": [],
    "GLM": [],
    "ZAI": []
  },
  "OpenrouterConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_supports_cache_control_in_content": [
      "self",
      "model"
    ],
    "remove_cache_control_flag_from_messages_and_tools": [
      "self",
      "model",
      "messages",
      "tools"
    ],
    "_move_cache_control_to_content": [
      "self",
      "messages"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "OpenRouterChatCompletionStreamingHandler": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "PerplexityResponsesConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "_transform_tools": [
      "self",
      "tools"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "_format_input": [
      "self",
      "input"
    ],
    "transform_response_api_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "_transform_usage": [
      "self",
      "usage_data"
    ],
    "transform_streaming_response": [
      "self",
      "model",
      "parsed_chunk",
      "logging_obj"
    ],
    "_transform_perplexity_chunk": [
      "self",
      "chunk"
    ]
  },
  "_PerplexitySearchRequestRequired": {},
  "PerplexitySearchRequest": {},
  "PerplexitySearchConfig": {
    "PERPLEXITY_API_BASE": [],
    "ui_friendly_name": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "PerplexityChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_enhance_usage_with_perplexity_fields": [
      "self",
      "model_response",
      "raw_response_json"
    ],
    "_add_citations_as_annotations": [
      "self",
      "model_response",
      "raw_response_json"
    ]
  },
  "StabilityImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_model_endpoint": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "use_multipart_form_data": [
      "self"
    ]
  },
  "get_stability_image_generation_config": [
    "model"
  ],
  "StabilityImageEditConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "_get_model_endpoint": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "api_key",
      "json_mode"
    ],
    "use_multipart_form_data": [
      "self"
    ]
  },
  "get_stability_image_edit_config": [
    "model"
  ],
  "cost_per_second": [
    "model",
    "custom_llm_provider",
    "duration"
  ],
  "video_generation_cost": [
    "model",
    "duration_seconds",
    "custom_llm_provider"
  ],
  "openaiOSeriesConfig": [],
  "openAIGPT5Config": [],
  "MistralEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ]
  },
  "OpenAIConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_completion_tokens",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "OpenAIChatCompletionResponseIterator": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "OpenAIChatCompletion": {
    "__init__": [
      "self"
    ],
    "_set_dynamic_params_on_client": [
      "self",
      "client",
      "organization",
      "max_retries"
    ],
    "_get_openai_client": [
      "self",
      "is_async",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "shared_session"
    ],
    "make_openai_chat_completion_request": [
      "self",
      "openai_aclient",
      "data",
      "timeout",
      "logging_obj"
    ],
    "make_sync_openai_chat_completion_request": [
      "self",
      "openai_client",
      "data",
      "timeout",
      "logging_obj"
    ],
    "_call_agentic_completion_hooks_openai": [
      "self",
      "response",
      "model",
      "messages",
      "optional_params",
      "logging_obj",
      "stream",
      "litellm_params"
    ],
    "mock_streaming": [
      "self",
      "response",
      "logging_obj",
      "model",
      "stream_options"
    ],
    "completion": [
      "self",
      "model_response",
      "timeout",
      "optional_params",
      "litellm_params",
      "logging_obj",
      "model",
      "messages",
      "print_verbose",
      "api_key",
      "api_base",
      "api_version",
      "dynamic_params",
      "azure_ad_token",
      "acompletion",
      "logger_fn",
      "headers",
      "custom_prompt_dict",
      "client",
      "organization",
      "custom_llm_provider",
      "drop_params",
      "shared_session"
    ],
    "acompletion": [
      "self",
      "messages",
      "optional_params",
      "litellm_params",
      "provider_config",
      "model",
      "model_response",
      "logging_obj",
      "timeout",
      "api_key",
      "api_base",
      "api_version",
      "organization",
      "client",
      "max_retries",
      "headers",
      "drop_params",
      "stream_options",
      "fake_stream",
      "shared_session"
    ],
    "streaming": [
      "self",
      "logging_obj",
      "timeout",
      "data",
      "model",
      "api_key",
      "api_base",
      "api_version",
      "organization",
      "client",
      "max_retries",
      "headers",
      "stream_options"
    ],
    "async_streaming": [
      "self",
      "timeout",
      "messages",
      "optional_params",
      "litellm_params",
      "provider_config",
      "model",
      "logging_obj",
      "api_key",
      "api_base",
      "api_version",
      "organization",
      "client",
      "max_retries",
      "headers",
      "drop_params",
      "stream_options",
      "shared_session"
    ],
    "get_stream_options": [
      "self",
      "stream_options",
      "api_base"
    ],
    "make_openai_embedding_request": [
      "self",
      "openai_aclient",
      "data",
      "timeout",
      "logging_obj"
    ],
    "make_sync_openai_embedding_request": [
      "self",
      "openai_client",
      "data",
      "timeout",
      "logging_obj"
    ],
    "aembedding": [
      "self",
      "input",
      "data",
      "model_response",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "client",
      "max_retries",
      "shared_session"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "timeout",
      "logging_obj",
      "model_response",
      "optional_params",
      "api_key",
      "api_base",
      "client",
      "aembedding",
      "max_retries",
      "shared_session"
    ],
    "aimage_generation": [
      "self",
      "prompt",
      "data",
      "model_response",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "client",
      "max_retries",
      "organization"
    ],
    "image_generation": [
      "self",
      "model",
      "prompt",
      "timeout",
      "optional_params",
      "logging_obj",
      "api_key",
      "api_base",
      "model_response",
      "client",
      "aimg_generation",
      "organization"
    ],
    "audio_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "api_key",
      "api_base",
      "organization",
      "project",
      "max_retries",
      "timeout",
      "aspeech",
      "client",
      "shared_session"
    ],
    "async_audio_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "api_key",
      "api_base",
      "organization",
      "project",
      "max_retries",
      "timeout",
      "client",
      "shared_session"
    ]
  },
  "OpenAIFilesAPI": {
    "__init__": [
      "self"
    ],
    "get_openai_client": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "_is_async"
    ],
    "acreate_file": [
      "self",
      "create_file_data",
      "openai_client"
    ],
    "create_file": [
      "self",
      "_is_async",
      "create_file_data",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "afile_content": [
      "self",
      "file_content_request",
      "openai_client"
    ],
    "file_content": [
      "self",
      "_is_async",
      "file_content_request",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "aretrieve_file": [
      "self",
      "file_id",
      "openai_client"
    ],
    "retrieve_file": [
      "self",
      "_is_async",
      "file_id",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "adelete_file": [
      "self",
      "file_id",
      "openai_client"
    ],
    "delete_file": [
      "self",
      "_is_async",
      "file_id",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "alist_files": [
      "self",
      "openai_client",
      "purpose"
    ],
    "list_files": [
      "self",
      "_is_async",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "organization",
      "purpose",
      "client"
    ]
  },
  "OpenAIBatchesAPI": {
    "__init__": [
      "self"
    ],
    "get_openai_client": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "_is_async"
    ],
    "acreate_batch": [
      "self",
      "create_batch_data",
      "openai_client"
    ],
    "create_batch": [
      "self",
      "_is_async",
      "create_batch_data",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "aretrieve_batch": [
      "self",
      "retrieve_batch_data",
      "openai_client"
    ],
    "retrieve_batch": [
      "self",
      "_is_async",
      "retrieve_batch_data",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "acancel_batch": [
      "self",
      "cancel_batch_data",
      "openai_client"
    ],
    "cancel_batch": [
      "self",
      "_is_async",
      "cancel_batch_data",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "alist_batches": [
      "self",
      "openai_client",
      "after",
      "limit"
    ],
    "list_batches": [
      "self",
      "_is_async",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "after",
      "limit",
      "client"
    ]
  },
  "OpenAIAssistantsAPI": {
    "__init__": [
      "self"
    ],
    "get_openai_client": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "async_get_openai_client": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "async_get_assistants": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "order",
      "limit",
      "before",
      "after"
    ],
    "get_assistants": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "aget_assistants",
      "order",
      "limit",
      "before",
      "after"
    ],
    "async_create_assistants": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "create_assistant_data"
    ],
    "create_assistants": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "create_assistant_data",
      "client",
      "async_create_assistants"
    ],
    "async_delete_assistant": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "assistant_id"
    ],
    "delete_assistant": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "assistant_id",
      "client",
      "async_delete_assistants"
    ],
    "a_add_message": [
      "self",
      "thread_id",
      "message_data",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "add_message": [
      "self",
      "thread_id",
      "message_data",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "a_add_message"
    ],
    "async_get_messages": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "get_messages": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "aget_messages"
    ],
    "async_create_thread": [
      "self",
      "metadata",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "messages"
    ],
    "create_thread": [
      "self",
      "metadata",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "messages",
      "client",
      "acreate_thread"
    ],
    "async_get_thread": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "get_thread": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "aget_thread"
    ],
    "delete_thread": [
      "self"
    ],
    "arun_thread": [
      "self",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "stream",
      "tools",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "async_run_thread_stream": [
      "self",
      "client",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "tools",
      "event_handler"
    ],
    "run_thread_stream": [
      "self",
      "client",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "tools",
      "event_handler"
    ],
    "run_thread": [
      "self",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "stream",
      "tools",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "arun_thread",
      "event_handler"
    ]
  },
  "_get_client_init_params": [
    "cls"
  ],
  "drop_params_from_unprocessable_entity_error": [
    "e",
    "data"
  ],
  "BaseOpenAILLM": {
    "get_cached_openai_client": [
      "client_initialization_params",
      "client_type"
    ],
    "set_cached_openai_client": [
      "openai_client",
      "client_type",
      "client_initialization_params"
    ],
    "get_openai_client_cache_key": [
      "client_initialization_params",
      "client_type"
    ],
    "get_openai_client_initialization_param_fields": [
      "client_type"
    ],
    "_get_async_http_client": [
      "shared_session"
    ],
    "_get_sync_http_client": []
  },
  "OpenAITextToSpeechHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "OpenAIWhisperAudioTranscriptionConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_audio_transcription_response": [
      "self",
      "raw_response"
    ]
  },
  "OpenAIGPTAudioTranscriptionConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ]
  },
  "OpenAIAudioTranscription": {
    "make_openai_audio_transcriptions_request": [
      "self",
      "openai_aclient",
      "data",
      "timeout"
    ],
    "make_sync_openai_audio_transcriptions_request": [
      "self",
      "openai_client",
      "data",
      "timeout"
    ],
    "audio_transcriptions": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params",
      "model_response",
      "timeout",
      "max_retries",
      "logging_obj",
      "api_key",
      "api_base",
      "client",
      "atranscription",
      "provider_config",
      "shared_session"
    ],
    "async_audio_transcriptions": [
      "self",
      "audio_file",
      "data",
      "model_response",
      "timeout",
      "logging_obj",
      "api_key",
      "api_base",
      "client",
      "max_retries",
      "shared_session"
    ]
  },
  "OpenAIAudioTranscriptionHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "OpenAIImageVariationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request_image_variation": [
      "self",
      "model",
      "image",
      "optional_params",
      "headers"
    ],
    "async_transform_response_image_variation": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "image",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key"
    ],
    "transform_response_image_variation": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "image",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "OpenAIImageVariationsHandler": {
    "get_sync_client": [
      "self",
      "client",
      "init_client_params"
    ],
    "get_async_client": [
      "self",
      "client",
      "init_client_params"
    ],
    "async_image_variations": [
      "self",
      "api_key",
      "api_base",
      "organization",
      "client",
      "data",
      "headers",
      "model",
      "timeout",
      "max_retries",
      "logging_obj",
      "model_response",
      "optional_params",
      "litellm_params",
      "image",
      "provider_config"
    ],
    "image_variations": [
      "self",
      "model_response",
      "api_key",
      "api_base",
      "model",
      "image",
      "timeout",
      "custom_llm_provider",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "print_verbose",
      "logger_fn",
      "client",
      "organization",
      "headers"
    ]
  },
  "OpenAIResponsesAPIConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "_validate_input_param": [
      "self",
      "input"
    ],
    "_handle_reasoning_item": [
      "self",
      "item"
    ],
    "transform_response_api_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_streaming_response": [
      "self",
      "model",
      "parsed_chunk",
      "logging_obj"
    ],
    "get_event_model_class": [
      "event_type"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "transform_delete_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_input_items_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "before",
      "include",
      "limit",
      "order"
    ],
    "transform_list_input_items_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_cancel_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_compact_response_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_compact_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "OpenAIResponsesHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "_extract_and_transform_tools": [
      "self",
      "tools",
      "tools_to_check"
    ],
    "_remap_tools_to_responses_api_format": [
      "self",
      "guardrailed_tools"
    ],
    "_merge_tools_after_guardrail": [
      "self",
      "original_tools",
      "remapped"
    ],
    "_apply_guardrailed_tools_to_data": [
      "self",
      "data",
      "original_tools",
      "guardrailed_tools"
    ],
    "_extract_input_text_and_images": [
      "self",
      "message",
      "msg_idx",
      "texts_to_check",
      "images_to_check",
      "task_mappings"
    ],
    "_apply_guardrail_responses_to_input": [
      "self",
      "messages",
      "responses",
      "task_mappings"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "process_output_streaming_response": [
      "self",
      "responses_so_far",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "_check_streaming_has_ended": [
      "self",
      "responses_so_far"
    ],
    "get_streaming_string_so_far": [
      "self",
      "responses_so_far"
    ],
    "_has_text_content": [
      "self",
      "response"
    ],
    "_extract_output_text_and_images": [
      "self",
      "output_item",
      "output_idx",
      "texts_to_check",
      "images_to_check",
      "task_mappings",
      "tool_calls_to_check"
    ],
    "_apply_guardrail_responses_to_output": [
      "self",
      "response",
      "responses",
      "task_mappings"
    ]
  },
  "OpenAIVectorStoreConfig": {
    "ASSISTANTS_HEADER_KEY": [],
    "ASSISTANTS_HEADER_VALUE": [],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "OpenAIEmbeddingsHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "_process_string_input": [
      "self",
      "data",
      "input_data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "_process_list_input": [
      "self",
      "data",
      "input_data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "OpenAIVideoConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "video_create_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_video_create_request": [
      "self",
      "model",
      "prompt",
      "api_base",
      "video_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_video_create_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "custom_llm_provider",
      "request_data"
    ],
    "transform_video_content_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_remix_request": [
      "self",
      "video_id",
      "prompt",
      "api_base",
      "litellm_params",
      "headers",
      "extra_body"
    ],
    "transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_remix_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_video_list_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_delete_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_status_retrieve_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_status_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "_add_image_to_files": [
      "self",
      "files_list",
      "image",
      "field_name"
    ]
  },
  "OpenAIRealtime": {
    "_get_default_api_base": [
      "self"
    ],
    "_get_additional_headers": [
      "self",
      "api_key"
    ],
    "_get_ssl_config": [
      "self",
      "url"
    ],
    "_construct_url": [
      "self",
      "api_base",
      "query_params"
    ],
    "async_realtime": [
      "self",
      "model",
      "websocket",
      "logging_obj",
      "api_base",
      "api_key",
      "client",
      "timeout",
      "query_params"
    ]
  },
  "OpenAIEvalsConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "endpoint",
      "eval_id"
    ],
    "transform_create_eval_request": [
      "self",
      "create_request",
      "litellm_params",
      "headers"
    ],
    "transform_create_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_evals_request": [
      "self",
      "list_params",
      "litellm_params",
      "headers"
    ],
    "transform_list_evals_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_eval_request": [
      "self",
      "eval_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_update_eval_request": [
      "self",
      "eval_id",
      "update_request",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_update_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_eval_request": [
      "self",
      "eval_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_cancel_eval_request": [
      "self",
      "eval_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_eval_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_create_run_request": [
      "self",
      "eval_id",
      "create_request",
      "litellm_params",
      "headers"
    ],
    "transform_create_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_runs_request": [
      "self",
      "eval_id",
      "list_params",
      "litellm_params",
      "headers"
    ],
    "transform_list_runs_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_run_request": [
      "self",
      "eval_id",
      "run_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_cancel_run_request": [
      "self",
      "eval_id",
      "run_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_run_request": [
      "self",
      "eval_id",
      "run_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_run_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "GPTImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "DallE2ImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "DallE3ImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "get_openai_image_generation_config": [
    "model"
  ],
  "OpenAIImageGenerationHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "is_tokens_or_list_of_tokens": [
    "value"
  ],
  "_transform_prompt": [
    "messages"
  ],
  "OpenAITextCompletionConfig": {
    "__init__": [
      "self",
      "best_of",
      "echo",
      "frequency_penalty",
      "logit_bias",
      "logprobs",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "suffix",
      "temperature",
      "top_p"
    ],
    "get_config": [
      "cls"
    ],
    "convert_to_chat_model_response_object": [
      "self",
      "response_object",
      "model_response_object"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "transform_text_completion_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "headers"
    ]
  },
  "OpenAITextCompletion": {
    "openai_text_completion_global_config": [],
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "api_key"
    ],
    "completion": [
      "self",
      "model_response",
      "api_key",
      "model",
      "messages",
      "timeout",
      "custom_llm_provider",
      "logging_obj",
      "optional_params",
      "print_verbose",
      "api_base",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "client",
      "organization",
      "headers"
    ],
    "acompletion": [
      "self",
      "logging_obj",
      "api_base",
      "data",
      "headers",
      "model_response",
      "api_key",
      "model",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "streaming": [
      "self",
      "logging_obj",
      "api_key",
      "data",
      "headers",
      "model_response",
      "model",
      "timeout",
      "api_base",
      "max_retries",
      "client",
      "organization"
    ],
    "async_streaming": [
      "self",
      "logging_obj",
      "api_key",
      "data",
      "headers",
      "model_response",
      "model",
      "timeout",
      "max_retries",
      "api_base",
      "client",
      "organization"
    ]
  },
  "OpenAITextCompletionHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "OpenAIContainerConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "container_create_optional_params",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_container_create_request": [
      "self",
      "name",
      "container_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_container_create_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_container_list_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_retrieve_request": [
      "self",
      "container_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_container_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_delete_request": [
      "self",
      "container_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_container_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_file_list_request": [
      "self",
      "container_id",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_container_file_list_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_container_file_content_request": [
      "self",
      "container_id",
      "file_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_container_file_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "OpenAIFineTuningAPI": {
    "__init__": [
      "self"
    ],
    "get_openai_client": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "_is_async",
      "api_version",
      "litellm_params"
    ],
    "acreate_fine_tuning_job": [
      "self",
      "create_fine_tuning_job_data",
      "openai_client"
    ],
    "create_fine_tuning_job": [
      "self",
      "_is_async",
      "create_fine_tuning_job_data",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "acancel_fine_tuning_job": [
      "self",
      "fine_tuning_job_id",
      "openai_client"
    ],
    "cancel_fine_tuning_job": [
      "self",
      "_is_async",
      "fine_tuning_job_id",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ],
    "alist_fine_tuning_jobs": [
      "self",
      "openai_client",
      "after",
      "limit"
    ],
    "list_fine_tuning_jobs": [
      "self",
      "_is_async",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "after",
      "limit"
    ],
    "aretrieve_fine_tuning_job": [
      "self",
      "fine_tuning_job_id",
      "openai_client"
    ],
    "retrieve_fine_tuning_job": [
      "self",
      "_is_async",
      "fine_tuning_job_id",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "organization",
      "client"
    ]
  },
  "_clean_dict": [
    "source"
  ],
  "OpenAIVectorStoreFilesConfig": {
    "ASSISTANTS_HEADER_KEY": [],
    "ASSISTANTS_HEADER_VALUE": [],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_file_endpoints_by_type": [
      "self"
    ],
    "validate_environment": [
      "self"
    ],
    "get_complete_url": [
      "self"
    ],
    "transform_create_vector_store_file_request": [
      "self"
    ],
    "transform_create_vector_store_file_response": [
      "self"
    ],
    "transform_list_vector_store_files_request": [
      "self"
    ],
    "transform_list_vector_store_files_response": [
      "self"
    ],
    "transform_retrieve_vector_store_file_request": [
      "self"
    ],
    "transform_retrieve_vector_store_file_response": [
      "self"
    ],
    "transform_retrieve_vector_store_file_content_request": [
      "self"
    ],
    "transform_retrieve_vector_store_file_content_response": [
      "self"
    ],
    "transform_update_vector_store_file_request": [
      "self"
    ],
    "transform_update_vector_store_file_response": [
      "self"
    ],
    "transform_delete_vector_store_file_request": [
      "self"
    ],
    "transform_delete_vector_store_file_response": [
      "self"
    ]
  },
  "OpenAIImageEditConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "_add_image_to_files": [
      "self",
      "files_list",
      "image",
      "field_name"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "get_openai_image_edit_config": [
    "model"
  ],
  "DallE2ImageEditConfig": {
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ]
  },
  "OpenAIGPT5Config": {
    "is_model_gpt_5_model": [
      "cls",
      "model"
    ],
    "is_model_gpt_5_codex_model": [
      "cls",
      "model"
    ],
    "is_model_gpt_5_1_codex_max_model": [
      "cls",
      "model"
    ],
    "is_model_gpt_5_1_model": [
      "cls",
      "model"
    ],
    "is_model_gpt_5_2_pro_model": [
      "cls",
      "model"
    ],
    "is_model_gpt_5_2_model": [
      "cls",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "OpenAIOSeriesConfig": {
    "get_config": [
      "cls"
    ],
    "translate_developer_role_to_system_role": [
      "self",
      "messages"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "is_model_o_series_model": [
      "self",
      "model"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ]
  },
  "OpenAIGPTConfig": {
    "_is_base_class": [],
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "contains_pdf_url": [
      "self",
      "content_item"
    ],
    "_handle_pdf_url": [
      "self",
      "content_item"
    ],
    "_async_handle_pdf_url": [
      "self",
      "content_item"
    ],
    "_common_file_data_check": [
      "self",
      "content_item"
    ],
    "_apply_common_transform_content_item": [
      "self",
      "content_item"
    ],
    "_transform_content_item": [
      "self",
      "content_item"
    ],
    "_async_transform_content_item": [
      "self",
      "content_item",
      "is_async"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "remove_cache_control_flag_from_messages_and_tools": [
      "self",
      "model",
      "messages",
      "tools"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "async_transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_passed_in_tools": [
      "self",
      "optional_params"
    ],
    "_check_and_fix_if_content_is_tool_call": [
      "self",
      "content",
      "optional_params"
    ],
    "_get_finish_reason": [
      "self",
      "message",
      "received_finish_reason"
    ],
    "_transform_choices": [
      "self",
      "choices",
      "json_mode",
      "optional_params"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_base_model": [
      "model"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "OpenAIChatCompletionStreamingHandler": {
    "_map_reasoning_to_reasoning_content": [
      "self",
      "choices"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "OpenAIGPTAudioConfig": {
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "is_model_gpt_audio_model": [
      "self",
      "model"
    ],
    "_map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "OpenAIChatCompletionsHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "_extract_inputs": [
      "self",
      "message",
      "msg_idx",
      "texts_to_check",
      "images_to_check",
      "tool_calls_to_check",
      "text_task_mappings",
      "tool_call_task_mappings"
    ],
    "_apply_guardrail_responses_to_input_texts": [
      "self",
      "messages",
      "responses",
      "task_mappings"
    ],
    "_apply_guardrail_responses_to_input_tool_calls": [
      "self",
      "messages",
      "tool_calls",
      "task_mappings"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "process_output_streaming_response": [
      "self",
      "responses_so_far",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ],
    "_combine_streaming_texts": [
      "self",
      "responses_so_far"
    ],
    "_has_text_content": [
      "self",
      "response"
    ],
    "_extract_output_text_images_and_tool_calls": [
      "self",
      "choice",
      "choice_idx",
      "texts_to_check",
      "images_to_check",
      "tool_calls_to_check",
      "text_task_mappings",
      "tool_call_task_mappings"
    ],
    "_convert_tool_call_to_dict": [
      "self",
      "tool_call"
    ],
    "_apply_guardrail_responses_to_output_texts": [
      "self",
      "response",
      "responses",
      "task_mappings"
    ],
    "_apply_guardrail_responses_to_output_tool_calls": [
      "self",
      "response",
      "tool_calls",
      "task_mappings"
    ],
    "_apply_guardrail_responses_to_output_streaming": [
      "self",
      "responses",
      "guardrailed_texts",
      "task_mappings"
    ]
  },
  "_ISO_YMD": [],
  "_UNIX_TIMESTAMP": [],
  "BRAVE_SECTIONS": [],
  "to_yyyy_mm_dd": [
    "s"
  ],
  "_BraveSearchRequestRequired": {},
  "BraveSearchRequest": {},
  "BraveSearchConfig": {
    "BRAVE_API_BASE": [],
    "ui_friendly_name": [],
    "get_http_method": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params",
      "api_key",
      "search_engine_id"
    ],
    "_append_domain_filters": [
      "query",
      "domains"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "_sections_from_params": [
      "query_params"
    ]
  },
  "WandbConfig": {
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "VolcEngineConfig": [],
  "VolcEngineError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "get_volcengine_base_url": [
    "api_base"
  ],
  "get_volcengine_headers": [
    "api_key",
    "extra_headers"
  ],
  "VolcEngineResponsesAPIConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_streaming_response": [
      "self",
      "model",
      "parsed_chunk",
      "logging_obj"
    ],
    "transform_response_api_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "transform_delete_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_delete_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_get_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_list_input_items_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "before",
      "include",
      "limit",
      "order"
    ],
    "transform_list_input_items_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_cancel_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "_fill_missing_fields": [
      "chunk",
      "event_model"
    ],
    "_default_for_annotation": [
      "annotation"
    ],
    "_maybe_fill_nested": [
      "value",
      "annotation"
    ],
    "_pick_model_class": [
      "annotation",
      "value"
    ]
  },
  "VolcEngineEmbeddingConfig": {
    "__init__": [
      "self",
      "encoding_format"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "VolcEngineChatConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "replace_max_completion_tokens_with_max_tokens"
    ]
  },
  "_DuckDuckGoSearchRequestRequired": {},
  "DuckDuckGoSearchRequest": {},
  "DuckDuckGoSearchConfig": {
    "DUCKDUCKGO_API_BASE": [],
    "ui_friendly_name": [],
    "get_http_method": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "EmpowerChatConfig": {},
  "_FirecrawlSearchRequestRequired": {},
  "FirecrawlSearchRequest": {},
  "FirecrawlSearchConfig": {
    "FIRECRAWL_API_BASE": [],
    "ui_friendly_name": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "VoyageError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "VoyageEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "VoyageContextualEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "is_contextualized_embeddings": [
      "model"
    ]
  },
  "VoyageRerankConfig": {
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "calculate_rerank_cost": [
      "self",
      "model",
      "custom_llm_provider",
      "billed_units",
      "model_info"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "LLMGW_PATH": [],
  "DataRobotConfig": {
    "_resolve_api_key": [
      "api_key"
    ],
    "_resolve_api_base": [
      "api_base"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "MinimaxMessagesConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "MinimaxChatConfig": {
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "remove_cache_control_flag_from_messages_and_tools": [
      "self",
      "model",
      "messages",
      "tools"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "MinimaxException": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "MinimaxTextToSpeechConfig": {
    "TTS_BASE_URL": [],
    "TTS_ENDPOINT_PATH": [],
    "VOICE_MAPPINGS": [],
    "FORMAT_MAPPINGS": [],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_extract_voice_id": [
      "self",
      "voice"
    ],
    "_resolve_voice_id": [
      "self",
      "voice",
      "params"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "ElevenLabsException": {},
  "ElevenLabsAudioTranscriptionConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ],
    "transform_audio_transcription_response": [
      "self",
      "raw_response"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "ElevenLabsTextToSpeechConfig": {
    "TTS_BASE_URL": [],
    "TTS_ENDPOINT_PATH": [],
    "DEFAULT_OUTPUT_FORMAT": [],
    "VOICE_MAPPINGS": [],
    "FORMAT_MAPPINGS": [],
    "ELEVENLABS_QUERY_PARAMS_KEY": [],
    "ELEVENLABS_VOICE_ID_KEY": [],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_extract_voice_id": [
      "self",
      "voice"
    ],
    "_resolve_voice_id": [
      "self",
      "voice",
      "params"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_add_elevenlabs_specific_params": [
      "self",
      "mapped_voice",
      "query_params",
      "mapped_params",
      "kwargs",
      "remaining_params"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "PredibaseError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response",
      "headers"
    ]
  },
  "PredibaseConfig": {
    "__init__": [
      "self",
      "best_of",
      "decoder_input_details",
      "details",
      "max_new_tokens",
      "repetition_penalty",
      "return_full_text",
      "seed",
      "stop",
      "temperature",
      "top_k",
      "top_p",
      "truncate",
      "typical_p",
      "watermark"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "PredibaseChatCompletion": {
    "__init__": [
      "self"
    ],
    "output_parser": [
      "self",
      "generated_text"
    ],
    "process_response": [
      "self",
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "print_verbose",
      "encoding"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "tenant_id",
      "timeout",
      "acompletion",
      "logger_fn",
      "headers"
    ],
    "async_completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "stream",
      "data",
      "optional_params",
      "timeout",
      "litellm_params",
      "logger_fn",
      "headers"
    ],
    "async_streaming": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "data",
      "timeout",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers"
    ],
    "embedding": [
      "self"
    ]
  },
  "NLPCloudError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "NLPCloudConfig": {
    "__init__": [
      "self",
      "max_length",
      "length_no_input",
      "end_sequence",
      "remove_end_sequence",
      "remove_input",
      "bad_words",
      "temperature",
      "top_p",
      "top_k",
      "repetition_penalty",
      "num_beams",
      "num_return_sequences"
    ],
    "get_config": [
      "cls"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "nlp_config": [],
  "clean_and_iterate_chunks": [
    "response"
  ],
  "HyperbolicChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ]
  },
  "HF_HUB_URL": [],
  "HuggingFaceError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response",
      "headers"
    ]
  },
  "hf_tasks": [],
  "hf_task_list": [],
  "output_parser": [
    "generated_text"
  ],
  "_fetch_inference_provider_mapping": [
    "model"
  ],
  "tgi_models_cache": [],
  "conv_models_cache": [],
  "HuggingFaceEmbeddingConfig": {
    "__init__": [
      "self",
      "best_of",
      "decoder_input_details",
      "details",
      "max_new_tokens",
      "repetition_penalty",
      "return_full_text",
      "seed",
      "temperature",
      "top_k",
      "top_n_tokens",
      "top_p",
      "truncate",
      "typical_p",
      "watermark"
    ],
    "get_config": [
      "cls"
    ],
    "get_special_options_params": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_hf_api_key": [
      "self"
    ],
    "read_tgi_conv_models": [
      "self"
    ],
    "get_hf_task_for_model": [
      "self",
      "model"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "get_api_base": [
      "self",
      "api_base",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "_convert_streamed_response_to_complete_response": [
      "self",
      "response",
      "logging_obj",
      "model",
      "data",
      "api_key"
    ],
    "convert_to_model_response_object": [
      "self",
      "completion_response",
      "model_response",
      "task",
      "optional_params",
      "encoding",
      "messages",
      "model"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "config": [],
  "hf_tasks_embeddings": [],
  "get_hf_task_embedding_for_model": [
    "model",
    "task_type",
    "api_base"
  ],
  "async_get_hf_task_embedding_for_model": [
    "model",
    "task_type",
    "api_base"
  ],
  "HuggingFaceEmbedding": {
    "__init__": [
      "self"
    ],
    "_transform_input_on_pipeline_tag": [
      "self",
      "input",
      "pipeline_tag"
    ],
    "_async_transform_input": [
      "self",
      "model",
      "task_type",
      "embed_url",
      "input",
      "optional_params"
    ],
    "_process_optional_params": [
      "self",
      "data",
      "optional_params"
    ],
    "_transform_input": [
      "self",
      "input",
      "model",
      "call_type",
      "optional_params",
      "embed_url"
    ],
    "_process_embedding_response": [
      "self",
      "embeddings",
      "model_response",
      "model",
      "input",
      "encoding"
    ],
    "aembedding": [
      "self",
      "model",
      "input",
      "model_response",
      "timeout",
      "logging_obj",
      "optional_params",
      "api_base",
      "api_key",
      "headers",
      "encoding",
      "client"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "model_response",
      "optional_params",
      "litellm_params",
      "logging_obj",
      "encoding",
      "api_key",
      "api_base",
      "timeout",
      "aembedding",
      "client",
      "headers"
    ]
  },
  "HuggingFaceRerankResponseItem": {},
  "HuggingFaceRerankResponse": {},
  "HuggingFaceRerankResponseList": [],
  "HuggingFaceRerankConfig": {
    "get_api_base": [
      "self",
      "model",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params",
      "api_base"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_api_credentials": [
      "self",
      "api_key",
      "api_base"
    ]
  },
  "_build_chat_completion_url": [
    "model_url"
  ],
  "HuggingFaceChatConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_base_url": [
      "self",
      "model",
      "base_url"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "BasetenConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "response_format",
      "seed",
      "stop",
      "stream",
      "temperature",
      "top_p",
      "tool_choice",
      "tools",
      "user",
      "presence_penalty",
      "frequency_penalty",
      "stream_options"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "is_dedicated_deployment": [
      "model"
    ],
    "get_api_base_for_model": [
      "model"
    ]
  },
  "TopazException": {},
  "TopazModelInfo": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_base_model": [
      "model"
    ]
  },
  "TopazImageVariationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "prepare_file_tuple": [
      "self",
      "file_data"
    ],
    "transform_request_image_variation": [
      "self",
      "model",
      "image",
      "optional_params",
      "headers"
    ],
    "_common_transform_response_image_variation": [
      "self",
      "image_content",
      "response_ms"
    ],
    "async_transform_response_image_variation": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "image",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key"
    ],
    "transform_response_image_variation": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "image",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "AzureAssistantsAPI": {
    "__init__": [
      "self"
    ],
    "get_azure_client": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "async_get_azure_client": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "async_get_assistants": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "get_assistants": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "aget_assistants",
      "litellm_params"
    ],
    "a_add_message": [
      "self",
      "thread_id",
      "message_data",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "add_message": [
      "self",
      "thread_id",
      "message_data",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "a_add_message",
      "litellm_params"
    ],
    "async_get_messages": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "get_messages": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "aget_messages",
      "litellm_params"
    ],
    "async_create_thread": [
      "self",
      "metadata",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "messages",
      "litellm_params"
    ],
    "create_thread": [
      "self",
      "metadata",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "messages",
      "client",
      "acreate_thread",
      "litellm_params"
    ],
    "async_get_thread": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "get_thread": [
      "self",
      "thread_id",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "aget_thread",
      "litellm_params"
    ],
    "arun_thread": [
      "self",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "stream",
      "tools",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "async_run_thread_stream": [
      "self",
      "client",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "tools",
      "event_handler",
      "litellm_params"
    ],
    "run_thread_stream": [
      "self",
      "client",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "tools",
      "event_handler",
      "litellm_params"
    ],
    "run_thread": [
      "self",
      "thread_id",
      "assistant_id",
      "additional_instructions",
      "instructions",
      "metadata",
      "model",
      "stream",
      "tools",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "arun_thread",
      "event_handler",
      "litellm_params"
    ],
    "async_create_assistants": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "create_assistant_data",
      "litellm_params"
    ],
    "create_assistants": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "create_assistant_data",
      "client",
      "async_create_assistants",
      "litellm_params"
    ],
    "async_delete_assistant": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "client",
      "assistant_id",
      "litellm_params"
    ],
    "delete_assistant": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "timeout",
      "max_retries",
      "assistant_id",
      "async_delete_assistants",
      "client",
      "litellm_params"
    ]
  },
  "AzureOpenAIAssistantsAPIConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_create_message_params": [
      "self"
    ],
    "map_openai_params_create_message_params": [
      "self",
      "non_default_params",
      "optional_params"
    ]
  },
  "_check_dynamic_azure_params": [
    "azure_client_params",
    "azure_client"
  ],
  "AzureChatCompletion": {
    "__init__": [
      "self"
    ],
    "make_sync_azure_openai_chat_completion_request": [
      "self",
      "azure_client",
      "data",
      "timeout"
    ],
    "make_azure_openai_chat_completion_request": [
      "self",
      "azure_client",
      "data",
      "timeout",
      "logging_obj"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "api_key",
      "api_base",
      "api_version",
      "api_type",
      "azure_ad_token",
      "azure_ad_token_provider",
      "dynamic_params",
      "print_verbose",
      "timeout",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "acompletion",
      "headers",
      "client"
    ],
    "acompletion": [
      "self",
      "api_key",
      "api_version",
      "model",
      "api_base",
      "data",
      "timeout",
      "dynamic_params",
      "model_response",
      "logging_obj",
      "max_retries",
      "azure_ad_token",
      "azure_ad_token_provider",
      "convert_tool_call_to_json_mode",
      "client",
      "litellm_params"
    ],
    "streaming": [
      "self",
      "logging_obj",
      "api_base",
      "api_key",
      "api_version",
      "dynamic_params",
      "data",
      "model",
      "timeout",
      "max_retries",
      "azure_ad_token",
      "azure_ad_token_provider",
      "client",
      "litellm_params"
    ],
    "async_streaming": [
      "self",
      "logging_obj",
      "api_base",
      "api_key",
      "api_version",
      "dynamic_params",
      "data",
      "model",
      "timeout",
      "max_retries",
      "azure_ad_token",
      "azure_ad_token_provider",
      "client",
      "litellm_params"
    ],
    "aembedding": [
      "self",
      "model",
      "data",
      "model_response",
      "input",
      "logging_obj",
      "api_base",
      "api_key",
      "api_version",
      "client",
      "timeout",
      "max_retries",
      "azure_ad_token",
      "azure_ad_token_provider",
      "litellm_params"
    ],
    "embedding": [
      "self",
      "model",
      "input",
      "api_base",
      "api_version",
      "timeout",
      "logging_obj",
      "model_response",
      "optional_params",
      "api_key",
      "azure_ad_token",
      "azure_ad_token_provider",
      "max_retries",
      "client",
      "aembedding",
      "headers",
      "litellm_params"
    ],
    "make_async_azure_httpx_request": [
      "self",
      "client",
      "timeout",
      "api_base",
      "api_version",
      "api_key",
      "data",
      "headers"
    ],
    "make_sync_azure_httpx_request": [
      "self",
      "client",
      "timeout",
      "api_base",
      "api_version",
      "api_key",
      "data",
      "headers"
    ],
    "create_azure_base_url": [
      "self",
      "azure_client_params",
      "model"
    ],
    "aimage_generation": [
      "self",
      "data",
      "model_response",
      "azure_client_params",
      "api_key",
      "input",
      "logging_obj",
      "headers",
      "client",
      "timeout",
      "model"
    ],
    "image_generation": [
      "self",
      "prompt",
      "timeout",
      "optional_params",
      "logging_obj",
      "headers",
      "model",
      "api_key",
      "api_base",
      "api_version",
      "model_response",
      "azure_ad_token",
      "azure_ad_token_provider",
      "client",
      "aimg_generation",
      "litellm_params"
    ],
    "audio_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "api_key",
      "api_base",
      "api_version",
      "organization",
      "max_retries",
      "timeout",
      "azure_ad_token",
      "azure_ad_token_provider",
      "aspeech",
      "client",
      "litellm_params"
    ],
    "async_audio_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "api_key",
      "api_base",
      "api_version",
      "azure_ad_token",
      "azure_ad_token_provider",
      "max_retries",
      "timeout",
      "client",
      "litellm_params"
    ],
    "get_headers": [
      "self",
      "model",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "mode",
      "messages",
      "input",
      "prompt"
    ]
  },
  "AzureAudioTranscription": {
    "audio_transcriptions": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "logging_obj",
      "model_response",
      "timeout",
      "max_retries",
      "api_key",
      "api_base",
      "api_version",
      "client",
      "azure_ad_token",
      "atranscription",
      "litellm_params"
    ],
    "async_audio_transcriptions": [
      "self",
      "audio_file",
      "model",
      "data",
      "model_response",
      "timeout",
      "logging_obj",
      "api_version",
      "api_key",
      "api_base",
      "client",
      "max_retries",
      "litellm_params"
    ]
  },
  "AzureOpenAIExceptionMapping": {
    "create_content_policy_violation_error": [
      "message",
      "model",
      "extra_information",
      "original_exception"
    ],
    "_extract_azure_error": [
      "original_exception"
    ]
  },
  "azure_ad_cache": [],
  "AzureOpenAIError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response",
      "headers",
      "body"
    ]
  },
  "process_azure_headers": [
    "headers"
  ],
  "get_azure_ad_token_from_entra_id": [
    "tenant_id",
    "client_id",
    "client_secret",
    "scope"
  ],
  "get_azure_ad_token_from_username_password": [
    "client_id",
    "azure_username",
    "azure_password",
    "scope"
  ],
  "get_azure_ad_token_from_oidc": [
    "azure_ad_token",
    "azure_client_id",
    "azure_tenant_id",
    "scope"
  ],
  "select_azure_base_url_or_endpoint": [
    "azure_client_params"
  ],
  "get_azure_ad_token": [
    "litellm_params"
  ],
  "BaseAzureLLM": {
    "_try_get_default_azure_credential_provider": [
      "scope"
    ],
    "get_azure_openai_client": [
      "self",
      "api_key",
      "api_base",
      "api_version",
      "client",
      "litellm_params",
      "_is_async",
      "model"
    ],
    "initialize_azure_sdk_client": [
      "self",
      "litellm_params",
      "api_key",
      "api_base",
      "model_name",
      "api_version",
      "is_async"
    ],
    "_init_azure_client_for_cloudflare_ai_gateway": [
      "self",
      "api_base",
      "model",
      "api_version",
      "max_retries",
      "timeout",
      "litellm_params",
      "api_key",
      "azure_ad_token",
      "azure_ad_token_provider",
      "acompletion",
      "client"
    ],
    "_base_validate_azure_environment": [
      "headers",
      "litellm_params"
    ],
    "_get_base_azure_url": [
      "api_base",
      "litellm_params",
      "route",
      "default_api_version"
    ],
    "_is_azure_v1_api_version": [
      "api_version"
    ],
    "_resolve_env_var": [
      "self",
      "litellm_params",
      "param_key",
      "env_var_key"
    ]
  },
  "AzureBatchesAPI": {
    "__init__": [
      "self"
    ],
    "acreate_batch": [
      "self",
      "create_batch_data",
      "azure_client"
    ],
    "create_batch": [
      "self",
      "_is_async",
      "create_batch_data",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "aretrieve_batch": [
      "self",
      "retrieve_batch_data",
      "client"
    ],
    "retrieve_batch": [
      "self",
      "_is_async",
      "retrieve_batch_data",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "acancel_batch": [
      "self",
      "cancel_batch_data",
      "client"
    ],
    "cancel_batch": [
      "self",
      "_is_async",
      "cancel_batch_data",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "alist_batches": [
      "self",
      "client",
      "after",
      "limit"
    ],
    "list_batches": [
      "self",
      "_is_async",
      "api_key",
      "api_base",
      "api_version",
      "timeout",
      "max_retries",
      "after",
      "limit",
      "client",
      "litellm_params"
    ]
  },
  "AzureOpenAIOSeriesResponsesAPIConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "is_o_series_model": [
      "self",
      "model"
    ]
  },
  "AzureOpenAIResponsesAPIConfig": {
    "AZURE_UNSUPPORTED_PARAMS": [],
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_stripped_model_name": [
      "self",
      "model"
    ],
    "_handle_reasoning_item": [
      "self",
      "item"
    ],
    "_validate_input_param": [
      "self",
      "input"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "_construct_url_for_response_id_in_path": [
      "self",
      "api_base",
      "response_id"
    ],
    "transform_delete_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_get_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_list_input_items_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "before",
      "include",
      "limit",
      "order"
    ],
    "transform_cancel_response_api_request": [
      "self",
      "response_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_cancel_response_api_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "AzureOpenAIVectorStoreConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ]
  },
  "AzureVideoConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "video_create_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "forward_messages": [
    "client_ws",
    "backend_ws"
  ],
  "AzureOpenAIRealtime": {
    "_construct_url": [
      "self",
      "api_base",
      "model",
      "api_version",
      "realtime_protocol"
    ],
    "async_realtime": [
      "self",
      "model",
      "websocket",
      "logging_obj",
      "api_base",
      "api_key",
      "api_version",
      "azure_ad_token",
      "client",
      "timeout",
      "realtime_protocol"
    ]
  },
  "AzureGPTImageGenerationConfig": {},
  "AzureDallE2ImageGenerationConfig": {},
  "AzureDallE3ImageGenerationConfig": {},
  "get_azure_image_generation_config": [
    "model"
  ],
  "AzurePassthroughConfig": {
    "is_streaming_request": [
      "self",
      "endpoint",
      "request_data"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "endpoint",
      "request_query_params",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_base_model": [
      "model"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ]
  },
  "AzureOpenAITextConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p"
    ]
  },
  "openai_text_completion_config": [],
  "AzureTextCompletion": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "api_key",
      "azure_ad_token"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "model_response",
      "api_key",
      "api_base",
      "api_version",
      "api_type",
      "azure_ad_token",
      "azure_ad_token_provider",
      "print_verbose",
      "timeout",
      "logging_obj",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "acompletion",
      "headers",
      "client"
    ],
    "acompletion": [
      "self",
      "api_key",
      "api_version",
      "model",
      "api_base",
      "data",
      "timeout",
      "model_response",
      "logging_obj",
      "max_retries",
      "azure_ad_token",
      "client",
      "litellm_params"
    ],
    "streaming": [
      "self",
      "logging_obj",
      "api_base",
      "api_key",
      "api_version",
      "data",
      "model",
      "timeout",
      "azure_ad_token",
      "client",
      "litellm_params"
    ],
    "async_streaming": [
      "self",
      "logging_obj",
      "api_base",
      "api_key",
      "api_version",
      "data",
      "model",
      "timeout",
      "azure_ad_token",
      "client",
      "litellm_params"
    ]
  },
  "AzureOpenAIFilesAPI": {
    "__init__": [
      "self"
    ],
    "_prepare_create_file_data": [
      "create_file_data"
    ],
    "acreate_file": [
      "self",
      "create_file_data",
      "openai_client"
    ],
    "create_file": [
      "self",
      "_is_async",
      "create_file_data",
      "api_base",
      "api_key",
      "api_version",
      "timeout",
      "max_retries",
      "client",
      "litellm_params"
    ],
    "afile_content": [
      "self",
      "file_content_request",
      "openai_client"
    ],
    "file_content": [
      "self",
      "_is_async",
      "file_content_request",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "api_version",
      "client",
      "litellm_params"
    ],
    "aretrieve_file": [
      "self",
      "file_id",
      "openai_client"
    ],
    "retrieve_file": [
      "self",
      "_is_async",
      "file_id",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "api_version",
      "client",
      "litellm_params"
    ],
    "adelete_file": [
      "self",
      "file_id",
      "openai_client"
    ],
    "delete_file": [
      "self",
      "_is_async",
      "file_id",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "organization",
      "api_version",
      "client",
      "litellm_params"
    ],
    "alist_files": [
      "self",
      "openai_client",
      "purpose"
    ],
    "list_files": [
      "self",
      "_is_async",
      "api_base",
      "api_key",
      "timeout",
      "max_retries",
      "purpose",
      "api_version",
      "client",
      "litellm_params"
    ]
  },
  "AzureOpenAIFineTuningAPI": {
    "get_openai_client": [
      "self",
      "api_key",
      "api_base",
      "timeout",
      "max_retries",
      "organization",
      "client",
      "_is_async",
      "api_version",
      "litellm_params"
    ]
  },
  "AzureImageEditConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ]
  },
  "AzureOpenAIGPT5Config": {
    "GPT5_SERIES_ROUTE": [],
    "is_model_gpt_5_model": [
      "cls",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "api_version"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "AzureOpenAIO1Config": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_get_o_series_only_params": [
      "self",
      "model"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ],
    "is_o_series_model": [
      "self",
      "model"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "AzureOpenAIConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_is_response_format_supported_model": [
      "self",
      "model"
    ],
    "_is_response_format_supported_api_version": [
      "self",
      "api_version_year",
      "api_version_month"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "api_version"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_mapped_special_auth_params": [
      "self"
    ],
    "map_special_auth_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "get_eu_regions": [
      "self"
    ],
    "get_us_regions": [
      "self"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "AzureOpenAIO1ChatCompletion": {
    "completion": [
      "self",
      "model_response",
      "timeout",
      "optional_params",
      "litellm_params",
      "logging_obj",
      "model",
      "messages",
      "print_verbose",
      "api_key",
      "api_base",
      "api_version",
      "dynamic_params",
      "azure_ad_token",
      "acompletion",
      "logger_fn",
      "headers",
      "custom_prompt_dict",
      "client",
      "organization",
      "custom_llm_provider",
      "drop_params",
      "shared_session"
    ]
  },
  "AzureAVATextToSpeechConfig": {
    "DEFAULT_VOICE": [],
    "COGNITIVE_SERVICES_DOMAIN": [],
    "TTS_SPEECH_DOMAIN": [],
    "TTS_ENDPOINT_PATH": [],
    "VOICE_MAPPINGS": [],
    "FORMAT_MAPPINGS": [],
    "dispatch_text_to_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params_dict",
      "logging_obj",
      "timeout",
      "extra_headers",
      "base_llm_http_handler",
      "aspeech",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_convert_speed_to_azure_rate": [
      "self",
      "speed"
    ],
    "_build_express_as_element": [
      "self",
      "content",
      "style",
      "styledegree",
      "role"
    ],
    "_get_voice_language": [
      "self",
      "voice_name",
      "explicit_lang"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "_is_cognitive_services_endpoint": [
      "self",
      "hostname"
    ],
    "_is_tts_endpoint": [
      "self",
      "hostname"
    ],
    "_extract_region_from_hostname": [
      "self",
      "hostname",
      "domain"
    ],
    "_build_tts_url": [
      "self",
      "region"
    ],
    "is_ssml_input": [
      "self",
      "input"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "RecraftImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "get_recraft_image_generation_config": [
    "model"
  ],
  "RecraftImageEditConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "_get_image_files_for_request": [
      "self",
      "image"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "LmStudioEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ]
  },
  "LMStudioChatConfig": {
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "MoonshotChatConfig": {
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_add_tool_choice_required_message": [
      "self",
      "messages",
      "optional_params"
    ]
  },
  "OobaboogaError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "OobaboogaConfig": {
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ]
  },
  "oobabooga_config": [],
  "AmazonNovaChatConfig": {
    "__init__": [
      "self",
      "max_completion_tokens",
      "max_tokens",
      "temperature",
      "top_p",
      "tools",
      "reasoning_effort"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AWSPollyTextToSpeechConfig": {
    "__init__": [
      "self"
    ],
    "DEFAULT_VOICE": [],
    "DEFAULT_ENGINE": [],
    "DEFAULT_OUTPUT_FORMAT": [],
    "DEFAULT_REGION": [],
    "VOICE_MAPPINGS": [],
    "FORMAT_MAPPINGS": [],
    "VALID_ENGINES": [],
    "dispatch_text_to_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params_dict",
      "logging_obj",
      "timeout",
      "extra_headers",
      "base_llm_http_handler",
      "aspeech",
      "api_base",
      "api_key"
    ],
    "_get_aws_region_name_for_polly": [
      "self",
      "optional_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "_extract_engine_from_model": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "is_ssml_input": [
      "self",
      "input"
    ],
    "_sign_polly_request": [
      "self",
      "request_body",
      "endpoint_url",
      "litellm_params"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "GaladrielChatConfig": {},
  "RunwayMLVideoConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "video_create_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "transform_video_create_request": [
      "self",
      "model",
      "prompt",
      "api_base",
      "video_create_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_video_create_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "custom_llm_provider",
      "request_data"
    ],
    "_map_runway_status": [
      "self",
      "runway_status"
    ],
    "_parse_runway_timestamp": [
      "self",
      "timestamp_str"
    ],
    "transform_video_content_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "_extract_video_url_from_response": [
      "self",
      "response_data"
    ],
    "transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "async_transform_video_content_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_remix_request": [
      "self",
      "video_id",
      "prompt",
      "api_base",
      "litellm_params",
      "headers",
      "extra_body"
    ],
    "transform_video_remix_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_list_request": [
      "self",
      "api_base",
      "litellm_params",
      "headers",
      "after",
      "limit",
      "order",
      "extra_query"
    ],
    "transform_video_list_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "transform_video_delete_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_delete_response": [
      "self",
      "raw_response",
      "logging_obj"
    ],
    "transform_video_status_retrieve_request": [
      "self",
      "video_id",
      "api_base",
      "litellm_params",
      "headers"
    ],
    "transform_video_status_retrieve_response": [
      "self",
      "raw_response",
      "logging_obj",
      "custom_llm_provider"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "RunwayMLImageGenerationConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_transform_runwayml_response_to_openai": [
      "response_data",
      "model_response"
    ],
    "_check_timeout": [
      "start_time",
      "timeout_secs"
    ],
    "_check_task_status": [
      "response_data"
    ],
    "_poll_task_sync": [
      "self",
      "task_id",
      "api_base",
      "headers",
      "timeout_secs"
    ],
    "_poll_task_async": [
      "self",
      "task_id",
      "api_base",
      "headers",
      "timeout_secs"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "async_transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "get_runwayml_image_generation_config": [
    "model"
  ],
  "RunwayMLTextToSpeechConfig": {
    "VOICE_MAPPINGS": [],
    "dispatch_text_to_speech": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params_dict",
      "logging_obj",
      "timeout",
      "extra_headers",
      "base_llm_http_handler",
      "aspeech",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "model",
      "optional_params",
      "voice",
      "drop_params",
      "kwargs"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "_check_timeout": [
      "start_time",
      "timeout_secs"
    ],
    "_check_task_status": [
      "response_data"
    ],
    "_poll_task_sync": [
      "self",
      "task_id",
      "api_base",
      "headers",
      "timeout_secs"
    ],
    "_poll_task_async": [
      "self",
      "task_id",
      "api_base",
      "headers",
      "timeout_secs"
    ],
    "transform_text_to_speech_request": [
      "self",
      "model",
      "input",
      "voice",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "async_transform_text_to_speech_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "CompactifAIChatConfig": {
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "Boto3CredentialsInfo": {},
  "AwsAuthError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "BaseAWSLLM": {
    "__init__": [
      "self"
    ],
    "_get_ssl_verify": [
      "self",
      "ssl_verify"
    ],
    "get_cache_key": [
      "self",
      "credential_args"
    ],
    "get_credentials": [
      "self",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_session_token",
      "aws_region_name",
      "aws_session_name",
      "aws_profile_name",
      "aws_role_name",
      "aws_web_identity_token",
      "aws_sts_endpoint",
      "aws_external_id",
      "ssl_verify"
    ],
    "_get_aws_region_from_model_arn": [
      "self",
      "model"
    ],
    "_get_provider_from_model_path": [
      "model_path"
    ],
    "get_bedrock_invoke_provider": [
      "model"
    ],
    "get_bedrock_model_id": [
      "optional_params",
      "provider",
      "model"
    ],
    "_get_model_id_from_model_with_spec": [
      "model",
      "spec"
    ],
    "encode_model_id": [
      "model_id"
    ],
    "get_bedrock_embedding_provider": [
      "model"
    ],
    "_get_aws_region_name": [
      "self",
      "optional_params",
      "model",
      "model_id"
    ],
    "get_aws_region_name_for_non_llm_api_calls": [
      "self",
      "aws_region_name"
    ],
    "_parse_arn_account_and_role_name": [
      "arn"
    ],
    "_is_already_running_as_role": [
      "self",
      "aws_role_name",
      "ssl_verify"
    ],
    "_auth_with_web_identity_token": [
      "self",
      "aws_web_identity_token",
      "aws_role_name",
      "aws_session_name",
      "aws_region_name",
      "aws_sts_endpoint",
      "aws_external_id",
      "ssl_verify"
    ],
    "_handle_irsa_cross_account": [
      "self",
      "irsa_role_arn",
      "aws_role_name",
      "aws_session_name",
      "region",
      "web_identity_token_file",
      "aws_external_id",
      "ssl_verify"
    ],
    "_handle_irsa_same_account": [
      "self",
      "aws_role_name",
      "aws_session_name",
      "region",
      "aws_external_id",
      "ssl_verify"
    ],
    "_extract_credentials_and_ttl": [
      "self",
      "sts_response"
    ],
    "_auth_with_aws_role": [
      "self",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_session_token",
      "aws_role_name",
      "aws_session_name",
      "aws_external_id",
      "ssl_verify"
    ],
    "_auth_with_aws_profile": [
      "self",
      "aws_profile_name"
    ],
    "_auth_with_aws_session_token": [
      "self",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_session_token"
    ],
    "_auth_with_access_key_and_secret_key": [
      "self",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_region_name"
    ],
    "_auth_with_env_vars": [
      "self"
    ],
    "_get_default_ttl_for_boto3_credentials": [
      "self"
    ],
    "get_runtime_endpoint": [
      "self",
      "api_base",
      "aws_bedrock_runtime_endpoint",
      "aws_region_name",
      "endpoint_type"
    ],
    "_select_default_endpoint_url": [
      "self",
      "endpoint_type",
      "aws_region_name"
    ],
    "_get_boto_credentials_from_optional_params": [
      "self",
      "optional_params",
      "model"
    ],
    "get_request_headers": [
      "self",
      "credentials",
      "aws_region_name",
      "extra_headers",
      "endpoint_url",
      "data",
      "headers",
      "api_key"
    ],
    "_filter_headers_for_aws_signature": [
      "self",
      "headers"
    ],
    "_sign_request": [
      "self",
      "service_name",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "model",
      "stream",
      "fake_stream",
      "api_key"
    ]
  },
  "BedrockError": {},
  "_get_model_info": [],
  "get_cached_model_info": [],
  "AmazonBedrockGlobalConfig": {
    "__init__": [
      "self"
    ],
    "get_mapped_special_auth_params": [
      "self"
    ],
    "map_special_auth_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "get_all_regions": [
      "self"
    ],
    "get_ap_regions": [
      "self"
    ],
    "get_sa_regions": [
      "self"
    ],
    "get_eu_regions": [
      "self"
    ],
    "get_ca_regions": [
      "self"
    ],
    "get_us_regions": [
      "self"
    ]
  },
  "add_custom_header": [
    "headers"
  ],
  "_get_bedrock_client_ssl_verify": [],
  "init_bedrock_client": [
    "region_name",
    "aws_access_key_id",
    "aws_secret_access_key",
    "aws_region_name",
    "aws_bedrock_runtime_endpoint",
    "aws_session_name",
    "aws_profile_name",
    "aws_role_name",
    "aws_web_identity_token",
    "extra_headers",
    "timeout"
  ],
  "get_bedrock_tool_name": [
    "response_tool_name"
  ],
  "_get_all_bedrock_regions": [],
  "get_bedrock_cross_region_inference_regions": [],
  "extract_model_name_from_bedrock_arn": [
    "model"
  ],
  "strip_bedrock_routing_prefix": [
    "model"
  ],
  "strip_bedrock_throughput_suffix": [
    "model"
  ],
  "get_bedrock_base_model": [
    "model"
  ],
  "is_claude_4_5_on_bedrock": [
    "model"
  ],
  "BedrockModelInfo": {
    "global_config": [],
    "all_global_regions": [],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_token_counter": [
      "self"
    ],
    "extract_model_name_from_arn": [
      "model"
    ],
    "get_non_litellm_routing_model_name": [
      "model"
    ],
    "get_base_model": [
      "model"
    ],
    "_supported_cross_region_inference_region": [],
    "get_bedrock_route": [
      "model"
    ],
    "_explicit_converse_route": [
      "model"
    ],
    "_explicit_invoke_route": [
      "model"
    ],
    "_explicit_agent_route": [
      "model"
    ],
    "_explicit_agentcore_route": [
      "model"
    ],
    "_explicit_converse_like_route": [
      "model"
    ],
    "_explicit_async_invoke_route": [
      "model"
    ],
    "_explicit_openai_route": [
      "model"
    ],
    "get_bedrock_provider_config_for_messages_api": [
      "model"
    ]
  },
  "get_bedrock_chat_config": [
    "model"
  ],
  "BedrockEventStreamDecoderBase": {
    "_response_stream_shape_cache": [],
    "__init__": [
      "self"
    ],
    "get_response_stream_shape": [
      "self"
    ],
    "_parse_message_from_event": [
      "self",
      "event"
    ]
  },
  "get_anthropic_beta_from_headers": [
    "headers"
  ],
  "CommonBatchFilesUtils": {
    "__init__": [
      "self"
    ],
    "get_bedrock_model_id_from_litellm_model": [
      "self",
      "model"
    ],
    "parse_s3_uri": [
      "self",
      "s3_uri"
    ],
    "extract_model_from_s3_file_path": [
      "self",
      "s3_uri",
      "optional_params"
    ],
    "sign_aws_request": [
      "self",
      "service_name",
      "data",
      "endpoint_url",
      "optional_params",
      "method"
    ],
    "generate_unique_job_name": [
      "self",
      "model",
      "prefix"
    ],
    "get_s3_bucket_and_key_from_config": [
      "self",
      "litellm_params",
      "optional_params",
      "bucket_env_var",
      "key_prefix"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BedrockBatchesConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_batch_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "data"
    ],
    "transform_create_batch_request": [
      "self",
      "model",
      "create_batch_data",
      "optional_params",
      "litellm_params"
    ],
    "transform_create_batch_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_retrieve_batch_request": [
      "self",
      "batch_id",
      "optional_params",
      "litellm_params"
    ],
    "_parse_timestamps_and_status": [
      "self",
      "response_data",
      "status_str"
    ],
    "_extract_file_configs": [
      "self",
      "response_data"
    ],
    "_extract_errors_and_metadata": [
      "self",
      "response_data",
      "raw_response"
    ],
    "transform_retrieve_batch_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "BedrockBatchesHandler": {
    "_handle_async_invoke_status": [
      "batch_id",
      "aws_region_name",
      "logging_obj"
    ]
  },
  "BedrockVectorStoreConfig": {
    "__init__": [
      "self"
    ],
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_map_operator_to_aws": [
      "self",
      "operator"
    ],
    "_map_operator_filter": [
      "self",
      "filter_dict"
    ],
    "_map_and_or_filters": [
      "self",
      "value"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key"
    ],
    "_get_file_id_from_metadata": [
      "self",
      "metadata"
    ],
    "_get_filename_from_metadata": [
      "self",
      "metadata"
    ],
    "_get_attributes_from_metadata": [
      "self",
      "metadata"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "BedrockRealtimeConfig": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "api_key"
    ],
    "requires_session_configuration": [
      "self"
    ],
    "session_configuration_request": [
      "self",
      "model",
      "tools"
    ],
    "_transform_tools_to_bedrock_format": [
      "self",
      "tools"
    ],
    "_map_audio_format_to_sample_rate": [
      "self",
      "audio_format",
      "is_output"
    ],
    "transform_session_update_event": [
      "self",
      "json_message"
    ],
    "transform_input_audio_buffer_append_event": [
      "self",
      "json_message"
    ],
    "transform_input_audio_buffer_commit_event": [
      "self",
      "json_message"
    ],
    "transform_conversation_item_create_event": [
      "self",
      "json_message"
    ],
    "transform_response_create_event": [
      "self",
      "json_message"
    ],
    "transform_response_cancel_event": [
      "self",
      "json_message"
    ],
    "transform_realtime_request": [
      "self",
      "message",
      "model",
      "session_configuration_request"
    ],
    "transform_session_start_event": [
      "self",
      "event",
      "model",
      "logging_obj"
    ],
    "transform_content_start_event": [
      "self",
      "event",
      "current_response_id",
      "current_output_item_id",
      "current_conversation_id"
    ],
    "transform_text_output_event": [
      "self",
      "event",
      "current_output_item_id",
      "current_response_id",
      "current_delta_chunks"
    ],
    "transform_audio_output_event": [
      "self",
      "event",
      "current_output_item_id",
      "current_response_id"
    ],
    "transform_content_end_event": [
      "self",
      "event",
      "current_output_item_id",
      "current_response_id",
      "current_delta_type",
      "current_delta_chunks"
    ],
    "transform_prompt_end_event": [
      "self",
      "event",
      "current_response_id",
      "current_conversation_id"
    ],
    "transform_tool_use_event": [
      "self",
      "event",
      "current_output_item_id",
      "current_response_id"
    ],
    "transform_conversation_item_create_tool_result_event": [
      "self",
      "json_message"
    ],
    "transform_realtime_response": [
      "self",
      "message",
      "model",
      "logging_obj",
      "realtime_response_transform_input"
    ]
  },
  "BedrockRealtime": {
    "__init__": [
      "self"
    ],
    "async_realtime": [
      "self",
      "model",
      "websocket",
      "logging_obj",
      "api_base",
      "api_key",
      "timeout",
      "aws_region_name",
      "aws_access_key_id",
      "aws_secret_access_key",
      "aws_session_token",
      "aws_role_name",
      "aws_session_name",
      "aws_profile_name",
      "aws_web_identity_token",
      "aws_sts_endpoint",
      "aws_bedrock_runtime_endpoint",
      "aws_external_id"
    ],
    "_forward_client_to_bedrock": [
      "self",
      "client_ws",
      "bedrock_stream",
      "transformation_config",
      "model",
      "session_state"
    ],
    "_forward_bedrock_to_client": [
      "self",
      "bedrock_stream",
      "client_ws",
      "transformation_config",
      "model",
      "logging_obj",
      "session_state"
    ]
  },
  "AmazonAnthropicClaudeMessagesConfig": {
    "DEFAULT_BEDROCK_ANTHROPIC_API_VERSION": [],
    "__init__": [
      "self"
    ],
    "validate_anthropic_messages_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_remove_ttl_from_cache_control": [
      "self",
      "anthropic_messages_request",
      "model"
    ],
    "_supports_extended_thinking_on_bedrock": [
      "self",
      "model"
    ],
    "_is_claude_opus_4_5": [
      "self",
      "model"
    ],
    "_is_claude_4_5_on_bedrock": [
      "self",
      "model"
    ],
    "_supports_tool_search_on_bedrock": [
      "self",
      "model"
    ],
    "_get_tool_search_beta_header_for_bedrock": [
      "self",
      "model",
      "tool_search_used",
      "programmatic_tool_calling_used",
      "input_examples_used",
      "beta_set"
    ],
    "_convert_output_format_to_inline_schema": [
      "self",
      "output_format",
      "anthropic_messages_request"
    ],
    "transform_anthropic_messages_request": [
      "self",
      "model",
      "messages",
      "anthropic_messages_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "get_async_streaming_response_iterator": [
      "self",
      "model",
      "httpx_response",
      "request_body",
      "litellm_logging_obj"
    ],
    "bedrock_sse_wrapper": [
      "self",
      "completion_stream",
      "litellm_logging_obj",
      "request_body"
    ]
  },
  "AmazonAnthropicClaudeMessagesStreamDecoder": {
    "__init__": [
      "self",
      "model"
    ],
    "_chunk_parser": [
      "self",
      "chunk_data"
    ]
  },
  "BedrockTokenCounter": {
    "should_use_token_counting_api": [
      "self",
      "custom_llm_provider"
    ],
    "count_tokens": [
      "self",
      "model_to_use",
      "messages",
      "contents",
      "deployment",
      "request_model"
    ]
  },
  "BedrockCountTokensConfig": {
    "_detect_input_type": [
      "self",
      "request_data"
    ],
    "transform_anthropic_to_bedrock_count_tokens": [
      "self",
      "request_data"
    ],
    "_transform_to_converse_format": [
      "self",
      "messages"
    ],
    "_transform_to_invoke_model_format": [
      "self",
      "request_data"
    ],
    "get_bedrock_count_tokens_endpoint": [
      "self",
      "model",
      "aws_region_name"
    ],
    "transform_bedrock_response_to_anthropic": [
      "self",
      "bedrock_response"
    ],
    "validate_count_tokens_request": [
      "self",
      "request_data"
    ]
  },
  "BedrockCountTokensHandler": {
    "handle_count_tokens_request": [
      "self",
      "request_data",
      "litellm_params",
      "resolved_model"
    ]
  },
  "AmazonTitanG1Config": {
    "__init__": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_transform_request": [
      "self",
      "input",
      "inference_params"
    ],
    "_transform_response": [
      "self",
      "response_list",
      "model"
    ]
  },
  "AmazonNovaEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_parse_data_url": [
      "self",
      "data_url"
    ],
    "_transform_request": [
      "self",
      "input",
      "inference_params",
      "async_invoke_route",
      "model_id",
      "output_s3_uri"
    ],
    "_wrap_async_invoke_request": [
      "self",
      "model_input",
      "model_id",
      "output_s3_uri"
    ],
    "_transform_response": [
      "self",
      "response_list",
      "model",
      "batch_data"
    ],
    "_transform_async_invoke_response": [
      "self",
      "response",
      "model"
    ]
  },
  "AmazonTitanV2Config": {
    "__init__": [
      "self",
      "normalize",
      "dimensions"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_transform_request": [
      "self",
      "input",
      "inference_params"
    ],
    "_transform_response": [
      "self",
      "response_list",
      "model"
    ]
  },
  "BedrockCohereEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_is_v3_model": [
      "self",
      "model"
    ],
    "_transform_request": [
      "self",
      "model",
      "input",
      "inference_params"
    ]
  },
  "BedrockEmbedding": {
    "_load_credentials": [
      "self",
      "optional_params"
    ],
    "async_embeddings": [
      "self"
    ],
    "_make_sync_call": [
      "self",
      "client",
      "timeout",
      "api_base",
      "headers",
      "data"
    ],
    "_make_async_call": [
      "self",
      "client",
      "timeout",
      "api_base",
      "headers",
      "data"
    ],
    "_transform_response": [
      "self",
      "response_list",
      "model",
      "provider",
      "is_async_invoke",
      "batch_data"
    ],
    "_single_func_embeddings": [
      "self",
      "client",
      "timeout",
      "batch_data",
      "credentials",
      "extra_headers",
      "endpoint_url",
      "aws_region_name",
      "model",
      "logging_obj",
      "provider",
      "api_key",
      "is_async_invoke"
    ],
    "_async_single_func_embeddings": [
      "self",
      "client",
      "timeout",
      "batch_data",
      "credentials",
      "extra_headers",
      "endpoint_url",
      "aws_region_name",
      "model",
      "logging_obj",
      "provider",
      "api_key",
      "is_async_invoke"
    ],
    "embeddings": [
      "self",
      "model",
      "input",
      "api_base",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "client",
      "timeout",
      "aembedding",
      "extra_headers",
      "optional_params",
      "litellm_params",
      "api_key"
    ],
    "_get_async_invoke_status": [
      "self",
      "invocation_arn",
      "aws_region_name",
      "logging_obj"
    ]
  },
  "AmazonTitanMultimodalEmbeddingG1Config": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_transform_request": [
      "self",
      "input",
      "inference_params"
    ],
    "_transform_response": [
      "self",
      "response_list",
      "model",
      "batch_data"
    ]
  },
  "TwelveLabsMarengoEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_extract_bucket_owner_from_params": [
      "self",
      "inference_params"
    ],
    "_is_s3_url": [
      "self",
      "input"
    ],
    "_transform_request": [
      "self",
      "input",
      "inference_params",
      "async_invoke_route",
      "model_id",
      "output_s3_uri"
    ],
    "_wrap_async_invoke_request": [
      "self",
      "model_input",
      "model_id",
      "output_s3_uri"
    ],
    "_transform_response": [
      "self",
      "response_list",
      "model"
    ],
    "_transform_async_invoke_response": [
      "self",
      "response",
      "model"
    ]
  },
  "AmazonStabilityConfig": {
    "__init__": [
      "self",
      "cfg_scale",
      "seed",
      "steps",
      "width",
      "height"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "cls",
      "model"
    ],
    "map_openai_params": [
      "cls",
      "non_default_params",
      "optional_params"
    ],
    "transform_request_body": [
      "cls",
      "text",
      "optional_params"
    ],
    "transform_response_dict_to_openai_response": [
      "cls",
      "model_response",
      "response_dict"
    ],
    "cost_calculator": [
      "cls",
      "model",
      "image_response",
      "size",
      "optional_params"
    ]
  },
  "AmazonStability3Config": {
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "cls",
      "model"
    ],
    "_is_stability_3_model": [
      "cls",
      "model"
    ],
    "transform_request_body": [
      "cls",
      "text",
      "optional_params"
    ],
    "map_openai_params": [
      "cls",
      "non_default_params",
      "optional_params"
    ],
    "transform_response_dict_to_openai_response": [
      "cls",
      "model_response",
      "response_dict"
    ],
    "cost_calculator": [
      "cls",
      "model",
      "image_response",
      "size",
      "optional_params"
    ]
  },
  "BedrockImagePreparedRequest": {},
  "BedrockImageConfigClass": [],
  "BedrockImageGeneration": {
    "get_config_class": [
      "cls",
      "model"
    ],
    "image_generation": [
      "self",
      "model",
      "prompt",
      "model_response",
      "optional_params",
      "logging_obj",
      "timeout",
      "aimg_generation",
      "api_base",
      "extra_headers",
      "client",
      "api_key"
    ],
    "async_image_generation": [
      "self",
      "prepared_request",
      "timeout",
      "model",
      "logging_obj",
      "prompt",
      "model_response",
      "client"
    ],
    "_extract_headers_from_optional_params": [
      "self",
      "optional_params"
    ],
    "_prepare_request": [
      "self",
      "model",
      "optional_params",
      "api_base",
      "extra_headers",
      "logging_obj",
      "prompt",
      "api_key"
    ],
    "_get_request_body": [
      "self",
      "model",
      "prompt",
      "optional_params"
    ],
    "_transform_response_dict_to_openai_response": [
      "self",
      "model_response",
      "model",
      "logging_obj",
      "prompt",
      "response",
      "data"
    ]
  },
  "AmazonNovaCanvasConfig": {
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "cls",
      "model"
    ],
    "_is_nova_model": [
      "cls",
      "model"
    ],
    "transform_request_body": [
      "cls",
      "text",
      "optional_params"
    ],
    "map_openai_params": [
      "cls",
      "non_default_params",
      "optional_params"
    ],
    "transform_response_dict_to_openai_response": [
      "cls",
      "model_response",
      "response_dict"
    ],
    "cost_calculator": [
      "cls",
      "model",
      "image_response",
      "size",
      "optional_params"
    ]
  },
  "AmazonTitanImageGenerationConfig": {
    "__init__": [
      "self",
      "cfg_scale",
      "seed",
      "steps",
      "width",
      "height"
    ],
    "get_config": [
      "cls"
    ],
    "_is_titan_model": [
      "cls",
      "model"
    ],
    "get_supported_openai_params": [
      "cls",
      "model"
    ],
    "map_openai_params": [
      "cls",
      "non_default_params",
      "optional_params"
    ],
    "transform_request_body": [
      "cls",
      "text",
      "optional_params"
    ],
    "transform_response_dict_to_openai_response": [
      "cls",
      "model_response",
      "response_dict"
    ],
    "cost_calculator": [
      "cls",
      "model",
      "image_response",
      "size",
      "optional_params"
    ]
  },
  "BedrockPassthroughConfig": {
    "is_streaming_request": [
      "self",
      "endpoint",
      "request_data"
    ],
    "_encode_model_id_for_endpoint": [
      "self",
      "model_id"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "endpoint",
      "request_query_params",
      "litellm_params"
    ],
    "sign_request": [
      "self",
      "headers",
      "litellm_params",
      "request_data",
      "api_base",
      "model"
    ],
    "logging_non_streaming_response": [
      "self",
      "model",
      "custom_llm_provider",
      "httpx_response",
      "request_data",
      "logging_obj",
      "endpoint"
    ],
    "_convert_raw_bytes_to_str_lines": [
      "self",
      "raw_bytes"
    ],
    "handle_logging_collected_chunks": [
      "self",
      "all_chunks",
      "litellm_logging_obj",
      "model",
      "custom_llm_provider",
      "endpoint"
    ]
  },
  "BedrockFilesConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "file_upload_http_method": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_get_content_from_openai_file": [
      "self",
      "openai_file_content"
    ],
    "_get_s3_object_name_from_batch_jsonl": [
      "self",
      "openai_jsonl_content"
    ],
    "get_object_name": [
      "self",
      "extracted_file_data",
      "purpose"
    ],
    "get_complete_file_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "data"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_openai_to_bedrock_params": [
      "self",
      "openai_request_body",
      "provider"
    ],
    "_transform_openai_jsonl_content_to_bedrock_jsonl_content": [
      "self",
      "openai_jsonl_content"
    ],
    "transform_create_file_request": [
      "self",
      "model",
      "create_file_data",
      "optional_params",
      "litellm_params"
    ],
    "_sign_s3_request": [
      "self",
      "content",
      "api_base",
      "optional_params"
    ],
    "_convert_https_url_to_s3_uri": [
      "self",
      "https_url"
    ],
    "transform_create_file_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "transform_retrieve_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_retrieve_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_delete_file_request": [
      "self",
      "file_id",
      "optional_params",
      "litellm_params"
    ],
    "transform_delete_file_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_list_files_request": [
      "self",
      "purpose",
      "optional_params",
      "litellm_params"
    ],
    "transform_list_files_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ],
    "transform_file_content_request": [
      "self",
      "file_content_request",
      "optional_params",
      "litellm_params"
    ],
    "transform_file_content_response": [
      "self",
      "raw_response",
      "logging_obj",
      "litellm_params"
    ]
  },
  "BedrockJsonlFilesTransformation": {
    "transform_openai_file_content_to_bedrock_file_content": [
      "self",
      "openai_file_content"
    ],
    "_transform_openai_jsonl_content_to_bedrock_jsonl_content": [
      "self",
      "openai_jsonl_content"
    ],
    "_get_s3_object_name": [
      "self",
      "openai_jsonl_content"
    ],
    "_get_content_from_openai_file": [
      "self",
      "openai_file_content"
    ],
    "transform_s3_bucket_response_to_openai_file_object": [
      "self",
      "create_file_data",
      "s3_upload_response"
    ]
  },
  "BedrockFilesHandler": {
    "__init__": [
      "self"
    ],
    "_extract_s3_uri_from_file_id": [
      "self",
      "file_id"
    ],
    "_parse_s3_uri": [
      "self",
      "s3_uri"
    ],
    "afile_content": [
      "self",
      "file_content_request",
      "optional_params",
      "timeout",
      "max_retries"
    ],
    "file_content": [
      "self",
      "_is_async",
      "file_content_request",
      "api_base",
      "optional_params",
      "timeout",
      "max_retries"
    ]
  },
  "BedrockRerankConfig": {
    "_transform_sources": [
      "self",
      "documents"
    ],
    "_transform_request": [
      "self",
      "request_data"
    ],
    "_transform_response": [
      "self",
      "response"
    ]
  },
  "BedrockRerankHandler": {
    "arerank": [
      "self",
      "prepared_request",
      "client"
    ],
    "rerank": [
      "self",
      "model",
      "query",
      "documents",
      "optional_params",
      "logging_obj",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "_is_async",
      "api_base",
      "extra_headers",
      "client"
    ],
    "_prepare_request": [
      "self",
      "model",
      "api_base",
      "extra_headers",
      "data",
      "optional_params"
    ]
  },
  "BedrockStabilityImageEditConfig": {
    "_is_stability_edit_model": [
      "cls",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "image_edit_optional_params",
      "model",
      "drop_params"
    ],
    "transform_image_edit_request": [
      "self",
      "model",
      "prompt",
      "image",
      "image_edit_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_edit_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj",
      "api_key",
      "json_mode"
    ],
    "use_multipart_form_data": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "model",
      "api_base",
      "litellm_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key"
    ]
  },
  "BedrockImageEditPreparedRequest": {},
  "BedrockImageEdit": {
    "get_config_class": [
      "cls",
      "model"
    ],
    "image_edit": [
      "self",
      "model",
      "image",
      "prompt",
      "model_response",
      "optional_params",
      "logging_obj",
      "timeout",
      "aimage_edit",
      "api_base",
      "extra_headers",
      "client",
      "api_key"
    ],
    "async_image_edit": [
      "self",
      "prepared_request",
      "timeout",
      "model",
      "logging_obj",
      "prompt",
      "model_response",
      "client"
    ],
    "_prepare_request": [
      "self",
      "model",
      "image",
      "prompt",
      "optional_params",
      "api_base",
      "extra_headers",
      "logging_obj",
      "api_key"
    ],
    "_get_request_body": [
      "self",
      "model",
      "image",
      "prompt",
      "optional_params"
    ],
    "_transform_response_dict_to_openai_response": [
      "self",
      "model_response",
      "model",
      "logging_obj",
      "prompt",
      "response",
      "data"
    ]
  },
  "converse_config": [],
  "AmazonCohereChatConfig": {
    "__init__": [
      "self",
      "documents",
      "search_queries_only",
      "preamble",
      "max_tokens",
      "temperature",
      "p",
      "k",
      "prompt_truncation",
      "frequency_penalty",
      "presence_penalty",
      "seed",
      "return_prompt",
      "stop_sequences",
      "raw_prompting"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params"
    ]
  },
  "BedrockLLM": {
    "__init__": [
      "self"
    ],
    "is_claude_messages_api_model": [
      "model"
    ],
    "convert_messages_to_prompt": [
      "self",
      "model",
      "messages",
      "provider",
      "custom_prompt_dict"
    ],
    "process_response": [
      "self",
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "print_verbose",
      "encoding"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "logging_obj",
      "optional_params",
      "acompletion",
      "timeout",
      "litellm_params",
      "logger_fn",
      "extra_headers",
      "client"
    ],
    "async_completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "print_verbose",
      "data",
      "timeout",
      "encoding",
      "logging_obj",
      "stream",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers",
      "client"
    ],
    "async_streaming": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "print_verbose",
      "data",
      "timeout",
      "encoding",
      "logging_obj",
      "stream",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers",
      "client",
      "stream_chunk_size"
    ],
    "_get_provider_from_model_path": [
      "model_path"
    ]
  },
  "AmazonAnthropicClaudeStreamDecoder": {
    "__init__": [
      "self",
      "model",
      "sync_stream",
      "json_mode"
    ],
    "_chunk_parser": [
      "self",
      "chunk_data"
    ]
  },
  "AmazonDeepSeekR1StreamDecoder": {
    "__init__": [
      "self",
      "model",
      "sync_stream"
    ],
    "_chunk_parser": [
      "self",
      "chunk_data"
    ]
  },
  "BEDROCK_COMPUTER_USE_TOOLS": [],
  "UNSUPPORTED_BEDROCK_CONVERSE_BETA_PATTERNS": [],
  "BEDROCK_NATIVE_STRUCTURED_OUTPUT_MODELS": [],
  "AmazonConverseConfig": {
    "__init__": [
      "self",
      "maxTokens",
      "stopSequences",
      "temperature",
      "topP",
      "topK"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config_blocks": [
      "cls"
    ],
    "_convert_consecutive_user_messages_to_guarded_text": [
      "messages",
      "optional_params"
    ],
    "get_config": [
      "cls"
    ],
    "_validate_request_metadata": [
      "self",
      "metadata"
    ],
    "_is_nova_2_model": [
      "self",
      "model"
    ],
    "_map_web_search_options": [
      "self",
      "web_search_options",
      "model"
    ],
    "_transform_reasoning_effort_to_reasoning_config": [
      "self",
      "reasoning_effort"
    ],
    "_handle_reasoning_effort_parameter": [
      "self",
      "model",
      "reasoning_effort",
      "optional_params"
    ],
    "_clamp_thinking_budget_tokens": [
      "optional_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_tool_choice_values": [
      "self",
      "model",
      "tool_choice",
      "drop_params"
    ],
    "get_supported_image_types": [
      "self"
    ],
    "get_supported_document_types": [
      "self"
    ],
    "get_supported_video_types": [
      "self"
    ],
    "get_all_supported_content_types": [
      "self"
    ],
    "is_computer_use_tool_used": [
      "self",
      "tools",
      "model"
    ],
    "_transform_computer_use_tools": [
      "self",
      "computer_use_tools"
    ],
    "_separate_computer_use_tools": [
      "self",
      "tools",
      "model"
    ],
    "_create_json_tool_call_for_response_format": [
      "self",
      "json_schema",
      "description"
    ],
    "_supports_native_structured_outputs": [
      "model"
    ],
    "_add_additional_properties_to_schema": [
      "schema"
    ],
    "_create_output_config_for_response_format": [
      "json_schema",
      "name",
      "description"
    ],
    "_apply_tool_call_transformation": [
      "self",
      "tools",
      "model",
      "non_default_params",
      "optional_params"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_map_service_tier_param": [
      "self",
      "value",
      "optional_params"
    ],
    "_translate_response_format_param": [
      "self",
      "value",
      "model",
      "optional_params",
      "non_default_params",
      "is_thinking_enabled"
    ],
    "update_optional_params_with_thinking_tokens": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "_get_cache_point_block": [
      "self",
      "message_block",
      "block_type",
      "model"
    ],
    "_transform_system_message": [
      "self",
      "messages",
      "model"
    ],
    "_transform_inference_params": [
      "self",
      "inference_params"
    ],
    "_handle_top_k_value": [
      "self",
      "model",
      "inference_params"
    ],
    "_prepare_request_params": [
      "self",
      "optional_params",
      "model"
    ],
    "_process_tools_and_beta": [
      "self",
      "original_tools",
      "model",
      "headers",
      "additional_request_params"
    ],
    "_transform_request_helper": [
      "self",
      "model",
      "system_content_blocks",
      "optional_params",
      "messages",
      "headers"
    ],
    "_async_transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_transform_reasoning_content": [
      "self",
      "reasoning_content_blocks"
    ],
    "_transform_thinking_blocks": [
      "self",
      "thinking_blocks"
    ],
    "_transform_usage": [
      "self",
      "usage"
    ],
    "get_tool_call_names": [
      "self",
      "tools"
    ],
    "apply_tool_call_transformation_if_needed": [
      "self",
      "message",
      "tools",
      "initial_finish_reason"
    ],
    "_translate_message_content": [
      "self",
      "content_blocks"
    ],
    "_transform_response": [
      "self",
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "encoding"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider",
      "fake_stream"
    ]
  },
  "BedrockConverseLLM": {
    "__init__": [
      "self"
    ],
    "async_streaming": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "timeout",
      "encoding",
      "logging_obj",
      "stream",
      "optional_params",
      "litellm_params",
      "credentials",
      "logger_fn",
      "headers",
      "client",
      "fake_stream",
      "json_mode",
      "api_key",
      "stream_chunk_size"
    ],
    "async_completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "timeout",
      "encoding",
      "logging_obj",
      "stream",
      "optional_params",
      "litellm_params",
      "credentials",
      "logger_fn",
      "headers",
      "client",
      "api_key"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "encoding",
      "logging_obj",
      "optional_params",
      "acompletion",
      "timeout",
      "litellm_params",
      "logger_fn",
      "extra_headers",
      "client",
      "api_key"
    ]
  },
  "get_bedrock_event_stream_decoder": [
    "invoke_provider",
    "model",
    "sync_stream",
    "json_mode"
  ],
  "AmazonCohereConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "temperature",
      "return_likelihood"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "AmazonLlamaConfig": {
    "__init__": [
      "self",
      "maxTokenCount",
      "temperature",
      "topP"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "AmazonMistralConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "temperature",
      "top_p",
      "top_k",
      "stop"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_outputText": [
      "completion_response",
      "model_response"
    ]
  },
  "AmazonInvokeConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "_apply_config_to_params": [
      "self",
      "config",
      "inference_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "get_bedrock_invoke_provider": [
      "model"
    ],
    "_get_provider_from_model_path": [
      "model_path"
    ],
    "convert_messages_to_prompt": [
      "self",
      "model",
      "messages",
      "provider",
      "custom_prompt_dict"
    ]
  },
  "AmazonInvokeNovaConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_filter_allowed_fields": [
      "self",
      "bedrock_invoke_nova_request"
    ],
    "_remove_empty_system_messages": [
      "self",
      "bedrock_invoke_nova_request"
    ]
  },
  "AmazonQwen3Config": {
    "__init__": [
      "self",
      "max_tokens",
      "temperature",
      "top_p",
      "top_k",
      "stop"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_convert_messages_to_prompt": [
      "self",
      "messages"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AmazonAI21Config": {
    "__init__": [
      "self",
      "maxTokens",
      "temperature",
      "topP",
      "stopSequences",
      "frequencePenalty",
      "presencePenalty",
      "countPenalty"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "AmazonQwen2Config": {
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AmazonDeepSeekR1Config": {
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AmazonDeepseekR1ResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "AmazonBedrockOpenAIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_model_id": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "AmazonMoonshotConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "_get_model_id": [
      "self",
      "model"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_extract_reasoning_from_content": [
      "self",
      "content"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "AmazonAnthropicConfig": {
    "__init__": [
      "self",
      "max_tokens_to_sample",
      "stop_sequences",
      "temperature",
      "top_k",
      "top_p",
      "anthropic_version"
    ],
    "get_config": [
      "cls"
    ],
    "get_legacy_anthropic_model_names": [],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "AmazonAnthropicClaudeConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_normalize_bedrock_tool_search_tools": [
      "self",
      "optional_params"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AmazonTitanConfig": {
    "__init__": [
      "self",
      "maxTokenCount",
      "stopSequences",
      "temperature",
      "topP"
    ],
    "get_config": [
      "cls"
    ],
    "_map_and_modify_arg": [
      "self",
      "supported_params",
      "provider",
      "model",
      "stop"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "AmazonTwelveLabsPegasusConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_normalize_response_format": [
      "self",
      "value"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_build_media_source": [
      "self",
      "optional_params"
    ],
    "_convert_messages_to_prompt": [
      "self",
      "messages"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "AmazonAgentCoreConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "_get_agent_runtime_arn": [
      "self",
      "model"
    ],
    "_extract_region_from_arn": [
      "self",
      "arn"
    ],
    "_get_runtime_session_id": [
      "self",
      "optional_params"
    ],
    "_get_runtime_user_id": [
      "self",
      "optional_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_extract_sse_json": [
      "self",
      "line"
    ],
    "_extract_usage_from_event": [
      "self",
      "event_data"
    ],
    "_extract_content_delta": [
      "self",
      "event_data"
    ],
    "_extract_content_from_message": [
      "self",
      "message"
    ],
    "_calculate_usage": [
      "self",
      "model",
      "messages",
      "content"
    ],
    "_parse_json_response": [
      "self",
      "response_json"
    ],
    "_get_parsed_response": [
      "self",
      "raw_response"
    ],
    "_parse_sse_stream": [
      "self",
      "response_text"
    ],
    "_stream_agentcore_response_sync": [
      "self",
      "response",
      "model"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "_stream_agentcore_response": [
      "self",
      "response",
      "model"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "has_custom_stream_wrapper": [
      "self"
    ],
    "supports_stream_param_in_request_body": [
      "self"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ]
  },
  "AmazonInvokeAgentConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "_get_agent_id_and_alias_id": [
      "self",
      "model"
    ],
    "_get_session_id": [
      "self",
      "optional_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_parse_aws_event_stream": [
      "self",
      "raw_content"
    ],
    "_parse_message_from_event": [
      "self",
      "event",
      "parser"
    ],
    "_extract_headers_from_event": [
      "self",
      "event"
    ],
    "_get_response_stream_shape": [
      "self"
    ],
    "_extract_response_content": [
      "self",
      "events"
    ],
    "_extract_usage_info": [
      "self",
      "events"
    ],
    "_is_trace_event": [
      "self",
      "event"
    ],
    "_get_trace_data": [
      "self",
      "event"
    ],
    "_extract_and_update_preprocessing_usage": [
      "self",
      "trace_data",
      "usage_info"
    ],
    "_extract_orchestration_model": [
      "self",
      "trace_data"
    ],
    "_build_model_response": [
      "self",
      "content",
      "model",
      "usage_info",
      "model_response"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "should_fake_stream": [
      "self",
      "model",
      "stream",
      "custom_llm_provider"
    ]
  },
  "_GooglePSESearchRequestRequired": {},
  "GooglePSESearchRequest": {},
  "GooglePSESearchConfig": {
    "GOOGLE_PSE_API_BASE": [],
    "ui_friendly_name": [],
    "get_http_method": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params",
      "api_key",
      "search_engine_id"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "DeepSeekChatConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "WatsonXAIError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "iam_token_cache": [],
  "get_watsonx_iam_url": [],
  "generate_iam_token": [
    "api_key"
  ],
  "_generate_watsonx_token": [
    "api_key",
    "token"
  ],
  "_get_api_params": [
    "params",
    "model"
  ],
  "_aconvert_watsonx_messages_core": [
    "model",
    "messages",
    "provider",
    "custom_prompt_dict",
    "apply_template_fn"
  ],
  "_convert_watsonx_messages_core": [
    "model",
    "messages",
    "provider",
    "custom_prompt_dict",
    "apply_template_fn"
  ],
  "aconvert_watsonx_messages_to_prompt": [
    "model",
    "messages",
    "provider",
    "custom_prompt_dict"
  ],
  "convert_watsonx_messages_to_prompt": [
    "model",
    "messages",
    "provider",
    "custom_prompt_dict"
  ],
  "IBMWatsonXMixin": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_get_base_url": [
      "self",
      "api_base"
    ],
    "_add_api_version_to_url": [
      "self",
      "url",
      "api_version"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_watsonx_credentials": [
      "optional_params",
      "api_key",
      "api_base"
    ],
    "_prepare_payload": [
      "self",
      "model",
      "api_params"
    ]
  },
  "IBMWatsonXEmbeddingConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ]
  },
  "IBMWatsonXAIConfig": {
    "__init__": [
      "self",
      "decoding_method",
      "temperature",
      "max_new_tokens",
      "min_new_tokens",
      "length_penalty",
      "stop_sequences",
      "top_k",
      "top_p",
      "repetition_penalty",
      "truncate_input_tokens",
      "include_stop_sequences",
      "return_options",
      "random_seed",
      "moderations",
      "stream"
    ],
    "get_config": [
      "cls"
    ],
    "is_watsonx_text_param": [
      "self",
      "param"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_mapped_special_auth_params": [
      "self"
    ],
    "map_special_auth_params": [
      "self",
      "non_default_params",
      "optional_params"
    ],
    "get_eu_regions": [
      "self"
    ],
    "get_us_regions": [
      "self"
    ],
    "_build_request_payload": [
      "self",
      "model",
      "prompt",
      "optional_params"
    ],
    "atransform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "WatsonxTextCompletionResponseIterator": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "IBMWatsonXRerankConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ]
  },
  "IBMWatsonXAudioTranscriptionConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "transform_audio_transcription_request": [
      "self",
      "model",
      "audio_file",
      "optional_params",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_audio_transcription_response": [
      "self",
      "raw_response"
    ]
  },
  "IBMWatsonXChatConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "is_tool_choice_option": [
      "self",
      "tool_choice"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_apply_prompt_template_core": [
      "model",
      "messages",
      "hf_template_fn"
    ],
    "aapply_prompt_template": [
      "model",
      "messages"
    ],
    "apply_prompt_template": [
      "model",
      "messages"
    ]
  },
  "watsonx_chat_transformation": [],
  "WatsonXChatHandler": {
    "__init__": [
      "self"
    ],
    "completion": [
      "self"
    ]
  },
  "NebiusConfig": {
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "VLLMError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response",
      "headers"
    ]
  },
  "VLLMModelInfo": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_base_model": [
      "model"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "VLLMPassthroughConfig": {
    "is_streaming_request": [
      "self",
      "endpoint",
      "request_data"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "endpoint",
      "request_query_params",
      "litellm_params"
    ]
  },
  "VLLMConfig": {},
  "llm": [],
  "batch_completions": [
    "model",
    "messages",
    "optional_params",
    "custom_prompt_dict"
  ],
  "MistralOCRConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_ocr_params": [
      "self",
      "model"
    ],
    "map_ocr_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "api_base",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params",
      "litellm_params"
    ],
    "transform_ocr_request": [
      "self",
      "model",
      "document",
      "optional_params",
      "headers"
    ],
    "transform_ocr_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ]
  },
  "MistralConfig": {
    "__init__": [
      "self",
      "temperature",
      "top_p",
      "max_tokens",
      "tools",
      "tool_choice",
      "random_seed",
      "safe_prompt",
      "response_format",
      "stop"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_map_tool_choice": [
      "self",
      "tool_choice"
    ],
    "_get_mistral_reasoning_system_prompt": [],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_transform_messages_async": [
      "self",
      "messages",
      "model"
    ],
    "_transform_messages_sync": [
      "self",
      "messages",
      "model"
    ],
    "_handle_message_with_file": [
      "self",
      "messages"
    ],
    "_add_reasoning_system_prompt_if_needed": [
      "self",
      "messages",
      "optional_params"
    ],
    "_clean_tool_schema_for_mistral": [
      "cls",
      "tools"
    ],
    "_handle_name_in_message": [
      "cls",
      "message"
    ],
    "_handle_tool_call_message": [
      "cls",
      "message"
    ],
    "_is_empty_assistant_message": [
      "cls",
      "message"
    ],
    "_handle_empty_content_response": [
      "response_data"
    ],
    "_convert_thinking_block_to_reasoning_content": [
      "thinking_blocks"
    ],
    "_handle_content_list_to_str_conversion": [
      "response_data"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "MistralChatResponseIterator": {
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "_normalize_content_blocks": [
      "content_blocks"
    ]
  },
  "LlamafileChatConfig": {
    "_resolve_api_key": [
      "api_key"
    ],
    "_resolve_api_base": [
      "api_base"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ]
  },
  "SnowflakeException": {},
  "SnowflakeBaseConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_get_api_base": [
      "self",
      "api_base",
      "optional_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ]
  },
  "SnowflakeBase": {
    "validate_environment": [
      "self",
      "headers",
      "JWT"
    ]
  },
  "SnowflakeEmbeddingConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "SnowflakeConfig": {
    "get_config": [
      "cls"
    ],
    "_transform_tool_calls_from_snowflake_to_openai": [
      "self",
      "content_list"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_transform_tools": [
      "self",
      "tools"
    ],
    "_transform_tool_choice": [
      "self",
      "tool_choice"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "GITHUB_CLIENT_ID": [],
  "GITHUB_DEVICE_CODE_URL": [],
  "GITHUB_ACCESS_TOKEN_URL": [],
  "GITHUB_API_KEY_URL": [],
  "Authenticator": {
    "__init__": [
      "self"
    ],
    "get_access_token": [
      "self"
    ],
    "get_api_key": [
      "self"
    ],
    "get_api_base": [
      "self"
    ],
    "_refresh_api_key": [
      "self"
    ],
    "_ensure_token_dir": [
      "self"
    ],
    "_get_github_headers": [
      "self",
      "access_token"
    ],
    "_get_device_code": [
      "self"
    ],
    "_poll_for_access_token": [
      "self",
      "device_code"
    ],
    "_login": [
      "self"
    ]
  },
  "COPILOT_VERSION": [],
  "EDITOR_PLUGIN_VERSION": [],
  "USER_AGENT": [],
  "API_VERSION": [],
  "GITHUB_COPILOT_API_BASE": [],
  "GithubCopilotError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response",
      "headers",
      "body"
    ]
  },
  "GetDeviceCodeError": {},
  "GetAccessTokenError": {},
  "APIKeyExpiredError": {},
  "RefreshAPIKeyError": {},
  "GetAPIKeyError": {},
  "get_copilot_default_headers": [
    "api_key"
  ],
  "GithubCopilotResponsesAPIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "_handle_reasoning_item": [
      "self",
      "item"
    ],
    "_get_input_from_params": [
      "self",
      "litellm_params"
    ],
    "_get_initiator": [
      "self",
      "input_param"
    ],
    "_has_vision_input": [
      "self",
      "input_param"
    ],
    "_contains_vision_content": [
      "self",
      "value",
      "depth",
      "max_depth"
    ]
  },
  "GithubCopilotEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "GithubCopilotConfig": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "custom_llm_provider"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "model",
      "api_base",
      "api_key",
      "custom_llm_provider"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_determine_initiator": [
      "self",
      "messages"
    ],
    "_has_vision_content": [
      "self",
      "messages"
    ]
  },
  "OCIError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "OCISignerProtocol": {
    "do_request_sign": [
      "self",
      "request"
    ]
  },
  "OCIRequestWrapper": {
    "path_url": [
      "self"
    ]
  },
  "sha256_base64": [
    "data"
  ],
  "build_signature_string": [
    "method",
    "path",
    "headers",
    "signed_headers"
  ],
  "load_private_key_from_str": [
    "key_str"
  ],
  "load_private_key_from_file": [
    "file_path"
  ],
  "get_vendor_from_model": [
    "model"
  ],
  "OCIChatConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_sign_with_oci_signer": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base"
    ],
    "_sign_with_manual_credentials": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base"
    ],
    "sign_request": [
      "self",
      "headers",
      "optional_params",
      "request_data",
      "api_base",
      "api_key",
      "model",
      "stream",
      "fake_stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_get_optional_params": [
      "self",
      "vendor",
      "optional_params"
    ],
    "adapt_messages_to_cohere_standard": [
      "self",
      "messages"
    ],
    "adapt_tool_definitions_to_cohere_standard": [
      "self",
      "tools"
    ],
    "_extract_text_content": [
      "self",
      "content"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_handle_cohere_response": [
      "self",
      "json_response",
      "model",
      "model_response"
    ],
    "_handle_generic_response": [
      "self",
      "json",
      "model",
      "model_response",
      "raw_response"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_sync_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_async_custom_stream_wrapper": [
      "self",
      "model",
      "custom_llm_provider",
      "logging_obj",
      "api_base",
      "headers",
      "data",
      "messages",
      "client",
      "json_mode",
      "signed_json_body"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "adapt_messages_to_generic_oci_standard_content_message": [
    "role",
    "content"
  ],
  "adapt_messages_to_generic_oci_standard_tool_call": [
    "role",
    "tool_calls"
  ],
  "adapt_messages_to_generic_oci_standard_tool_response": [
    "role",
    "tool_call_id",
    "content"
  ],
  "adapt_messages_to_generic_oci_standard": [
    "messages"
  ],
  "adapt_tool_definition_to_oci_standard": [
    "tools",
    "vendor"
  ],
  "adapt_tools_to_openai_standard": [
    "tools"
  ],
  "OCIStreamWrapper": {
    "__init__": [
      "self"
    ],
    "chunk_creator": [
      "self",
      "chunk"
    ],
    "_handle_cohere_stream_chunk": [
      "self",
      "dict_chunk"
    ],
    "_handle_generic_stream_chunk": [
      "self",
      "dict_chunk"
    ]
  },
  "_ParallelAISourcePolicy": {},
  "_ParallelAISearchRequestRequired": {},
  "ParallelAISearchRequest": {},
  "ParallelAISearchConfig": {
    "PARALLEL_AI_API_BASE": [],
    "PARALLEL_HEADER_SEARCH_EXTRACT_VALUE": [],
    "ui_friendly_name": [],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "_transform_query_to_objective": [
      "self",
      "query"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "GroqSTTConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format",
      "tools",
      "tool_choice"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params_stt": [
      "self"
    ],
    "get_supported_openai_response_formats_stt": [
      "self"
    ],
    "map_openai_params_stt": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "GroqChatConfig": {
    "__init__": [
      "self",
      "frequency_penalty",
      "function_call",
      "functions",
      "logit_bias",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "response_format",
      "tools",
      "tool_choice"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "_should_fake_stream": [
      "self",
      "optional_params"
    ],
    "_create_json_tool_call_for_response_format": [
      "self",
      "json_schema"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params",
      "replace_max_completion_tokens_with_max_tokens"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_map_groq_service_tier": [
      "self",
      "original_service_tier"
    ]
  },
  "GroqChatCompletionStreamingHandler": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "GroqChatCompletion": {
    "__init__": [
      "self"
    ],
    "completion": [
      "self"
    ]
  },
  "InfinityError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "InfinityEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "InfinityRerankConfig": {
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ]
  },
  "CometAPIException": {},
  "CometAPIEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "CometAPIImageGenerationConfig": {
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_image_generation_request": [
      "self",
      "model",
      "prompt",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_image_generation_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "get_cometapi_image_generation_config": [
    "model"
  ],
  "CometAPIConfig": {
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "remove_cache_control_flag_from_messages_and_tools": [
      "self",
      "model",
      "messages",
      "tools"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ]
  },
  "CometAPIChatCompletionStreamingHandler": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "CohereError": {
    "__init__": [
      "self",
      "status_code",
      "message"
    ]
  },
  "CohereModelInfo": {
    "get_provider_info": [
      "self",
      "model"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_api_base": [
      "api_base"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_base_model": [
      "model"
    ],
    "get_cohere_route": [
      "model"
    ]
  },
  "CohereV2ModelResponseIterator": {
    "__init__": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "_parse_content_delta": [
      "self",
      "chunk"
    ],
    "_parse_tool_call_delta": [
      "self",
      "chunk"
    ],
    "_parse_tool_plan_delta": [
      "self",
      "chunk"
    ],
    "_parse_citation_start": [
      "self",
      "chunk"
    ],
    "_parse_message_end": [
      "self",
      "chunk"
    ],
    "chunk_parser": [
      "self",
      "chunk"
    ],
    "__iter__": [
      "self"
    ],
    "__next__": [
      "self"
    ],
    "convert_str_chunk_to_generic_chunk": [
      "self",
      "chunk"
    ],
    "__aiter__": [
      "self"
    ],
    "__anext__": [
      "self"
    ]
  },
  "CohereEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "_is_v3_model": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_transform_request": [
      "self",
      "model",
      "input",
      "inference_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "_calculate_usage": [
      "self",
      "input",
      "encoding",
      "meta"
    ],
    "_transform_response": [
      "self",
      "response",
      "api_key",
      "logging_obj",
      "data",
      "model_response",
      "model",
      "encoding",
      "input"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "async_embedding": [
    "model",
    "data",
    "input",
    "model_response",
    "timeout",
    "logging_obj",
    "optional_params",
    "api_base",
    "api_key",
    "headers",
    "encoding",
    "client"
  ],
  "CohereRerankConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "api_key",
      "optional_params"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ],
    "transform_rerank_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "CohereRerankHandler": {
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "CohereRerankV2Config": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "model",
      "optional_params"
    ],
    "get_supported_cohere_rerank_params": [
      "self",
      "model"
    ],
    "map_cohere_rerank_params": [
      "self",
      "non_default_params",
      "model",
      "drop_params",
      "query",
      "documents",
      "custom_llm_provider",
      "top_n",
      "rank_fields",
      "return_documents",
      "max_chunks_per_doc",
      "max_tokens_per_doc"
    ],
    "transform_rerank_request": [
      "self",
      "model",
      "optional_rerank_params",
      "headers"
    ]
  },
  "CohereChatConfig": {
    "__init__": [
      "self",
      "preamble",
      "chat_history",
      "generation_id",
      "response_id",
      "conversation_id",
      "prompt_truncation",
      "connectors",
      "search_queries_only",
      "documents",
      "temperature",
      "max_tokens",
      "max_completion_tokens",
      "k",
      "p",
      "frequency_penalty",
      "presence_penalty",
      "tools",
      "tool_results",
      "seed"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_construct_cohere_tool": [
      "self",
      "tools"
    ],
    "_translate_openai_tool_to_cohere": [
      "self",
      "openai_tool"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "CohereV2ChatConfig": {
    "__init__": [
      "self",
      "preamble",
      "chat_history",
      "generation_id",
      "response_id",
      "conversation_id",
      "prompt_truncation",
      "connectors",
      "search_queries_only",
      "documents",
      "temperature",
      "max_tokens",
      "k",
      "p",
      "frequency_penalty",
      "presence_penalty",
      "tools",
      "tool_results",
      "seed"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "_translate_citations_to_openai_annotations": [
      "self",
      "citations"
    ]
  },
  "XAIModelInfo": {
    "get_provider_info": [
      "self",
      "model"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_api_base": [
      "api_base"
    ],
    "get_api_key": [
      "api_key"
    ],
    "get_base_model": [
      "model"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ]
  },
  "XAIResponsesAPIConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_transform_web_search_tool": [
      "self",
      "tool"
    ],
    "_transform_x_search_tool": [
      "self",
      "tool"
    ],
    "map_openai_params": [
      "self",
      "response_api_optional_params",
      "model",
      "drop_params"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ]
  },
  "XAIRealtime": {
    "_get_default_api_base": [
      "self"
    ],
    "_get_additional_headers": [
      "self",
      "api_key"
    ]
  },
  "XAIChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_supports_stop_reason": [
      "self",
      "model"
    ],
    "_supports_frequency_penalty": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_model_response_iterator": [
      "self",
      "streaming_response",
      "sync_stream",
      "json_mode"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "_fix_choice_finish_reason_for_tool_calls": [
      "choice"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ],
    "_enhance_usage_with_xai_web_search_fields": [
      "self",
      "model_response",
      "raw_response_json"
    ]
  },
  "XAIChatCompletionStreamingHandler": {
    "chunk_parser": [
      "self",
      "chunk"
    ]
  },
  "HerokuError": {},
  "HerokuChatConfig": {
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ]
  },
  "CodestralTextCompletionConfig": {
    "__init__": [
      "self",
      "suffix",
      "temperature",
      "top_p",
      "max_tokens",
      "min_tokens",
      "stream",
      "random_seed",
      "stop"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_chunk_parser": [
      "self",
      "chunk_data"
    ]
  },
  "TextCompletionCodestralError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response"
    ]
  },
  "CodestralTextCompletion": {
    "__init__": [
      "self"
    ],
    "_validate_environment": [
      "self",
      "api_key",
      "user_headers"
    ],
    "output_parser": [
      "self",
      "generated_text"
    ],
    "process_text_completion_response": [
      "self",
      "model",
      "response",
      "model_response",
      "stream",
      "logging_obj",
      "optional_params",
      "api_key",
      "data",
      "messages",
      "print_verbose",
      "encoding"
    ],
    "completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "custom_prompt_dict",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "optional_params",
      "timeout",
      "acompletion",
      "litellm_params",
      "logger_fn",
      "headers"
    ],
    "async_completion": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "stream",
      "data",
      "optional_params",
      "timeout",
      "litellm_params",
      "logger_fn",
      "headers"
    ],
    "async_streaming": [
      "self",
      "model",
      "messages",
      "api_base",
      "model_response",
      "print_verbose",
      "encoding",
      "api_key",
      "logging_obj",
      "data",
      "timeout",
      "optional_params",
      "litellm_params",
      "logger_fn",
      "headers"
    ],
    "embedding": [
      "self"
    ]
  },
  "_SearXNGSearchRequestRequired": {},
  "SearXNGSearchRequest": {},
  "SearXNGSearchConfig": {
    "ui_friendly_name": [],
    "get_http_method": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "optional_params",
      "data"
    ],
    "transform_search_request": [
      "self",
      "query",
      "optional_params"
    ],
    "transform_search_response": [
      "self",
      "raw_response",
      "logging_obj"
    ]
  },
  "VercelAIGatewayException": {},
  "VercelAIGatewayEmbeddingConfig": {
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "VercelAIGatewayConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ]
  },
  "SambanovaConfig": {
    "__init__": [
      "self",
      "max_tokens",
      "response_format",
      "stop",
      "stream",
      "stream_options",
      "temperature",
      "top_p",
      "top_k",
      "tool_choice",
      "tools"
    ],
    "get_config": [
      "cls"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "_transform_messages": [
      "self",
      "messages",
      "model",
      "is_async"
    ]
  },
  "SambaNovaError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "headers"
    ]
  },
  "SambaNovaEmbeddingConfig": {
    "__init__": [
      "self"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "get_supported_openai_params": [
      "self",
      "model"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ],
    "transform_embedding_request": [
      "self",
      "model",
      "input",
      "optional_params",
      "headers"
    ],
    "transform_embedding_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "api_key",
      "request_data",
      "optional_params",
      "litellm_params"
    ],
    "get_error_class": [
      "self",
      "error_message",
      "status_code",
      "headers"
    ]
  },
  "PassThroughEndpointHandler": {
    "_get_guardrail_settings": [
      "self",
      "litellm_logging_obj",
      "guardrail_name"
    ],
    "_extract_text_for_guardrail": [
      "self",
      "data",
      "field_expressions"
    ],
    "process_input_messages": [
      "self",
      "data",
      "guardrail_to_apply",
      "litellm_logging_obj"
    ],
    "process_output_response": [
      "self",
      "response",
      "guardrail_to_apply",
      "litellm_logging_obj",
      "user_api_key_dict"
    ]
  },
  "RAGFlowVectorStoreConfig": {
    "get_auth_credentials": [
      "self",
      "litellm_params"
    ],
    "get_vector_store_endpoints_by_type": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "litellm_params"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ],
    "transform_search_vector_store_request": [
      "self",
      "vector_store_id",
      "query",
      "vector_store_search_optional_params",
      "api_base",
      "litellm_logging_obj",
      "litellm_params"
    ],
    "transform_search_vector_store_response": [
      "self",
      "response",
      "litellm_logging_obj"
    ],
    "transform_create_vector_store_request": [
      "self",
      "vector_store_create_optional_params",
      "api_base"
    ],
    "transform_create_vector_store_response": [
      "self",
      "response"
    ]
  },
  "RAGFlowConfig": {
    "_parse_ragflow_model": [
      "self",
      "model"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "api_key",
      "model",
      "optional_params",
      "litellm_params",
      "stream"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "model",
      "api_base",
      "api_key",
      "custom_llm_provider"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "transform_request": [
      "self",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "headers"
    ]
  },
  "TOKEN_EXPIRY_SKEW_SECONDS": [],
  "DEVICE_CODE_TIMEOUT_SECONDS": [],
  "DEVICE_CODE_COOLDOWN_SECONDS": [],
  "DEVICE_CODE_POLL_SLEEP_SECONDS": [],
  "CHATGPT_AUTH_BASE": [],
  "CHATGPT_DEVICE_CODE_URL": [],
  "CHATGPT_DEVICE_TOKEN_URL": [],
  "CHATGPT_OAUTH_TOKEN_URL": [],
  "CHATGPT_DEVICE_VERIFY_URL": [],
  "CHATGPT_API_BASE": [],
  "CHATGPT_CLIENT_ID": [],
  "DEFAULT_ORIGINATOR": [],
  "DEFAULT_USER_AGENT": [],
  "CHATGPT_DEFAULT_INSTRUCTIONS": [],
  "ChatGPTAuthError": {
    "__init__": [
      "self",
      "status_code",
      "message",
      "request",
      "response",
      "headers",
      "body"
    ]
  },
  "RefreshAccessTokenError": {},
  "_safe_header_value": [
    "value"
  ],
  "_sanitize_user_agent_token": [
    "value"
  ],
  "_terminal_user_agent": [],
  "_get_litellm_version": [],
  "get_chatgpt_originator": [],
  "get_chatgpt_user_agent": [
    "originator"
  ],
  "get_chatgpt_default_headers": [
    "access_token",
    "account_id",
    "session_id"
  ],
  "get_chatgpt_default_instructions": [],
  "_normalize_litellm_params": [
    "litellm_params"
  ],
  "get_chatgpt_session_id": [
    "litellm_params"
  ],
  "ensure_chatgpt_session_id": [
    "litellm_params"
  ],
  "ChatGPTResponsesAPIConfig": {
    "__init__": [
      "self"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "litellm_params"
    ],
    "transform_responses_api_request": [
      "self",
      "model",
      "input",
      "response_api_optional_request_params",
      "litellm_params",
      "headers"
    ],
    "transform_response_api_response": [
      "self",
      "model",
      "raw_response",
      "logging_obj"
    ],
    "get_complete_url": [
      "self",
      "api_base",
      "litellm_params"
    ]
  },
  "ChatGPTConfig": {
    "__init__": [
      "self",
      "api_key",
      "api_base",
      "custom_llm_provider"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "model",
      "api_base",
      "api_key",
      "custom_llm_provider"
    ],
    "validate_environment": [
      "self",
      "headers",
      "model",
      "messages",
      "optional_params",
      "litellm_params",
      "api_key",
      "api_base"
    ],
    "map_openai_params": [
      "self",
      "non_default_params",
      "optional_params",
      "model",
      "drop_params"
    ]
  },
  "LemonadeChatConfig": {
    "__init__": [
      "self",
      "repeat_penalty",
      "functions",
      "logit_bias",
      "max_completion_tokens",
      "max_tokens",
      "n",
      "presence_penalty",
      "stop",
      "temperature",
      "top_p",
      "top_k",
      "response_format",
      "tools"
    ],
    "custom_llm_provider": [
      "self"
    ],
    "get_config": [
      "cls"
    ],
    "get_models": [
      "self",
      "api_key",
      "api_base"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ],
    "transform_response": [
      "self",
      "model",
      "raw_response",
      "model_response",
      "logging_obj",
      "request_data",
      "messages",
      "optional_params",
      "litellm_params",
      "encoding",
      "api_key",
      "json_mode"
    ]
  },
  "LambdaAIChatConfig": {
    "custom_llm_provider": [
      "self"
    ],
    "_get_openai_compatible_provider_info": [
      "self",
      "api_base",
      "api_key"
    ]
  },
  "FriendliaiChatConfig": {},
  "AWSSecretsManagerV2": {
    "__init__": [
      "self",
      "aws_region_name",
      "aws_role_name",
      "aws_session_name",
      "aws_external_id",
      "aws_profile_name",
      "aws_web_identity_token",
      "aws_sts_endpoint"
    ],
    "validate_environment": [
      "cls"
    ],
    "load_aws_secret_manager": [
      "cls",
      "use_aws_secret_manager",
      "key_management_settings"
    ],
    "async_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout",
      "primary_secret_name"
    ],
    "sync_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout",
      "primary_secret_name"
    ],
    "_parse_primary_secret": [
      "self",
      "primary_secret_json_str"
    ],
    "sync_read_secret_from_primary_secret": [
      "self",
      "secret_name",
      "primary_secret_name"
    ],
    "async_read_secret_from_primary_secret": [
      "self",
      "secret_name",
      "primary_secret_name"
    ],
    "async_write_secret": [
      "self",
      "secret_name",
      "secret_value",
      "description",
      "optional_params",
      "timeout",
      "tags"
    ],
    "async_put_secret_value": [
      "self",
      "secret_name",
      "secret_value",
      "optional_params",
      "timeout"
    ],
    "async_rotate_secret": [
      "self",
      "current_secret_name",
      "new_secret_name",
      "new_secret_value",
      "optional_params",
      "timeout"
    ],
    "async_delete_secret": [
      "self",
      "secret_name",
      "recovery_window_in_days",
      "optional_params",
      "timeout"
    ],
    "_prepare_request": [
      "self",
      "action",
      "secret_name",
      "secret_value",
      "optional_params",
      "request_data"
    ]
  },
  "infer_credential_type_from_environment": [],
  "get_azure_ad_token_provider": [
    "azure_scope",
    "azure_credential"
  ],
  "load_google_kms": [
    "use_google_kms"
  ],
  "load_custom_secret_manager": [
    "config_file_path"
  ],
  "HashicorpSecretManager": {
    "__init__": [
      "self"
    ],
    "_verify_required_credentials_exist": [
      "self"
    ],
    "_auth_via_approle": [
      "self"
    ],
    "_auth_via_tls_cert": [
      "self"
    ],
    "_get_tls_cert_auth_body": [
      "self"
    ],
    "get_url": [
      "self",
      "secret_name",
      "namespace",
      "mount_name",
      "path_prefix"
    ],
    "_sanitize_plain_value": [
      "self",
      "value"
    ],
    "_sanitize_path_component": [
      "self",
      "value"
    ],
    "_extract_secret_manager_settings": [
      "self",
      "optional_params"
    ],
    "_build_secret_target": [
      "self",
      "secret_name",
      "optional_params"
    ],
    "_get_request_headers": [
      "self"
    ],
    "async_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "sync_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "async_write_secret": [
      "self",
      "secret_name",
      "secret_value",
      "description",
      "optional_params",
      "timeout",
      "tags"
    ],
    "async_rotate_secret": [
      "self",
      "current_secret_name",
      "new_secret_name",
      "new_secret_value",
      "optional_params",
      "timeout"
    ],
    "async_delete_secret": [
      "self",
      "secret_name",
      "recovery_window_in_days",
      "optional_params",
      "timeout"
    ],
    "_get_secret_value_from_json_response": [
      "self",
      "json_resp"
    ]
  },
  "oidc_cache": [],
  "_get_oidc_http_handler": [
    "timeout"
  ],
  "str_to_bool": [
    "value"
  ],
  "get_secret_str": [
    "secret_name",
    "default_value"
  ],
  "get_secret_bool": [
    "secret_name",
    "default_value"
  ],
  "get_secret": [
    "secret_name",
    "default_value"
  ],
  "_should_read_secret_from_secret_manager": [],
  "load_aws_kms": [
    "use_aws_kms"
  ],
  "AWSKeyManagementService_V2": {
    "__init__": [
      "self"
    ],
    "validate_environment": [
      "self"
    ],
    "load_aws_kms": [
      "self",
      "use_aws_kms"
    ],
    "decrypt_value": [
      "self",
      "secret_name"
    ]
  },
  "decrypt_env_var": [],
  "BaseSecretManager": {
    "async_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "sync_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "async_write_secret": [
      "self",
      "secret_name",
      "secret_value",
      "description",
      "optional_params",
      "timeout",
      "tags"
    ],
    "async_delete_secret": [
      "self",
      "secret_name",
      "recovery_window_in_days",
      "optional_params",
      "timeout"
    ],
    "async_rotate_secret": [
      "self",
      "current_secret_name",
      "new_secret_name",
      "new_secret_value",
      "optional_params",
      "timeout"
    ]
  },
  "GoogleSecretManager": {
    "__init__": [
      "self",
      "refresh_interval",
      "always_read_secret_manager"
    ],
    "get_secret_from_google_secret_manager": [
      "self",
      "secret_name"
    ]
  },
  "CyberArkSecretManager": {
    "__init__": [
      "self"
    ],
    "_authenticate": [
      "self"
    ],
    "_get_request_headers": [
      "self"
    ],
    "_ensure_variable_exists": [
      "self",
      "secret_name"
    ],
    "get_url": [
      "self",
      "secret_name"
    ],
    "async_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "sync_read_secret": [
      "self",
      "secret_name",
      "optional_params",
      "timeout"
    ],
    "async_write_secret": [
      "self",
      "secret_name",
      "secret_value",
      "description",
      "optional_params",
      "timeout",
      "tags"
    ],
    "async_delete_secret": [
      "self",
      "secret_name",
      "recovery_window_in_days",
      "optional_params",
      "timeout"
    ]
  },
  "_is_base64": [
    "s"
  ],
  "get_secret_from_manager": [
    "client",
    "key_manager",
    "secret_name",
    "key_management_settings"
  ]
}