{
  "is_cuda_v2": [],
  "PACKAGE_LIST": [],
  "BaseEnv": {
    "__init__": [
      "self"
    ],
    "get_info": [
      "self"
    ],
    "get_topology": [
      "self"
    ],
    "get_package_versions": [
      "self"
    ],
    "get_device_info": [
      "self"
    ],
    "get_hypervisor_vendor": [
      "self"
    ],
    "get_ulimit_soft": [
      "self"
    ],
    "check_env": [
      "self"
    ]
  },
  "GPUEnv": {
    "get_info": [
      "self"
    ],
    "_get_cuda_version_info": [
      "self"
    ],
    "_get_nvcc_info": [
      "self"
    ],
    "_get_cuda_driver_version": [
      "self"
    ],
    "get_topology": [
      "self"
    ]
  },
  "HIPEnv": {
    "get_info": [
      "self"
    ],
    "_get_cuda_version_info": [
      "self"
    ],
    "_get_hipcc_info": [
      "self"
    ],
    "_get_rocm_driver_version": [
      "self"
    ],
    "get_topology": [
      "self"
    ]
  },
  "NPUEnv": {
    "EXTRA_PACKAGE_LIST": [],
    "__init__": [
      "self"
    ],
    "get_info": [
      "self"
    ],
    "get_device_info": [
      "self"
    ],
    "_get_cann_version_info": [
      "self"
    ],
    "_get_cann_info": [
      "self",
      "CANN_HOME"
    ],
    "_get_ascend_driver_version": [
      "self"
    ],
    "get_topology": [
      "self"
    ]
  },
  "run_server": [
    "server_args"
  ],
  "logger": [],
  "execute_once": [
    "func"
  ],
  "info_once": [
    "message"
  ],
  "convert_json_schema_to_str": [
    "json_schema"
  ],
  "get_exception_traceback": [],
  "is_same_type": [
    "values"
  ],
  "read_jsonl": [
    "filename"
  ],
  "dump_state_text": [
    "filename",
    "states",
    "mode"
  ],
  "HttpResponse": {
    "__init__": [
      "self",
      "resp"
    ],
    "json": [
      "self"
    ],
    "status_code": [
      "self"
    ]
  },
  "http_request": [
    "url",
    "json",
    "stream",
    "api_key",
    "verify",
    "method"
  ],
  "encode_image_base64": [
    "image_path"
  ],
  "encode_frame": [
    "frame"
  ],
  "encode_video_base64": [
    "video_path",
    "num_frames"
  ],
  "_is_chinese_char": [
    "cp"
  ],
  "find_printable_text": [
    "text"
  ],
  "LazyImport": {
    "__init__": [
      "self",
      "module_name",
      "class_name"
    ],
    "_load": [
      "self"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__call__": [
      "self"
    ]
  },
  "download_and_cache_file": [
    "url",
    "filename"
  ],
  "is_in_ci": [],
  "print_highlight": [
    "html_content"
  ],
  "process_socket_map": [],
  "reserve_port": [
    "host",
    "start",
    "end"
  ],
  "release_port": [
    "lock_socket"
  ],
  "execute_shell_command": [
    "command"
  ],
  "launch_server_cmd": [
    "command",
    "host",
    "port"
  ],
  "terminate_process": [
    "process"
  ],
  "wait_for_server": [
    "base_url",
    "timeout"
  ],
  "TypeBasedDispatcher": {
    "__init__": [
      "self",
      "mapping"
    ],
    "add_fallback_fn": [
      "self",
      "fallback_fn"
    ],
    "__iadd__": [
      "self",
      "other"
    ],
    "__call__": [
      "self",
      "obj"
    ]
  },
  "trim_overlap": [
    "existing_text",
    "new_chunk"
  ],
  "stream_and_merge": [
    "llm",
    "prompt",
    "sampling_params"
  ],
  "async_stream_and_merge": [
    "llm",
    "prompt",
    "sampling_params"
  ],
  "resolve_obj_by_qualname": [
    "qualname"
  ],
  "Anthropic": [],
  "LiteLLM": [],
  "OpenAI": [],
  "VertexAI": [],
  "ServerArgs": [],
  "Engine": [],
  "__all__": [],
  "CompileArgs": {
    "add_cli_args": [
      "parser"
    ],
    "from_cli_args": [
      "cls",
      "args"
    ]
  },
  "warm_up_compile": [
    "disaggregation_mode",
    "tokenizer_manager"
  ],
  "launch_server_internal": [
    "server_args"
  ],
  "launch_server_process_and_send_one_request": [
    "server_args",
    "compile_args"
  ],
  "refine_server_args": [
    "server_args",
    "compile_args"
  ],
  "run_compile": [
    "server_args",
    "compile_args"
  ],
  "ASSISTANT_SUFFIX": [],
  "_ROUTING_KEY_HEADER": [],
  "TERM_PLOTLIB_AVAILABLE": [],
  "_get_bool_env_var": [
    "name",
    "default"
  ],
  "_create_bench_client_session": [],
  "RequestFuncInput": {},
  "RequestFuncOutput": {
    "init_new": [
      "request_func_input"
    ]
  },
  "remove_prefix": [
    "text",
    "prefix"
  ],
  "remove_suffix": [
    "text",
    "suffix"
  ],
  "get_auth_headers": [],
  "parse_custom_headers": [
    "header_list"
  ],
  "get_request_headers": [],
  "async_request_trt_llm": [
    "request_func_input",
    "pbar"
  ],
  "async_request_openai_completions": [
    "request_func_input",
    "pbar"
  ],
  "async_request_openai_chat_completions": [
    "request_func_input",
    "pbar"
  ],
  "async_request_truss": [
    "request_func_input",
    "pbar"
  ],
  "async_request_sglang_generate": [
    "request_func_input",
    "pbar"
  ],
  "async_request_gserver": [
    "request_func_input",
    "pbar"
  ],
  "async_request_profile": [
    "api_url"
  ],
  "_build_profile_urls": [
    "profile_prefill_url",
    "profile_decode_url"
  ],
  "_call_profile_pd": [
    "profile_urls",
    "mode"
  ],
  "get_model": [
    "pretrained_model_name_or_path"
  ],
  "get_tokenizer": [
    "pretrained_model_name_or_path"
  ],
  "get_processor": [
    "pretrained_model_name_or_path"
  ],
  "get_dataset": [
    "args",
    "tokenizer",
    "model_id"
  ],
  "ASYNC_REQUEST_FUNCS": [],
  "BenchmarkMetrics": {},
  "SHAREGPT_REPO_ID": [],
  "SHAREGPT_FILENAME": [],
  "MOONCAKE_DATASET_URL": [],
  "download_and_cache_hf_file": [
    "repo_id",
    "filename",
    "repo_type"
  ],
  "is_file_valid_json": [
    "path"
  ],
  "DatasetRow": {
    "__post_init__": [
      "self"
    ]
  },
  "get_mooncake_request_over_time": [
    "input_requests",
    "tokenizer",
    "slowdown_factor",
    "num_rounds"
  ],
  "sample_mmmu_requests": [
    "num_requests",
    "processor",
    "backend",
    "fixed_output_len",
    "random_sample"
  ],
  "sample_sharegpt_requests": [
    "dataset_path",
    "num_requests",
    "tokenizer",
    "fixed_output_len",
    "context_len",
    "prompt_suffix",
    "apply_chat_template"
  ],
  "sample_custom_requests": [
    "dataset_path",
    "num_requests",
    "tokenizer",
    "fixed_output_len",
    "context_len",
    "prompt_suffix",
    "apply_chat_template"
  ],
  "compute_random_lens": [
    "full_len",
    "range_ratio",
    "num"
  ],
  "sample_random_requests": [
    "input_len",
    "output_len",
    "num_prompts",
    "range_ratio",
    "tokenizer",
    "dataset_path",
    "random_sample",
    "return_text"
  ],
  "parse_image_resolution": [
    "image_resolution"
  ],
  "create_mm_data_row": [
    "text_prompt",
    "images",
    "images_base64",
    "output_len",
    "processor",
    "backend"
  ],
  "sample_image_requests": [
    "num_requests",
    "image_count",
    "input_len",
    "output_len",
    "range_ratio",
    "processor",
    "image_content",
    "image_format",
    "image_resolution",
    "backend",
    "random_image_count"
  ],
  "get_available_tokens": [
    "tokenizer"
  ],
  "gen_prompt": [
    "tokenizer",
    "token_num"
  ],
  "gen_mm_prompt": [
    "tokenizer",
    "image_pad_id",
    "token_num"
  ],
  "get_gen_prefix_cache_path": [
    "args",
    "tokenizer"
  ],
  "sample_generated_shared_prefix_requests": [
    "num_groups",
    "prompts_per_group",
    "system_prompt_len",
    "question_len",
    "output_len",
    "range_ratio",
    "tokenizer",
    "args"
  ],
  "get_request": [
    "input_requests",
    "request_rate",
    "use_trace_timestamps",
    "slowdown_factor"
  ],
  "calculate_metrics": [
    "input_requests",
    "outputs",
    "dur_s",
    "tokenizer",
    "backend",
    "accept_length",
    "plot_throughput"
  ],
  "MULTI_TURN_BACKENDS": [],
  "wrap_multi_turn_request_func": [
    "request_func",
    "backend"
  ],
  "benchmark": [
    "backend",
    "api_url",
    "base_url",
    "model_id",
    "tokenizer",
    "input_requests",
    "request_rate",
    "max_concurrency",
    "disable_tqdm",
    "lora_names",
    "lora_request_distribution",
    "lora_zipf_alpha",
    "extra_request_body",
    "profile",
    "pd_separated",
    "flush_cache",
    "warmup_requests",
    "use_trace_timestamps",
    "mooncake_slowdown_factor",
    "mooncake_num_rounds",
    "profile_prefill_url",
    "profile_decode_url"
  ],
  "check_chat_template": [
    "model_path"
  ],
  "set_global_args": [
    "args_"
  ],
  "run_benchmark": [
    "args_"
  ],
  "set_ulimit": [
    "target_soft_limit"
  ],
  "LoRAPathAction": {
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "GlobalConfig": {
    "__init__": [
      "self"
    ]
  },
  "global_config": [],
  "BenchArgs": {
    "add_cli_args": [
      "parser"
    ],
    "from_cli_args": [
      "cls",
      "args"
    ]
  },
  "throughput_test_once": [
    "backend_name",
    "backend",
    "reqs",
    "ignore_eos",
    "extra_request_body",
    "profile",
    "return_logprob",
    "logprob_start_len"
  ],
  "monitor_trace_file": [
    "known_files",
    "directory",
    "interval"
  ],
  "throughput_test": [
    "server_args",
    "bench_args"
  ],
  "profile_activities": [],
  "start_profile": [
    "profile_activities",
    "profile_record_shapes",
    "rank_print"
  ],
  "stop_profile": [
    "profiler",
    "profile_activities",
    "rank_print",
    "save_trace",
    "trace_filename",
    "stage"
  ],
  "load_model": [
    "server_args",
    "port_args",
    "gpu_id",
    "tp_rank"
  ],
  "prepare_inputs_for_correctness_test": [
    "bench_args",
    "tokenizer",
    "custom_prompts"
  ],
  "prepare_extend_inputs_for_correctness_test": [
    "bench_args",
    "input_ids",
    "reqs",
    "model_runner"
  ],
  "prepare_synthetic_inputs_for_latency_test": [
    "batch_size",
    "input_len",
    "custom_inputs"
  ],
  "TreeCacheNamespace": {
    "supports_swa": [
      "self"
    ],
    "supports_mamba": [
      "self"
    ],
    "is_chunk_cache": [
      "self"
    ],
    "is_tree_cache": [
      "self"
    ]
  },
  "extend": [
    "reqs",
    "model_runner"
  ],
  "decode": [
    "input_token_ids",
    "batch",
    "model_runner"
  ],
  "_maybe_prepare_mlp_sync_batch": [
    "batch",
    "model_runner"
  ],
  "_read_prompts_from_file": [
    "prompt_file",
    "rank_print"
  ],
  "_get_torch_profiler_output_dir": [],
  "_create_torch_profiler_filename": [
    "profile_filename_prefix",
    "batch_size",
    "input_len",
    "output_len",
    "stage"
  ],
  "_save_profile_trace_results": [
    "profiler",
    "filename"
  ],
  "correctness_test": [
    "server_args",
    "port_args",
    "bench_args",
    "gpu_id",
    "tp_rank"
  ],
  "synchronize": [
    "device"
  ],
  "latency_test_run_once": [
    "run_name",
    "model_runner",
    "rank_print",
    "reqs",
    "batch_size",
    "input_len",
    "output_len",
    "device",
    "log_decode_step",
    "profile",
    "profile_record_shapes",
    "profile_activities",
    "profile_filename_prefix",
    "profile_stage",
    "tp_rank"
  ],
  "latency_test": [
    "server_args",
    "port_args",
    "bench_args",
    "gpu_id",
    "tp_rank"
  ],
  "main": [
    "server_args",
    "bench_args"
  ],
  "TYPE_CHECKING": [],
  "__version__": [],
  "version": [],
  "__version_tuple__": [],
  "version_tuple": [],
  "__commit_id__": [],
  "commit_id": [],
  "PROFILER_DIR": [],
  "run_profile": [
    "url",
    "num_steps",
    "activities",
    "output_dir",
    "profile_by_stage",
    "merge_profiles",
    "profile_prefix"
  ],
  "ConfigArgumentMerger": {
    "__init__": [
      "self",
      "parser",
      "boolean_actions"
    ],
    "merge_config_with_args": [
      "self",
      "cli_args"
    ],
    "_extract_config_file_path": [
      "self",
      "args"
    ],
    "_parse_yaml_config": [
      "self",
      "file_path"
    ],
    "_validate_yaml_file": [
      "self",
      "file_path"
    ],
    "_convert_config_to_args": [
      "self",
      "config"
    ],
    "_add_boolean_arg": [
      "self",
      "args",
      "key",
      "value"
    ],
    "_add_list_arg": [
      "self",
      "args",
      "key",
      "value"
    ],
    "_add_scalar_arg": [
      "self",
      "args",
      "key",
      "value"
    ]
  },
  "DEFAULT_UVICORN_ACCESS_LOG_EXCLUDE_PREFIXES": [],
  "SAMPLING_BACKEND_CHOICES": [],
  "LOAD_FORMAT_CHOICES": [],
  "QUANTIZATION_CHOICES": [],
  "SPECULATIVE_DRAFT_MODEL_QUANTIZATION_CHOICES": [],
  "ATTENTION_BACKEND_CHOICES": [],
  "LORA_BACKEND_CHOICES": [],
  "DISAGG_TRANSFER_BACKEND_CHOICES": [],
  "ENCODER_TRANSFER_BACKEND_CHOICES": [],
  "GRAMMAR_BACKEND_CHOICES": [],
  "DETERMINISTIC_ATTENTION_BACKEND_CHOICES": [],
  "RADIX_SUPPORTED_DETERMINISTIC_ATTENTION_BACKEND": [],
  "NSA_PREFILL_CP_SPLIT_CHOICES": [],
  "DEFAULT_LORA_EVICTION_POLICY": [],
  "NSA_CHOICES": [],
  "RADIX_EVICTION_POLICY_CHOICES": [],
  "RL_ON_POLICY_TARGET_CHOICES": [],
  "MOE_RUNNER_BACKEND_CHOICES": [],
  "MOE_A2A_BACKEND_CHOICES": [],
  "FP8_GEMM_RUNNER_BACKEND_CHOICES": [],
  "FP4_GEMM_RUNNER_BACKEND_CHOICES": [],
  "MAMBA_SSM_DTYPE_CHOICES": [],
  "MAMBA_SCHEDULER_STRATEGY_CHOICES": [],
  "add_load_format_choices": [
    "choices"
  ],
  "add_quantization_method_choices": [
    "choices"
  ],
  "add_attention_backend_choices": [
    "choices"
  ],
  "add_disagg_transfer_backend_choices": [
    "choices"
  ],
  "add_grammar_backend_choices": [
    "choices"
  ],
  "add_moe_runner_backend_choices": [
    "choices"
  ],
  "add_fp8_gemm_runner_backend_choices": [
    "choices"
  ],
  "add_fp4_gemm_runner_backend_choices": [
    "choices"
  ],
  "add_deterministic_attention_backend_choices": [
    "choices"
  ],
  "add_radix_supported_deterministic_attention_backend_choices": [
    "choices"
  ],
  "add_radix_eviction_policy_choices": [
    "choices"
  ],
  "add_rl_on_policy_target_choices": [
    "choices"
  ],
  "add_mamba_ssm_dtype_choices": [
    "choices"
  ],
  "set_global_server_args_for_scheduler": [
    "server_args"
  ],
  "set_global_server_args_for_tokenizer": [],
  "get_global_server_args": [],
  "prepare_server_args": [
    "argv"
  ],
  "ZMQ_TCP_PORT_DELTA": [],
  "DP_ATTENTION_HANDSHAKE_PORT_DELTA": [],
  "PortArgs": {
    "init_new": [
      "server_args",
      "dp_rank",
      "worker_ports"
    ]
  },
  "print_deprecated_warning": [
    "message"
  ],
  "DeprecatedAction": {
    "__init__": [
      "self",
      "option_strings",
      "dest",
      "nargs"
    ],
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "auto_choose_speculative_params": [
    "self"
  ],
  "temp_set_env": [],
  "EnvField": {
    "_allow_set_name": [],
    "__init__": [
      "self",
      "default"
    ],
    "__set_name__": [
      "self",
      "owner",
      "name"
    ],
    "parse": [
      "self",
      "value"
    ],
    "get": [
      "self"
    ],
    "is_set": [
      "self"
    ],
    "set": [
      "self",
      "value"
    ],
    "override": [
      "self",
      "value"
    ],
    "clear": [
      "self"
    ],
    "__bool__": [
      "self"
    ],
    "__len__": [
      "self"
    ]
  },
  "EnvTuple": {
    "parse": [
      "self",
      "value"
    ]
  },
  "EnvStr": {
    "parse": [
      "self",
      "value"
    ]
  },
  "EnvBool": {
    "parse": [
      "self",
      "value"
    ]
  },
  "EnvInt": {
    "parse": [
      "self",
      "value"
    ]
  },
  "EnvFloat": {
    "parse": [
      "self",
      "value"
    ]
  },
  "ToolStrictLevel": {
    "OFF": [],
    "FUNCTION": [],
    "PARAMETER": []
  },
  "Envs": {
    "SGLANG_USE_MODELSCOPE": [],
    "SGLANG_DISABLED_MODEL_ARCHS": [],
    "SGLANG_LOG_GC": [],
    "SGLANG_LOG_FORWARD_ITERS": [],
    "SGLANG_LOG_MS": [],
    "SGLANG_DISABLE_REQUEST_LOGGING": [],
    "SGLANG_LOG_REQUEST_EXCEEDED_MS": [],
    "SGLANG_LOG_SCHEDULER_STATUS_TARGET": [],
    "SGLANG_LOG_SCHEDULER_STATUS_INTERVAL": [],
    "SGLANG_IS_IN_CI": [],
    "SGLANG_IS_IN_CI_AMD": [],
    "SGLANG_TEST_MAX_RETRY": [],
    "SGLANG_GRAMMAR_POLL_INTERVAL": [],
    "SGLANG_GRAMMAR_MAX_POLL_ITERATIONS": [],
    "SGLANG_USE_CUTEDSL_GDN_DECODE": [],
    "SGLANG_DETECT_SLOW_RANK": [],
    "SGLANG_TEST_STUCK_DETOKENIZER": [],
    "SGLANG_TEST_STUCK_DP_CONTROLLER": [],
    "SGLANG_TEST_STUCK_SCHEDULER_INIT": [],
    "SGLANG_TEST_STUCK_TOKENIZER": [],
    "SGLANG_TEST_CRASH_AFTER_STREAM_OUTPUTS": [],
    "IS_BLACKWELL": [],
    "IS_H200": [],
    "SGLANG_SET_CPU_AFFINITY": [],
    "SGLANG_PROFILE_WITH_STACK": [],
    "SGLANG_PROFILE_RECORD_SHAPES": [],
    "SGLANG_PROFILE_V2": [],
    "SGLANG_RECORD_STEP_TIME": [],
    "SGLANG_FORCE_SHUTDOWN": [],
    "SGLANG_DEBUG_MEMORY_POOL": [],
    "SGLANG_TEST_REQUEST_TIME_STATS": [],
    "SGLANG_DISABLE_TP_MEMORY_INBALANCE_CHECK": [],
    "SGLANG_SIMULATE_ACC_LEN": [],
    "SGLANG_SIMULATE_ACC_METHOD": [],
    "SGLANG_TORCH_PROFILER_DIR": [],
    "SGLANG_OTLP_EXPORTER_SCHEDULE_DELAY_MILLIS": [],
    "SGLANG_OTLP_EXPORTER_MAX_EXPORT_BATCH_SIZE": [],
    "SGLANG_NATIVE_MOVE_KV_CACHE": [],
    "SGLANG_ENABLE_TP_MEMORY_INBALANCE_CHECK": [],
    "SGLANG_TEST_RETRACT": [],
    "SGLANG_TEST_RETRACT_INTERVAL": [],
    "SGLANG_TEST_RETRACT_NO_PREFILL_BS": [],
    "SGLANG_ENABLE_STRICT_MEM_CHECK_DURING_BUSY": [],
    "SGLANG_ENABLE_STRICT_MEM_CHECK_DURING_IDLE": [],
    "SGLANG_INIT_NEW_TOKEN_RATIO": [],
    "SGLANG_MIN_NEW_TOKEN_RATIO_FACTOR": [],
    "SGLANG_NEW_TOKEN_RATIO_DECAY_STEPS": [],
    "SGLANG_RETRACT_DECODE_STEPS": [],
    "SGLANG_CLIP_MAX_NEW_TOKENS_ESTIMATION": [],
    "SGLANG_SCHEDULER_RECV_SKIPPER_WEIGHT_DEFAULT": [],
    "SGLANG_SCHEDULER_RECV_SKIPPER_WEIGHT_DECODE": [],
    "SGLANG_SCHEDULER_RECV_SKIPPER_WEIGHT_TARGET_VERIFY": [],
    "SGLANG_SCHEDULER_RECV_SKIPPER_WEIGHT_NONE": [],
    "SGLANG_DISAGGREGATION_THREAD_POOL_SIZE": [],
    "SGLANG_DISAGGREGATION_QUEUE_SIZE": [],
    "SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT": [],
    "SGLANG_DISAGGREGATION_HEARTBEAT_INTERVAL": [],
    "SGLANG_DISAGGREGATION_HEARTBEAT_MAX_FAILURE": [],
    "SGLANG_DISAGGREGATION_WAITING_TIMEOUT": [],
    "SGLANG_EMPTY_CACHE_INTERVAL": [],
    "SGLANG_DISABLE_CONSECUTIVE_PREFILL_OVERLAP": [],
    "SGLANG_SCHEDULER_MAX_RECV_PER_POLL": [],
    "SGLANG_EXPERIMENTAL_CPP_RADIX_TREE": [],
    "SGLANG_DYNAMIC_CHUNKING_SMOOTH_FACTOR": [],
    "SGLANG_SCHEDULER_SKIP_ALL_GATHER": [],
    "SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE": [],
    "SGLANG_PREFILL_DELAYER_MAX_DELAY_PASSES": [],
    "SGLANG_PREFILL_DELAYER_TOKEN_USAGE_LOW_WATERMARK": [],
    "SGLANG_DATA_PARALLEL_BUDGET_INTERVAL": [],
    "SGLANG_QUEUED_TIMEOUT_MS": [],
    "SGLANG_NCCL_ALL_GATHER_IN_OVERLAP_SCHEDULER_SYNC_BATCH": [],
    "SGLANG_TEST_PD_DISAGG_BACKEND": [],
    "SGLANG_TEST_PD_DISAGG_DEVICES": [],
    "SGLANG_USE_MESSAGE_QUEUE_BROADCASTER": [],
    "SGLANG_ONE_VISIBLE_DEVICE_PER_PROCESS": [],
    "SGLANG_FORWARD_UNKNOWN_TOOLS": [],
    "SGLANG_HICACHE_HF3FS_CONFIG_PATH": [],
    "SGLANG_MOONCAKE_CUSTOM_MEM_POOL": [],
    "ENABLE_ASCEND_TRANSFER_WITH_MOONCAKE": [],
    "ASCEND_NPU_PHY_ID": [],
    "SGLANG_MOONCAKE_SEND_AUX_TCP": [],
    "SGLANG_HICACHE_MOONCAKE_CONFIG_PATH": [],
    "MOONCAKE_MASTER": [],
    "MOONCAKE_CLIENT": [],
    "MOONCAKE_LOCAL_HOSTNAME": [],
    "MOONCAKE_TE_META_DATA_SERVER": [],
    "MOONCAKE_GLOBAL_SEGMENT_SIZE": [],
    "MOONCAKE_PROTOCOL": [],
    "MOONCAKE_DEVICE": [],
    "MOONCAKE_MASTER_METRICS_PORT": [],
    "MOONCAKE_CHECK_SERVER": [],
    "MOONCAKE_STANDALONE_STORAGE": [],
    "SGLANG_USE_AITER": [],
    "SGLANG_ROCM_FUSED_DECODE_MLA": [],
    "SGLANG_ROCM_DISABLE_LINEARQUANT": [],
    "SGLANG_NPU_DISABLE_ACL_FORMAT_WEIGHT": [],
    "SGLANG_NPU_USE_MULTI_STREAM": [],
    "SGLANG_NPU_USE_MLAPO": [],
    "SGLANG_INT4_WEIGHT": [],
    "SGLANG_CPU_QUANTIZATION": [],
    "SGLANG_USE_DYNAMIC_MXFP4_LINEAR": [],
    "SGLANG_FORCE_FP8_MARLIN": [],
    "SGLANG_MOE_NVFP4_DISPATCH": [],
    "SGLANG_NVFP4_CKPT_FP8_GEMM_IN_ATTN": [],
    "SGLANG_PER_TOKEN_GROUP_QUANT_8BIT_V2": [],
    "SGLANG_NVFP4_CKPT_FP8_NEXTN_MOE": [],
    "SGLANG_IS_FLASHINFER_AVAILABLE": [],
    "SGLANG_ENABLE_FLASHINFER_FP8_GEMM": [],
    "SGLANG_FLASHINFER_FP4_GEMM_BACKEND": [],
    "SGLANG_FLASHINFER_WORKSPACE_SIZE": [],
    "SGLANG_TRITON_DECODE_ATTN_STATIC_KV_SPLITS": [],
    "SGLANG_USE_CUSTOM_TRITON_KERNEL_CACHE": [],
    "SGLANG_ENABLE_TORCH_COMPILE": [],
    "SGLANG_EXPERT_LOCATION_UPDATER_LOG_INPUT": [],
    "SGLANG_EXPERT_LOCATION_UPDATER_CANARY": [],
    "SGLANG_EXPERT_LOCATION_UPDATER_LOG_METRICS": [],
    "SGLANG_LOG_EXPERT_LOCATION_METADATA": [],
    "SGLANG_EXPERT_DISTRIBUTION_RECORDER_DIR": [],
    "SGLANG_EPLB_HEATMAP_COLLECTION_INTERVAL": [],
    "SGLANG_ENABLE_EPLB_BALANCEDNESS_METRIC": [],
    "SGLANG_TBO_DEBUG": [],
    "SGLANG_ENABLE_JIT_DEEPGEMM": [],
    "SGLANG_JIT_DEEPGEMM_PRECOMPILE": [],
    "SGLANG_JIT_DEEPGEMM_FAST_WARMUP": [],
    "SGLANG_JIT_DEEPGEMM_COMPILE_WORKERS": [],
    "SGLANG_IN_DEEPGEMM_PRECOMPILE_STAGE": [],
    "SGLANG_DG_CACHE_DIR": [],
    "SGLANG_DG_USE_NVRTC": [],
    "SGLANG_USE_DEEPGEMM_BMM": [],
    "SGLANG_CHUNKED_PREFIX_CACHE_THRESHOLD": [],
    "SGLANG_DEEPEP_BF16_DISPATCH": [],
    "SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK": [],
    "SGLANG_DEEPEP_LL_COMBINE_SEND_NUM_SMS": [],
    "SGLANG_BLACKWELL_OVERLAP_SHARED_EXPERTS_OUTSIDE_SBO": [],
    "SGLANG_NSA_FUSE_TOPK": [],
    "SGLANG_NSA_ENABLE_MTP_PRECOMPUTE_METADATA": [],
    "SGLANG_SKIP_SGL_KERNEL_VERSION_CHECK": [],
    "USE_VLLM_CUTLASS_W8A8_FP8_KERNEL": [],
    "USE_TRITON_W8A8_FP8_KERNEL": [],
    "SGLANG_RETURN_ORIGINAL_LOGPROB": [],
    "SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN": [],
    "SGLANG_MOE_PADDING": [],
    "SGLANG_CUTLASS_MOE": [],
    "HF_HUB_DISABLE_XET": [],
    "DISABLE_OPENAPI_DOC": [],
    "SGLANG_ENABLE_TORCH_INFERENCE_MODE": [],
    "SGLANG_IS_FIRST_RANK_ON_NODE": [],
    "SGLANG_SUPPORT_CUTLASS_BLOCK_FP8": [],
    "SGLANG_SYNC_TOKEN_IDS_ACROSS_TP": [],
    "SGLANG_ENABLE_COLOCATED_BATCH_GEN": [],
    "SGLANG_ENABLE_DETERMINISTIC_INFERENCE": [],
    "SGLANG_USE_1STAGE_ALLREDUCE": [],
    "SGLANG_FLASHINFER_PREFILL_SPLIT_TILE_SIZE": [],
    "SGLANG_FLASHINFER_DECODE_SPLIT_TILE_SIZE": [],
    "SGLANG_TRITON_PREFILL_TRUNCATION_ALIGN_SIZE": [],
    "SGLANG_TRITON_DECODE_SPLIT_TILE_SIZE": [],
    "SGLANG_SPEC_EXPANSION_SAFETY_FACTOR": [],
    "SGLANG_ROPE_CACHE_SAFETY_MARGIN": [],
    "SGLANG_ROPE_CACHE_ALIGN": [],
    "SGLANG_ENABLE_SPEC_V2": [],
    "SGLANG_ENABLE_OVERLAP_PLAN_STREAM": [],
    "SGLANG_SPEC_ENABLE_STRICT_FILTER_CHECK": [],
    "SGLANG_VLM_CACHE_SIZE_MB": [],
    "SGLANG_IMAGE_MAX_PIXELS": [],
    "SGLANG_RESIZE_RESAMPLE": [],
    "SGLANG_MM_BUFFER_SIZE_MB": [],
    "SGLANG_MM_PRECOMPUTE_HASH": [],
    "SGLANG_VIT_ENABLE_CUDA_GRAPH": [],
    "SGLANG_MM_SKIP_COMPUTE_HASH": [],
    "SGLANG_USE_CUDA_IPC_TRANSPORT": [],
    "SGLANG_MM_FEATURE_CACHE_MB": [],
    "SGLANG_MM_ITEM_MEM_POOL_RECYCLE_INTERVAL_SEC": [],
    "SGLANG_ENABLE_MM_SPLITTING": [],
    "SGLANG_MEMORY_SAVER_CUDA_GRAPH": [],
    "SGLANG_EMBEDDINGS_SPARSE_HEAD": [],
    "SGLANG_ENABLE_LOGITS_PROCESSER_CHUNK": [],
    "SGLANG_LOGITS_PROCESSER_CHUNK_SIZE": [],
    "SGLANG_TOOL_STRICT_LEVEL": [],
    "SGLANG_NGRAM_FORCE_GREEDY_VERIFY": [],
    "SGLANG_WARMUP_TIMEOUT": [],
    "SGLANG_ENABLE_HEALTH_ENDPOINT_GENERATION": [],
    "SGLANG_EXTERNAL_MODEL_PACKAGE": [],
    "SGLANG_EXTERNAL_MM_MODEL_ARCH": [],
    "SGLANG_EXTERNAL_MM_PROCESSOR_PACKAGE": [],
    "SGLANG_NUMA_BIND_V2": [],
    "SGLANG_ENABLE_METRICS_DEVICE_TIMER": [],
    "SGLANG_ENABLE_METRICS_DP_ATTENTION": [],
    "SGLANG_PATCH_TOKENIZER": [],
    "SGLANG_REQUEST_STATE_WAIT_TIMEOUT": [],
    "SGLANG_USE_AITER_FP8_PER_TOKEN": []
  },
  "envs": [],
  "_print_deprecated_env": [
    "new_name",
    "old_name"
  ],
  "_warn_deprecated_env_to_cli_flag": [
    "env_name",
    "suggestion"
  ],
  "_convert_SGL_to_SGLANG": [],
  "example_with_exit_stack": [],
  "example_with_subprocess": [],
  "example_with_implicit_bool_avoidance": [],
  "examples": [],
  "GPU_MEMORY_TYPE_KV_CACHE": [],
  "GPU_MEMORY_TYPE_WEIGHTS": [],
  "GPU_MEMORY_TYPE_CUDA_GRAPH": [],
  "GPU_MEMORY_ALL_TYPES": [],
  "DllmConfig": {
    "__init__": [
      "self",
      "algorithm",
      "algorithm_config",
      "block_size",
      "mask_id",
      "max_running_requests"
    ],
    "from_server_args": [
      "server_args"
    ]
  },
  "DllmAlgorithm": {
    "__init__": [
      "self",
      "config"
    ],
    "from_server_args": [
      "server_args"
    ]
  },
  "LowConfidence": {
    "__init__": [
      "self",
      "config"
    ],
    "run": [
      "self",
      "model_runner",
      "forward_batch"
    ]
  },
  "Algorithm": [],
  "import_algorithms": [],
  "get_algorithm": [
    "config"
  ],
  "algo_name_to_cls": [],
  "MAMBA_STATE_PER_REQ_PREFIX_CACHE": [],
  "MAMBA_STATE_PER_REQ_NO_CACHE": [],
  "write_req_to_token_pool_triton": [
    "req_to_token_ptr",
    "req_pool_indices",
    "prefix_tensors",
    "pre_lens",
    "seq_lens",
    "extend_lens",
    "out_cache_loc",
    "req_to_token_ptr_stride"
  ],
  "write_cache_indices": [
    "out_cache_loc",
    "req_pool_indices_tensor",
    "req_pool_indices_cpu",
    "prefix_lens_tensor",
    "prefix_lens_cpu",
    "seq_lens_tensor",
    "seq_lens_cpu",
    "extend_lens_tensor",
    "extend_lens_cpu",
    "prefix_tensors",
    "req_to_token_pool"
  ],
  "get_last_loc": [
    "req_to_token",
    "req_pool_indices_tensor",
    "prefix_lens_tensor"
  ],
  "get_last_loc_torch": [
    "req_to_token",
    "req_pool_indices_tensor",
    "prefix_lens_tensor"
  ],
  "get_last_loc_kernel": [
    "req_to_token",
    "req_pool_indices_tensor",
    "prefix_lens_tensor",
    "result",
    "num_tokens",
    "req_to_token_stride",
    "BLOCK_SIZE"
  ],
  "get_last_loc_triton": [
    "req_to_token",
    "req_pool_indices_tensor",
    "prefix_lens_tensor"
  ],
  "alloc_token_slots": [
    "tree_cache",
    "num_tokens",
    "backup_state"
  ],
  "evict_from_tree_cache": [
    "tree_cache",
    "num_tokens"
  ],
  "alloc_paged_token_slots_extend": [
    "tree_cache",
    "prefix_lens",
    "prefix_lens_cpu",
    "seq_lens",
    "seq_lens_cpu",
    "last_loc",
    "extend_num_tokens",
    "backup_state"
  ],
  "alloc_req_slots": [
    "req_to_token_pool",
    "num_reqs",
    "reqs",
    "tree_cache"
  ],
  "alloc_for_extend": [
    "batch"
  ],
  "alloc_paged_token_slots_decode": [
    "tree_cache",
    "seq_lens",
    "seq_lens_cpu",
    "last_loc",
    "token_per_req"
  ],
  "alloc_for_decode": [
    "batch",
    "token_per_req"
  ],
  "release_kv_cache": [
    "req",
    "tree_cache",
    "is_insert"
  ],
  "available_and_evictable_str": [
    "tree_cache"
  ],
  "GB": [],
  "SWAKVPool": {
    "__init__": [
      "self",
      "size",
      "size_swa",
      "page_size",
      "dtype",
      "head_num",
      "head_dim",
      "swa_attention_layer_ids",
      "full_attention_layer_ids",
      "enable_kvcache_transpose",
      "device",
      "token_to_kv_pool_class"
    ],
    "register_mapping": [
      "self",
      "full_to_swa_index_mapping"
    ],
    "get_kv_size_bytes": [
      "self"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ],
    "get_state_buf_infos": [
      "self"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "set_swa_loc": [
      "self",
      "loc"
    ],
    "translate_loc_from_full_to_swa": [
      "self",
      "kv_indices"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v",
      "k_scale",
      "v_scale"
    ],
    "move_kv_cache": [
      "self",
      "tgt_loc",
      "src_loc"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ]
  },
  "SWATokenToKVPoolAllocator": {
    "__init__": [
      "self",
      "size",
      "size_swa",
      "page_size",
      "dtype",
      "device",
      "kvcache",
      "need_sort"
    ],
    "available_size": [
      "self"
    ],
    "full_available_size": [
      "self"
    ],
    "swa_available_size": [
      "self"
    ],
    "size": [
      "self"
    ],
    "size_swa": [
      "self"
    ],
    "size_full": [
      "self"
    ],
    "debug_print": [
      "self"
    ],
    "get_kvcache": [
      "self"
    ],
    "translate_loc_from_full_to_swa": [
      "self",
      "kv_indices"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "alloc_extend": [
      "self",
      "prefix_lens",
      "prefix_lens_cpu",
      "seq_lens",
      "seq_lens_cpu",
      "last_loc",
      "extend_num_tokens"
    ],
    "alloc_decode": [
      "self",
      "seq_lens",
      "seq_lens_cpu",
      "last_loc"
    ],
    "free": [
      "self",
      "free_index"
    ],
    "free_swa": [
      "self",
      "free_index"
    ],
    "backup_state": [
      "self"
    ],
    "restore_state": [
      "self",
      "state"
    ],
    "clear": [
      "self"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ]
  },
  "MultimodalCache": {
    "__init__": [
      "self"
    ],
    "combine_hashes": [
      "mm_hashes"
    ],
    "get": [
      "self",
      "mm_hashes",
      "combined_hash"
    ],
    "set": [
      "self",
      "mm_hash",
      "embedding",
      "mm_embedding_allocator"
    ],
    "has": [
      "self",
      "mm_hash"
    ],
    "free": [
      "self",
      "mm_hash",
      "mm_embedding_allocator"
    ],
    "clear": [
      "self"
    ],
    "available_size": [
      "self"
    ]
  },
  "_get_tensor_size": [
    "embedding"
  ],
  "EmbeddingResult": {},
  "MultiModalStaticCache": {
    "__init__": [
      "self",
      "max_size"
    ],
    "get": [
      "self",
      "mm_hashes",
      "combined_hash"
    ],
    "set": [
      "self",
      "mm_hash",
      "embedding",
      "loc"
    ],
    "has": [
      "self",
      "mm_hash"
    ],
    "free": [
      "self",
      "mm_hash",
      "mm_embedding_allocator"
    ],
    "clear": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "available_size": [
      "self"
    ]
  },
  "set_mla_kv_buffer_kernel": [
    "kv_buffer_ptr",
    "cache_k_nope_ptr",
    "cache_k_rope_ptr",
    "loc_ptr",
    "buffer_stride",
    "nope_stride",
    "rope_stride",
    "nope_dim",
    "rope_dim",
    "BLOCK"
  ],
  "set_mla_kv_buffer_triton": [
    "kv_buffer",
    "loc",
    "cache_k_nope",
    "cache_k_rope"
  ],
  "set_mla_kv_scale_buffer_kernel": [
    "kv_buffer_ptr",
    "cache_k_nope_ptr",
    "cache_k_rope_ptr",
    "loc_ptr",
    "buffer_stride",
    "nope_stride",
    "rope_stride",
    "nope_dim",
    "rope_dim",
    "BLOCK"
  ],
  "set_mla_kv_scale_buffer_triton": [
    "kv_buffer",
    "loc",
    "cache_k_nope",
    "cache_k_rope"
  ],
  "get_mla_kv_buffer_kernel": [
    "kv_buffer_ptr",
    "cache_k_nope_ptr",
    "cache_k_rope_ptr",
    "loc_ptr",
    "buffer_stride",
    "nope_stride",
    "rope_stride",
    "nope_dim",
    "rope_dim"
  ],
  "get_mla_kv_buffer_triton": [
    "kv_buffer",
    "loc",
    "cache_k_nope",
    "cache_k_rope"
  ],
  "maybe_init_custom_mem_pool": [
    "device"
  ],
  "convert_to_bigram_key": [
    "tokens"
  ],
  "EvictionStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "LRUStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "LFUStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "FIFOStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "MRUStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "FILOStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "PriorityStrategy": {
    "get_priority": [
      "self",
      "node"
    ]
  },
  "_is_cuda": [],
  "_is_npu": [],
  "_is_xpu": [],
  "synchronized": [
    "func"
  ],
  "HostTensorAllocator": {
    "__init__": [
      "self"
    ],
    "allocate": [
      "self",
      "dims",
      "dtype",
      "device"
    ]
  },
  "get_allocator_from_storage": [
    "allocator_type"
  ],
  "alloc_with_host_register": [
    "dims",
    "dtype",
    "device",
    "pin_memory",
    "allocator"
  ],
  "alloc_with_pin_memory": [
    "dims",
    "dtype",
    "device",
    "pin_memory",
    "allocator"
  ],
  "ALLOC_MEMORY_FUNCS": [],
  "HostKVCache": {
    "__init__": [
      "self",
      "device_pool",
      "host_to_device_ratio",
      "host_size",
      "page_size",
      "layout",
      "pin_memory",
      "device",
      "allocator_type"
    ],
    "get_size_per_token": [
      "self"
    ],
    "init_kv_buffer": [
      "self"
    ],
    "load_to_device_per_layer": [
      "self",
      "device_pool",
      "host_indices",
      "device_indices",
      "layer_id",
      "io_backend"
    ],
    "backup_from_device_all_layer": [
      "self",
      "device_pool",
      "host_indices",
      "device_indices",
      "io_backend"
    ],
    "get_data_page": [
      "self",
      "index",
      "flat"
    ],
    "get_dummy_flat_data_page": [
      "self"
    ],
    "set_from_flat_data_page": [
      "self",
      "index",
      "data_page"
    ],
    "clear": [
      "self"
    ],
    "available_size": [
      "self"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "free": [
      "self",
      "indices"
    ]
  },
  "MHATokenToKVPoolHost": {
    "__init__": [
      "self",
      "device_pool",
      "host_to_device_ratio",
      "host_size",
      "page_size",
      "layout",
      "pin_memory",
      "device",
      "allocator_type"
    ],
    "get_size_per_token": [
      "self"
    ],
    "get_ksize_per_token": [
      "self"
    ],
    "init_kv_buffer": [
      "self"
    ],
    "k_buffer": [
      "self"
    ],
    "v_buffer": [
      "self"
    ],
    "load_to_device_per_layer": [
      "self",
      "device_pool",
      "host_indices",
      "device_indices",
      "layer_id",
      "io_backend"
    ],
    "backup_from_device_all_layer": [
      "self",
      "device_pool",
      "host_indices",
      "device_indices",
      "io_backend"
    ],
    "get_data_page": [
      "self",
      "index",
      "flat"
    ],
    "get_dummy_flat_data_page": [
      "self"
    ],
    "set_from_flat_data_page": [
      "self",
      "index",
      "data_page"
    ],
    "get_page_buffer_meta": [
      "self",
      "indices"
    ]
  },
  "MLATokenToKVPoolHost": {
    "__init__": [
      "self",
      "device_pool",
      "host_to_device_ratio",
      "host_size",
      "page_size",
      "layout",
      "pin_memory",
      "device",
      "allocator_type"
    ],
    "get_size_per_token": [
      "self"
    ],
    "get_ksize_per_token": [
      "self"
    ],
    "init_kv_buffer": [
      "self"
    ],
    "load_to_device_per_layer": [
      "self",
      "device_pool",
      "host_indices",
      "device_indices",
      "layer_id",
      "io_backend"
    ],
    "backup_from_device_all_layer": [
      "self",
      "device_pool",
      "host_indices",
      "device_indices",
      "io_backend"
    ],
    "get_data_page": [
      "self",
      "index",
      "flat"
    ],
    "get_dummy_flat_data_page": [
      "self"
    ],
    "set_from_flat_data_page": [
      "self",
      "index",
      "data_page"
    ],
    "get_page_buffer_meta": [
      "self",
      "indices"
    ]
  },
  "BaseTokenToKVPoolAllocator": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "device",
      "kvcache",
      "need_sort"
    ],
    "debug_print": [
      "self"
    ],
    "available_size": [
      "self"
    ],
    "get_kvcache": [
      "self"
    ],
    "restore_state": [
      "self",
      "state"
    ],
    "backup_state": [
      "self"
    ],
    "free_group_begin": [
      "self"
    ],
    "free_group_end": [
      "self"
    ],
    "merge_and_sort_free": [
      "self"
    ],
    "get_cpu_copy": [
      "self"
    ],
    "load_cpu_copy": [
      "self"
    ],
    "alloc_extend": [
      "self"
    ],
    "alloc_decode": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "free": [
      "self",
      "free_index"
    ]
  },
  "TokenToKVPoolAllocator": {
    "__init__": [
      "self",
      "size",
      "dtype",
      "device",
      "kvcache",
      "need_sort"
    ],
    "clear": [
      "self"
    ],
    "available_size": [
      "self"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "free": [
      "self",
      "free_index"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ]
  },
  "alloc_extend_kernel": [
    "pre_lens_ptr",
    "seq_lens_ptr",
    "last_loc_ptr",
    "free_page_ptr",
    "out_indices",
    "bs_upper",
    "page_size",
    "max_num_extend_tokens"
  ],
  "alloc_decode_kernel": [
    "seq_lens_ptr",
    "last_loc_ptr",
    "free_page_ptr",
    "out_indices",
    "bs_upper",
    "page_size"
  ],
  "PagedTokenToKVPoolAllocator": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "device",
      "kvcache",
      "need_sort"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "alloc_extend": [
      "self",
      "prefix_lens",
      "prefix_lens_cpu",
      "seq_lens",
      "seq_lens_cpu",
      "last_loc",
      "extend_num_tokens"
    ],
    "alloc_decode": [
      "self",
      "seq_lens",
      "seq_lens_cpu",
      "last_loc"
    ],
    "free": [
      "self",
      "free_index"
    ],
    "clear": [
      "self"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ]
  },
  "store_cache": [],
  "_is_hip": [],
  "get_tensor_size_bytes": [
    "t"
  ],
  "_set_kv_buffer_impl": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "indices",
    "row_dim",
    "store_dtype",
    "device_module",
    "alt_stream",
    "same_kv_dim"
  ],
  "ReqToTokenPool": {
    "__init__": [
      "self",
      "size",
      "max_context_len",
      "device",
      "enable_memory_saver"
    ],
    "write": [
      "self",
      "indices",
      "values"
    ],
    "available_size": [
      "self"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "free": [
      "self",
      "free_index"
    ],
    "clear": [
      "self"
    ]
  },
  "MambaPool": {
    "__init__": [
      "self"
    ],
    "get_speculative_mamba2_params_all_layers": [
      "self"
    ],
    "mamba2_layer_cache": [
      "self",
      "layer_id"
    ],
    "available_size": [
      "self"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "free": [
      "self",
      "free_index"
    ],
    "clear": [
      "self"
    ],
    "copy_from": [
      "self",
      "src_index",
      "dst_index"
    ],
    "fork_from": [
      "self",
      "src_index"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ]
  },
  "HybridReqToTokenPool": {
    "__init__": [
      "self"
    ],
    "_init_mamba_pool": [
      "self",
      "size",
      "mamba_spec_state_size",
      "cache_params",
      "device",
      "enable_mamba_extra_buffer",
      "speculative_num_draft_tokens"
    ],
    "alloc": [
      "self",
      "need_size",
      "reqs"
    ],
    "get_mamba_indices": [
      "self",
      "req_indices"
    ],
    "mamba2_layer_cache": [
      "self",
      "layer_id"
    ],
    "get_speculative_mamba2_params_all_layers": [
      "self"
    ],
    "get_mamba_ping_pong_other_idx": [
      "self",
      "mamba_next_track_idx"
    ],
    "free": [
      "self",
      "free_index",
      "free_mamba_cache",
      "mamba_ping_pong_track_buffer_to_keep"
    ],
    "clear": [
      "self"
    ]
  },
  "KVCache": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "layer_num",
      "device",
      "enable_memory_saver",
      "start_layer",
      "end_layer"
    ],
    "_finalize_allocation_log": [
      "self",
      "num_tokens"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v"
    ],
    "register_layer_transfer_counter": [
      "self",
      "layer_transfer_counter"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ],
    "maybe_get_custom_mem_pool": [
      "self"
    ]
  },
  "MHATokenToKVPool": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "head_num",
      "head_dim",
      "layer_num",
      "device",
      "enable_memory_saver",
      "v_head_dim",
      "swa_head_num",
      "swa_head_dim",
      "swa_v_head_dim",
      "start_layer",
      "end_layer",
      "enable_alt_stream",
      "enable_kv_cache_copy"
    ],
    "_init_kv_copy_and_warmup": [
      "self"
    ],
    "_create_buffers": [
      "self"
    ],
    "_clear_buffers": [
      "self"
    ],
    "get_kv_size_bytes": [
      "self"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ],
    "_get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "_get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v",
      "k_scale",
      "v_scale",
      "layer_id_override"
    ],
    "move_kv_cache": [
      "self",
      "tgt_loc",
      "src_loc"
    ]
  },
  "MHATokenToKVPoolFP4": {
    "_create_buffers": [
      "self"
    ],
    "_clear_buffers": [
      "self"
    ],
    "_get_key_buffer": [
      "self",
      "layer_id"
    ],
    "_get_value_buffer": [
      "self",
      "layer_id"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v",
      "k_scale",
      "v_scale",
      "layer_id_override"
    ]
  },
  "HybridLinearKVPool": {
    "__init__": [
      "self",
      "size",
      "dtype",
      "page_size",
      "head_num",
      "head_dim",
      "full_attention_layer_ids",
      "enable_kvcache_transpose",
      "device",
      "mamba_pool",
      "enable_memory_saver",
      "use_mla",
      "kv_lora_rank",
      "qk_rope_head_dim"
    ],
    "get_kv_size_bytes": [
      "self"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ],
    "get_state_buf_infos": [
      "self"
    ],
    "maybe_get_custom_mem_pool": [
      "self"
    ],
    "_transfer_full_attention_id": [
      "self",
      "layer_id"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "_transfer_id_context": [
      "self",
      "layer"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v",
      "k_scale",
      "v_scale"
    ],
    "move_kv_cache": [
      "self",
      "tgt_loc",
      "src_loc"
    ],
    "get_v_head_dim": [
      "self"
    ],
    "set_mla_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k_nope",
      "cache_k_rope"
    ],
    "get_mla_kv_buffer": [
      "self",
      "layer",
      "loc",
      "dst_dtype"
    ]
  },
  "MLATokenToKVPool": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "kv_lora_rank",
      "qk_rope_head_dim",
      "layer_num",
      "device",
      "enable_memory_saver",
      "start_layer",
      "end_layer",
      "use_nsa",
      "override_kv_cache_dim"
    ],
    "_create_buffers": [
      "self"
    ],
    "_clear_buffers": [
      "self"
    ],
    "get_kv_size_bytes": [
      "self"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v"
    ],
    "set_mla_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k_nope",
      "cache_k_rope"
    ],
    "get_mla_kv_buffer": [
      "self",
      "layer",
      "loc",
      "dst_dtype"
    ],
    "get_cpu_copy": [
      "self",
      "indices"
    ],
    "load_cpu_copy": [
      "self",
      "kv_cache_cpu",
      "indices"
    ]
  },
  "MLATokenToKVPoolFP4": {
    "_create_buffers": [
      "self"
    ],
    "_clear_buffers": [
      "self"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v"
    ],
    "set_mla_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k_nope",
      "cache_k_rope"
    ]
  },
  "NSATokenToKVPool": {
    "quant_block_size": [],
    "index_k_with_scale_buffer_dtype": [],
    "rope_storage_dtype": [],
    "__init__": [
      "self",
      "size",
      "page_size",
      "kv_lora_rank",
      "dtype",
      "qk_rope_head_dim",
      "layer_num",
      "device",
      "index_head_dim",
      "enable_memory_saver",
      "start_layer",
      "end_layer"
    ],
    "get_index_k_with_scale_buffer": [
      "self",
      "layer_id"
    ],
    "get_index_k_continuous": [
      "self",
      "layer_id",
      "seq_len",
      "page_indices"
    ],
    "get_index_k_scale_continuous": [
      "self",
      "layer_id",
      "seq_len",
      "page_indices"
    ],
    "get_index_k_scale_buffer": [
      "self",
      "layer_id",
      "seq_len",
      "page_indices"
    ],
    "set_index_k_scale_buffer": [
      "self",
      "layer_id",
      "loc",
      "index_k",
      "index_k_scale"
    ],
    "get_state_buf_infos": [
      "self"
    ],
    "get_kv_size_bytes": [
      "self"
    ]
  },
  "DoubleSparseTokenToKVPool": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "head_num",
      "head_dim",
      "layer_num",
      "device",
      "heavy_channel_num",
      "enable_memory_saver",
      "start_layer",
      "end_layer"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_label_buffer": [
      "self",
      "layer_id"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v",
      "cache_label"
    ]
  },
  "move_kv_cache_native": [
    "k_buffer",
    "v_buffer",
    "tgt_loc",
    "src_loc"
  ],
  "copy_all_layer_kv_cache_tiled": [
    "data_ptrs",
    "strides",
    "tgt_loc_ptr",
    "src_loc_ptr",
    "num_locs",
    "num_locs_upper",
    "BYTES_PER_TILE"
  ],
  "RadixKey": {
    "__init__": [
      "self",
      "token_ids",
      "extra_key",
      "is_bigram"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "__repr__": [
      "self"
    ]
  },
  "TreeNode": {
    "counter": [],
    "__init__": [
      "self",
      "id",
      "priority"
    ],
    "evicted": [
      "self"
    ],
    "backuped": [
      "self"
    ],
    "protect_host": [
      "self"
    ],
    "release_host": [
      "self"
    ],
    "get_last_hash_value": [
      "self"
    ],
    "get_prefix_hash_values": [
      "self",
      "node"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "_check_extra_key": [
    "key0",
    "key1"
  ],
  "_key_match_page_size1": [
    "key0",
    "key1"
  ],
  "_key_match_paged": [
    "key0",
    "key1",
    "page_size"
  ],
  "get_child_key": [
    "key",
    "page_size"
  ],
  "compute_node_hash_values": [
    "node",
    "page_size"
  ],
  "split_node_hash_value": [
    "child_hash_value",
    "split_len",
    "page_size"
  ],
  "RadixCache": {
    "__init__": [
      "self",
      "params"
    ],
    "create_simulated": [
      "self",
      "disable",
      "mock_allocator",
      "page_size",
      "enable_kv_cache_events"
    ],
    "reset": [
      "self"
    ],
    "maybe_bigram_convert": [
      "self",
      "key",
      "value"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "insert": [
      "self",
      "key",
      "value",
      "chunked",
      "priority"
    ],
    "_page_align_keys": [
      "self",
      "key"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "cache_unfinished_req": [
      "self",
      "req",
      "chunked"
    ],
    "pretty_print": [
      "self"
    ],
    "total_size": [
      "self"
    ],
    "evict": [
      "self",
      "num_tokens"
    ],
    "inc_lock_ref": [
      "self",
      "node"
    ],
    "dec_lock_ref": [
      "self",
      "node"
    ],
    "evictable_size": [
      "self"
    ],
    "protected_size": [
      "self"
    ],
    "all_values_flatten": [
      "self"
    ],
    "_match_prefix_helper": [
      "self",
      "node",
      "key"
    ],
    "_split_node": [
      "self",
      "key",
      "child",
      "split_len"
    ],
    "_insert_helper": [
      "self",
      "node",
      "key",
      "value",
      "priority"
    ],
    "_print_helper": [
      "self",
      "node",
      "indent"
    ],
    "_delete_leaf": [
      "self",
      "node"
    ],
    "_total_size_helper": [
      "self"
    ],
    "_collect_leaves": [
      "self"
    ],
    "_record_store_event": [
      "self",
      "node"
    ],
    "_record_remove_event": [
      "self",
      "node"
    ],
    "_record_all_cleared_event": [
      "self"
    ],
    "take_events": [
      "self"
    ]
  },
  "get_last_access_time": [],
  "LRUList": {
    "__init__": [
      "self",
      "mamba"
    ],
    "_add_node": [
      "self",
      "node"
    ],
    "_add_node_after": [
      "self",
      "old_node",
      "new_node"
    ],
    "_remove_node": [
      "self",
      "node"
    ],
    "_get_lru": [
      "self"
    ],
    "reset_node_mru": [
      "self",
      "node"
    ],
    "reset_node_and_parents_mru": [
      "self",
      "node",
      "root_node"
    ],
    "insert_mru": [
      "self",
      "node"
    ],
    "remove_node": [
      "self",
      "node"
    ],
    "get_lru_no_lock": [
      "self"
    ],
    "get_leaf_lru_no_lock": [
      "self"
    ],
    "get_prev_no_lock": [
      "self",
      "node",
      "check_id"
    ],
    "get_prev_leaf_no_lock": [
      "self",
      "node",
      "check_id"
    ],
    "in_list": [
      "self",
      "node"
    ],
    "pretty_print": [
      "self",
      "tree_cache"
    ],
    "sanity_check_evictable_size": [
      "self"
    ],
    "sanity_check": [
      "self",
      "tree_cache"
    ]
  },
  "MambaRadixCache": {
    "__init__": [
      "self",
      "params"
    ],
    "supports_mamba": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "insert": [
      "self",
      "key",
      "value",
      "mamba_value"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "cache_unfinished_req": [
      "self",
      "req",
      "chunked"
    ],
    "pretty_print": [
      "self"
    ],
    "total_size": [
      "self"
    ],
    "_evict_leaf_node": [
      "self",
      "x",
      "is_evict_mamba"
    ],
    "evict_mamba": [
      "self",
      "mamba_num"
    ],
    "evict": [
      "self",
      "full_num_tokens"
    ],
    "inc_lock_ref": [
      "self",
      "node"
    ],
    "dec_lock_ref": [
      "self",
      "node"
    ],
    "sanity_check": [
      "self"
    ],
    "evictable_size": [
      "self"
    ],
    "full_evictable_size": [
      "self"
    ],
    "mamba_evictable_size": [
      "self"
    ],
    "full_lru_list_evictable_size": [
      "self"
    ],
    "mamba_lru_list_evictable_size": [
      "self"
    ],
    "protected_size": [
      "self"
    ],
    "full_protected_size": [
      "self"
    ],
    "mamba_protected_size": [
      "self"
    ],
    "all_values_flatten": [
      "self"
    ],
    "all_mamba_values_flatten": [
      "self"
    ],
    "_match_prefix_helper": [
      "self",
      "key"
    ],
    "_split_node": [
      "self",
      "key",
      "child",
      "split_len"
    ],
    "_insert_helper": [
      "self",
      "node",
      "key",
      "value",
      "mamba_value"
    ],
    "_iteratively_delete_tombstone_leaf": [
      "self",
      "node"
    ],
    "_delete_leaf": [
      "self",
      "node"
    ],
    "_tombstone_internal_node": [
      "self",
      "node"
    ],
    "_delete_tombstone_leaf": [
      "self",
      "node"
    ],
    "_collect_leaves": [
      "self"
    ],
    "_collect_nontombstone_nodes": [
      "self"
    ],
    "_collect_all_nodes": [
      "self"
    ],
    "_print_helper": [
      "self",
      "node",
      "indent"
    ],
    "_total_size_helper": [
      "self"
    ]
  },
  "ChunkCache": {
    "__init__": [
      "self",
      "params"
    ],
    "is_chunk_cache": [
      "self"
    ],
    "disable": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "cache_unfinished_req": [
      "self",
      "req",
      "chunked"
    ],
    "evict": [
      "self",
      "num_tokens"
    ],
    "inc_lock_ref": [
      "self",
      "node"
    ],
    "dec_lock_ref": [
      "self",
      "node",
      "swa_uuid_for_lock"
    ],
    "protected_size": [
      "self"
    ],
    "pretty_print": [
      "self"
    ]
  },
  "SWAChunkCache": {
    "__init__": [
      "self",
      "params"
    ],
    "supports_swa": [
      "self"
    ],
    "evict": [
      "self",
      "num_tokens"
    ]
  },
  "get_hash_str": [
    "token_ids",
    "prior_hash"
  ],
  "hash_str_to_int64": [
    "hash_str"
  ],
  "HiCacheStorageConfig": {},
  "HiCacheStorageExtraInfo": {},
  "HiCacheStorage": {
    "register_mem_pool_host": [
      "self",
      "mem_pool_host"
    ],
    "batch_get_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "batch_set_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_sizes"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_sizes"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ],
    "exists": [
      "self",
      "key"
    ],
    "batch_exists": [
      "self",
      "keys",
      "extra_info"
    ],
    "clear": [
      "self"
    ],
    "get_stats": [
      "self"
    ]
  },
  "HiCacheFile": {
    "__init__": [
      "self",
      "storage_config",
      "file_path"
    ],
    "_get_suffixed_key": [
      "self",
      "key"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_sizes"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_sizes"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ],
    "exists": [
      "self",
      "key"
    ],
    "clear": [
      "self"
    ]
  },
  "CacheInitParams": {},
  "RadixCacheCpp": {
    "__init__": [
      "self",
      "params",
      "server_args",
      "enable_write_cancel"
    ],
    "_merge_tensor": [
      "self",
      "l"
    ],
    "reset": [
      "self"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "_insert": [
      "self",
      "key",
      "value"
    ],
    "dec_lock_ref": [
      "self",
      "node"
    ],
    "inc_lock_ref": [
      "self",
      "node"
    ],
    "evict": [
      "self",
      "num_tokens"
    ],
    "evictable_size": [
      "self"
    ],
    "protected_size": [
      "self"
    ],
    "total_size": [
      "self"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "cache_unfinished_req": [
      "self",
      "req",
      "chunked"
    ],
    "pretty_print": [
      "self"
    ]
  },
  "gen_swa_uuid": [],
  "SWARadixCache": {
    "__init__": [
      "self",
      "params"
    ],
    "supports_swa": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "insert": [
      "self",
      "key",
      "value",
      "prev_prefix_len",
      "swa_evicted_seqlen"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "cache_unfinished_req": [
      "self",
      "req",
      "chunked"
    ],
    "pretty_print": [
      "self"
    ],
    "total_size": [
      "self"
    ],
    "evict": [
      "self",
      "full_num_tokens",
      "swa_num_tokens"
    ],
    "inc_lock_ref": [
      "self",
      "node"
    ],
    "dec_lock_ref": [
      "self",
      "node",
      "swa_uuid_for_lock"
    ],
    "sanity_check": [
      "self"
    ],
    "evictable_size": [
      "self"
    ],
    "full_evictable_size": [
      "self"
    ],
    "swa_evictable_size": [
      "self"
    ],
    "full_lru_list_evictable_size": [
      "self"
    ],
    "swa_lru_list_evictable_size": [
      "self"
    ],
    "protected_size": [
      "self"
    ],
    "full_protected_size": [
      "self"
    ],
    "swa_protected_size": [
      "self"
    ],
    "all_values_flatten": [
      "self"
    ],
    "_match_prefix_helper": [
      "self",
      "key"
    ],
    "_split_node": [
      "self",
      "key",
      "child",
      "split_len"
    ],
    "_insert_helper": [
      "self",
      "node",
      "key",
      "value",
      "update_kv_after_len",
      "swa_evicted_seqlen"
    ],
    "_add_new_node": [
      "self",
      "parent",
      "key",
      "value",
      "swa_tombstone"
    ],
    "_iteratively_delete_tombstone_leaf": [
      "self",
      "node"
    ],
    "_delete_leaf": [
      "self",
      "node"
    ],
    "_tombstone_internal_node": [
      "self",
      "node"
    ],
    "_delete_tombstone_leaf": [
      "self",
      "node"
    ],
    "_collect_leaves": [
      "self"
    ],
    "_collect_nontombstone_nodes": [
      "self"
    ],
    "_collect_all_nodes": [
      "self"
    ],
    "_print_helper": [
      "self",
      "node",
      "indent"
    ],
    "_total_size_helper": [
      "self"
    ]
  },
  "PrefixCacheTrait": {},
  "MatchPrefixParams": {},
  "MatchResult": {},
  "BasePrefixCache": {
    "init_metrics_collector": [
      "self"
    ],
    "update_eviction_metrics": [
      "self",
      "num_evicted",
      "start_time"
    ],
    "reset": [
      "self"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "cache_unfinished_req": [
      "self",
      "req"
    ],
    "evict": [
      "self",
      "num_tokens"
    ],
    "inc_lock_ref": [
      "self",
      "node"
    ],
    "dec_lock_ref": [
      "self",
      "node",
      "swa_uuid_for_lock"
    ],
    "evictable_size": [
      "self"
    ],
    "full_evictable_size": [
      "self"
    ],
    "swa_evictable_size": [
      "self"
    ],
    "protected_size": [
      "self"
    ],
    "full_protected_size": [
      "self"
    ],
    "swa_protected_size": [
      "self"
    ],
    "total_size": [
      "self"
    ],
    "pretty_print": [
      "self"
    ],
    "init_load_back": [
      "self",
      "last_host_node",
      "host_hit_length"
    ],
    "ready_to_load_host_cache": [
      "self"
    ],
    "check_hicache_events": [
      "self"
    ],
    "take_events": [
      "self"
    ],
    "supports_swa": [
      "self"
    ],
    "supports_mamba": [
      "self"
    ],
    "is_chunk_cache": [
      "self"
    ],
    "is_tree_cache": [
      "self"
    ]
  },
  "HiRadixCache": {
    "__init__": [
      "self",
      "params",
      "server_args"
    ],
    "_parse_storage_backend_extra_config": [
      "self",
      "storage_backend_extra_config"
    ],
    "reset": [
      "self"
    ],
    "get_height": [
      "self",
      "node"
    ],
    "clear_storage_backend": [
      "self"
    ],
    "write_backup": [
      "self",
      "node",
      "write_back"
    ],
    "write_backup_storage": [
      "self",
      "node"
    ],
    "_inc_hit_count": [
      "self",
      "node",
      "chunked"
    ],
    "writing_check": [
      "self",
      "write_back"
    ],
    "loading_check": [
      "self"
    ],
    "evictable_size": [
      "self"
    ],
    "evict": [
      "self",
      "num_tokens"
    ],
    "_evict_backuped": [
      "self",
      "node"
    ],
    "_evict_regular": [
      "self",
      "node"
    ],
    "evict_host": [
      "self",
      "num_tokens"
    ],
    "load_back": [
      "self",
      "node",
      "mem_quota"
    ],
    "init_load_back": [
      "self",
      "last_node",
      "host_hit_length",
      "mem_quota"
    ],
    "ready_to_load_host_cache": [
      "self"
    ],
    "check_hicache_events": [
      "self"
    ],
    "drain_storage_control_queues": [
      "self"
    ],
    "_prefetch_timeout_check_linear_func": [
      "self",
      "operation"
    ],
    "can_terminate_prefetch": [
      "self",
      "operation"
    ],
    "check_prefetch_progress": [
      "self",
      "req_id"
    ],
    "terminate_prefetch": [
      "self",
      "req_id"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "prefetch_from_storage": [
      "self",
      "req_id",
      "last_host_node",
      "new_input_tokens",
      "last_hash",
      "prefix_keys"
    ],
    "_insert_helper_host": [
      "self",
      "node",
      "key",
      "host_value",
      "hash_value"
    ],
    "_match_prefix_helper": [
      "self",
      "node",
      "key"
    ],
    "_split_node": [
      "self",
      "key",
      "child",
      "split_len"
    ],
    "insert": [
      "self",
      "key",
      "value",
      "chunked",
      "priority"
    ],
    "_collect_leaves_device": [
      "self"
    ],
    "release_aborted_request": [
      "self",
      "rid"
    ]
  },
  "_abs_path": [],
  "radix_tree_cpp": [],
  "StorageBackendFactory": {
    "_load_backend_class": [
      "module_path",
      "class_name",
      "backend_name"
    ],
    "register_backend": [
      "cls",
      "name",
      "module_path",
      "class_name"
    ],
    "create_backend": [
      "cls",
      "backend_name",
      "storage_config",
      "mem_pool_host"
    ],
    "_create_dynamic_backend": [
      "cls",
      "backend_config",
      "storage_config",
      "mem_pool_host"
    ],
    "_create_builtin_backend": [
      "cls",
      "backend_name",
      "backend_class",
      "storage_config",
      "mem_pool_host"
    ]
  },
  "RankMetadata": {
    "__init__": [
      "self",
      "num_pages"
    ],
    "exists_keys": [
      "self",
      "keys"
    ],
    "reserve_and_allocate_page_indices": [
      "self",
      "keys"
    ],
    "confirm_write": [
      "self",
      "written_keys_to_confirm",
      "pages_to_release"
    ],
    "delete_keys": [
      "self",
      "keys"
    ],
    "clear_all": [
      "self"
    ],
    "get_page_indices": [
      "self",
      "keys"
    ]
  },
  "GlobalMetadataState": {
    "__init__": [
      "self",
      "persistence_path",
      "save_interval"
    ],
    "load_from_disk": [
      "self"
    ],
    "save_to_disk": [
      "self"
    ],
    "schedule_save": [
      "self"
    ],
    "shutdown": [
      "self"
    ]
  },
  "Hf3fsMetadataServer": {
    "__init__": [
      "self",
      "persistence_path",
      "save_interval"
    ],
    "_setup_routes": [
      "self"
    ],
    "get_rank_metadata": [
      "self",
      "rank"
    ],
    "_read_json": [
      "self",
      "request"
    ],
    "_json_response": [
      "self",
      "content"
    ],
    "initialize": [
      "self",
      "rank",
      "request"
    ],
    "exists": [
      "self",
      "rank",
      "request"
    ],
    "reserve_and_allocate_page_indices": [
      "self",
      "rank",
      "request"
    ],
    "confirm_write": [
      "self",
      "rank",
      "request"
    ],
    "delete_keys": [
      "self",
      "rank",
      "request"
    ],
    "clear": [
      "self",
      "rank"
    ],
    "get_page_indices": [
      "self",
      "rank",
      "request"
    ],
    "run": [
      "self",
      "host",
      "port"
    ]
  },
  "Hf3fsGlobalMetadataClient": {
    "__init__": [
      "self",
      "base_url",
      "max_retries"
    ],
    "_post": [
      "self",
      "endpoint",
      "json_data"
    ],
    "initialize": [
      "self",
      "rank",
      "num_pages"
    ],
    "reserve_and_allocate_page_indices": [
      "self",
      "rank",
      "keys"
    ],
    "confirm_write": [
      "self",
      "rank",
      "written_keys_to_confirm",
      "pages_to_release"
    ],
    "delete_keys": [
      "self",
      "rank",
      "keys"
    ],
    "exists": [
      "self",
      "rank",
      "keys"
    ],
    "clear": [
      "self",
      "rank"
    ],
    "get_page_indices": [
      "self",
      "rank",
      "keys"
    ]
  },
  "Hf3fsLocalMetadataClient": {
    "__init__": [
      "self"
    ],
    "initialize": [
      "self",
      "rank",
      "num_pages"
    ],
    "reserve_and_allocate_page_indices": [
      "self",
      "rank",
      "keys"
    ],
    "confirm_write": [
      "self",
      "rank",
      "written_keys_to_confirm",
      "pages_to_release"
    ],
    "delete_keys": [
      "self",
      "rank",
      "keys"
    ],
    "exists": [
      "self",
      "rank",
      "keys"
    ],
    "clear": [
      "self",
      "rank"
    ],
    "get_page_indices": [
      "self",
      "rank",
      "keys"
    ]
  },
  "run_metadata_server": [
    "host",
    "port",
    "persistence_path",
    "save_interval"
  ],
  "Hf3fsClient": {
    "__init__": [
      "self",
      "path",
      "size",
      "bytes_per_page",
      "entries"
    ],
    "batch_read": [
      "self",
      "offsets",
      "tensors"
    ],
    "batch_write": [
      "self",
      "offsets",
      "tensors"
    ],
    "check": [
      "self",
      "offsets",
      "tensors"
    ],
    "get_size": [
      "self"
    ],
    "close": [
      "self"
    ],
    "flush": [
      "self"
    ]
  },
  "Hf3fsMockClient": {
    "__init__": [
      "self",
      "path",
      "size",
      "bytes_per_page",
      "entries"
    ],
    "batch_read": [
      "self",
      "offsets",
      "tensors"
    ],
    "batch_write": [
      "self",
      "offsets",
      "tensors"
    ],
    "check": [
      "self",
      "offsets",
      "tensors"
    ],
    "get_size": [
      "self"
    ],
    "close": [
      "self"
    ],
    "flush": [
      "self"
    ]
  },
  "root": [],
  "hf3fs_utils": [],
  "HF3FS_AVAILABLE": [],
  "rsynchronized": [],
  "wsynchronized": [],
  "Hf3fsUsrBioClient": {
    "__init__": [
      "self",
      "path",
      "size",
      "bytes_per_page",
      "entries",
      "client_timeout"
    ],
    "batch_read": [
      "self",
      "offsets",
      "tensors"
    ],
    "batch_write": [
      "self",
      "offsets",
      "tensors"
    ],
    "check": [
      "self",
      "offsets",
      "tensors"
    ],
    "get_size": [
      "self"
    ],
    "close": [
      "self"
    ],
    "flush": [
      "self"
    ]
  },
  "Hf3fsMetadataInterface": {
    "initialize": [
      "self",
      "rank",
      "num_pages"
    ],
    "reserve_and_allocate_page_indices": [
      "self",
      "rank",
      "keys"
    ],
    "confirm_write": [
      "self",
      "rank",
      "written_keys_to_confirm",
      "pages_to_release"
    ],
    "get_page_indices": [
      "self",
      "rank",
      "keys"
    ],
    "delete_keys": [
      "self",
      "rank",
      "keys"
    ],
    "exists": [
      "self",
      "rank",
      "keys"
    ],
    "clear": [
      "self",
      "rank"
    ]
  },
  "AtomicCounter": {
    "__init__": [
      "self",
      "n"
    ],
    "next": [
      "self"
    ]
  },
  "create_hf3fs_client": [
    "path",
    "size",
    "bytes_per_page",
    "entries",
    "client_timeout",
    "use_mock"
  ],
  "HiCacheHF3FS": {
    "__init__": [
      "self",
      "rank",
      "file_path",
      "file_size",
      "numjobs",
      "bytes_per_page",
      "entries",
      "client_timeout",
      "dtype",
      "metadata_client",
      "is_mla_model",
      "is_page_first_layout",
      "use_mock_client"
    ],
    "from_env_config": [
      "bytes_per_page",
      "dtype",
      "storage_config"
    ],
    "_batch_get": [
      "self",
      "keys",
      "values"
    ],
    "_batch_set": [
      "self",
      "keys",
      "values"
    ],
    "delete": [
      "self",
      "key"
    ],
    "exists": [
      "self",
      "key"
    ],
    "batch_exists": [
      "self",
      "keys",
      "extra_info"
    ],
    "clear": [
      "self"
    ],
    "close": [
      "self"
    ],
    "get_stats": [
      "self"
    ],
    "register_mem_pool_host": [
      "self",
      "mem_pool_host"
    ],
    "_get_mha_zero_copy_keys": [
      "self",
      "keys"
    ],
    "_get_mha_zero_copy_values": [
      "self",
      "values"
    ],
    "_batch_get_preprocess": [
      "self",
      "keys",
      "host_indices"
    ],
    "_batch_get_postprocess": [
      "self",
      "host_indices",
      "values",
      "results"
    ],
    "batch_get_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "_batch_set_preprocess": [
      "self",
      "keys",
      "host_indices"
    ],
    "batch_set_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_sizes"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_sizes"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ]
  },
  "test_rw_shm": [],
  "TestNixlUnified": {
    "setUp": [
      "self"
    ],
    "tearDown": [
      "self"
    ],
    "delete_test_file": [
      "self",
      "file_path"
    ],
    "verify_tensors_equal": [
      "self",
      "expected",
      "actual"
    ],
    "verify_tensor_lists_equal": [
      "self",
      "expected",
      "actual"
    ],
    "test_single_set_get": [
      "self"
    ],
    "test_batch_set_get": [
      "self"
    ],
    "test_mixed_operations": [
      "self"
    ],
    "test_data_integrity": [
      "self"
    ],
    "test_basic_file_operations": [
      "self"
    ],
    "test_create_nixl_tuples": [
      "self"
    ],
    "test_error_handling": [
      "self"
    ],
    "test_register_buffers": [
      "self"
    ],
    "test_register_files_with_tuples": [
      "self"
    ]
  },
  "NixlBackendSelection": {
    "FILE_PLUGINS": [],
    "OBJ_PLUGINS": [],
    "__init__": [
      "self",
      "plugin"
    ],
    "set_bucket": [
      "self",
      "bucket_name"
    ],
    "create_backend": [
      "self",
      "agent"
    ]
  },
  "NixlRegistration": {
    "__init__": [
      "self",
      "agent"
    ],
    "create_query_tuples": [
      "self",
      "key",
      "mem_type",
      "file_manager"
    ],
    "_register_memory": [
      "self",
      "items",
      "mem_type"
    ]
  },
  "NixlFileManager": {
    "__init__": [
      "self",
      "base_dir"
    ],
    "get_file_path": [
      "self",
      "key"
    ],
    "create_file": [
      "self",
      "file_path"
    ],
    "open_file": [
      "self",
      "file_path"
    ],
    "close_file": [
      "self",
      "fd"
    ],
    "files_to_nixl_tuples": [
      "self",
      "file_paths"
    ]
  },
  "HiCacheNixl": {
    "__init__": [
      "self",
      "storage_config",
      "file_path",
      "plugin"
    ],
    "_get_suffixed_key": [
      "self",
      "key"
    ],
    "register_buffers": [
      "self",
      "buffers"
    ],
    "register_files": [
      "self",
      "file_paths",
      "open_file"
    ],
    "register_objects": [
      "self",
      "keys",
      "sizes"
    ],
    "_execute_transfer": [
      "self",
      "buffers",
      "keys",
      "direction"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_sizes"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_sizes"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ],
    "exists": [
      "self",
      "key"
    ]
  },
  "setup": [],
  "AIBrixKVCacheStorageTest": {
    "test_with_page_size": [
      "self"
    ]
  },
  "AibrixKVCacheStorage": {
    "__init__": [
      "self",
      "storage_config",
      "mem_pool"
    ],
    "_aibrix_kvcache_metrics_report": [
      "self"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_size"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_size"
    ],
    "batch_exists": [
      "self",
      "keys",
      "extra_info"
    ],
    "exists": [
      "self",
      "key"
    ]
  },
  "DEFAULT_LOCAL_BUFFER_SIZE": [],
  "SETUP_TIMEOUT": [],
  "MooncakeHostTensorAllocator": {
    "__init__": [
      "self"
    ],
    "allocate": [
      "self",
      "dims",
      "dtype",
      "device"
    ]
  },
  "_parse_global_segment_size": [
    "value"
  ],
  "MooncakeStoreConfig": {
    "from_file": [],
    "load_from_env": [],
    "load_from_extra_config": [
      "extra_config"
    ]
  },
  "MooncakeStore": {
    "__init__": [
      "self",
      "storage_config",
      "mem_pool"
    ],
    "check_server": [
      "self"
    ],
    "warmup": [
      "self"
    ],
    "register_mem_pool_host": [
      "self",
      "mem_pool_host"
    ],
    "_get_mha_buffer_meta": [
      "self",
      "keys",
      "indices"
    ],
    "_get_mla_buffer_meta": [
      "self",
      "keys",
      "indices"
    ],
    "_batch_preprocess": [
      "self",
      "keys",
      "host_indices"
    ],
    "_batch_postprocess": [
      "self",
      "results",
      "is_set_operate"
    ],
    "batch_get_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "batch_set_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_sizes"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_sizes"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "exists": [
      "self",
      "key"
    ],
    "batch_exists": [
      "self",
      "keys",
      "extra_info"
    ],
    "close": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "_put_batch_zero_copy_impl": [
      "self",
      "key_strs",
      "buffer_ptrs",
      "buffer_sizes"
    ],
    "_get_batch_zero_copy_impl": [
      "self",
      "key_strs",
      "buffer_ptrs",
      "buffer_sizes"
    ],
    "_batch_exist": [
      "self",
      "key_strs"
    ],
    "get_stats": [
      "self"
    ]
  },
  "generate_batch_query_keys": [
    "kv_num",
    "config"
  ],
  "create_mock_host_kv_cache": [
    "buffer_size",
    "dtype"
  ],
  "test_single_operation": [],
  "test_batch_operation": [
    "config"
  ],
  "TensorPoolSize": [],
  "REMOTE_EIC_YAML_ENV_VAR": [],
  "G_EnableKVSetGPUDirect": [],
  "G_EnableKVGetGPUDirect": [],
  "G_EnableGPUNicAffinity": [],
  "GPUNicAffinity": [],
  "CPUNicAffinity": [],
  "get_eic_config_file_path": [],
  "FlexibleKVCacheMemoryPool": {
    "__init__": [
      "self",
      "conn",
      "kvcache_shape",
      "kvcache_dtype",
      "device"
    ],
    "try_allocate_kv_cache": [
      "self",
      "shape",
      "dtype",
      "count"
    ],
    "free_to_mempool": [
      "self",
      "data_ptr"
    ],
    "check_data_ptr_allocated": [
      "self",
      "data_ptr"
    ],
    "left_count": [
      "self"
    ]
  },
  "EICStorage": {
    "__init__": [
      "self",
      "hicache_config",
      "memory_pool_host"
    ],
    "warmup": [
      "self"
    ],
    "register_mem_pool_host": [
      "self",
      "memory_pool_host"
    ],
    "_init_eic_prefix": [
      "self"
    ],
    "_get_eic_key": [
      "self",
      "keys"
    ],
    "set": [
      "self",
      "key",
      "value",
      "target_location",
      "target_size"
    ],
    "batch_set": [
      "self",
      "keys",
      "values",
      "target_locations",
      "target_sizes"
    ],
    "get": [
      "self",
      "key",
      "target_location",
      "target_size"
    ],
    "batch_get": [
      "self",
      "keys",
      "target_locations",
      "target_sizes"
    ],
    "_batch_exists_impl": [
      "self",
      "keys"
    ],
    "exists": [
      "self",
      "key"
    ],
    "batch_exists": [
      "self",
      "keys",
      "extra_info"
    ],
    "delete": [
      "self",
      "key"
    ],
    "clear": [
      "self"
    ],
    "_filter_kv_cache": [
      "self",
      "total_len"
    ],
    "zero_copy_batch_set": [
      "self",
      "keys",
      "values"
    ],
    "zero_copy_batch_get": [
      "self",
      "keys",
      "values"
    ],
    "generic_batch_set": [
      "self",
      "keys",
      "values"
    ],
    "generic_batch_get": [
      "self",
      "keys",
      "buffers"
    ],
    "_get_mha_zero_copy_keys": [
      "self",
      "keys"
    ],
    "_get_mha_zero_copy_values": [
      "self",
      "values"
    ],
    "_batch_get_preprocess": [
      "self",
      "keys",
      "host_indices"
    ],
    "_batch_get_postprocess": [
      "self",
      "host_indices",
      "values",
      "results"
    ],
    "batch_get_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ],
    "_batch_set_preprocess": [
      "self",
      "keys",
      "host_indices"
    ],
    "batch_set_v1": [
      "self",
      "keys",
      "host_indices",
      "extra_info"
    ]
  },
  "pase_args": [],
  "init_eic_client": [],
  "test_set": [
    "eic_client"
  ],
  "test_get": [
    "eic_client"
  ],
  "test_exists": [
    "eic_client"
  ],
  "test_load_store_metadata": [],
  "LayerTransferCounter": {
    "__init__": [
      "self",
      "num_layers",
      "load_stream",
      "lmc_connector",
      "printable"
    ],
    "wait_until": [
      "self",
      "layer_id"
    ]
  },
  "LMCRadixCache": {
    "__init__": [
      "self",
      "params",
      "model_config",
      "tp_size",
      "rank",
      "tp_group"
    ],
    "reset": [
      "self"
    ],
    "match_prefix": [
      "self",
      "params"
    ],
    "cache_finished_req": [
      "self",
      "req",
      "is_insert"
    ],
    "evict": [
      "self",
      "num_tokens"
    ],
    "pretty_print": [
      "self"
    ]
  },
  "_ALGORITHM_REGISTRY": [],
  "_create_sparse_algorithm": [
    "config",
    "device"
  ],
  "_create_backend_adaptor": [
    "backend",
    "device",
    "sparse_algorithm",
    "req_to_token_pool"
  ],
  "_parse_sparse_config": [
    "server_args"
  ],
  "create_sparse_coordinator": [
    "device",
    "req_to_token_pool",
    "token_to_kv_pool",
    "start_layer",
    "end_layer",
    "server_args"
  ],
  "register_sparse_coordinator": [
    "coordinator"
  ],
  "get_sparse_coordinator": [],
  "QuestAlgorithm": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "_initialize_representation_pools": [
      "self",
      "start_layer",
      "end_layer",
      "total_num_pages"
    ],
    "_compute_page_representations": [
      "self",
      "layer_id",
      "reqs",
      "seq_lens",
      "start_page",
      "end_page",
      "k_buffer"
    ],
    "_retrieve_page_scores": [
      "self",
      "layer_id",
      "phys_pages",
      "req_pool_indices",
      "queries"
    ]
  },
  "BaseSparseAlgorithm": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "initialize_representation_pool": [
      "self",
      "start_layer",
      "end_layer",
      "token_to_kv_pool",
      "req_to_token_pool",
      "states"
    ],
    "construct_representations": [
      "self",
      "layer_id",
      "req_pool_indices",
      "seq_lens",
      "k_buffer",
      "forward_batch"
    ],
    "update_representations": [
      "self",
      "layer_id",
      "req_pool_indices",
      "seq_lens",
      "k_buffer",
      "forward_batch"
    ],
    "retrieve_topk": [
      "self",
      "queries",
      "layer_id",
      "req_pool_indices",
      "sparse_mask"
    ]
  },
  "BaseSparseAlgorithmImpl": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "initialize_representation_pool": [
      "self",
      "start_layer",
      "end_layer",
      "token_to_kv_pool",
      "req_to_token_pool",
      "states"
    ],
    "construct_representations": [
      "self",
      "layer_id",
      "req_pool_indices",
      "seq_lens",
      "k_buffer",
      "forward_batch"
    ],
    "update_representations": [
      "self",
      "layer_id",
      "req_pool_indices",
      "seq_lens",
      "k_buffer",
      "forward_batch"
    ],
    "retrieve_topk": [
      "self",
      "queries",
      "layer_id",
      "req_pool_indices",
      "sparse_mask"
    ],
    "_initialize_representation_pools": [
      "self",
      "start_layer",
      "end_layer",
      "total_num_pages"
    ],
    "_compute_page_representations": [
      "self",
      "layer_id",
      "reqs",
      "seq_lens",
      "start_page",
      "end_page",
      "k_buffer"
    ],
    "_retrieve_page_scores": [
      "self",
      "layer_id",
      "phys_pages",
      "req_pool_indices",
      "queries"
    ]
  },
  "DeepSeekNSAAlgorithm": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "retrieve_topk": [
      "self",
      "queries",
      "layer_id",
      "req_pool_indices",
      "sparse_mask",
      "attn_metadata"
    ],
    "initialize_representation_pool": [
      "self",
      "start_layer",
      "end_layer",
      "token_to_kv_pool",
      "req_to_token_pool",
      "states"
    ],
    "construct_representations": [
      "self",
      "layer_id",
      "req_pool_indices",
      "seq_lens",
      "k_buffer",
      "forward_batch"
    ],
    "update_representations": [
      "self",
      "layer_id",
      "req_pool_indices",
      "seq_lens",
      "k_buffer",
      "forward_batch"
    ]
  },
  "BackendAdaptor": {
    "__init__": [
      "self",
      "device"
    ],
    "save_original_metadata": [
      "self",
      "metadata"
    ],
    "adapt_for_attn_metadata": [
      "self",
      "selected_indices",
      "valid_lengths",
      "sparse_mask",
      "current_metadata",
      "forward_batch",
      "req_to_token",
      "page_size",
      "layer_id"
    ]
  },
  "NSABackendAdaptor": {
    "__init__": [
      "self",
      "device",
      "req_to_token_pool"
    ],
    "adapt_for_attn_metadata": [
      "self",
      "selected_indices",
      "valid_lengths",
      "sparse_mask",
      "current_metadata",
      "forward_batch",
      "req_to_token",
      "page_size",
      "layer_id"
    ]
  },
  "FlashAttentionAdaptor": {
    "save_original_metadata": [
      "self",
      "metadata"
    ],
    "adapt_for_attn_metadata": [
      "self",
      "selected_indices",
      "valid_lengths",
      "sparse_mask",
      "current_metadata",
      "forward_batch",
      "req_to_token",
      "page_size",
      "layer_id"
    ],
    "_logical_to_physical_pages_batch": [
      "self",
      "logical_pages",
      "req_pool_indices",
      "req_to_token",
      "page_size"
    ]
  },
  "RequestTrackers": {
    "__init__": [
      "self",
      "max_pool_size",
      "device",
      "num_layers",
      "min_sparse_prompt_len",
      "max_context_len"
    ],
    "register": [
      "self",
      "idx",
      "prompt_len"
    ],
    "clear": [
      "self",
      "idx"
    ]
  },
  "SparseConfig": {},
  "SparseCoordinator": {
    "__init__": [
      "self",
      "config",
      "algorithm",
      "backend_adaptor",
      "req_to_token_pool",
      "token_to_kv_pool",
      "start_layer",
      "end_layer",
      "device"
    ],
    "on_request_begin": [
      "self",
      "req"
    ],
    "on_request_end": [
      "self",
      "req"
    ],
    "forward_begin": [
      "self",
      "forward_batch"
    ],
    "forward_end": [
      "self",
      "forward_batch"
    ],
    "attention_begin": [
      "self",
      "query",
      "key",
      "value",
      "layer",
      "forward_batch",
      "attn_metadata"
    ],
    "attention_end": [
      "self",
      "output",
      "layer",
      "forward_batch"
    ],
    "_handle_sparse_retrieve": [
      "self",
      "query",
      "layer",
      "forward_batch",
      "attn_metadata"
    ],
    "_compute_sparse_mask": [
      "self",
      "req_pool_indices"
    ]
  },
  "_alloc_extend_naive": [
    "prefix_lens",
    "seq_lens",
    "last_loc",
    "free_pages",
    "out_indices",
    "page_size",
    "device"
  ],
  "NPUPagedTokenToKVPoolAllocator": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "device",
      "kvcache",
      "need_sort"
    ],
    "alloc_extend": [
      "self",
      "prefix_lens",
      "prefix_lens_cpu",
      "seq_lens",
      "seq_lens_cpu",
      "last_loc",
      "extend_num_tokens"
    ],
    "alloc_decode": [
      "self",
      "seq_lens",
      "seq_lens_cpu",
      "last_loc"
    ],
    "free": [
      "self",
      "free_index"
    ]
  },
  "cmo_stream": [],
  "get_cmo_stream": [],
  "set_cmo_stream": [
    "stream"
  ],
  "prepare_weight_cache": [
    "handle",
    "cache",
    "PREFETCH_MAX_SIZE"
  ],
  "wait_cmo_stream": [],
  "indexer_weight_stream": [],
  "NPUACLFormat": {
    "ACL_FORMAT_UNDEFINED": [],
    "ACL_FORMAT_ND": [],
    "ACL_FORMAT_FRACTAL_NZ": []
  },
  "_call_once": [
    "fn"
  ],
  "set_default_server_args": [
    "args"
  ],
  "init_npu_backend": [],
  "npu_format_cast": [
    "tensor",
    "acl_format"
  ],
  "get_indexer_weight_stream": [],
  "NPUMHATokenToKVPool": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "head_num",
      "head_dim",
      "layer_num",
      "device",
      "enable_memory_saver",
      "start_layer",
      "end_layer",
      "enable_alt_stream",
      "enable_kv_cache_copy"
    ],
    "_create_buffers": [
      "self"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v",
      "k_scale",
      "v_scale",
      "layer_id_override"
    ]
  },
  "NPUMLATokenToKVPool": {
    "__init__": [
      "self",
      "size",
      "page_size",
      "dtype",
      "kv_lora_rank",
      "qk_rope_head_dim",
      "index_head_dim",
      "layer_num",
      "device",
      "enable_memory_saver",
      "start_layer",
      "end_layer"
    ],
    "get_kv_size_bytes": [
      "self"
    ],
    "get_kv_buffer": [
      "self",
      "layer_id"
    ],
    "get_key_buffer": [
      "self",
      "layer_id"
    ],
    "get_value_buffer": [
      "self",
      "layer_id"
    ],
    "get_index_k_buffer": [
      "self",
      "layer_id"
    ],
    "get_contiguous_buf_infos": [
      "self"
    ],
    "set_kv_buffer": [
      "self",
      "layer",
      "loc",
      "cache_k",
      "cache_v"
    ],
    "set_index_k_buffer": [
      "self",
      "layer_id",
      "loc",
      "index_k"
    ]
  },
  "fused_topk_npu": [
    "hidden_states",
    "router_logits",
    "topk_config",
    "num_token_non_padded",
    "expert_location_dispatch_info"
  ],
  "_reshape_kv_for_fia_nz": [
    "tensor",
    "num_heads",
    "head_dim",
    "page_size"
  ],
  "ForwardMetadata": {},
  "AscendAttnMaskBuilder": {
    "__init__": [
      "self",
      "model_runner",
      "device",
      "use_fia",
      "use_mla"
    ],
    "generate_mask_flag": [
      "max_seq_len"
    ],
    "generate_attn_mask": [
      "max_seq_len",
      "mode",
      "dtype"
    ],
    "get_attention_mask_id": [
      "seq_lens",
      "extend_lens"
    ],
    "update_attn_cache": [
      "self",
      "seqlen",
      "mask_cache",
      "seq_len_cached",
      "dtype",
      "mode"
    ],
    "get_splitfuse_attn_mask": [
      "self",
      "seq_lens"
    ]
  },
  "AscendAttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "get_verify_buffers_to_fill_after_draft": [
      "self"
    ],
    "update_verify_buffers_to_fill_after_draft": [
      "self",
      "spec_info",
      "cuda_graph_bs"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "do_cp_balance_attn": [
      "self",
      "q_nope",
      "k_nope",
      "q_pe",
      "k_pe",
      "topk_indices",
      "layer",
      "actual_seq_qlen",
      "actual_seq_lengths_kv"
    ],
    "forward_sparse": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "topk_indices"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "topk_indices",
      "sinks"
    ],
    "forward_mtp": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope"
    ],
    "forward_decode_graph": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "sinks"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "topk_indices",
      "sinks"
    ],
    "forward_mixed": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "topk_indices"
    ]
  },
  "AscendAttnMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "common_template": [
      "self",
      "forward_batch",
      "call_fn"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "is_mla_preprocess_enabled": [],
  "is_fia_nz": [],
  "round_up": [
    "val",
    "align"
  ],
  "transdata": [
    "nd_mat",
    "block_size"
  ],
  "trans_rope_weight": [
    "weight",
    "rope_dim"
  ],
  "NPUFusedMLAPreprocess": {
    "__init__": [
      "self",
      "fused_qkv_a_proj_with_mqa",
      "q_a_layernorm",
      "kv_a_layernorm",
      "q_b_proj",
      "w_kc",
      "rotary_emb",
      "layer_id",
      "num_local_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "quant_config"
    ],
    "preprocess_weights": [
      "self",
      "hidden_states"
    ],
    "get_sin_cos": [
      "self",
      "positions"
    ],
    "get_kv_cache_and_cache_idx": [
      "self",
      "forward_batch"
    ],
    "forward_absorb_prepare_npu_rms_norm_cache": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_mlapo": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ]
  },
  "_NPULinearMethodBase": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "NPUW8A8Int8LinearMethod": {
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "NPUW8A8Int8DynamicLinearMethod": {
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "NPU_W4A4DynamicLinearMethod": {
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias",
      "tp_rank"
    ]
  },
  "npu_fused_experts": [
    "hidden_states",
    "w13",
    "w13_scale",
    "w2",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "top_k"
  ],
  "npu_fused_moe_without_routing_weights_bf16": [
    "layer",
    "hidden_states",
    "group_list_type",
    "group_list",
    "output_dtype"
  ],
  "_NPUFusedMoEMethodBase": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "NPUW8A8Int8DynamicMoEMethod": {
    "_release_weight_cache": [
      "self",
      "weight"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "NPUW4A8Int8DynamicMoEMethod": {
    "_process_scale": [
      "self",
      "weight",
      "scale",
      "per_group_scale",
      "is_per_channel_weight"
    ],
    "_update_bias": [
      "self",
      "layer",
      "w13_bias",
      "w2_bias"
    ],
    "_pack_to_int32": [
      "self",
      "weight"
    ],
    "process_weights_after_loading": [
      "self",
      "layer",
      "is_per_channel_weight",
      "activation_use_clip"
    ],
    "_process_weights_without_clip": [
      "self",
      "layer",
      "is_per_channel_weight"
    ],
    "_process_weights_with_clip": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "NPUW4A16Int4DynamicMoEMethod": {
    "_pack_to_int32": [
      "self",
      "weight"
    ],
    "_unpack_from_int32": [
      "self",
      "value",
      "num_bits",
      "shape",
      "packed_dim"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "EAGLEDraftNpuGraphRunner": {
    "__init__": [
      "self",
      "eagle_worker"
    ],
    "_init_arch_map": [
      "self"
    ],
    "_create_graph": [
      "self"
    ],
    "_capture_init": [
      "self",
      "run_once_fn"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_get_update_attr_name": [
      "self"
    ],
    "_get_update_attr_type": [
      "self"
    ],
    "_replay_update": [
      "self",
      "seq_lens"
    ],
    "_replay": [
      "self",
      "forward_batch"
    ],
    "_cache_loc_dtype": [
      "self"
    ]
  },
  "is_npu": [],
  "patch_model_npu": [
    "model",
    "enable_compile",
    "num_tokens",
    "tp_group"
  ],
  "NPUGraphRunner": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "_init_arch_map": [
      "self"
    ],
    "_create_device_graph": [
      "self"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_get_update_attr_name": [
      "self"
    ],
    "_get_update_attr_type": [
      "self"
    ],
    "_update_inputs": [
      "self",
      "seq_lens"
    ],
    "_cache_loc_dtype": [
      "self"
    ],
    "_init_profile_context_and_memory_record": [
      "self"
    ],
    "_post_process_after_profile": [
      "self",
      "prof_context"
    ],
    "replay": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors"
    ]
  },
  "EAGLEDraftExtendNpuGraphRunner": {
    "__init__": [
      "self",
      "eagle_worker"
    ],
    "_create_graph": [
      "self"
    ],
    "_cache_loc_dtype": [
      "self"
    ],
    "_capture_init": [
      "self",
      "run_once_fn"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_replay_update": [
      "self",
      "seq_lens"
    ],
    "_replay": [
      "self",
      "forward_batch"
    ]
  },
  "forward_mha_prepare_npu": [
    "m",
    "positions",
    "hidden_states",
    "forward_batch",
    "zero_allocator"
  ],
  "forward_mha_core_npu": [
    "m",
    "q",
    "k",
    "v",
    "forward_batch"
  ],
  "forward_mla_prepare_npu": [
    "m",
    "positions",
    "hidden_states",
    "forward_batch",
    "zero_allocator"
  ],
  "forward_mla_core_npu": [
    "m",
    "q_pe",
    "k_pe",
    "q_nope_out",
    "k_nope",
    "forward_batch",
    "zero_allocator",
    "positions",
    "topk_indices"
  ],
  "forward_dsa_prepare_npu": [
    "m",
    "positions",
    "hidden_states",
    "forward_batch",
    "zero_allocator"
  ],
  "forward_dsa_core_npu": [
    "m",
    "q_pe",
    "k_pe",
    "q_nope_out",
    "k_nope",
    "topk_indices",
    "forward_batch",
    "zero_allocator",
    "positions"
  ],
  "rotate_input_ids_kernel": [
    "input_ids_ptr",
    "extend_start_loc_ptr",
    "extend_seq_lens_ptr",
    "topk_index_ptr",
    "select_index_ptr",
    "BLOCK_SIZE"
  ],
  "rotate_input_ids_triton": [
    "input_ids",
    "extend_start_loc",
    "extend_seq_lens",
    "topk_index",
    "select_index"
  ],
  "assign_new_state_kernel": [
    "old_input_ids_ptr",
    "old_positions_ptr",
    "old_hidden_states_ptr",
    "old_out_cache_loc_ptr",
    "old_extend_seq_lens_ptr",
    "old_extend_start_loc_ptr",
    "input_ids_ptr",
    "positions_ptr",
    "hidden_states_ptr",
    "out_cache_loc_ptr",
    "extend_seq_lens_ptr",
    "extend_start_loc_ptr",
    "next_token_ids_ptr",
    "seq_lens_ptr",
    "padding_lens_ptr",
    "req_pool_indices_ptr",
    "req_to_token_ptr",
    "req_to_hidden_states_pool_ptr",
    "step",
    "stride_hidden_seq",
    "stride_hidden_dim",
    "stride_pool_req",
    "stride_pool_step",
    "stride_pool_dim",
    "stride_req_token_0",
    "stride_req_token_1",
    "HIDDEN_DIM",
    "BLOCK_SEQ",
    "BLOCK_HID"
  ],
  "assign_new_state_triton": [
    "next_token_ids",
    "old_input_ids",
    "old_positions",
    "old_hidden_states",
    "old_out_cache_loc",
    "old_extend_seq_lens",
    "old_extend_start_loc",
    "input_ids",
    "positions",
    "hidden_states",
    "out_cache_loc",
    "extend_seq_lens",
    "extend_start_loc",
    "seq_lens",
    "padding_lens",
    "num_seqs",
    "step",
    "req_pool_indices",
    "req_to_token",
    "req_to_hidden_states_pool"
  ],
  "assign_hidden_states_pool_kernel": [
    "hidden_states_ptr",
    "req_pool_indices_ptr",
    "req_to_hidden_states_pool_ptr",
    "extend_seq_lens_ptr",
    "extend_start_loc_ptr",
    "stride_hidden_seq",
    "stride_hidden_dim",
    "stride_pool_req",
    "stride_pool_step",
    "stride_pool_dim",
    "HIDDEN_DIM",
    "pool_size",
    "BLOCK_HID"
  ],
  "assign_hidden_states_pool_triton": [
    "hidden_states",
    "req_pool_indices",
    "req_to_hidden_states_pool",
    "pool_size",
    "num_seqs",
    "extend_seq_lens",
    "extend_start_loc"
  ],
  "assign_hidden_states_pool_torch": [
    "hidden_states",
    "req_pool_indices",
    "req_to_hidden_states_pool",
    "pool_size",
    "num_seqs",
    "extend_seq_lens",
    "extend_start_loc"
  ],
  "NgramVerifyInput": {
    "__init__": [
      "self",
      "draft_token",
      "tree_mask",
      "positions",
      "retrive_index",
      "retrive_next_token",
      "retrive_next_sibling",
      "draft_token_num"
    ],
    "get_spec_adjust_token_coefficient": [
      "self"
    ],
    "prepare_for_verify": [
      "self",
      "batch",
      "page_size"
    ],
    "generate_attn_arg_prefill": [
      "self",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "req_to_token"
    ],
    "_fill_requests": [
      "self",
      "batch",
      "logits_output"
    ],
    "_free_cache": [
      "self",
      "batch",
      "page_size",
      "accept_length_cpu"
    ],
    "_greedy_verify": [
      "self",
      "batch",
      "logits_output"
    ],
    "_sampling_verify": [
      "self",
      "batch",
      "logits_output",
      "sampling_info"
    ],
    "verify": [
      "self",
      "batch",
      "logits_output",
      "page_size",
      "vocab_mask"
    ],
    "filter_batch": [
      "self",
      "new_indices",
      "has_been_filtered"
    ],
    "merge_batch": [
      "self",
      "spec_info"
    ]
  },
  "SIMULATE_ACC_LEN": [],
  "SIMULATE_ACC_METHOD": [],
  "TREE_TRAVERSE_TIME_THRESHOLD": [],
  "TREE_SPEC_KERNEL_AVAILABLE": [],
  "spec_need_hidden_states": [
    "server_args"
  ],
  "create_extend_after_decode_spec_info": [
    "verified_id",
    "seq_lens",
    "accept_lens",
    "positions",
    "new_verified_id",
    "bs_upper"
  ],
  "assign_req_to_token_pool": [
    "req_pool_indices",
    "req_to_token",
    "start_offset",
    "end_offset",
    "out_cache_loc",
    "pool_len",
    "bs_upper"
  ],
  "assign_req_to_token_pool_func": [
    "req_pool_indices",
    "req_to_token",
    "start_offset",
    "end_offset",
    "out_cache_loc",
    "batch_size"
  ],
  "assign_draft_cache_locs": [
    "req_pool_indices",
    "req_to_token",
    "seq_lens",
    "extend_lens",
    "num_new_pages_per_topk",
    "out_cache_loc",
    "source_cache_loc",
    "target_cache_loc",
    "last_page_lens_cumsum",
    "duplicate_cache_len",
    "pool_len",
    "topk",
    "speculative_num_steps",
    "page_size",
    "bs_upper",
    "iter_upper"
  ],
  "generate_draft_decode_kv_indices": [
    "req_pool_indices",
    "req_to_token",
    "paged_kernel_lens",
    "kv_indices",
    "kv_indptr",
    "positions",
    "pool_len",
    "kv_indices_stride",
    "kv_indptr_stride",
    "bs_upper",
    "iter_upper",
    "num_tokens_upper",
    "page_size"
  ],
  "align_evict_mask_to_page_size": [
    "seq_lens",
    "evict_mask",
    "page_size",
    "num_draft_tokens",
    "BLOCK_SIZE"
  ],
  "get_target_cache_loc": [
    "tgt_cache_loc",
    "to_free_slots",
    "accept_length",
    "to_free_num_slots",
    "out_cache_loc",
    "num_verify_tokens",
    "num_verify_tokens_upper",
    "bs_upper"
  ],
  "get_src_tgt_cache_loc": [
    "seq_lens",
    "out_cache_loc",
    "accept_index",
    "accept_length",
    "draft_token_num",
    "page_size"
  ],
  "filter_finished_cache_loc_kernel": [
    "out_cache_loc",
    "tgt_cache_loc",
    "accept_length",
    "accept_length_filter",
    "bs_upper",
    "num_verify_tokens_upper"
  ],
  "create_accept_length_filter": [
    "accept_length",
    "unfinished_index_device",
    "seq_lens"
  ],
  "select_top_k_tokens": [
    "i",
    "topk_p",
    "topk_index",
    "hidden_states",
    "scores",
    "topk"
  ],
  "generate_simulated_accept_index": [
    "accept_index",
    "predict",
    "accept_length",
    "bs",
    "spec_steps",
    "simulate_acc_len",
    "simulate_acc_method"
  ],
  "traverse_tree": [
    "retrieve_next_token",
    "retrieve_next_sibling",
    "draft_tokens",
    "grammar",
    "allocate_token_bitmask"
  ],
  "generate_token_bitmask": [
    "reqs",
    "verify_input",
    "retrieve_next_token_cpu",
    "retrieve_next_sibling_cpu",
    "draft_tokens_cpu",
    "vocab_size"
  ],
  "load_token_map": [
    "token_map_path"
  ],
  "draft_tp_context": [
    "tp_group"
  ],
  "detect_nan": [
    "logits_output"
  ],
  "get_last_loc_large_page_size_large_top_k": [
    "req_to_token",
    "req_pool_indices",
    "seq_lens",
    "speculative_num_steps",
    "topk",
    "page_size"
  ],
  "EAGLEDraftCudaGraphRunner": {
    "__init__": [
      "self",
      "eagle_worker"
    ],
    "_cache_loc_dtype": [
      "self"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ],
    "_create_graph": [
      "self"
    ],
    "_capture_init": [
      "self",
      "run_once_fn"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_replay": [
      "self",
      "forward_batch"
    ],
    "capture": [
      "self"
    ],
    "capture_one_batch_size": [
      "self",
      "num_seqs",
      "forward",
      "stream_idx"
    ],
    "_postprocess_output_to_raw_bs": [
      "self",
      "out",
      "raw_bs"
    ],
    "replay": [
      "self",
      "forward_batch"
    ]
  },
  "EAGLEDraftExtendCudaGraphRunner": {
    "__init__": [
      "self",
      "eagle_worker"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ],
    "_create_graph": [
      "self"
    ],
    "_cache_loc_dtype": [
      "self"
    ],
    "_capture_init": [
      "self",
      "run_once_fn"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_replay": [
      "self",
      "forward_batch"
    ],
    "capture": [
      "self"
    ],
    "capture_one_batch_size": [
      "self",
      "bs",
      "forward",
      "stream_idx"
    ],
    "replay": [
      "self",
      "forward_batch"
    ]
  },
  "MultiLayerEagleDraftExtendCudaGraphRunner": {
    "__init__": [
      "self",
      "eagle_worker",
      "step"
    ],
    "init_buffers_and_capture": [
      "self",
      "cuda_graph_buffers",
      "offset",
      "next_cuda_graph_runner"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ],
    "_create_graph": [
      "self"
    ],
    "_capture_init": [
      "self",
      "run_once_fn"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_replay": [
      "self",
      "forward_batch"
    ],
    "capture": [
      "self"
    ],
    "get_forward_batch": [
      "self",
      "bs"
    ],
    "capture_one_batch_size": [
      "self",
      "bs",
      "forward",
      "stream_idx"
    ],
    "init_replay_state": [
      "self",
      "forward_batch",
      "bs",
      "raw_bs",
      "num_tokens"
    ],
    "replay": [
      "self",
      "forward_batch",
      "init_state"
    ]
  },
  "MultiLayerEagleMultiStepDraftExtendCudaGraphRunner": {
    "__init__": [
      "self",
      "eagle_worker"
    ],
    "_init_and_capture": [
      "self"
    ],
    "reset_buffers": [
      "self",
      "forward_batch",
      "batch_result"
    ],
    "get_runner": [
      "self",
      "step"
    ],
    "get_last_runner": [
      "self"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ]
  },
  "USE_FULL_MASK": [],
  "NGRAMWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "clear_cache_pool": [
      "self"
    ],
    "_efficient_concat_last_n": [
      "self",
      "seq1",
      "seq2",
      "n"
    ],
    "_init_preallocated_tensors": [
      "self"
    ],
    "_prepare_draft_tokens": [
      "self",
      "batch"
    ],
    "_prepare_for_speculative_decoding": [
      "self",
      "batch"
    ],
    "_update_ngram_cache": [
      "self",
      "batch"
    ],
    "forward_batch_generation": [
      "self",
      "batch"
    ]
  },
  "SGLANG_RETURN_ORIGINAL_LOGPROB": [],
  "StandaloneWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ]
  },
  "_get_plan_stream": [
    "device"
  ],
  "EagleDraftWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "init_token_map": [
      "self"
    ],
    "init_lm_head": [
      "self"
    ],
    "init_attention_backend": [
      "self"
    ],
    "init_cuda_graphs": [
      "self"
    ],
    "draft": [
      "self",
      "model_worker_batch"
    ],
    "draft_forward": [
      "self",
      "forward_batch"
    ],
    "draft_extend": [
      "self"
    ],
    "_draft_extend_for_prefill": [
      "self",
      "batch",
      "target_hidden_states",
      "next_token_ids"
    ],
    "_draft_extend_for_decode": [
      "self",
      "batch",
      "batch_result"
    ]
  },
  "EAGLEWorkerV2": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "target_worker": [
      "self"
    ],
    "draft_worker": [
      "self"
    ],
    "clear_cache_pool": [
      "self"
    ],
    "forward_batch_generation": [
      "self",
      "model_worker_batch"
    ],
    "verify": [
      "self",
      "batch"
    ],
    "move_accepted_tokens_to_target_kvcache": [
      "self",
      "batch",
      "accept_index",
      "accept_length"
    ],
    "update_weights_from_tensor": [
      "self",
      "recv_req"
    ]
  },
  "organize_draft_results": [
    "score_list",
    "token_list",
    "parents_list",
    "num_draft_token"
  ],
  "TreeMaskMode": {
    "FULL_MASK": [],
    "QLEN_ONLY": [],
    "QLEN_ONLY_BITPACKING": []
  },
  "build_tree_kernel_efficient": [
    "verified_id",
    "parent_list",
    "top_scores_index",
    "draft_tokens",
    "seq_lens",
    "seq_lens_sum",
    "topk",
    "spec_steps",
    "num_verify_tokens",
    "tree_mask_mode",
    "tree_mask_buf",
    "position_buf"
  ],
  "verify_tree_greedy_func": [
    "predicts",
    "accept_index",
    "accept_token_num",
    "candidates",
    "retrive_index",
    "retrive_next_token",
    "retrive_next_sibling",
    "target_predict",
    "topk"
  ],
  "BaseDraftWorker": {
    "draft": [],
    "draft_extend": []
  },
  "BaseSpecWorker": {
    "target_worker": [
      "self"
    ],
    "draft_worker": [
      "self"
    ],
    "clear_cache_pool": [
      "self"
    ]
  },
  "SpeculativeAlgorithm": {
    "EAGLE": [],
    "EAGLE3": [],
    "STANDALONE": [],
    "NGRAM": [],
    "NONE": [],
    "from_string": [
      "cls",
      "name"
    ],
    "is_none": [
      "self"
    ],
    "is_eagle": [
      "self"
    ],
    "is_eagle3": [
      "self"
    ],
    "is_standalone": [
      "self"
    ],
    "is_ngram": [
      "self"
    ],
    "supports_spec_v2": [
      "self"
    ],
    "create_worker": [
      "self",
      "server_args"
    ]
  },
  "SpecInputType": {
    "EAGLE_DRAFT": [],
    "EAGLE_VERIFY": [],
    "NGRAM_VERIFY": []
  },
  "SpecInput": {
    "__init__": [
      "self",
      "spec_input_type"
    ],
    "is_draft_input": [
      "self"
    ],
    "is_verify_input": [
      "self"
    ],
    "get_spec_adjust_token_coefficient": [
      "self"
    ],
    "get_spec_adjusted_global_num_tokens": [
      "self",
      "forward_batch"
    ]
  },
  "assign_draft_cache_locs_page_size_1": [
    "req_pool_indices",
    "req_to_token",
    "seq_lens",
    "out_cache_loc",
    "pool_len",
    "topk",
    "speculative_num_steps"
  ],
  "EagleDraftInputV2Mixin": {
    "prepare_for_decode": [
      "self",
      "batch"
    ],
    "prepare_for_v2_draft": [
      "self",
      "req_to_token_pool",
      "batch",
      "cuda_graph_runner",
      "draft_model_runner",
      "topk",
      "num_steps"
    ],
    "prepare_for_extend_to_fill_draft_kvcache": [
      "self",
      "batch",
      "predict",
      "num_draft_tokens",
      "draft_model_runner",
      "cuda_graph_runner"
    ]
  },
  "EagleVerifyInputV2Mixin": {
    "prepare_for_v2_verify": [
      "self",
      "req_to_token_pool",
      "batch",
      "target_worker"
    ],
    "sample": [
      "self",
      "batch",
      "logits_output",
      "vocab_mask"
    ]
  },
  "fill_new_verified_id": [
    "verified_id",
    "accept_lens",
    "new_verified_id",
    "num_draft_tokens"
  ],
  "fill_accepted_out_cache_loc": [
    "accept_index",
    "out_cache_loc",
    "accepted_out_cache_loc",
    "size_upper"
  ],
  "assign_extend_cache_locs": [
    "req_pool_indices",
    "req_to_token",
    "start_offset",
    "end_offset",
    "out_cache_loc",
    "pool_len",
    "bs_upper"
  ],
  "assign_extend_cache_locs_func": [
    "req_pool_indices",
    "req_to_token",
    "start_offset",
    "end_offset",
    "batch_size",
    "draft_token_num",
    "device"
  ],
  "MultiLayerEagleDraftWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "mtp_model_runner": [
      "self",
      "step"
    ],
    "init_lm_head": [
      "self"
    ],
    "init_attention_backend": [
      "self"
    ],
    "init_cuda_graphs": [
      "self"
    ],
    "reset_cuda_graph_buffers": [
      "self",
      "forward_batch",
      "batch_result"
    ],
    "draft": [
      "self",
      "model_worker_batch"
    ],
    "draft_forward": [
      "self",
      "forward_batch"
    ],
    "draft_extend": [
      "self"
    ],
    "_draft_extend_for_prefill": [
      "self",
      "batch",
      "target_hidden_states",
      "next_token_ids"
    ],
    "_draft_extend_for_decode": [
      "self",
      "batch",
      "batch_result"
    ]
  },
  "MultiLayerEagleWorkerV2": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "target_worker": [
      "self"
    ],
    "draft_worker": [
      "self"
    ],
    "clear_cache_pool": [
      "self"
    ],
    "forward_batch_generation": [
      "self",
      "model_worker_batch"
    ],
    "verify": [
      "self",
      "batch"
    ]
  },
  "EAGLEWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "init_attention_backend": [
      "self"
    ],
    "init_cuda_graphs": [
      "self"
    ],
    "draft_model_runner": [
      "self"
    ],
    "forward_batch_generation": [
      "self",
      "batch"
    ],
    "check_forward_draft_extend_after_decode": [
      "self",
      "batch"
    ],
    "forward_target_extend": [
      "self",
      "batch"
    ],
    "_draft_preprocess_decode": [
      "self",
      "batch"
    ],
    "_draft_preprocess_idle": [
      "self",
      "batch"
    ],
    "draft": [
      "self",
      "batch"
    ],
    "draft_forward": [
      "self",
      "forward_batch"
    ],
    "clear_cache_pool": [
      "self"
    ],
    "verify": [
      "self",
      "batch",
      "spec_info"
    ],
    "_mamba_verify_update": [
      "self",
      "batch",
      "res",
      "logits_output",
      "spec_info",
      "seq_lens_pre_verify"
    ],
    "forward_draft_extend": [
      "self",
      "batch",
      "hidden_states",
      "next_token_ids",
      "seq_lens_cpu"
    ],
    "forward_draft_extend_after_decode": [
      "self",
      "batch"
    ],
    "capture_for_decode": [
      "self",
      "logits_output",
      "draft_input"
    ],
    "update_weights_from_tensor": [
      "self",
      "recv_req"
    ]
  },
  "get_last_loc_large_page_size_top_k_1": [
    "req_to_token",
    "req_pool_indices",
    "seq_lens",
    "speculative_num_steps"
  ],
  "EagleVerifyInput": {
    "__post_init__": [
      "self"
    ],
    "get_spec_adjust_token_coefficient": [
      "self"
    ],
    "create_idle_input": [
      "cls",
      "topk",
      "spec_steps",
      "num_verify_tokens"
    ],
    "prepare_for_verify": [
      "self",
      "batch",
      "page_size"
    ],
    "generate_attn_arg_prefill": [
      "self",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "req_to_token"
    ],
    "verify": [
      "self",
      "batch",
      "logits_output",
      "token_to_kv_pool_allocator",
      "page_size",
      "vocab_mask"
    ]
  },
  "EagleDraftInput": {
    "__post_init__": [
      "self"
    ],
    "get_spec_adjust_token_coefficient": [
      "self"
    ],
    "prepare_for_extend": [
      "self",
      "batch"
    ],
    "create_idle_input": [
      "cls",
      "device",
      "hidden_size",
      "dtype",
      "topk",
      "capture_hidden_mode"
    ],
    "prepare_extend_after_decode": [
      "self",
      "batch",
      "speculative_num_steps"
    ],
    "generate_attn_arg_prefill": [
      "self",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "req_to_token"
    ],
    "filter_batch": [
      "self",
      "new_indices",
      "has_been_filtered"
    ],
    "merge_batch": [
      "self",
      "spec_info"
    ]
  },
  "EagleVerifyOutput": {},
  "DraftBackendFactory": {
    "__init__": [
      "self",
      "server_args",
      "draft_model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "_create_backend": [
      "self",
      "backend_name",
      "backend_map",
      "error_template"
    ],
    "create_decode_backend": [
      "self"
    ],
    "create_draft_extend_backend": [
      "self"
    ],
    "_create_nsa_decode_backend": [
      "self"
    ],
    "_create_nsa_prefill_backend": [
      "self"
    ],
    "_create_flashinfer_decode_backend": [
      "self"
    ],
    "_create_triton_decode_backend": [
      "self"
    ],
    "_create_aiter_decode_backend": [
      "self"
    ],
    "_create_fa3_decode_backend": [
      "self"
    ],
    "_create_flashmla_decode_backend": [
      "self"
    ],
    "_create_trtllm_mha_decode_backend": [
      "self"
    ],
    "_create_trtllm_mla_decode_backend": [
      "self"
    ],
    "_create_ascend_decode_backend": [
      "self"
    ],
    "_create_flashinfer_prefill_backend": [
      "self"
    ],
    "_create_triton_prefill_backend": [
      "self"
    ],
    "_create_aiter_prefill_backend": [
      "self"
    ],
    "_create_fa3_prefill_backend": [
      "self"
    ],
    "_create_trtllm_mha_prefill_backend": [
      "self"
    ],
    "_create_trtllm_mla_prefill_backend": [
      "self"
    ],
    "_create_ascend_prefill_backend": [
      "self"
    ],
    "_create_flashmla_prefill_backend": [
      "self"
    ]
  },
  "MultiLayerEagleWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "init_attention_backend": [
      "self"
    ],
    "init_cuda_graphs": [
      "self"
    ],
    "mtp_model_runner": [
      "self",
      "layer_id"
    ],
    "forward_batch_generation": [
      "self",
      "batch"
    ],
    "check_forward_draft_extend_after_decode": [
      "self",
      "batch"
    ],
    "forward_target_extend": [
      "self",
      "batch"
    ],
    "_draft_preprocess_decode": [
      "self",
      "batch"
    ],
    "_draft_preprocess_idle": [
      "self",
      "batch"
    ],
    "draft": [
      "self",
      "batch"
    ],
    "clear_cache_pool": [
      "self"
    ],
    "verify": [
      "self",
      "batch",
      "spec_info"
    ],
    "forward_draft_extend": [
      "self",
      "batch",
      "hidden_states",
      "next_token_ids",
      "seq_lens_cpu"
    ],
    "forward_draft_extend_after_decode": [
      "self",
      "batch"
    ]
  },
  "StandaloneDraftWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ],
    "init_lm_head": [
      "self"
    ]
  },
  "StandaloneWorkerV2": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "dp_rank",
      "moe_ep_rank",
      "nccl_port",
      "target_worker"
    ]
  },
  "ngram_cache_cpp": [],
  "NgramCache": {
    "__init__": [
      "self",
      "branch_length",
      "min_match_window_size",
      "max_match_window_size",
      "min_bfs_breadth",
      "max_bfs_breadth",
      "draft_token_num",
      "match_type",
      "capacity"
    ],
    "batch_put": [
      "self",
      "batch_tokens"
    ],
    "synchronize": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "batch_get": [
      "self",
      "batch_tokens"
    ],
    "leaf_paths_from_mask": [
      "self",
      "tokens",
      "tree_mask"
    ],
    "debug_result": [
      "self",
      "decoding_ids",
      "decoding_masks",
      "tokenizer"
    ]
  },
  "StreamingParseResult": {
    "__init__": [
      "self",
      "normal_text",
      "reasoning_text"
    ]
  },
  "BaseReasoningFormatDetector": {
    "__init__": [
      "self",
      "think_start_token",
      "think_end_token",
      "force_reasoning",
      "stream_reasoning"
    ],
    "detect_and_parse": [
      "self",
      "text"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text"
    ]
  },
  "DeepSeekR1Detector": {
    "__init__": [
      "self",
      "stream_reasoning",
      "force_reasoning"
    ]
  },
  "Qwen3Detector": {
    "__init__": [
      "self",
      "stream_reasoning",
      "force_reasoning"
    ]
  },
  "KimiDetector": {
    "__init__": [
      "self",
      "stream_reasoning",
      "force_reasoning"
    ]
  },
  "GptOssDetector": {
    "__init__": [
      "self",
      "stream_reasoning",
      "force_reasoning"
    ],
    "detect_and_parse": [
      "self",
      "text"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text"
    ]
  },
  "MiniMaxAppendThinkDetector": {
    "__init__": [
      "self",
      "stream_reasoning",
      "force_reasoning"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text"
    ],
    "detect_and_parse": [
      "self",
      "text"
    ]
  },
  "NanoV3Detector": {
    "__init__": [
      "self",
      "stream_reasoning",
      "force_reasoning"
    ]
  },
  "ReasoningParser": {
    "__init__": [
      "self",
      "model_type",
      "stream_reasoning",
      "force_reasoning"
    ],
    "parse_non_stream": [
      "self",
      "full_text"
    ],
    "parse_stream_chunk": [
      "self",
      "chunk_text"
    ]
  },
  "Event": {},
  "Token": {},
  "prefix_hold": [
    "text",
    "tokens"
  ],
  "iter_tokens": [
    "text",
    "start_pos"
  ],
  "CanonicalStrategy": {
    "__init__": [
      "self"
    ],
    "parse": [
      "self",
      "text"
    ],
    "_parse_partial_analysis": [
      "self",
      "text",
      "tokens",
      "start_pos"
    ],
    "_extract_channel_type": [
      "self",
      "header_text"
    ],
    "_parse_block": [
      "self",
      "text",
      "tokens",
      "start_pos"
    ],
    "_is_commentary_filler_between_blocks": [
      "self",
      "text",
      "tokens",
      "pos"
    ],
    "_is_standalone_structural_token": [
      "self",
      "content"
    ]
  },
  "TextStrategy": {
    "__init__": [
      "self"
    ],
    "set_buffer_context": [
      "self",
      "buffer"
    ],
    "parse": [
      "self",
      "text"
    ]
  },
  "HarmonyParser": {
    "__init__": [
      "self"
    ],
    "parse": [
      "self",
      "chunk"
    ]
  },
  "SeparatorStyle": {
    "ADD_COLON_SINGLE": [],
    "ADD_COLON_TWO": [],
    "ADD_COLON_SPACE_SINGLE": [],
    "NO_COLON_SINGLE": [],
    "NO_COLON_TWO": [],
    "ADD_NEW_LINE_SINGLE": [],
    "LLAMA2": [],
    "LLAMA3": [],
    "LLAMA4": [],
    "CHATGLM": [],
    "CHATML": [],
    "CHATINTERN": [],
    "DOLLY": [],
    "RWKV": [],
    "PHOENIX": [],
    "ROBIN": [],
    "FALCON_CHAT": [],
    "CHATGLM3": [],
    "DEEPSEEK_CHAT": [],
    "METAMATH": [],
    "DeepSeekVL2": [],
    "QWEN2_VL_EMBED": [],
    "QWEN2_AUDIO": [],
    "GEMMA3": [],
    "MPT": [],
    "PADDLE_OCR": []
  },
  "Conversation": {
    "get_prompt": [
      "self"
    ],
    "set_system_message": [
      "self",
      "system_message"
    ],
    "append_message": [
      "self",
      "role",
      "message"
    ],
    "append_image": [
      "self",
      "image",
      "detail"
    ],
    "append_video": [
      "self",
      "video"
    ],
    "append_audio": [
      "self",
      "audio"
    ],
    "update_last_message": [
      "self",
      "message"
    ],
    "to_gradio_chatbot": [
      "self"
    ],
    "to_openai_api_messages": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "dict": [
      "self"
    ]
  },
  "register_conv_template": [
    "template",
    "override"
  ],
  "register_conv_template_matching_function": [
    "func"
  ],
  "get_conv_template_by_model_path": [
    "model_path"
  ],
  "chat_template_exists": [
    "template_name"
  ],
  "generate_embedding_convs": [
    "texts",
    "images",
    "videos",
    "template_name"
  ],
  "_MODELS_REQUIRING_MODALITY_SUPPLEMENT": [],
  "_get_full_multimodal_text_prompt": [
    "modality_token",
    "modality_count",
    "text_prompt"
  ],
  "generate_chat_conv": [
    "request",
    "template_name"
  ],
  "MODEL_TYPE_TO_TEMPLATE": [],
  "match_points_v15_chat": [
    "model_path"
  ],
  "get_model_type": [
    "model_path"
  ],
  "match_internvl": [
    "model_path"
  ],
  "match_deepseek_janus_pro": [
    "model_path"
  ],
  "match_vicuna": [
    "model_path"
  ],
  "match_deepseek_vl": [
    "model_path"
  ],
  "match_qwen_chat_ml": [
    "model_path"
  ],
  "match_minicpm": [
    "model_path"
  ],
  "match_phi_4_mm": [
    "model_path"
  ],
  "match_deepseek_ocr": [
    "model_path"
  ],
  "match_paddle_ocr": [
    "model_path"
  ],
  "completion_template_name": [],
  "FimPosition": {
    "MIDDLE": [],
    "END": []
  },
  "CompletionTemplate": {},
  "register_completion_template": [
    "template",
    "override"
  ],
  "completion_template_exists": [
    "template_name"
  ],
  "is_completion_template_defined": [],
  "generate_completion_prompt_from_request": [
    "request"
  ],
  "generate_completion_prompt": [
    "prompt",
    "suffix",
    "template_name"
  ],
  "_is_var_access": [
    "node",
    "varname"
  ],
  "_is_attr_access": [
    "node",
    "varname",
    "key"
  ],
  "_is_var_or_elems_access": [
    "node",
    "varname",
    "key"
  ],
  "_try_extract_ast": [
    "chat_template"
  ],
  "detect_jinja_template_content_format": [
    "chat_template"
  ],
  "process_content_for_template_format": [
    "msg_dict",
    "content_format",
    "image_data",
    "video_data",
    "audio_data",
    "modalities"
  ],
  "set_default_torch_dtype": [
    "dtype"
  ],
  "resolve_transformers_arch": [
    "model_config",
    "architectures"
  ],
  "get_model_architecture": [
    "model_config"
  ],
  "get_architecture_class_name": [
    "model_config"
  ],
  "post_load_weights": [
    "model",
    "model_config"
  ],
  "should_deepgemm_weight_requant_ue8m0": [
    "weight_block_size"
  ],
  "should_async_load": [
    "weight"
  ],
  "maybe_executor_submit": [],
  "enable_hf_transfer": [],
  "temp_dir": [],
  "get_lock": [
    "model_name_or_path",
    "cache_dir",
    "suffix"
  ],
  "_shared_pointers": [
    "tensors"
  ],
  "convert_bin_to_safetensor_file": [
    "pt_filename",
    "sf_filename"
  ],
  "replace_prefix": [
    "key",
    "prefix_mapping"
  ],
  "replace_substrings": [
    "key",
    "substring_mapping"
  ],
  "DisabledTqdm": {
    "__init__": [
      "self"
    ]
  },
  "get_quant_config": [
    "model_config",
    "load_config",
    "packed_modules_mapping",
    "remap_prefix"
  ],
  "_check_index_files_exist": [
    "snapshot_dir"
  ],
  "_find_local_hf_snapshot_dir_unlocked": [
    "model_name_or_path",
    "cache_dir",
    "allow_patterns",
    "revision"
  ],
  "download_weights_from_hf": [
    "model_name_or_path",
    "cache_dir",
    "allow_patterns",
    "revision",
    "ignore_patterns",
    "max_retries"
  ],
  "download_safetensors_index_file_from_hf": [
    "model_name_or_path",
    "index_file",
    "cache_dir",
    "revision"
  ],
  "filter_duplicate_safetensors_files": [
    "hf_weights_files",
    "hf_folder",
    "index_file"
  ],
  "maybe_add_mtp_safetensors": [
    "hf_weights_files",
    "hf_folder",
    "index_file",
    "hf_config"
  ],
  "filter_files_not_needed_for_inference": [
    "hf_weights_files"
  ],
  "np_cache_weights_iterator": [
    "model_name_or_path",
    "cache_dir",
    "hf_folder",
    "hf_weights_files"
  ],
  "decrypt": [
    "fn",
    "key"
  ],
  "safetensors_encrypted_weights_iterator": [
    "hf_weights_files",
    "is_all_weights_sharded",
    "decryption_key"
  ],
  "safetensors_weights_iterator": [
    "hf_weights_files",
    "is_all_weights_sharded",
    "decryption_key",
    "disable_mmap"
  ],
  "fastsafetensors_weights_iterator": [
    "hf_weights_files"
  ],
  "multi_thread_safetensors_weights_iterator": [
    "hf_weights_files",
    "is_all_weights_sharded",
    "decryption_key",
    "max_workers",
    "disable_mmap"
  ],
  "_load_pt_file": [
    "bin_file"
  ],
  "pt_weights_iterator": [
    "hf_weights_files"
  ],
  "multi_thread_pt_weights_iterator": [
    "hf_weights_files",
    "max_workers"
  ],
  "get_gguf_extra_tensor_names": [
    "gguf_file",
    "gguf_to_hf_name_map"
  ],
  "gguf_quant_weights_iterator": [
    "gguf_file",
    "gguf_to_hf_name_map"
  ],
  "convert_pyslice_to_tensor": [
    "x"
  ],
  "default_weight_loader": [
    "param",
    "loaded_weight"
  ],
  "row_parallel_weight_loader": [
    "param",
    "loaded_weight"
  ],
  "LoaderFunction": [],
  "sharded_weight_loader": [
    "shard_axis"
  ],
  "composed_weight_loader": [
    "loader",
    "fn"
  ],
  "runai_safetensors_weights_iterator": [
    "hf_weights_files"
  ],
  "set_runai_streamer_env": [
    "load_config"
  ],
  "initialize_dummy_weights": [
    "model",
    "low",
    "high",
    "seed"
  ],
  "maybe_remap_kv_scale_name": [
    "name",
    "params_dict"
  ],
  "KVCacheQuantSchema": {
    "check_is_fp8": [
      "self"
    ],
    "check_tp_ranks": [
      "self",
      "info"
    ],
    "check_current_rank": [
      "self",
      "info"
    ]
  },
  "QuantParamSchema": {
    "model_config": [],
    "check_model_type": [
      "self",
      "info"
    ]
  },
  "kv_cache_scales_loader": [
    "filename",
    "tp_rank",
    "tp_size",
    "num_hidden_layers",
    "model_type"
  ],
  "get_actual_shard_size": [
    "shard_size",
    "weight_start",
    "weight_end"
  ],
  "reset_param_data_if_needed": [
    "param_data",
    "dim",
    "start",
    "length"
  ],
  "narrow_padded_param_and_loaded_weight": [
    "param_data",
    "loaded_weight",
    "param_data_start",
    "weight_start",
    "dim",
    "shard_size",
    "narrow_weight"
  ],
  "DEFAULT_GPU_MEMORY_FRACTION_FOR_CALIBRATION": [],
  "device_loading_context": [
    "module",
    "target_device"
  ],
  "_get_quantization_config": [
    "model_config",
    "load_config",
    "packed_modules_mapping",
    "remap_prefix"
  ],
  "_initialize_model": [
    "model_config",
    "load_config"
  ],
  "BaseModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ]
  },
  "DefaultModelLoader": {
    "DEFAULT_NUM_THREADS": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_maybe_download_from_modelscope": [
      "self",
      "model",
      "revision"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision",
      "fall_back_to_pt"
    ],
    "_get_weights_iterator": [
      "self",
      "source"
    ],
    "_get_all_weights": [
      "self",
      "model_config",
      "model"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "_load_modelopt_base_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ],
    "load_weights_and_postprocess": [
      "model",
      "weights",
      "target_device"
    ]
  },
  "LayeredModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "load_model": [
      "self"
    ]
  },
  "QuantizedRLModelLoader": {
    "RECORDED_LOADER_KEYS": [],
    "SKIP_QUANTIZATION_PARAMS": [],
    "STACKED_PARAMS_MAPPING": [],
    "_QKV_SHARD_ALIASES": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision",
      "fall_back_to_pt"
    ],
    "_bind_method_to_cls": [
      "func",
      "obj"
    ],
    "load_weights_and_postprocess": [
      "self",
      "model",
      "weights",
      "target_device"
    ],
    "is_reload_scenario": [
      "model"
    ],
    "_is_stacked_param": [
      "name"
    ],
    "_resolve_stacked_info": [
      "name"
    ],
    "_store_quantized_scale": [
      "scale_store",
      "name",
      "scale"
    ],
    "_apply_scale_update": [
      "all_params",
      "param_name",
      "scale_info"
    ],
    "rebinding_and_load_weights": [
      "model",
      "first_time_load_weights",
      "weights"
    ],
    "_get_updated_params": [
      "weights_list",
      "model"
    ]
  },
  "DummyModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ]
  },
  "ShardedStateLoader": {
    "DEFAULT_PATTERN": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_filter_subtensors": [
      "tensors"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ],
    "save_model": [
      "model",
      "path",
      "pattern",
      "max_size"
    ]
  },
  "BitsAndBytesModelLoader": {
    "possible_config_file_names": [],
    "default_target_modules": [],
    "__init__": [
      "self",
      "load_config"
    ],
    "_get_config_file": [
      "self",
      "qlora_adapter"
    ],
    "_get_weight_files": [
      "self",
      "model_name_or_path",
      "allowed_patterns",
      "revision"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "revision"
    ],
    "_hf_weight_iter": [
      "self",
      "hf_weights_files",
      "use_safetensors"
    ],
    "_get_quantized_weights_iterator": [
      "self",
      "model_name_or_path",
      "revision",
      "pre_quant",
      "load_8bit"
    ],
    "_is_8bit_weight_name": [
      "self",
      "weight_name"
    ],
    "_is_4bit_weight_name": [
      "self",
      "weight_name"
    ],
    "_quantized_8bit_generator": [
      "self",
      "hf_weights_files",
      "use_safetensors",
      "quant_state_dict"
    ],
    "_quantized_4bit_generator": [
      "self",
      "hf_weights_files",
      "use_safetensors",
      "quant_state_dict"
    ],
    "_unquantized_generator": [
      "self",
      "hf_weights_files",
      "use_safetensors",
      "quant_state_dict"
    ],
    "_load_weights": [
      "self",
      "model_config",
      "model"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ]
  },
  "GGUFModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path"
    ],
    "_get_gguf_weights_map": [
      "self",
      "model_config"
    ],
    "_get_weights_iterator": [
      "self",
      "model_name_or_path",
      "gguf_to_hf_name_map"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ]
  },
  "RemoteInstanceModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "load_model": [
      "self"
    ],
    "load_model_from_remote_instance_by_nccl": [
      "self",
      "model",
      "client",
      "model_config",
      "device_config"
    ],
    "load_model_from_remote_instance_by_transfer_engine": [
      "self",
      "model",
      "transfer_engine",
      "seed_url",
      "tp_rank"
    ]
  },
  "RemoteModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "_get_weights_iterator_kv": [
      "self",
      "client"
    ],
    "_get_weights_iterator_fs": [
      "self",
      "client"
    ],
    "download_model": [
      "self",
      "model_config"
    ],
    "save_model": [
      "model",
      "model_path",
      "url"
    ],
    "_load_model_from_remote_kv": [
      "self",
      "model",
      "model_config",
      "client"
    ],
    "_load_model_from_remote_fs": [
      "self",
      "model",
      "client",
      "model_config",
      "device_config"
    ],
    "load_model": [
      "self"
    ]
  },
  "load_model_with_cpu_quantization": [
    "self"
  ],
  "ModelOptModelLoader": {
    "__init__": [
      "self",
      "load_config"
    ],
    "_setup_modelopt_quantization": [
      "self",
      "model",
      "tokenizer",
      "quant_cfg",
      "quantized_ckpt_restore_path",
      "quantized_ckpt_save_path",
      "export_path"
    ],
    "_maybe_export_modelopt": [
      "self",
      "model",
      "export_path"
    ],
    "_export_modelopt_checkpoint": [
      "self",
      "model",
      "export_path",
      "model_path",
      "trust_remote_code"
    ],
    "load_model": [
      "self"
    ],
    "_standard_quantization_workflow": [
      "self",
      "model_config",
      "device_config"
    ]
  },
  "get_model_loader": [
    "load_config",
    "model_config"
  ],
  "VALIDATION_MARKER_VERSION": [],
  "_remote_file_exists": [
    "repo_id",
    "filename",
    "revision",
    "allow_remote_check"
  ],
  "_get_validation_marker_path": [
    "snapshot_dir"
  ],
  "_get_per_run_marker_dir": [],
  "_get_per_run_marker_path": [
    "snapshot_dir"
  ],
  "_read_per_run_marker": [
    "snapshot_dir"
  ],
  "_write_per_run_marker": [
    "snapshot_dir",
    "model_id",
    "required_files"
  ],
  "_remove_per_run_marker": [
    "snapshot_dir"
  ],
  "_read_validation_marker": [
    "snapshot_dir"
  ],
  "_write_validation_marker": [
    "snapshot_dir",
    "passed"
  ],
  "_validate_json_file": [
    "file_path",
    "file_name"
  ],
  "_validate_config_and_tokenizer_files": [
    "snapshot_dir",
    "model_id",
    "revision",
    "allow_remote_check"
  ],
  "ci_validate_cache_and_enable_offline_if_complete": [
    "snapshot_dir",
    "weight_files",
    "model_name_or_path"
  ],
  "_infer_component_type": [
    "component_name",
    "component_info"
  ],
  "_check_component_config": [
    "component_dir",
    "component_type"
  ],
  "_check_component_weights": [
    "component_dir"
  ],
  "_format_component_list": [
    "components",
    "max_show"
  ],
  "_validate_diffusion_model": [
    "snapshot_dir"
  ],
  "validate_cache_with_detailed_reason": [
    "snapshot_dir",
    "weight_files",
    "model_name_or_path"
  ],
  "validate_cache_lightweight": [
    "snapshot_dir",
    "requires_hf_quant_config"
  ],
  "_validate_safetensors_file": [
    "file_path"
  ],
  "_validate_sharded_model": [
    "snapshot_dir",
    "weight_files"
  ],
  "_cleanup_corrupted_files_selective": [
    "model_name_or_path",
    "corrupted_files"
  ],
  "_cleanup_corrupted_model_cache": [
    "model_name_or_path",
    "snapshot_dir",
    "reason"
  ],
  "ci_validate_and_cleanup_local_snapshot": [
    "model_name_or_path",
    "found_local_snapshot_dir",
    "local_weight_files"
  ],
  "_validate_weights_after_download": [
    "hf_folder",
    "allow_patterns",
    "model_name_or_path"
  ],
  "ci_download_with_validation_and_retry": [
    "model_name_or_path",
    "allow_patterns",
    "ignore_patterns",
    "cache_dir",
    "revision",
    "max_retries"
  ],
  "ci_validate_and_clean_hf_cache": [
    "model_path"
  ],
  "RemoteInstanceWeightLoaderBackend": {
    "NCCL": [],
    "TRANSFER_ENGINE": []
  },
  "trigger_init_weights_send_group_for_remote_instance_request": [
    "remote_instance_weight_loader_seed_instance_ip",
    "remote_instance_weight_loader_seed_instance_service_port",
    "remote_instance_weight_loader_send_weights_group_ports",
    "remote_instance_weight_loader_client_id"
  ],
  "trigger_transferring_weights_request": [
    "remote_instance_weight_loader_seed_instance_ip",
    "remote_instance_weight_loader_seed_instance_service_port",
    "remote_instance_weight_loader_send_weights_group_ports",
    "remote_instance_weight_loader_client_id"
  ],
  "get_remote_instance_transfer_engine_info_per_rank": [
    "seed_url",
    "rank"
  ],
  "parse_remote_instance_transfer_engine_info_from_scheduler_infos": [
    "scheduler_infos"
  ],
  "register_memory_region": [
    "model",
    "transfer_engine"
  ],
  "register_memory_region_v1": [
    "model",
    "transfer_engine"
  ],
  "register_memory_region_v2": [
    "model",
    "transfer_engine"
  ],
  "Tool": {
    "get_result": [
      "self",
      "context"
    ]
  },
  "HarmonyBrowserTool": {
    "__init__": [
      "self"
    ],
    "get_result": [
      "self",
      "context"
    ],
    "tool_config": [
      "self"
    ]
  },
  "HarmonyPythonTool": {
    "__init__": [
      "self"
    ],
    "get_result": [
      "self",
      "context"
    ],
    "tool_config": [
      "self"
    ]
  },
  "HEALTH_CHECK_TIMEOUT": [],
  "WAIT_WEIGHTS_READY_TIMEOUT": [],
  "_GlobalState": {},
  "set_global_state": [
    "global_state"
  ],
  "get_global_state": [],
  "init_multi_tokenizer": [],
  "lifespan": [
    "fast_api_app"
  ],
  "app": [],
  "validation_exception_handler": [
    "request",
    "exc"
  ],
  "validate_json_request": [
    "raw_request"
  ],
  "health_generate": [
    "request"
  ],
  "get_model_info": [],
  "model_info": [],
  "weight_version": [],
  "get_server_info": [],
  "server_info": [],
  "get_load": [],
  "set_internal_state": [
    "obj",
    "request"
  ],
  "generate_request": [
    "obj",
    "request"
  ],
  "encode_request": [
    "obj",
    "request"
  ],
  "classify_request": [
    "obj",
    "request"
  ],
  "flush_cache": [],
  "clear_hicache_storage_backend": [],
  "start_profile_async": [
    "obj"
  ],
  "stop_profile_async": [],
  "freeze_gc_async": [],
  "start_expert_distribution_record_async": [],
  "stop_expert_distribution_record_async": [],
  "dump_expert_distribution_record_async": [],
  "update_weights_from_disk": [
    "obj",
    "request"
  ],
  "init_weights_send_group_for_remote_instance": [
    "obj",
    "request"
  ],
  "send_weights_to_remote_instance": [
    "obj",
    "request"
  ],
  "get_remote_instance_transfer_engine_info": [
    "rank"
  ],
  "init_weights_update_group": [
    "obj",
    "request"
  ],
  "destroy_weights_update_group": [
    "obj",
    "request"
  ],
  "update_weights_from_tensor": [
    "obj",
    "request"
  ],
  "update_weights_from_distributed": [
    "obj",
    "request"
  ],
  "update_weights_from_ipc": [
    "obj",
    "request"
  ],
  "update_weight_version": [
    "obj",
    "request"
  ],
  "get_weights_by_name": [
    "obj",
    "request"
  ],
  "release_memory_occupation": [
    "obj",
    "request"
  ],
  "resume_memory_occupation": [
    "obj",
    "request"
  ],
  "check_weights": [
    "obj",
    "request"
  ],
  "slow_down": [
    "obj",
    "request"
  ],
  "load_lora_adapter": [
    "obj",
    "request"
  ],
  "load_lora_adapter_from_tensors": [
    "obj",
    "request"
  ],
  "unload_lora_adapter": [
    "obj",
    "request"
  ],
  "open_session": [
    "obj",
    "request"
  ],
  "close_session": [
    "obj",
    "request"
  ],
  "configure_logging": [
    "obj",
    "request"
  ],
  "abort_request": [
    "obj",
    "request"
  ],
  "parse_function_call_request": [
    "obj",
    "request"
  ],
  "separate_reasoning_request": [
    "obj",
    "request"
  ],
  "pause_generation": [
    "obj",
    "request"
  ],
  "continue_generation": [
    "obj",
    "request"
  ],
  "openai_v1_completions": [
    "request",
    "raw_request"
  ],
  "openai_v1_chat_completions": [
    "request",
    "raw_request"
  ],
  "openai_v1_embeddings": [
    "request",
    "raw_request"
  ],
  "openai_v1_classify": [
    "request",
    "raw_request"
  ],
  "openai_v1_tokenize": [
    "request",
    "raw_request"
  ],
  "openai_v1_detokenize": [
    "request",
    "raw_request"
  ],
  "available_models": [],
  "retrieve_model": [
    "model"
  ],
  "v1_score_request": [
    "request",
    "raw_request"
  ],
  "v1_responses_request": [
    "request",
    "raw_request"
  ],
  "v1_retrieve_responses": [
    "response_id",
    "raw_request"
  ],
  "v1_cancel_responses": [
    "response_id",
    "raw_request"
  ],
  "v1_rerank_request": [
    "request",
    "raw_request"
  ],
  "ollama_root": [],
  "ollama_chat": [
    "request",
    "raw_request"
  ],
  "ollama_generate": [
    "request",
    "raw_request"
  ],
  "ollama_tags": [
    "raw_request"
  ],
  "ollama_show": [
    "request",
    "raw_request"
  ],
  "sagemaker_health": [],
  "sagemaker_chat_completions": [
    "request",
    "raw_request"
  ],
  "vertex_generate": [
    "vertex_req",
    "raw_request"
  ],
  "_create_error_response": [
    "e"
  ],
  "MINIMUM_PNG_PICTURE_BASE64": [],
  "_execute_server_warmup": [
    "server_args"
  ],
  "_wait_and_warmup": [
    "server_args",
    "launch_callback",
    "execute_warmup_func"
  ],
  "_wait_weights_ready": [],
  "launch_server": [
    "server_args",
    "init_tokenizer_manager_func",
    "run_scheduler_process_func",
    "run_detokenizer_process_func",
    "execute_warmup_func",
    "launch_callback"
  ],
  "EngineBase": {
    "generate": [
      "self",
      "prompt",
      "sampling_params",
      "input_ids",
      "image_data",
      "return_logprob",
      "logprob_start_len",
      "top_logprobs_num",
      "token_ids_logprob",
      "lora_path",
      "custom_logit_processor",
      "return_hidden_states",
      "stream",
      "bootstrap_host",
      "bootstrap_port",
      "bootstrap_room",
      "data_parallel_rank",
      "rid"
    ],
    "flush_cache": [
      "self"
    ],
    "update_weights_from_tensor": [
      "self",
      "named_tensors",
      "load_format",
      "flush_cache"
    ],
    "load_lora_adapter": [
      "self",
      "lora_name",
      "lora_path"
    ],
    "unload_lora_adapter": [
      "self",
      "lora_name"
    ],
    "release_memory_occupation": [
      "self"
    ],
    "resume_memory_occupation": [
      "self"
    ],
    "shutdown": [
      "self"
    ]
  },
  "_warmup_registry": [],
  "warmup": [
    "name"
  ],
  "execute_warmups": [
    "disaggregation_mode",
    "warmup_names",
    "tokenizer_manager"
  ],
  "voice_chat": [
    "disaggregation_mode",
    "tokenizer_manager"
  ],
  "REASONING_EFFORT": [],
  "_harmony_encoding": [],
  "get_encoding": [],
  "get_system_message": [
    "model_identity",
    "reasoning_effort",
    "start_date",
    "browser_description",
    "python_description"
  ],
  "get_developer_message": [
    "instructions",
    "tools"
  ],
  "get_user_message": [
    "content"
  ],
  "parse_response_input": [
    "response_msg",
    "prev_responses"
  ],
  "parse_response_output": [
    "output"
  ],
  "parse_chat_input": [
    "chat_msg"
  ],
  "render_for_completion": [
    "messages"
  ],
  "get_stop_tokens_for_assistant_actions": [],
  "get_streamable_parser_for_assistant": [],
  "parse_output_message": [
    "message"
  ],
  "parse_remaining_state": [
    "parser"
  ],
  "parse_output_into_messages": [
    "token_ids"
  ],
  "init_tokenizer_manager": [
    "server_args",
    "port_args",
    "TokenizerManagerClass"
  ],
  "_set_envs_and_config": [
    "server_args"
  ],
  "_wait_for_scheduler_ready": [
    "scheduler_pipe_readers",
    "scheduler_procs"
  ],
  "_launch_scheduler_processes": [
    "server_args",
    "port_args",
    "run_scheduler_process_func"
  ],
  "_launch_subprocesses": [
    "server_args",
    "init_tokenizer_manager_func",
    "run_scheduler_process_func",
    "run_detokenizer_process_func",
    "port_args"
  ],
  "launch_server_process": [
    "server_args"
  ],
  "HttpServerEngineAdapter": {
    "__init__": [
      "self"
    ],
    "_make_request": [
      "self",
      "endpoint",
      "payload"
    ],
    "update_weights_from_tensor": [
      "self",
      "named_tensors",
      "load_format",
      "flush_cache"
    ],
    "shutdown": [
      "self"
    ],
    "generate": [
      "self",
      "prompt",
      "sampling_params",
      "input_ids",
      "image_data",
      "return_logprob",
      "logprob_start_len",
      "top_logprobs_num",
      "token_ids_logprob",
      "lora_path",
      "custom_logit_processor"
    ],
    "release_memory_occupation": [
      "self"
    ],
    "resume_memory_occupation": [
      "self"
    ],
    "flush_cache": [
      "self"
    ]
  },
  "ConversationContext": {
    "append_output": [
      "self",
      "output"
    ],
    "call_tool": [
      "self"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ]
  },
  "SimpleContext": {
    "__init__": [
      "self"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "call_tool": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ]
  },
  "HarmonyContext": {
    "__init__": [
      "self",
      "messages",
      "tool_sessions"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "messages": [
      "self"
    ],
    "need_builtin_tool_call": [
      "self"
    ],
    "call_tool": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ],
    "call_search_tool": [
      "self",
      "tool_session",
      "last_msg"
    ],
    "call_python_tool": [
      "self",
      "tool_session",
      "last_msg"
    ]
  },
  "StreamingHarmonyContext": {
    "__init__": [
      "self"
    ],
    "messages": [
      "self"
    ],
    "append_output": [
      "self",
      "output"
    ],
    "is_expecting_start": [
      "self"
    ],
    "is_assistant_action_turn": [
      "self"
    ],
    "render_for_completion": [
      "self"
    ]
  },
  "_convert_loads_to_protobuf": [
    "result"
  ],
  "_compute_aggregate_protobuf": [
    "loads"
  ],
  "SGLangSchedulerServicer": {
    "__init__": [
      "self",
      "request_manager",
      "server_args",
      "model_info",
      "scheduler_info",
      "health_servicer"
    ],
    "Generate": [
      "self",
      "request",
      "context"
    ],
    "Embed": [
      "self",
      "request",
      "_context"
    ],
    "HealthCheck": [
      "self",
      "request",
      "context"
    ],
    "Abort": [
      "self",
      "request",
      "_context"
    ],
    "GetModelInfo": [
      "self",
      "_request",
      "_context"
    ],
    "GetServerInfo": [
      "self",
      "_request",
      "_context"
    ],
    "GetLoads": [
      "self",
      "request",
      "context"
    ],
    "_convert_generate_request": [
      "self",
      "grpc_req"
    ],
    "_convert_embed_request": [
      "self",
      "grpc_req"
    ],
    "_convert_sampling_params": [
      "self",
      "grpc_params"
    ],
    "_convert_output_logprobs_to_proto": [
      "self",
      "logprobs_data"
    ],
    "_convert_input_logprobs_to_proto": [
      "self",
      "logprobs_data"
    ],
    "_create_chunk_response": [
      "self",
      "request_id",
      "output"
    ],
    "_create_completion_response": [
      "self",
      "request_id",
      "output"
    ],
    "shutdown": [
      "self"
    ]
  },
  "serve_grpc": [
    "server_args",
    "model_info"
  ],
  "_execute_grpc_server_warmup": [
    "server_args"
  ],
  "_wait_and_warmup_grpc": [
    "server_args",
    "health_servicer"
  ],
  "router": [],
  "_OPTIONAL_METRIC_SECTIONS": [],
  "_get_tokenizer_manager": [],
  "_loads_dict_factory": [
    "items"
  ],
  "_compute_aggregate": [
    "load_dicts"
  ],
  "_format_loads_prometheus": [
    "load_results"
  ],
  "get_loads": [
    "dp_rank",
    "include",
    "format",
    "tokenizer_manager"
  ],
  "OpenAIServingClassify": {
    "__init__": [
      "self",
      "tokenizer_manager",
      "template_manager"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_validate_request": [
      "self",
      "request"
    ],
    "_get_id2label_mapping": [
      "self"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_build_classify_response": [
      "self",
      "ret"
    ]
  },
  "list_server_and_tools": [
    "server_url"
  ],
  "trim_schema": [
    "schema"
  ],
  "post_process_tools_description": [
    "list_tools_result"
  ],
  "ToolServer": {
    "has_tool": [
      "self",
      "tool_name"
    ],
    "get_tool_description": [
      "self",
      "tool_name"
    ],
    "get_tool_session": [
      "self",
      "tool_name"
    ]
  },
  "MCPToolServer": {
    "__init__": [
      "self"
    ],
    "add_tool_server": [
      "self",
      "server_url"
    ],
    "has_tool": [
      "self",
      "tool_name"
    ],
    "get_tool_description": [
      "self",
      "tool_name"
    ],
    "get_tool_session": [
      "self",
      "tool_name"
    ]
  },
  "DemoToolServer": {
    "__init__": [
      "self"
    ],
    "has_tool": [
      "self",
      "tool_name"
    ],
    "get_tool_description": [
      "self",
      "tool_name"
    ],
    "get_tool_session": [
      "self",
      "tool_name"
    ]
  },
  "OpenAIServingCompletion": {
    "__init__": [
      "self",
      "tokenizer_manager",
      "template_manager"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "_validate_request": [
      "self",
      "request"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_build_sampling_params": [
      "self",
      "request"
    ],
    "_handle_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_generate_completion_stream": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_build_completion_response": [
      "self",
      "request",
      "ret",
      "created"
    ],
    "_get_echo_text": [
      "self",
      "request",
      "index"
    ],
    "_prepare_echo_prompts": [
      "self",
      "request"
    ]
  },
  "_extract_max_dynamic_patch": [
    "request"
  ],
  "OpenAIServingChat": {
    "__init__": [
      "self",
      "tokenizer_manager",
      "template_manager"
    ],
    "_handle_last_assistant_message": [
      "self",
      "messages",
      "request"
    ],
    "_append_assistant_prefix_to_prompt_ids": [
      "self",
      "prompt_ids",
      "assistant_prefix"
    ],
    "_use_dpsk_v32_encoding": [
      "self"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "_validate_request": [
      "self",
      "request"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_process_messages": [
      "self",
      "request",
      "is_multimodal"
    ],
    "_apply_jinja_template": [
      "self",
      "request",
      "tools",
      "is_multimodal"
    ],
    "_apply_conversation_template": [
      "self",
      "request",
      "is_multimodal"
    ],
    "_handle_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_generate_chat_stream": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_build_chat_response": [
      "self",
      "request",
      "ret",
      "created"
    ],
    "_process_logprobs_tokens": [
      "self",
      "logprobs",
      "use_token_index"
    ],
    "_process_response_logprobs": [
      "self",
      "ret_item"
    ],
    "_process_tool_call_id": [
      "self",
      "call_item",
      "history_tool_calls_cnt"
    ],
    "_process_tool_calls": [
      "self",
      "text",
      "tools",
      "finish_reason",
      "tool_choice",
      "history_tool_calls_cnt"
    ],
    "_process_streaming_logprobs": [
      "self",
      "content",
      "n_prev_token"
    ],
    "_process_reasoning_stream": [
      "self",
      "index",
      "delta",
      "reasoning_parser_dict",
      "content",
      "request"
    ],
    "_get_history_tool_calls_cnt": [
      "self",
      "request"
    ],
    "_get_reasoning_from_request": [
      "self",
      "request"
    ],
    "_process_tool_call_stream": [
      "self",
      "index",
      "delta",
      "parser_dict",
      "content",
      "request",
      "has_tool_calls"
    ],
    "_check_for_unstreamed_tool_args": [
      "self",
      "parser",
      "content",
      "request",
      "index"
    ]
  },
  "_get_yes_no_token_ids": [
    "tokenizer"
  ],
  "_is_qwen3_reranker_template": [
    "chat_template"
  ],
  "_is_qwen3_vl_reranker_template": [
    "chat_template"
  ],
  "_is_qwen3_vl_model": [
    "model_path"
  ],
  "_detect_rerank_backend": [],
  "_qwen3_rerank_score": [
    "p_yes",
    "p_no"
  ],
  "_get_jinja_env": [],
  "_render_jinja_chat_template": [
    "chat_template"
  ],
  "_render_vl_jinja_template": [
    "chat_template"
  ],
  "_extract_text_from_content": [
    "content"
  ],
  "OpenAIServingRerank": {
    "__init__": [
      "self",
      "tokenizer_manager",
      "template_manager"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "_validate_request": [
      "self",
      "request"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_handle_rerank_paths": [
      "self"
    ],
    "_handle_text_reranker_request": [
      "self"
    ],
    "_handle_vl_reranker_request": [
      "self",
      "request",
      "raw_request",
      "_chat_template"
    ],
    "_build_vl_reranker_content": [
      "self",
      "query",
      "document"
    ],
    "_content_to_template_list": [
      "self",
      "content",
      "image_data",
      "video_data"
    ],
    "_extract_score_from_logprobs": [
      "self",
      "ret"
    ],
    "_build_rerank_response": [
      "self",
      "ret",
      "request"
    ]
  },
  "OpenAIServingScore": {
    "_request_id_prefix": [
      "self"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ]
  },
  "OpenAIServingResponses": {
    "__init__": [
      "self",
      "tokenizer_manager",
      "template_manager"
    ],
    "create_error_response": [
      "self",
      "message",
      "err_type",
      "status_code",
      "param"
    ],
    "create_streaming_error_response": [
      "self",
      "message",
      "err_type",
      "status_code"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "create_responses": [
      "self",
      "request",
      "raw_request"
    ],
    "_make_request": [
      "self",
      "request",
      "prev_response",
      "tokenizer"
    ],
    "_make_request_with_harmony": [
      "self",
      "request",
      "prev_response"
    ],
    "responses_full_generator": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time"
    ],
    "_make_response_output_items": [
      "self",
      "request",
      "final_output",
      "tokenizer"
    ],
    "_make_response_output_items_with_harmony": [
      "self",
      "context"
    ],
    "_construct_input_messages": [
      "self",
      "request",
      "prev_response"
    ],
    "_construct_input_messages_with_harmony": [
      "self",
      "request",
      "prev_response"
    ],
    "_run_background_request": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time"
    ],
    "retrieve_responses": [
      "self",
      "response_id"
    ],
    "cancel_responses": [
      "self",
      "response_id"
    ],
    "_make_invalid_id_error": [
      "self",
      "response_id"
    ],
    "_make_not_found_error": [
      "self",
      "response_id"
    ],
    "responses_stream_generator": [
      "self",
      "request",
      "sampling_params",
      "result_generator",
      "context",
      "model_name",
      "tokenizer",
      "request_metadata",
      "created_time"
    ],
    "_generate_with_builtin_tools": [
      "self",
      "request_id",
      "request_prompt",
      "adapted_request",
      "sampling_params",
      "context",
      "raw_request",
      "priority"
    ]
  },
  "to_openai_style_logprobs": [
    "input_token_logprobs",
    "output_token_logprobs",
    "input_top_logprobs",
    "output_top_logprobs"
  ],
  "process_hidden_states_from_ret": [
    "ret_item",
    "request"
  ],
  "DEFAULT_MODEL_NAME": [],
  "ModelCard": {},
  "ModelList": {},
  "ErrorResponse": {},
  "LogProbs": {},
  "TopLogprob": {},
  "ChatCompletionTokenLogprob": {},
  "ChoiceLogprobs": {},
  "UsageInfo": {},
  "StreamOptions": {},
  "JsonSchemaResponseFormat": {},
  "ResponseFormat": {},
  "StructuresResponseFormat": {},
  "LegacyStructuralTagResponseFormat": {},
  "FileRequest": {},
  "FileResponse": {},
  "FileDeleteResponse": {},
  "BatchRequest": {},
  "BatchResponse": {},
  "CompletionRequest": {
    "validate_max_tokens_positive": [
      "cls",
      "v"
    ]
  },
  "CompletionResponseChoice": {
    "_serialize": [
      "self",
      "handler"
    ]
  },
  "CompletionResponse": {},
  "CompletionResponseStreamChoice": {
    "_serialize": [
      "self",
      "handler"
    ]
  },
  "CompletionStreamResponse": {},
  "ChatCompletionMessageContentTextPart": {},
  "ChatCompletionMessageContentImageURL": {},
  "ChatCompletionMessageContentVideoURL": {},
  "ChatCompletionMessageContentAudioURL": {},
  "ChatCompletionMessageContentImagePart": {},
  "ChatCompletionMessageContentVideoPart": {},
  "ChatCompletionMessageContentAudioPart": {},
  "ChatCompletionMessageContentPart": [],
  "RerankContentPart": [],
  "RerankContent": [],
  "FunctionResponse": {},
  "ToolCall": {},
  "ChatCompletionMessageGenericParam": {
    "_normalize_role": [
      "cls",
      "v"
    ]
  },
  "ChatCompletionMessageUserParam": {},
  "ChatCompletionMessageParam": [],
  "Function": {},
  "ToolChoiceFuncName": {},
  "ToolChoice": {},
  "ChatCompletionRequest": {
    "_DEFAULT_SAMPLING_PARAMS": [],
    "set_tool_choice_default": [
      "cls",
      "values"
    ],
    "normalize_reasoning_inputs": [
      "cls",
      "values"
    ],
    "set_json_schema": [
      "cls",
      "values"
    ],
    "to_sampling_params": [
      "self",
      "stop",
      "model_generation_config",
      "tool_call_constraint"
    ]
  },
  "ChatMessage": {},
  "ChatCompletionResponseChoice": {
    "_serialize": [
      "self",
      "handler"
    ]
  },
  "ChatCompletionResponse": {},
  "DeltaMessage": {
    "_serialize": [
      "self",
      "handler"
    ]
  },
  "ChatCompletionResponseStreamChoice": {},
  "ChatCompletionStreamResponse": {},
  "MultimodalEmbeddingInput": {},
  "EmbeddingInput": [],
  "EmbeddingRequest": {},
  "EmbeddingObject": {},
  "ClassifyInput": [],
  "ClassifyRequest": {},
  "ClassifyData": {},
  "ClassifyResponse": {},
  "EmbeddingResponse": {},
  "ScoringRequest": {},
  "ScoringResponse": {},
  "V1RerankReqInput": {
    "validate_top_n": [
      "cls",
      "v"
    ],
    "is_multimodal": [
      "self"
    ]
  },
  "RerankResponse": {
    "_serialize": [
      "self",
      "handler"
    ]
  },
  "TokenizeRequest": {},
  "TokenizeResponse": {},
  "DetokenizeRequest": {},
  "DetokenizeResponse": {},
  "OpenAIServingRequest": [],
  "ResponseReasoningParam": {},
  "ResponseTool": {},
  "ResponsesRequest": {
    "_DEFAULT_SAMPLING_PARAMS": [],
    "to_sampling_params": [
      "self",
      "default_max_tokens",
      "default_params"
    ]
  },
  "PromptTokenUsageInfo": {},
  "ResponsesResponse": {
    "from_request": [
      "cls",
      "request",
      "sampling_params",
      "model_name",
      "created_time",
      "output",
      "status",
      "usage"
    ]
  },
  "RequestResponseMetadata": {},
  "MessageProcessingResult": {},
  "ToolCallProcessingResult": {},
  "ResponseReasoningTextContent": {},
  "OpenAIServingEmbedding": {
    "__init__": [
      "self",
      "tokenizer_manager",
      "template_manager"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "_validate_request": [
      "self",
      "request"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_build_embedding_response": [
      "self",
      "ret"
    ]
  },
  "OpenAIServingBase": {
    "__init__": [
      "self",
      "tokenizer_manager"
    ],
    "_parse_model_parameter": [
      "self",
      "model"
    ],
    "_resolve_lora_path": [
      "self",
      "request_model",
      "explicit_lora_path"
    ],
    "_validate_lora_enabled": [
      "self",
      "adapter_name"
    ],
    "handle_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_request_id_prefix": [
      "self"
    ],
    "_generate_request_id_base": [
      "self",
      "request"
    ],
    "_compute_extra_key": [
      "self",
      "request"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request",
      "validation_time"
    ],
    "_handle_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ],
    "_validate_request": [
      "self",
      "_"
    ],
    "create_error_response": [
      "self",
      "message",
      "err_type",
      "status_code",
      "param"
    ],
    "create_streaming_error_response": [
      "self",
      "message",
      "err_type",
      "status_code"
    ],
    "extract_custom_labels": [
      "self",
      "raw_request"
    ],
    "extract_routing_key": [
      "self",
      "raw_request"
    ]
  },
  "OpenAIServingTokenize": {
    "_request_id_prefix": [
      "self"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ]
  },
  "OpenAIServingDetokenize": {
    "_request_id_prefix": [
      "self"
    ],
    "_convert_to_internal_request": [
      "self",
      "request",
      "raw_request"
    ],
    "_handle_non_streaming_request": [
      "self",
      "adapted_request",
      "request",
      "raw_request"
    ]
  },
  "UsageProcessor": {
    "_details_if_cached": [
      "count"
    ],
    "calculate_response_usage": [
      "responses",
      "n_choices",
      "enable_cache_report"
    ],
    "calculate_streaming_usage": [
      "prompt_tokens",
      "completion_tokens",
      "cached_tokens",
      "n_choices",
      "enable_cache_report"
    ],
    "calculate_token_usage": [
      "prompt_tokens",
      "completion_tokens",
      "cached_tokens"
    ]
  },
  "DS32EncodingError": {},
  "TOOLS_SYSTEM_TEMPLATE": [],
  "thinking_template": [],
  "tool_calls_template": [],
  "to_json": [
    "value"
  ],
  "tools_from_openai_format": [
    "tools"
  ],
  "tool_calls_from_openai_format": [
    "tool_calls"
  ],
  "tool_calls_to_openai_format": [
    "tool_calls"
  ],
  "encode_arguments_to_dsml": [
    "tool_call"
  ],
  "decode_dsml_to_arguments": [
    "tool_name",
    "tool_args"
  ],
  "render_tools": [
    "tools"
  ],
  "find_last_user_index": [
    "messages"
  ],
  "render_message": [
    "index",
    "messages",
    "thinking_mode"
  ],
  "drop_thinking_messages": [
    "messages",
    "last_user_idx"
  ],
  "encode_messages": [
    "messages",
    "thinking_mode",
    "context",
    "drop_thinking",
    "add_default_bos_token"
  ],
  "_read_until_stop": [
    "index",
    "text",
    "stop"
  ],
  "parse_tool_calls": [
    "index",
    "text"
  ],
  "parse_message_from_completion_text": [
    "text",
    "thinking_mode"
  ],
  "OllamaServing": {
    "__init__": [
      "self",
      "tokenizer_manager"
    ],
    "_get_timestamp": [
      "self"
    ],
    "_convert_options_to_sampling_params": [
      "self",
      "options"
    ],
    "handle_chat": [
      "self",
      "request",
      "raw_request"
    ],
    "_generate_chat_response": [
      "self",
      "gen_request",
      "raw_request",
      "model_name"
    ],
    "_stream_chat_response": [
      "self",
      "gen_request",
      "raw_request",
      "model_name"
    ],
    "handle_generate": [
      "self",
      "request",
      "raw_request"
    ],
    "_generate_generate_response": [
      "self",
      "gen_request",
      "raw_request",
      "model_name"
    ],
    "_stream_generate_response": [
      "self",
      "gen_request",
      "raw_request",
      "model_name"
    ],
    "get_tags": [
      "self"
    ],
    "get_show": [
      "self",
      "model"
    ]
  },
  "OllamaMessage": {},
  "OllamaChatRequest": {},
  "OllamaChatResponse": {},
  "OllamaChatStreamResponse": {},
  "OllamaGenerateRequest": {},
  "OllamaGenerateResponse": {},
  "OllamaGenerateStreamResponse": {},
  "OllamaModelInfo": {},
  "OllamaTagsResponse": {},
  "OllamaShowRequest": {},
  "OllamaShowResponse": {},
  "SmartRouter": {
    "CLASSIFICATION_PROMPT": [],
    "__init__": [
      "self",
      "local_host",
      "remote_host",
      "local_model",
      "remote_model",
      "judge_model",
      "judge_host"
    ],
    "_classify_with_llm": [
      "self",
      "prompt",
      "verbose"
    ],
    "should_use_remote": [
      "self",
      "prompt",
      "verbose"
    ],
    "chat": [
      "self",
      "prompt",
      "messages",
      "verbose",
      "force_local",
      "force_remote"
    ],
    "chat_stream": [
      "self",
      "prompt",
      "messages",
      "verbose",
      "force_local",
      "force_remote"
    ]
  },
  "opentelemetry_imported": [],
  "tracing_enabled": [],
  "_trace_context_propagator": [],
  "TRACE_HEADERS": [],
  "is_tracing_enabled": [],
  "extract_trace_headers": [
    "headers"
  ],
  "SglangTraceThreadInfo": {},
  "SglangTraceSliceContext": {},
  "SglangTraceThreadContext": {},
  "SglangTraceReqContext": {},
  "SglangTracePropagateContext": {
    "to_dict": [
      "self"
    ],
    "instance_from_dict": [
      "cls",
      "d"
    ]
  },
  "SglangTraceCustomIdGenerator": {
    "__init__": [
      "self"
    ],
    "generate_trace_id": [
      "self"
    ],
    "generate_span_id": [
      "self"
    ]
  },
  "__get_cur_time_ns": [],
  "__get_host_id": [],
  "process_tracing_init": [
    "otlp_endpoint",
    "server_name"
  ],
  "get_otlp_span_exporter": [
    "endpoint"
  ],
  "trace_set_thread_info": [
    "thread_label",
    "tp_rank",
    "dp_rank"
  ],
  "__create_thread_context": [
    "pid",
    "req_span_context",
    "ts"
  ],
  "trace_get_proc_propagate_context": [
    "rid",
    "remote_propagate"
  ],
  "trace_set_proc_propagate_context": [
    "rid",
    "trace_context"
  ],
  "trace_get_remote_propagate_context": [
    "bootstrap_room_list"
  ],
  "trace_set_remote_propagate_context": [
    "base64_str"
  ],
  "trace_req_start": [
    "rid",
    "bootstrap_room",
    "ts",
    "role",
    "external_trace_header"
  ],
  "trace_req_finish": [
    "rid",
    "ts",
    "attrs"
  ],
  "trace_slice_start": [
    "name",
    "rid",
    "ts",
    "anonymous"
  ],
  "trace_slice_end": [
    "name",
    "rid",
    "ts",
    "attrs",
    "auto_next_anon",
    "thread_finish_flag"
  ],
  "trace_slice": [],
  "trace_event": [
    "name",
    "rid",
    "ts",
    "attrs"
  ],
  "trace_slice_add_attr": [
    "rid",
    "attrs"
  ],
  "trace_slice_batch": [
    "name",
    "reqs"
  ],
  "trace_event_batch": [
    "name",
    "reqs",
    "ts",
    "attrs"
  ],
  "make_compiler": [
    "config"
  ],
  "make_backend": [
    "graph",
    "compile_config",
    "inductor_config",
    "graph_pool",
    "piecewise_compile_index",
    "total_piecewise_compiles",
    "sym_shape_indices",
    "compiled_graph_for_general_shape",
    "sglang_backend"
  ],
  "CompilerManager": {
    "__init__": [
      "self",
      "config"
    ],
    "compute_hash": [
      "self"
    ],
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "save_to_file": [
      "self"
    ],
    "load": [
      "self",
      "graph",
      "example_inputs",
      "graph_index",
      "runtime_shape"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "inductor_config",
      "graph_index",
      "num_graphs",
      "runtime_shape"
    ]
  },
  "SplitItem": {},
  "split_graph": [
    "graph",
    "ops"
  ],
  "global_graph_pool": [],
  "compilation_start_time": [],
  "PiecewiseCompileInterpreter": {
    "__init__": [
      "self",
      "module",
      "compile_submod_names",
      "inductor_config",
      "graph_pool",
      "compile_config",
      "sglang_backend"
    ],
    "run": [
      "self"
    ],
    "call_module": [
      "self",
      "target",
      "args",
      "kwargs"
    ]
  },
  "set_model_tag": [
    "tag"
  ],
  "SGLangBackend": {
    "__init__": [
      "self",
      "config",
      "graph_pool"
    ],
    "configure_post_pass": [
      "self"
    ],
    "__call__": [
      "self",
      "graph",
      "example_inputs"
    ]
  },
  "_pass_context": [],
  "PassContext": {
    "__init__": [
      "self",
      "runtime_shape"
    ]
  },
  "get_pass_context": [],
  "pass_context": [
    "runtime_shape"
  ],
  "InductorPass": {
    "uuid": [
      "self"
    ],
    "hash_source": [],
    "hash_dict": [
      "dict_"
    ],
    "is_applicable_for_shape": [
      "self",
      "shape"
    ]
  },
  "CallableInductorPass": {
    "__init__": [
      "self",
      "callable",
      "uuid"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "uuid": [
      "self"
    ]
  },
  "SGLangInductorPass": {
    "__init__": [
      "self"
    ],
    "dump_graph": [
      "self",
      "graph",
      "stage"
    ],
    "begin": [
      "self"
    ],
    "end_and_log": [
      "self"
    ]
  },
  "PrinterInductorPass": {
    "__init__": [
      "self",
      "name"
    ],
    "__call__": [
      "self",
      "graph"
    ]
  },
  "FixFunctionalizationPass": {
    "__call__": [
      "self",
      "graph"
    ],
    "_remove": [
      "self",
      "node_or_nodes"
    ],
    "defunctionalize": [
      "self",
      "graph",
      "node",
      "mutated_args",
      "args"
    ],
    "replace_users_with_mutated_args": [
      "self",
      "node",
      "mutated_args"
    ],
    "getitem_users": [
      "self",
      "node"
    ],
    "insert_defunctionalized": [
      "self",
      "graph",
      "node",
      "args"
    ]
  },
  "PostGradPassManager": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "graph"
    ],
    "configure": [
      "self"
    ],
    "add": [
      "self",
      "pass_"
    ],
    "uuid": [
      "self"
    ]
  },
  "CompilerInterface": {
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "compute_hash": [
      "self"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "runtime_shape",
      "key"
    ],
    "load": [
      "self",
      "handle",
      "graph",
      "example_inputs",
      "graph_index",
      "runtime_shape"
    ]
  },
  "get_inductor_factors": [],
  "AlwaysHitShapeEnv": {
    "__init__": [
      "self"
    ],
    "evaluate_guards_expression": [
      "self"
    ],
    "get_pruned_guards": [
      "self"
    ],
    "produce_guards_expression": [
      "self"
    ]
  },
  "InductorAdaptor": {
    "name": [],
    "compute_hash": [
      "self"
    ],
    "initialize_cache": [
      "self",
      "cache_dir",
      "disable_cache",
      "prefix"
    ],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "runtime_shape",
      "key"
    ],
    "load": [
      "self",
      "handle",
      "graph",
      "example_inputs",
      "graph_index",
      "runtime_shape"
    ],
    "metrics_context": [
      "self"
    ]
  },
  "set_inductor_config": [
    "config",
    "runtime_shape"
  ],
  "EagerAdapter": {
    "name": [],
    "compile": [
      "self",
      "graph",
      "example_inputs",
      "compiler_config",
      "runtime_shape",
      "key",
      "num_graphs"
    ],
    "load": [
      "self",
      "handle",
      "graph",
      "example_inputs",
      "graph_index",
      "runtime_shape",
      "num_graphs"
    ]
  },
  "is_func": [
    "node",
    "target"
  ],
  "is_auto_func": [
    "node",
    "op"
  ],
  "find_specified_fn_maybe": [
    "nodes",
    "op"
  ],
  "find_specified_fn": [
    "nodes",
    "op"
  ],
  "find_auto_fn_maybe": [
    "nodes",
    "op"
  ],
  "find_auto_fn": [
    "nodes",
    "op"
  ],
  "find_getitem_maybe": [
    "node",
    "idx"
  ],
  "find_getitem": [
    "node",
    "idx"
  ],
  "find_op_nodes": [
    "op",
    "graph"
  ],
  "get_only_user": [
    "node"
  ],
  "SPLIT_OPS": [],
  "register_split_op": [
    "op_name"
  ],
  "CompilationConfig": {
    "__init__": [
      "self",
      "capture_sizes",
      "compiler",
      "enable_debug_mode"
    ],
    "add_split_op": [
      "self",
      "op"
    ],
    "add_traced_file": [
      "self",
      "file_path"
    ],
    "get_traced_files": [
      "self"
    ],
    "get_capture_sizes": [
      "self"
    ],
    "get_enable_debug_mode": [
      "self"
    ]
  },
  "_COMPILE_ENABLED": [],
  "set_compiled": [
    "enabled"
  ],
  "IntermediateTensors": {
    "__init__": [
      "self",
      "tensors"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "items": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_normalize_dims": [
    "dims",
    "ndim"
  ],
  "_MaybeIntermediateTensors": {
    "__init__": [
      "self",
      "obj"
    ]
  },
  "_mark_dynamic_on_value": [
    "val",
    "dims"
  ],
  "_infer_dynamic_arg_dims_from_annotations": [
    "forward_fn"
  ],
  "install_torch_compiled": [
    "module"
  ],
  "NPUPiecewiseBackend": {
    "__init__": [
      "self",
      "graph",
      "compile_config",
      "inductor_config",
      "graph_pool",
      "piecewise_compile_index",
      "total_piecewise_compiles",
      "sym_shape_indices",
      "compiled_graph_for_general_shape",
      "sglang_backend"
    ],
    "__call__": [
      "self"
    ]
  },
  "weak_ref_tensors": [
    "tensors"
  ],
  "_in_piecewise_cuda_graph": [],
  "_in_pcg_torch_compile": [],
  "_pcg_capture_stream": [],
  "is_in_piecewise_cuda_graph": [],
  "is_in_pcg_torch_compile": [],
  "get_pcg_capture_stream": [],
  "enable_piecewise_cuda_graph_compile": [],
  "enable_piecewise_cuda_graph": [],
  "set_pcg_capture_stream": [
    "stream"
  ],
  "ForwardContext": {
    "__init__": [
      "self"
    ],
    "set_forward_batch": [
      "self",
      "forward_batch"
    ],
    "set_attention_layers": [
      "self",
      "layers"
    ],
    "set_quant_config": [
      "self",
      "quant_config"
    ],
    "set_moe_layers": [
      "self",
      "layers"
    ]
  },
  "get_forward_context": [],
  "set_forward_context": [
    "forward_batch",
    "attention_layers",
    "quant_config",
    "moe_layers"
  ],
  "ConcreteSizeEntry": {},
  "CUDAPiecewiseBackend": {
    "__init__": [
      "self",
      "graph",
      "compile_config",
      "inductor_config",
      "graph_pool",
      "piecewise_compile_index",
      "total_piecewise_compiles",
      "sym_shape_indices",
      "compiled_graph_for_general_shape",
      "sglang_backend"
    ],
    "check_for_ending_compilation": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "CompilationCounter": {
    "clone": [
      "self"
    ],
    "expect": [
      "self"
    ]
  },
  "compilation_counter": [],
  "_PRIORITY_MIN": [],
  "_PRIORITY_MAX": [],
  "_LOW_PRIORITY_VALUE": [],
  "_HIGH_PRIORITY_VALUE": [],
  "UNKNOWN_PRIORITY_VALUE": [],
  "transform_priority": [
    "priority"
  ],
  "SGLANG_TEST_REQUEST_TIME_STATS": [],
  "get_histogram_conf_from_env": [
    "env_var_name"
  ],
  "TimeStats": {
    "get_queueing_time": [
      "self"
    ],
    "get_prefill_launch_delay": [
      "self"
    ],
    "get_prefill_launch_latency": [
      "self"
    ],
    "get_prefill_finished_ts": [
      "self"
    ],
    "convert_to_duration": [
      "self"
    ],
    "format_duration": [
      "self",
      "duration"
    ],
    "disagg_mode_str": [
      "self"
    ]
  },
  "SchedulerStats": {},
  "ROUTING_KEY_REQ_COUNT_BUCKET_BOUNDS": [],
  "compute_routing_key_stats": [
    "routing_keys"
  ],
  "DPCooperationInfo": {
    "create": [
      "forward_modes"
    ],
    "to_labels": [
      "self"
    ]
  },
  "SchedulerMetricsCollector": {
    "__init__": [
      "self",
      "labels",
      "enable_lora",
      "server_args"
    ],
    "_log_gauge": [
      "self",
      "gauge",
      "data"
    ],
    "_log_histogram": [
      "self",
      "histogram",
      "data"
    ],
    "increment_bootstrap_failed_reqs": [
      "self"
    ],
    "increment_transfer_failed_reqs": [
      "self"
    ],
    "increment_prefill_retries": [
      "self",
      "count"
    ],
    "observe_per_stage_req_latency": [
      "self",
      "stage",
      "latency"
    ],
    "observe_queue_time": [
      "self",
      "latency"
    ],
    "observe_prefill_delayer_outcome": [
      "self",
      "forward_passes",
      "wait_seconds",
      "input_estimation",
      "output_allow",
      "output_reason",
      "actual_execution"
    ],
    "increment_retracted_reqs": [
      "self",
      "num_retracted_reqs",
      "num_retracted_input_tokens",
      "num_retracted_output_tokens"
    ],
    "increment_cuda_graph_pass": [
      "self",
      "value"
    ],
    "increment_eplb_balancedness": [
      "self",
      "forward_mode",
      "balancedness"
    ],
    "increment_realtime_tokens": [
      "self",
      "dp_cooperation_info",
      "prefill_compute_tokens",
      "prefill_cache_tokens",
      "decode_tokens"
    ],
    "increment_gpu_execution_seconds": [
      "self",
      "category",
      "t",
      "dp_cooperation_info"
    ],
    "log_stats": [
      "self",
      "stats"
    ],
    "log_grammar_stats": [
      "self",
      "grammar_stats"
    ]
  },
  "TokenizerMetricsCollector": {
    "__init__": [
      "self",
      "server_args",
      "labels",
      "bucket_time_to_first_token",
      "bucket_inter_token_latency",
      "bucket_e2e_request_latency",
      "collect_tokens_histogram"
    ],
    "observe_one_finished_request": [
      "self",
      "labels",
      "prompt_tokens",
      "generation_tokens",
      "cached_tokens",
      "e2e_latency",
      "has_grammar",
      "retraction_count"
    ],
    "observe_time_to_first_token": [
      "self",
      "labels",
      "value"
    ],
    "check_time_to_first_token_straggler": [
      "self",
      "value"
    ],
    "observe_inter_token_latency": [
      "self",
      "labels",
      "internval",
      "num_new_tokens"
    ],
    "observe_one_aborted_request": [
      "self",
      "labels"
    ]
  },
  "StorageMetrics": {},
  "StorageMetricsCollector": {
    "__init__": [
      "self",
      "labels"
    ],
    "log_prefetched_tokens": [
      "self",
      "prefetched_tokens"
    ],
    "log_backuped_tokens": [
      "self",
      "backuped_tokens"
    ],
    "_log_histogram": [
      "self",
      "histogram",
      "data"
    ],
    "log_storage_metrics": [
      "self",
      "storage_metrics"
    ]
  },
  "ExpertDispatchCollector": {
    "__init__": [
      "self",
      "ep_size"
    ]
  },
  "RadixCacheMetricsCollector": {
    "__init__": [
      "self",
      "labels"
    ],
    "increment_eviction_num_tokens": [
      "self",
      "num_tokens"
    ],
    "increment_load_back_num_tokens": [
      "self",
      "num_tokens"
    ],
    "observe_eviction_duration": [
      "self",
      "duration_seconds"
    ],
    "observe_load_back_duration": [
      "self",
      "duration_seconds"
    ]
  },
  "start_cpu_monitor_thread": [
    "component",
    "interval"
  ],
  "two_sides_exponential_buckets": [
    "middle",
    "base",
    "count"
  ],
  "generate_buckets": [
    "buckets_rule",
    "default_buckets"
  ],
  "exponential_buckets": [
    "start",
    "width",
    "length"
  ],
  "enable_metrics": [],
  "enable_func_timer": [],
  "FUNC_LATENCY": [],
  "time_func_latency": [
    "func",
    "name"
  ],
  "enable_startup_metrics": [],
  "STARTUP_LATENCY_SECONDS": [],
  "enable_startup_timer": [],
  "set_startup_metric": [
    "context",
    "value",
    "should_log"
  ],
  "reset_startup_timers": [],
  "get_max_duration": [
    "context"
  ],
  "startup_timer": [
    "name",
    "log_only"
  ],
  "time_startup_latency": [
    "func",
    "name",
    "log_only"
  ],
  "SGLangCheckpointEngineWorkerExtension": {
    "__init__": [
      "self"
    ],
    "get_device_uuid": [
      "self"
    ],
    "get_device_id": [
      "self"
    ],
    "get_model_loader": [
      "self"
    ],
    "get_post_hook": [
      "self"
    ],
    "update_weights_from_ipc": [
      "self",
      "zmq_handles"
    ]
  },
  "SGLangCheckpointEngineWorkerExtensionImpl": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "get_device_uuid": [
      "self"
    ],
    "get_device_id": [
      "self"
    ],
    "get_model_loader": [
      "self"
    ],
    "get_post_hook": [
      "self"
    ]
  },
  "timer": [
    "msg"
  ],
  "check_sglang_ready": [
    "endpoint",
    "inference_parallel_size",
    "uds"
  ],
  "split_checkpoint_files": [
    "checkpoint_path",
    "rank",
    "world_size"
  ],
  "split_tensors": [
    "checkpoint_path",
    "rank",
    "world_size"
  ],
  "req_inference": [
    "endpoint",
    "inference_parallel_size",
    "timeout",
    "uds",
    "weight_version"
  ],
  "update_weights": [
    "ps",
    "checkpoint_name",
    "checkpoint_files",
    "named_tensors",
    "req_func",
    "inference_parallel_size",
    "endpoint",
    "save_metas_file",
    "update_method",
    "uds"
  ],
  "join": [
    "ps",
    "checkpoint_name",
    "load_metas_file",
    "req_func",
    "inference_parallel_size",
    "endpoint",
    "uds"
  ],
  "run_with_torchrun": [],
  "STREAM_GROUPS": [],
  "SM_COUNTS": [],
  "SM_GROUP_NUM": [],
  "CURRENT_STREAM_IDX": [],
  "CURRENT_STREAM_GROUP": [],
  "PDMuxConfig": {},
  "load_pdmux_config": [
    "config_path"
  ],
  "get_arch_constraints": [
    "compute_capability"
  ],
  "divide_sm": [
    "total_sms",
    "compute_capability",
    "groups"
  ],
  "initialize_stream_groups": [
    "gpu_id",
    "config"
  ],
  "set_current_stream_idx": [
    "idx"
  ],
  "get_stream_groups": [],
  "get_sm_counts": [],
  "get_current_stream_idx": [],
  "SchedulerMultiplexMixin": {
    "init_pdmux": [
      "self"
    ],
    "adjust_stream_groups": [
      "self"
    ],
    "update_split_prefill_batch": [
      "self",
      "sm_count"
    ],
    "event_loop_pdmux": [
      "self"
    ]
  },
  "GrammarStats": {},
  "BaseGrammarObject": {
    "__init__": [
      "self"
    ],
    "maybe_init_reasoning": [
      "self",
      "reasoning"
    ],
    "accept_token": [
      "self",
      "token"
    ],
    "rollback": [
      "self",
      "k"
    ],
    "is_terminated": [
      "self"
    ],
    "allocate_vocab_mask": [
      "self",
      "vocab_size",
      "batch_size",
      "device"
    ],
    "fill_vocab_mask": [
      "self",
      "vocab_mask",
      "idx"
    ],
    "move_vocab_mask": [
      "vocab_mask",
      "device"
    ],
    "apply_vocab_mask": [
      "logits",
      "vocab_mask"
    ],
    "copy": [
      "self"
    ],
    "finished": [
      "self",
      "finished"
    ],
    "try_jump_forward": [
      "self",
      "tokenizer"
    ],
    "jump_forward_str_state": [
      "self",
      "helper"
    ],
    "jump_and_retokenize": [
      "self",
      "old_output_ids",
      "new_output_ids",
      "next_state"
    ]
  },
  "INVALID_GRAMMAR_OBJ": [],
  "CacheEntry": {},
  "BaseGrammarBackend": {
    "__init__": [
      "self"
    ],
    "_not_supported": [
      "self",
      "key_type",
      "key_string"
    ],
    "dispatch_fallback": [
      "self",
      "key_type",
      "key_string"
    ],
    "dispatch_json": [
      "self",
      "key_string"
    ],
    "dispatch_regex": [
      "self",
      "key_string"
    ],
    "dispatch_ebnf": [
      "self",
      "key_string"
    ],
    "dispatch_structural_tag": [
      "self",
      "key_string"
    ],
    "_init_value_dispatch": [
      "self",
      "key",
      "require_reasoning"
    ],
    "get_cached_or_future_value": [
      "self",
      "key",
      "require_reasoning"
    ],
    "set_cache": [
      "self",
      "key",
      "value"
    ],
    "reset": [
      "self"
    ]
  },
  "GRAMMAR_BACKEND_REGISTRY": [],
  "register_grammar_backend": [
    "name",
    "init_func"
  ],
  "create_grammar_backend": [
    "server_args",
    "tokenizer",
    "vocab_size",
    "eos_token_ids"
  ],
  "MAX_ROLLBACK_TOKENS": [],
  "XGrammarGrammar": {
    "__init__": [
      "self",
      "matcher",
      "vocab_size",
      "ctx",
      "override_stop_tokens",
      "key_string",
      "grammar_stats"
    ],
    "accept_token": [
      "self",
      "token"
    ],
    "rollback": [
      "self",
      "k"
    ],
    "is_terminated": [
      "self"
    ],
    "allocate_vocab_mask": [
      "self",
      "vocab_size",
      "batch_size",
      "device"
    ],
    "fill_vocab_mask": [
      "self",
      "vocab_mask",
      "idx"
    ],
    "move_vocab_mask": [
      "vocab_mask",
      "device"
    ],
    "apply_vocab_mask": [
      "self",
      "logits",
      "vocab_mask"
    ],
    "copy": [
      "self"
    ],
    "try_jump_forward": [
      "self",
      "tokenizer"
    ],
    "jump_forward_str_state": [
      "self",
      "helper"
    ],
    "jump_and_retokenize": [
      "self",
      "old_output_ids",
      "new_output_ids",
      "next_state"
    ],
    "__repr__": [
      "self"
    ]
  },
  "TokenizerNotSupportedError": {},
  "XGrammarGrammarBackend": {
    "__init__": [
      "self",
      "tokenizer",
      "vocab_size",
      "model_eos_token_ids",
      "any_whitespace"
    ],
    "_sanitize_structural_format": [
      "structural_format"
    ],
    "_sanitize_structural_tag_structures": [
      "structural_tag"
    ],
    "_from_context": [
      "self",
      "ctx",
      "key_string",
      "grammar_stats"
    ],
    "dispatch_json": [
      "self",
      "key_string"
    ],
    "dispatch_ebnf": [
      "self",
      "key_string"
    ],
    "dispatch_regex": [
      "self",
      "key_string"
    ],
    "dispatch_structural_tag": [
      "self",
      "key_string"
    ],
    "reset": [
      "self"
    ]
  },
  "demo_test": [],
  "ReasonerGrammarObject": {
    "__init__": [
      "self",
      "grammar",
      "think_end_id"
    ],
    "maybe_init_reasoning": [
      "self",
      "reasoning"
    ],
    "transfer_state": [
      "self",
      "token"
    ],
    "rollback_state": [
      "self"
    ],
    "accept_token": [
      "self",
      "token"
    ],
    "is_terminated": [
      "self"
    ],
    "rollback": [
      "self",
      "k"
    ],
    "allocate_vocab_mask": [
      "self",
      "vocab_size",
      "batch_size",
      "device"
    ],
    "fill_vocab_mask": [
      "self",
      "vocab_mask",
      "idx"
    ],
    "move_vocab_mask": [
      "self",
      "vocab_mask",
      "device"
    ],
    "apply_vocab_mask": [
      "self"
    ],
    "copy": [
      "self"
    ],
    "finished": [
      "self",
      "finished"
    ],
    "try_jump_forward": [
      "self",
      "tokenizer"
    ],
    "jump_forward_str_state": [
      "self",
      "helper"
    ],
    "jump_and_retokenize": [
      "self",
      "old_output_ids",
      "new_output_ids",
      "next_state"
    ]
  },
  "ReasonerGrammarBackend": {
    "__init__": [
      "self",
      "grammar_backend",
      "think_end_id"
    ],
    "_init_value_dispatch": [
      "self",
      "key",
      "reasoning"
    ]
  },
  "is_legacy_structural_tag": [
    "obj"
  ],
  "OutlinesGrammar": {
    "__init__": [
      "self",
      "guide",
      "jump_forward_map"
    ],
    "accept_token": [
      "self",
      "token"
    ],
    "allocate_vocab_mask": [
      "self",
      "vocab_size",
      "batch_size",
      "device"
    ],
    "move_vocab_mask": [
      "vocab_mask",
      "device"
    ],
    "fill_vocab_mask": [
      "self",
      "vocab_mask",
      "idx"
    ],
    "apply_vocab_mask": [
      "logits",
      "vocab_mask"
    ],
    "copy": [
      "self"
    ],
    "try_jump_forward": [
      "self",
      "tokenizer"
    ],
    "jump_forward_str_state": [
      "self",
      "helper"
    ],
    "jump_and_retokenize": [
      "self",
      "old_output_ids",
      "new_output_ids",
      "next_state"
    ]
  },
  "OutlinesGrammarBackend": {
    "__init__": [
      "self",
      "tokenizer",
      "whitespace_pattern"
    ],
    "_compile_regex": [
      "self",
      "regex"
    ],
    "dispatch_ebnf": [
      "self",
      "key_string"
    ],
    "dispatch_structural_tag": [
      "self",
      "key_string"
    ],
    "dispatch_json": [
      "self",
      "key_string"
    ],
    "dispatch_regex": [
      "self",
      "key_string"
    ]
  },
  "build_regex_from_object": [
    "object",
    "whitespace_pattern"
  ],
  "IP_REGEX": [],
  "DISABLE_DISK_CACHE": [],
  "JumpEdge": {},
  "disk_cache": [
    "expire",
    "typed",
    "ignore"
  ],
  "init_state_to_jump_forward": [
    "regex_string"
  ],
  "OutlinesJumpForwardMap": {
    "__init__": [
      "self",
      "regex_string"
    ],
    "jump_forward_symbol": [
      "self",
      "state"
    ],
    "jump_forward_byte": [
      "self",
      "state"
    ],
    "is_jump_forward_symbol_state": [
      "self",
      "state"
    ]
  },
  "test_main": [
    "regex_string"
  ],
  "GrammarManager": {
    "__init__": [
      "self",
      "scheduler"
    ],
    "__len__": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "has_waiting_grammars": [
      "self"
    ],
    "abort_requests": [
      "self",
      "recv_req"
    ],
    "process_req_with_grammar": [
      "self",
      "req"
    ],
    "get_ready_grammar_requests": [
      "self"
    ]
  },
  "GuidanceGrammar": {
    "__init__": [
      "self",
      "llguidance_tokenizer",
      "serialized_grammar"
    ],
    "accept_token": [
      "self",
      "token"
    ],
    "fill_vocab_mask": [
      "self",
      "vocab_mask",
      "idx"
    ],
    "allocate_vocab_mask": [
      "self",
      "vocab_size",
      "batch_size",
      "device"
    ],
    "move_vocab_mask": [
      "vocab_mask",
      "device"
    ],
    "apply_vocab_mask": [
      "logits",
      "vocab_mask"
    ],
    "copy": [
      "self"
    ],
    "try_jump_forward": [
      "self",
      "tokenizer"
    ],
    "jump_forward_str_state": [
      "self",
      "helper"
    ],
    "jump_and_retokenize": [
      "self",
      "old_output_ids",
      "new_output_ids",
      "next_state"
    ]
  },
  "GuidanceBackend": {
    "__init__": [
      "self",
      "tokenizer",
      "any_whitespace",
      "whitespace_pattern",
      "n_vocab"
    ],
    "_from_serialized": [
      "self",
      "serialized_grammar"
    ],
    "dispatch_json": [
      "self",
      "key_string"
    ],
    "dispatch_regex": [
      "self",
      "key_string"
    ],
    "dispatch_ebnf": [
      "self",
      "key_string"
    ],
    "dispatch_structural_tag": [
      "self",
      "key_string"
    ]
  },
  "apply_token_bitmask_inplace_kernel": [
    "logits_ptr",
    "bitmask_ptr",
    "indices_ptr",
    "num_rows",
    "vocab_size",
    "logits_strides",
    "bitmask_strides",
    "NUM_SMS",
    "BLOCK_SIZE"
  ],
  "apply_token_bitmask_inplace_triton": [
    "logits",
    "bitmask",
    "indices"
  ],
  "_PATTERN_DECODE": [],
  "parse": [
    "lines"
  ],
  "_split_einops_pattern": [
    "pattern"
  ],
  "_get_einops_dim_index": [
    "pattern",
    "dim_name"
  ],
  "check_tensor_pair": [
    "path_baseline",
    "path_target",
    "diff_threshold",
    "name",
    "baseline_token_slice",
    "tensor_dim_desc"
  ],
  "_compute_and_print_diff": [
    "x_baseline",
    "x_target",
    "diff_threshold",
    "prefix_text"
  ],
  "_argmax_coord": [
    "x"
  ],
  "_compute_smaller_dtype": [
    "dtype_a",
    "dtype_b"
  ],
  "_try_unify_shape": [
    "x",
    "target_shape"
  ],
  "_calc_rel_diff": [
    "x",
    "y"
  ],
  "_load_object": [
    "path"
  ],
  "_comparison_preprocessor": [
    "x_baseline",
    "x_target",
    "name"
  ],
  "LocationInfo": {},
  "_get_location_info_of_target_pass_id": [],
  "TensorDimDesc": {},
  "_get_tensor_dim_descs": [],
  "_Dumper": {
    "__init__": [
      "self"
    ],
    "on_forward_pass_start": [
      "self"
    ],
    "_ensure_http_server": [
      "self"
    ],
    "_ensure_partial_name": [
      "self"
    ],
    "set_ctx": [
      "self"
    ],
    "override_enable": [
      "self",
      "value"
    ],
    "dump_dict": [
      "self",
      "name_prefix",
      "data",
      "save"
    ],
    "dump": [
      "self",
      "name",
      "value",
      "save"
    ]
  },
  "_torch_save": [
    "value",
    "path"
  ],
  "_get_partial_name": [],
  "_get_rank": [],
  "_obj_to_dict": [
    "obj"
  ],
  "_start_maybe_http_server": [
    "dumper"
  ],
  "_make_dumper_http_handler": [
    "rpc_handles"
  ],
  "_DumperRpcHandler": {
    "__init__": [
      "self",
      "dumper"
    ],
    "set_enable": [
      "self",
      "enable"
    ]
  },
  "_create_zmq_rpc_handles": [
    "handler",
    "base_port"
  ],
  "_ZmqRpcHandle": {
    "__init__": [
      "self",
      "socket",
      "debug_name"
    ],
    "__getattr__": [
      "self",
      "method_name"
    ]
  },
  "_get_local_ip_by_remote": [],
  "dumper": [],
  "get_truncated_value": [
    "value"
  ],
  "get_tensor_info": [
    "x"
  ],
  "TensorDumper": {
    "__init__": [
      "self",
      "dump_dir",
      "dump_layers",
      "tp_size",
      "tp_rank",
      "pp_rank"
    ],
    "get_dump_dir": [
      "self"
    ],
    "add_tensor": [
      "self",
      "name",
      "tensor_item"
    ],
    "dump_current_tensors": [
      "self"
    ],
    "_add_hook_recursive": [
      "self",
      "model",
      "prefix",
      "top_level_module_name",
      "layers_module_name"
    ],
    "_dump_hook": [
      "self",
      "tensor_name",
      "do_dump"
    ]
  },
  "register_forward_hook_for_model": [
    "model",
    "dump_dir",
    "dump_layers",
    "tp_size",
    "tp_rank",
    "pp_rank"
  ],
  "DumpLoader": {
    "__init__": [
      "self"
    ],
    "enable": [
      "self"
    ],
    "load": [
      "self",
      "name"
    ]
  },
  "read_meta": [
    "directory"
  ],
  "_add_duplicate_index": [
    "df"
  ],
  "find_row": [
    "df",
    "conditions"
  ],
  "_cast_to_polars_dtype": [
    "value",
    "target_dtype"
  ],
  "dump_loader": [],
  "_maybe_snapshot_download": [
    "path"
  ],
  "_transform_json": [
    "dir_input",
    "dir_output",
    "filename",
    "fn"
  ],
  "_transform_config": [
    "args",
    "config_json"
  ],
  "_transform_safetensors_index": [
    "args",
    "safetensors_index"
  ],
  "_transform_safetensors_file": [
    "state_dict",
    "safetensors_index",
    "debug_name"
  ],
  "_filter_tensor_name": [
    "args",
    "tensor_name"
  ],
  "_DESCRIPTION": [],
  "_compute_df_input_mode_simple_evals": [
    "args"
  ],
  "_compute_df_input_one_mode_simple_evals": [
    "path",
    "category",
    "trial_index"
  ],
  "_compute_id_from_object": [
    "obj"
  ],
  "_compute_df_raw": [
    "args"
  ],
  "_get_file_infos": [
    "args"
  ],
  "_read_df_raw": [
    "path",
    "category",
    "trial_index"
  ],
  "_transform_df_input": [
    "df"
  ],
  "_compute_df_meta": [
    "df_input"
  ],
  "_handle_one_prompt": [
    "df_one_prompt"
  ],
  "_compute_str_prefix_len": [
    "a",
    "b"
  ],
  "SimRequest": {
    "seq_len": [
      "self"
    ],
    "is_finished": [
      "self"
    ]
  },
  "MetricRecorder": {
    "on_step_end": [
      "self",
      "step",
      "gpu_states"
    ],
    "get_summary": [
      "self"
    ]
  },
  "BalancednessRecorder": {
    "__init__": [
      "self",
      "name",
      "value_fn"
    ],
    "on_step_end": [
      "self",
      "step",
      "gpu_states"
    ],
    "get_summary": [
      "self"
    ]
  },
  "BatchSizeBalancednessRecorder": [],
  "AttentionComputeBalancednessRecorder": [],
  "AvgBatchSizeRecorder": {
    "__init__": [
      "self"
    ],
    "on_step_end": [
      "self",
      "step",
      "gpu_states"
    ],
    "get_summary": [
      "self"
    ]
  },
  "SimulationResult": {},
  "Simulator": {
    "__init__": [
      "self",
      "num_gpus_per_engine",
      "router",
      "scheduler",
      "recorders",
      "log_level",
      "max_total_tokens",
      "stop_criteria",
      "max_steps"
    ],
    "run": [
      "self",
      "requests"
    ],
    "_should_stop": [
      "self"
    ],
    "_route_requests": [
      "self",
      "incoming_requests"
    ],
    "_schedule_all_gpus": [
      "self"
    ],
    "_execute_step": [
      "self"
    ],
    "_log_step": [
      "self"
    ],
    "_record_metrics": [
      "self"
    ],
    "_get_summary": [
      "self"
    ]
  },
  "_format_ids": [
    "requests",
    "limit"
  ],
  "create_arg_parser": [],
  "_load_requests": [
    "args"
  ],
  "_create_router": [
    "name",
    "total_gpus"
  ],
  "_create_scheduler": [
    "name"
  ],
  "StepRecord": {},
  "GPUState": {
    "batch_size": [
      "self"
    ],
    "total_attention_compute": [
      "self"
    ],
    "total_seq_len": [
      "self",
      "extra_reqs"
    ],
    "is_valid": [
      "self"
    ],
    "start_request": [
      "self",
      "req"
    ],
    "evict_request": [
      "self",
      "req"
    ],
    "execute_step": [
      "self"
    ],
    "get_step_record": [
      "self",
      "step"
    ]
  },
  "SchedulerPolicy": {
    "schedule": [
      "self",
      "gpu_state"
    ]
  },
  "FIFOScheduler": {
    "schedule": [
      "self",
      "gpu_state"
    ]
  },
  "load_from_request_logger": [
    "file_path"
  ],
  "generate_random_requests": [
    "num_requests",
    "input_len",
    "output_len",
    "range_ratio",
    "seed"
  ],
  "generate_gsp_requests": [
    "num_groups",
    "prompts_per_group",
    "system_prompt_len",
    "question_len",
    "output_len",
    "range_ratio",
    "seed"
  ],
  "_random_len": [
    "full_len",
    "range_ratio"
  ],
  "RandomRouter": {
    "__init__": [
      "self",
      "num_gpus"
    ],
    "route": [
      "self",
      "incoming_request"
    ]
  },
  "RouterPolicy": {
    "route": [
      "self",
      "incoming_request"
    ]
  },
  "StickyRouter": {
    "__init__": [
      "self",
      "num_gpus"
    ],
    "_assign_gpu": [
      "self"
    ],
    "route": [
      "self",
      "incoming_request"
    ]
  },
  "RoundRobinRouter": {
    "__init__": [
      "self",
      "num_gpus"
    ],
    "route": [
      "self",
      "incoming_request"
    ]
  },
  "RedisConnector": {
    "__init__": [
      "self",
      "url"
    ],
    "get": [
      "self",
      "key"
    ],
    "getstr": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "tensor"
    ],
    "setstr": [
      "self",
      "key",
      "obj"
    ],
    "list": [
      "self",
      "prefix"
    ],
    "weight_iterator": [
      "self",
      "rank"
    ],
    "pull_files": [
      "self",
      "allow_pattern",
      "ignore_pattern"
    ],
    "close": [
      "self"
    ]
  },
  "_filter_allow": [
    "paths",
    "patterns"
  ],
  "_filter_ignore": [
    "paths",
    "patterns"
  ],
  "list_files": [
    "s3",
    "path",
    "allow_pattern",
    "ignore_pattern"
  ],
  "S3Connector": {
    "__init__": [
      "self",
      "url"
    ],
    "glob": [
      "self",
      "allow_pattern"
    ],
    "pull_files": [
      "self",
      "allow_pattern",
      "ignore_pattern"
    ],
    "weight_iterator": [
      "self",
      "rank"
    ],
    "close": [
      "self"
    ]
  },
  "parse_model_name": [
    "url"
  ],
  "pull_files_from_db": [
    "connector",
    "model_name",
    "allow_pattern",
    "ignore_pattern"
  ],
  "BaseConnector": {
    "__init__": [
      "self",
      "url"
    ],
    "get_local_dir": [
      "self"
    ],
    "weight_iterator": [
      "self",
      "rank"
    ],
    "pull_files": [
      "self",
      "allow_pattern",
      "ignore_pattern"
    ],
    "close": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "__del__": [
      "self"
    ],
    "_close_by_signal": [
      "self",
      "existing_handler"
    ]
  },
  "BaseKVConnector": {
    "get": [
      "self",
      "key"
    ],
    "getstr": [
      "self",
      "key"
    ],
    "set": [
      "self",
      "key",
      "obj"
    ],
    "setstr": [
      "self",
      "key",
      "obj"
    ],
    "list": [
      "self",
      "prefix"
    ]
  },
  "BaseFileConnector": {
    "glob": [
      "self",
      "allow_pattern"
    ]
  },
  "ConnectorType": {
    "FS": [],
    "KV": [],
    "INSTANCE": []
  },
  "create_remote_connector": [
    "url",
    "device"
  ],
  "get_connector_type": [
    "client"
  ],
  "RemoteInstanceConnector": {
    "__init__": [
      "self",
      "url",
      "device"
    ],
    "build_group": [
      "self",
      "gpu_id",
      "tp_rank",
      "instance_ip",
      "group_rank",
      "world_size"
    ],
    "pull_files": [
      "self",
      "allow_pattern",
      "ignore_pattern"
    ],
    "weight_iterator": [
      "self",
      "rank"
    ]
  },
  "Serializer": {
    "to_bytes": [
      "self",
      "t"
    ]
  },
  "Deserializer": {
    "__init__": [
      "self",
      "dtype"
    ],
    "from_bytes": [
      "self",
      "bs"
    ]
  },
  "create_serde": [
    "serde_type"
  ],
  "SafeSerializer": {
    "__init__": [
      "self"
    ],
    "to_bytes": [
      "self",
      "t"
    ]
  },
  "SafeDeserializer": {
    "__init__": [
      "self"
    ],
    "from_bytes_normal": [
      "self",
      "b"
    ],
    "from_bytes": [
      "self",
      "b"
    ]
  },
  "is_capture_mode": [],
  "get_is_capture_mode": [],
  "model_capture_mode": [],
  "freeze_gc": [
    "enable_cudagraph_gc"
  ],
  "_to_torch": [
    "model",
    "reverse",
    "num_tokens"
  ],
  "patch_model": [
    "model",
    "enable_compile",
    "num_tokens",
    "tp_group"
  ],
  "set_torch_compile_config": [],
  "get_batch_sizes_to_capture": [
    "model_runner",
    "num_tokens_per_bs"
  ],
  "global_graph_memory_pool": [],
  "get_global_graph_memory_pool": [],
  "set_global_graph_memory_pool": [
    "val"
  ],
  "CudaGraphRunner": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "maybe_init_pdmux": [
      "self"
    ],
    "_cache_loc_dtype": [
      "self"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ],
    "_init_profile_context_and_memory_record": [
      "self"
    ],
    "_post_process_after_profile": [
      "self",
      "prof_context"
    ],
    "capture": [
      "self"
    ],
    "_capture_graph": [
      "self",
      "graph",
      "pool",
      "stream",
      "run_once_fn"
    ],
    "_create_device_graph": [
      "self"
    ],
    "capture_one_batch_size": [
      "self",
      "bs",
      "forward",
      "stream_idx"
    ],
    "recapture_if_needed": [
      "self",
      "forward_batch"
    ],
    "replay_prepare": [
      "self",
      "forward_batch",
      "pp_proxy_tensors"
    ],
    "replay": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors"
    ],
    "get_spec_info": [
      "self",
      "num_tokens"
    ]
  },
  "CUDA_GRAPH_CAPTURE_FAILED_MSG": [],
  "DeepEPCudaGraphRunnerAdapter": {
    "__init__": [
      "self"
    ],
    "capture": [
      "self",
      "is_extend_in_batch"
    ],
    "replay": [
      "self"
    ]
  },
  "register_fake_ops": [],
  "CPUGraphRunner": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ],
    "capture": [
      "self"
    ],
    "capture_one_batch_size": [
      "self",
      "bs",
      "forward"
    ],
    "recapture_if_needed": [
      "self",
      "forward_batch"
    ],
    "replay": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors"
    ],
    "get_spec_info": [
      "self",
      "num_tokens"
    ]
  },
  "CPU_GRAPH_CAPTURE_FAILED_MSG": [],
  "register_forward_hooks": [
    "model",
    "hook_specs"
  ],
  "resolve_callable": [
    "path"
  ],
  "_is_cpu_amx_available": [],
  "_is_cpu_arm64": [],
  "MLA_ATTENTION_BACKENDS": [],
  "CHUNKED_PREFIX_CACHE_SUPPORTED_ATTENTION_BACKENDS": [],
  "add_mla_attention_backend": [
    "backend_name"
  ],
  "add_chunked_prefix_cache_attention_backend": [
    "backend_name"
  ],
  "UNBALANCED_MODEL_LOADING_TIMEOUT_S": [],
  "resolve_language_model": [
    "model"
  ],
  "RankZeroFilter": {
    "__init__": [
      "self",
      "is_rank_zero"
    ],
    "filter": [
      "self",
      "record"
    ]
  },
  "ModelRunnerOutput": {},
  "ModelRunner": {
    "__init__": [
      "self",
      "model_config",
      "mem_fraction_static",
      "gpu_id",
      "tp_rank",
      "tp_size",
      "moe_ep_rank",
      "moe_ep_size",
      "pp_rank",
      "pp_size",
      "nccl_port",
      "server_args",
      "dp_rank",
      "is_draft_worker",
      "req_to_token_pool",
      "token_to_kv_pool_allocator",
      "draft_model_idx"
    ],
    "init_mindspore_runner": [
      "self"
    ],
    "initialize": [
      "self",
      "min_per_gpu_memory"
    ],
    "init_routed_experts_capturer": [
      "self"
    ],
    "remote_instance_init_transfer_engine": [
      "self"
    ],
    "model_specific_adjustment": [
      "self"
    ],
    "check_quantized_moe_compatibility": [
      "self"
    ],
    "init_torch_distributed": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "update_expert_location": [
      "self",
      "new_expert_location_metadata",
      "update_layer_ids"
    ],
    "update_weights_from_disk": [
      "self",
      "model_path",
      "load_format",
      "weight_name_filter",
      "recapture_cuda_graph"
    ],
    "init_weights_send_group_for_remote_instance": [
      "self",
      "master_address",
      "ports",
      "group_rank",
      "world_size",
      "group_name",
      "backend"
    ],
    "send_weights_to_remote_instance": [
      "self",
      "master_address",
      "ports",
      "group_name"
    ],
    "init_weights_update_group": [
      "self",
      "master_address",
      "master_port",
      "rank_offset",
      "world_size",
      "group_name",
      "backend"
    ],
    "destroy_weights_update_group": [
      "self",
      "group_name"
    ],
    "update_weights_from_distributed": [
      "self",
      "names",
      "dtypes",
      "shapes",
      "group_name",
      "load_format"
    ],
    "_update_bucketed_weights_from_distributed": [
      "self",
      "names",
      "dtypes",
      "shapes",
      "group_name"
    ],
    "update_weights_from_tensor": [
      "self",
      "named_tensors",
      "load_format"
    ],
    "_update_weights_from_flattened_bucket": [
      "self",
      "flattened_tensor_bucket_dict"
    ],
    "get_weights_by_name": [
      "self",
      "name",
      "truncate_size"
    ],
    "init_lora_manager": [
      "self"
    ],
    "load_lora_adapter": [
      "self",
      "lora_ref"
    ],
    "load_lora_adapter_from_tensors": [
      "self",
      "lora_ref",
      "tensors",
      "config_dict",
      "added_tokens_config"
    ],
    "unload_lora_adapter": [
      "self",
      "lora_ref"
    ],
    "qwen3_next_config": [
      "self"
    ],
    "hybrid_gdn_config": [
      "self"
    ],
    "mamba2_config": [
      "self"
    ],
    "max_token_pool_size": [
      "self"
    ],
    "kimi_linear_config": [
      "self"
    ],
    "mambaish_config": [
      "self"
    ],
    "can_run_piecewise_cuda_graph": [
      "self"
    ],
    "configure_kv_cache_dtype": [
      "self"
    ],
    "init_cublas": [
      "self"
    ],
    "init_attention_backend": [
      "self"
    ],
    "_get_attention_backend": [
      "self",
      "init_new_workspace"
    ],
    "_get_attention_backend_from_str": [
      "self",
      "backend_str",
      "init_new_workspace"
    ],
    "init_double_sparsity_channel_config": [
      "self",
      "selected_channel"
    ],
    "kernel_warmup": [
      "self"
    ],
    "_should_run_flashinfer_autotune": [
      "self"
    ],
    "_flashinfer_autotune": [
      "self"
    ],
    "_dummy_run": [
      "self",
      "batch_size"
    ],
    "init_device_graphs": [
      "self"
    ],
    "init_piecewise_cuda_graphs": [
      "self"
    ],
    "init_threads_binding": [
      "self"
    ],
    "apply_torch_tp": [
      "self"
    ],
    "update_decode_attn_backend": [
      "self",
      "stream_idx"
    ],
    "forward_decode": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors"
    ],
    "forward_extend": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors"
    ],
    "forward_idle": [
      "self",
      "forward_batch",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "forward_batch",
      "reinit_attn_backend",
      "forward_count"
    ],
    "forward": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors",
      "reinit_attn_backend",
      "split_forward_count"
    ],
    "_forward_raw": [
      "self",
      "forward_batch",
      "skip_attn_backend_init",
      "pp_proxy_tensors",
      "reinit_attn_backend",
      "split_forward_count"
    ],
    "_preprocess_logits": [
      "self",
      "logits_output",
      "sampling_info"
    ],
    "sample": [
      "self",
      "logits_output",
      "forward_batch"
    ],
    "compute_logprobs_only": [
      "self",
      "logits_output",
      "forward_batch"
    ],
    "model_is_mrope": [
      "self"
    ],
    "save_remote_model": [
      "self",
      "url"
    ],
    "save_sharded_model": [
      "self",
      "path",
      "pattern",
      "max_size"
    ],
    "check_weights": [
      "self",
      "action"
    ],
    "update_weights_from_ipc": [
      "self",
      "recv_req"
    ]
  },
  "_model_load_weights_direct": [
    "model",
    "named_tensors"
  ],
  "_unwrap_tensor": [
    "tensor",
    "tp_rank",
    "device"
  ],
  "LocalSerializedTensor": {
    "get": [
      "self",
      "rank"
    ]
  },
  "MAMBA_CACHE_SIZE_MAX_RUNNING_REQUESTS_RATIO": [],
  "MAMBA_CACHE_V2_ADDITIONAL_RATIO_OVERLAP": [],
  "MAMBA_CACHE_V2_ADDITIONAL_RATIO_NO_OVERLAP": [],
  "ModelRunnerKVCacheMixin": {
    "get_cell_size_per_token": [
      "self",
      "num_layers"
    ],
    "profile_max_num_token": [
      "self",
      "total_gpu_memory"
    ],
    "handle_max_mamba_cache": [
      "self",
      "total_rest_memory"
    ],
    "set_num_tokens_hybrid_swa": [
      "self"
    ],
    "init_memory_pool": [
      "self",
      "total_gpu_memory"
    ]
  },
  "_Tmp": {
    "__init__": [
      "self"
    ],
    "set_sched_process": [
      "self",
      "p"
    ],
    "__del__": [
      "self"
    ]
  },
  "_tmp": [],
  "_get_host_and_ip": [
    "distributed_init_method"
  ],
  "run_scheduler_init": [
    "rank",
    "local_rank",
    "world_size",
    "master_addr",
    "master_port"
  ],
  "set_ms_parallel_env": [
    "rank",
    "local_rank",
    "world_size",
    "init_method"
  ],
  "reuse_hccl_comm": [],
  "init_ms_distributed": [
    "world_size",
    "rank",
    "local_rank",
    "server_args",
    "port"
  ],
  "GraphInputBuffers": {
    "create": [
      "cls"
    ],
    "populate_from_forward_batch": [
      "self"
    ]
  },
  "ForwardBatchDeepSeekMHAMixin": {
    "get_max_chunk_capacity": [
      "self"
    ],
    "set_prefix_chunk_idx": [
      "self",
      "idx"
    ],
    "set_attn_attend_prefix_cache": [
      "self",
      "attn_attend_prefix_cache"
    ],
    "prepare_chunked_kv_indices": [
      "self",
      "device"
    ],
    "get_prefix_chunk_seq_lens": [
      "self",
      "prefix_lens",
      "num_prefix_chunks",
      "prefix_chunk_len"
    ],
    "prepare_chunked_prefix_cache_info": [
      "self",
      "device"
    ],
    "fetch_mha_one_shot_kv_indices": [
      "self"
    ]
  },
  "create_chunked_prefix_cache_kv_indices": [
    "req_to_token_ptr",
    "req_pool_indices_ptr",
    "chunk_start_idx_ptr",
    "chunk_seq_lens_ptr",
    "chunk_cu_seq_lens_ptr",
    "chunk_kv_indices_ptr",
    "req_to_token_ptr_stride"
  ],
  "PiecewiseCudaGraphRunner": {
    "is_mamba_track_enabled": [
      "self"
    ],
    "__init__": [
      "self",
      "model_runner"
    ],
    "warmup_torch_compile": [
      "self",
      "num_tokens"
    ],
    "_cache_loc_dtype": [
      "self"
    ],
    "can_run": [
      "self",
      "forward_batch"
    ],
    "capture": [
      "self"
    ],
    "capture_one_batch_size": [
      "self",
      "num_tokens"
    ],
    "replay_prepare": [
      "self",
      "forward_batch"
    ],
    "replay": [
      "self",
      "forward_batch"
    ],
    "get_spec_info": [
      "self",
      "num_tokens"
    ]
  },
  "PIECEWISE_CUDA_GRAPH_CAPTURE_FAILED_MSG": [],
  "ForwardMode": {
    "EXTEND": [],
    "DECODE": [],
    "MIXED": [],
    "IDLE": [],
    "TARGET_VERIFY": [],
    "DRAFT_EXTEND": [],
    "DRAFT_EXTEND_V2": [],
    "PREBUILT": [],
    "SPLIT_PREFILL": [],
    "DLLM_EXTEND": [],
    "is_prefill": [
      "self"
    ],
    "is_extend": [
      "self",
      "include_draft_extend_v2"
    ],
    "is_context_parallel_extend": [
      "self",
      "include_draft_extend_v2"
    ],
    "is_decode": [
      "self"
    ],
    "is_mixed": [
      "self"
    ],
    "is_idle": [
      "self"
    ],
    "is_decode_or_idle": [
      "self"
    ],
    "is_target_verify": [
      "self"
    ],
    "is_draft_extend": [
      "self",
      "include_v2"
    ],
    "is_draft_extend_v2": [
      "self"
    ],
    "is_extend_or_draft_extend_or_mixed": [
      "self",
      "include_draft_extend_v2"
    ],
    "is_cuda_graph": [
      "self"
    ],
    "is_cpu_graph": [
      "self"
    ],
    "is_split_prefill": [
      "self"
    ],
    "is_extend_without_speculative": [
      "self"
    ],
    "is_prebuilt": [
      "self"
    ],
    "is_dllm_extend": [
      "self"
    ]
  },
  "CaptureHiddenMode": {
    "NULL": [],
    "LAST": [],
    "FULL": [],
    "need_capture": [
      "self"
    ],
    "is_full": [
      "self"
    ],
    "is_last": [
      "self"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "compute_local_num_token_non_padded": [
    "global_num_token_non_padded",
    "num_tokens_per_dp"
  ],
  "ForwardBatch": {
    "init_new": [
      "cls",
      "batch",
      "model_runner"
    ],
    "adjust_num_token_non_padded_for_attn_tp": [
      "self",
      "server_args"
    ],
    "merge_mm_inputs": [
      "self"
    ],
    "contains_image_inputs": [
      "self"
    ],
    "contains_audio_inputs": [
      "self"
    ],
    "contains_video_inputs": [
      "self"
    ],
    "contains_mm_inputs": [
      "self"
    ],
    "_compute_spec_mrope_positions": [
      "self",
      "model_runner",
      "batch"
    ],
    "_expand_mrope_from_input": [
      "self",
      "mm_input",
      "seq_len"
    ],
    "_compute_mrope_positions": [
      "self",
      "model_runner",
      "batch"
    ],
    "_pad_tensor_to_size": [
      "self",
      "tensor",
      "size"
    ],
    "prepare_mlp_sync_batch": [
      "self",
      "model_runner"
    ],
    "_pad_inputs_to_size": [
      "self",
      "model_runner",
      "num_tokens",
      "bs"
    ],
    "prepare_attn_tp_scatter_input": [
      "self",
      "model_runner"
    ],
    "post_forward_mlp_sync_batch": [
      "self",
      "logits_output"
    ],
    "can_run_tbo": [
      "self"
    ]
  },
  "enable_num_token_non_padded": [
    "server_args"
  ],
  "PPProxyTensors": {
    "__init__": [
      "self",
      "tensors"
    ],
    "__getitem__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "__len__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ],
    "__repr__": [
      "self"
    ]
  },
  "compute_position": [
    "attn_backend",
    "extend_prefix_lens",
    "extend_seq_lens",
    "extend_seq_lens_sum"
  ],
  "compute_position_triton": [
    "extend_prefix_lens",
    "extend_seq_lens",
    "extend_seq_lens_sum"
  ],
  "compute_position_kernel": [
    "positions",
    "extend_start_loc",
    "extend_prefix_lens",
    "extend_seq_lens",
    "has_prefix"
  ],
  "compute_position_torch": [
    "extend_prefix_lens",
    "extend_seq_lens"
  ],
  "clamp_position": [
    "seq_lens"
  ],
  "_ENABLE_MM_DEEPGEMM": [],
  "_ENABLE_MM_FALLBACK_VARIANT": [],
  "_ENABLE_MM_COMPARISON_TEST": [],
  "_matmul_launch_metadata": [
    "grid",
    "kernel",
    "args"
  ],
  "_compute_pid": [
    "tile_id",
    "num_pid_in_group",
    "num_pid_m",
    "GROUP_SIZE_M",
    "NUM_SMS"
  ],
  "matmul_kernel_persistent": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "bias_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "NUM_SMS",
    "A_LARGE",
    "B_LARGE",
    "C_LARGE",
    "HAS_BIAS"
  ],
  "_matmul_persistent_triton": [
    "a",
    "b",
    "bias"
  ],
  "_matmul_persistent_deepgemm": [
    "a",
    "b",
    "bias"
  ],
  "matmul_persistent": [
    "a",
    "b",
    "bias"
  ],
  "_log_softmax_kernel": [
    "input_ptr",
    "output_ptr",
    "input_row_stride",
    "output_row_stride",
    "n_cols",
    "BLOCK_SIZE"
  ],
  "log_softmax": [
    "input",
    "dim"
  ],
  "mean_kernel": [
    "input_ptr",
    "output_ptr",
    "input_stride0",
    "input_stride1",
    "input_stride2",
    "output_stride0",
    "output_stride1",
    "M",
    "N",
    "K",
    "BLOCK_SIZE"
  ],
  "mean_dim": [
    "input",
    "dim",
    "keepdim",
    "dtype"
  ],
  "mm_batch_invariant": [
    "a",
    "b"
  ],
  "addmm_batch_invariant": [
    "bias",
    "a",
    "b"
  ],
  "_log_softmax_batch_invariant": [
    "input",
    "dim",
    "_half_to_float"
  ],
  "mean_batch_invariant": [
    "input",
    "dim",
    "keepdim",
    "dtype"
  ],
  "bmm_kernel_persistent": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "B",
    "M",
    "N",
    "K",
    "stride_ab",
    "stride_am",
    "stride_ak",
    "stride_bb",
    "stride_bk",
    "stride_bn",
    "stride_cb",
    "stride_cm",
    "stride_cn",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "NUM_SMS",
    "A_LARGE",
    "B_LARGE",
    "C_LARGE"
  ],
  "bmm_batch_invariant": [
    "a",
    "b"
  ],
  "_rms_norm_kernel": [
    "input_ptr",
    "weight_ptr",
    "output_ptr",
    "input_row_stride",
    "output_row_stride",
    "n_cols",
    "eps",
    "BLOCK_SIZE"
  ],
  "rms_norm": [
    "input",
    "weight",
    "eps"
  ],
  "rms_norm_batch_invariant": [
    "input",
    "weight",
    "eps"
  ],
  "_batch_invariant_MODE": [],
  "_batch_invariant_LIB": [],
  "_original_torch_bmm": [],
  "is_batch_invariant_mode_enabled": [],
  "enable_batch_invariant_mode": [
    "enable_bmm"
  ],
  "disable_batch_invariant_mode": [],
  "set_batch_invariant_mode": [
    "enabled"
  ],
  "AttentionBlockSize": [],
  "get_batch_invariant_attention_block_size": [],
  "LoRAOverlapLoadStatus": {
    "LOADED": [],
    "LOADING": [],
    "NOT_LOADED": []
  },
  "LoRAOverlapLoader": {
    "__init__": [
      "self",
      "lora_manager"
    ],
    "try_overlap_load_lora": [
      "self",
      "lora_id",
      "running_loras"
    ],
    "_check_overlap_load_status": [
      "self",
      "lora_id"
    ],
    "_try_start_overlap_load": [
      "self",
      "lora_id",
      "running_loras"
    ]
  },
  "LoRALayer": {
    "__init__": [
      "self",
      "config",
      "base_hf_config"
    ]
  },
  "LoRAAdapter": {
    "__init__": [
      "self",
      "uid",
      "config",
      "base_hf_config",
      "load_config",
      "lora_backend"
    ],
    "initialize_weights": [
      "self"
    ],
    "initialize_weights_from_tensors": [
      "self",
      "tensors"
    ],
    "_process_weight": [
      "self",
      "name",
      "loaded_weight"
    ],
    "_normalize_weights": [
      "self"
    ],
    "normalize_qkv_proj": [
      "self",
      "weight_names",
      "weights"
    ],
    "normalize_gate_up_proj": [
      "self",
      "weight_names",
      "weights"
    ],
    "pin_weights_in_cpu": [
      "self"
    ]
  },
  "EmptySlot": {
    "__slots__": [],
    "__repr__": [
      "self"
    ],
    "__new__": [
      "cls"
    ]
  },
  "EMPTY_SLOT": [],
  "LoRAMemoryPool": {
    "__init__": [
      "self",
      "base_hf_config",
      "max_loras_per_batch",
      "dtype",
      "tp_size",
      "tp_rank",
      "max_lora_rank",
      "target_modules",
      "base_model",
      "eviction_policy",
      "lora_added_tokens_size"
    ],
    "can_support": [
      "self",
      "config"
    ],
    "get_lora_A_shape": [
      "self",
      "module_name",
      "base_model",
      "max_lora_dim",
      "layer_idx"
    ],
    "get_embedding_lora_A_shape": [
      "self",
      "module_name",
      "base_model",
      "max_lora_dim",
      "layer_idx"
    ],
    "get_lora_B_shape": [
      "self",
      "module_name",
      "base_model",
      "max_lora_dim",
      "layer_idx"
    ],
    "get_embedding_lora_B_shape": [
      "self",
      "module_name",
      "base_model",
      "max_lora_dim",
      "layer_idx"
    ],
    "init_buffers": [
      "self",
      "base_model"
    ],
    "prepare_lora_batch": [
      "self",
      "cur_uids",
      "lora_adapters",
      "lora_modules",
      "lora_refs",
      "lora_embed_tokens_module",
      "lora_lm_head_module"
    ],
    "load_lora_weight_to_buffer": [
      "self",
      "uid",
      "buffer_id",
      "lora_adapter",
      "lora_modules",
      "lora_embed_tokens_module",
      "lora_lm_head_module"
    ],
    "get_embedding_tensor": [
      "self",
      "target_module",
      "lora_type"
    ],
    "get_tensor": [
      "self",
      "target_module",
      "layer_id",
      "lora_type"
    ],
    "get_buffer_id": [
      "self",
      "lora_uid"
    ]
  },
  "LoRABatchInfo": {},
  "LoRAType": {
    "LORA_A": [],
    "LORA_B": []
  },
  "get_hidden_dim": [
    "module_name",
    "config",
    "base_model",
    "layer_idx",
    "lora_added_vocab_size"
  ],
  "get_normalized_target_modules": [
    "target_modules"
  ],
  "get_stacked_multiply": [
    "module_name"
  ],
  "get_target_module_name": [
    "full_module_name",
    "target_modules"
  ],
  "EMBEDDING_NAMES": [],
  "ROW_PARALLELISM_LINEAR_LORA_NAMES": [],
  "generate_sequence_lengths": [
    "forward_batch",
    "device"
  ],
  "LoRARef": {
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "LoRARegistry": {
    "__init__": [
      "self",
      "lora_paths"
    ],
    "register": [
      "self",
      "lora_ref"
    ],
    "unregister": [
      "self",
      "lora_name"
    ],
    "acquire": [
      "self",
      "lora_name"
    ],
    "release": [
      "self",
      "lora_id"
    ],
    "wait_for_unload": [
      "self",
      "lora_id"
    ],
    "get_unregistered_loras": [
      "self",
      "lora_name"
    ],
    "lru_lora_name": [
      "self",
      "exclude_pinned"
    ],
    "_register_adapter": [
      "self",
      "lora_ref"
    ],
    "num_registered_loras": [
      "self"
    ],
    "get_all_adapters": [
      "self"
    ]
  },
  "BaseLayerWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "forward": [
      "self",
      "x"
    ],
    "set_lora_info": [
      "self"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "VocabParallelEmbeddingWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "set_lora_info": [
      "self",
      "new_embeddings_buffer",
      "embedding_A_buffer",
      "embedding_B_buffer"
    ],
    "apply_lora": [
      "self",
      "base_output",
      "input_",
      "batch_info"
    ],
    "run_lora_a_embedding": [
      "self",
      "input_",
      "batch_info"
    ],
    "extra_token_embedding": [
      "self",
      "input_",
      "base_output"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "ParallelLMHeadWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "set_lora_info": [
      "self",
      "lm_head_A_buffer",
      "lm_head_B_buffer"
    ],
    "apply_lora": [
      "self",
      "base_output",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "ColumnParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "set_lora_info": [
      "self",
      "A_buffer",
      "B_buffer"
    ],
    "apply_lora": [
      "self",
      "base_output",
      "x"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "MergedColumnParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "set_lora_info": [
      "self",
      "A_buffer",
      "B_buffer"
    ],
    "apply_lora": [
      "self",
      "base_output",
      "x"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "QKVParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "set_lora_info": [
      "self",
      "A_buffer_qkv",
      "B_buffer_qkv"
    ],
    "apply_lora": [
      "self",
      "base_output",
      "x"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "RowParallelLinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_backend"
    ],
    "set_lora_info": [
      "self",
      "A_buffer",
      "B_buffer"
    ],
    "apply_lora": [
      "self",
      "base_output",
      "x"
    ],
    "forward": [
      "self",
      "input_",
      "skip_all_reduce"
    ],
    "slice_lora_a_weights": [
      "self",
      "A",
      "tp_rank"
    ],
    "slice_lora_b_weights": [
      "self",
      "B",
      "tp_rank"
    ]
  },
  "get_lora_layer": [
    "layer",
    "lora_backend"
  ],
  "LoRAConfig": {
    "__init__": [
      "self",
      "path",
      "config_dict",
      "added_tokens_config"
    ],
    "from_dict": [
      "cls",
      "config_dict",
      "added_tokens_config"
    ],
    "get_lora_config": [
      "self",
      "dummy"
    ],
    "get_added_tokens_config": [
      "self"
    ]
  },
  "LoRAManager": {
    "__init__": [
      "self",
      "base_model",
      "base_hf_config",
      "max_loras_per_batch",
      "load_config",
      "dtype",
      "lora_backend",
      "tp_size",
      "tp_rank",
      "max_lora_rank",
      "target_modules",
      "lora_paths",
      "server_args"
    ],
    "init_cuda_graph_batch_info": [
      "self",
      "max_bs_in_cuda_graph",
      "num_tokens_per_bs"
    ],
    "create_lora_update_result": [
      "self",
      "success",
      "error_message"
    ],
    "load_lora_adapter": [
      "self",
      "lora_ref"
    ],
    "validate_new_adapter": [
      "self",
      "lora_config",
      "lora_ref"
    ],
    "unload_lora_adapter": [
      "self",
      "lora_ref"
    ],
    "validate_lora_batch": [
      "self",
      "lora_ids"
    ],
    "fetch_new_loras": [
      "self",
      "new_loras",
      "running_loras"
    ],
    "prepare_lora_batch": [
      "self",
      "forward_batch"
    ],
    "update_lora_info": [
      "self"
    ],
    "init_state": [
      "self",
      "max_lora_rank",
      "target_modules",
      "lora_paths"
    ],
    "init_lora_adapters": [
      "self",
      "lora_paths"
    ],
    "init_lora_shapes": [
      "self",
      "max_lora_rank",
      "target_modules"
    ],
    "load_lora_weights": [
      "self",
      "lora_ref"
    ],
    "load_lora_weights_from_tensors": [
      "self",
      "lora_ref",
      "tensors"
    ],
    "load_lora_adapter_from_tensors": [
      "self",
      "lora_ref",
      "tensors",
      "config_dict",
      "added_tokens_config"
    ],
    "init_memory_pool": [
      "self"
    ],
    "set_lora_module": [
      "self",
      "module_name",
      "module"
    ],
    "init_lora_modules": [
      "self"
    ]
  },
  "EvictionPolicy": {
    "mark_used": [
      "self",
      "uid"
    ],
    "select_victim": [
      "self",
      "candidates"
    ],
    "remove": [
      "self",
      "uid"
    ]
  },
  "LRUEvictionPolicy": {
    "__init__": [
      "self"
    ],
    "mark_used": [
      "self",
      "uid"
    ],
    "select_victim": [
      "self",
      "candidates"
    ],
    "remove": [
      "self",
      "uid"
    ]
  },
  "FIFOEvictionPolicy": {
    "__init__": [
      "self"
    ],
    "mark_used": [
      "self",
      "uid"
    ],
    "select_victim": [
      "self",
      "candidates"
    ],
    "remove": [
      "self",
      "uid"
    ]
  },
  "get_eviction_policy": [
    "policy_name"
  ],
  "_gate_up_lora_b_kernel": [
    "x",
    "weights",
    "output",
    "K",
    "output_dim",
    "x_stride_0",
    "x_stride_1",
    "w_stride_0",
    "w_stride_1",
    "w_stride_2",
    "output_stride_0",
    "output_stride_1",
    "seg_lens",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "BLOCK_S",
    "BLOCK_N",
    "BLOCK_K",
    "scalings"
  ],
  "gate_up_lora_b_fwd": [
    "x",
    "gate_up_lora_b",
    "batch_info",
    "output_dim",
    "base_output"
  ],
  "_embedding_lora_a_kernel": [
    "input_ids",
    "weights",
    "output",
    "extra_embeddings",
    "vocab_size",
    "rank",
    "num_loras",
    "w_stride_0",
    "w_stride_1",
    "w_stride_2",
    "output_stride_0",
    "output_stride_1",
    "extra_emb_stride_0",
    "extra_emb_stride_1",
    "extra_emb_stride_2",
    "seg_lens",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "BLOCK_RANK",
    "HAS_EXTRA_EMBEDDINGS"
  ],
  "embedding_lora_a_fwd": [
    "input_ids",
    "weights",
    "batch_info",
    "vocab_size",
    "extra_embeddings"
  ],
  "_qkv_lora_b_kernel": [
    "x",
    "weights",
    "output",
    "K",
    "max_qkv_out_dim",
    "x_stride_0",
    "x_stride_1",
    "w_stride_0",
    "w_stride_1",
    "w_stride_2",
    "output_stride_0",
    "output_stride_1",
    "seg_lens",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "n_offs",
    "BLOCK_S",
    "BLOCK_N",
    "BLOCK_K",
    "scalings"
  ],
  "qkv_lora_b_fwd": [
    "x",
    "qkv_lora_b",
    "batch_info",
    "output_offset",
    "max_qkv_out_dim",
    "base_output"
  ],
  "_chunked_lora_shrink_kernel": [
    "x",
    "weights",
    "output",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "permutation",
    "num_segs",
    "N",
    "K",
    "NUM_SLICES",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K"
  ],
  "chunked_sgmv_lora_shrink_forward": [
    "x",
    "weights",
    "batch_info",
    "num_slices"
  ],
  "_chunked_lora_expand_kernel": [
    "x",
    "weights",
    "output",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "permutation",
    "num_segs",
    "scalings",
    "slice_offsets",
    "NUM_SLICES",
    "OUTPUT_DIM",
    "MAX_RANK",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K"
  ],
  "chunked_sgmv_lora_expand_forward": [
    "x",
    "weights",
    "batch_info",
    "slice_offsets",
    "max_slice_size",
    "base_output"
  ],
  "_sgemm_lora_a_kernel": [
    "x",
    "weights",
    "output",
    "N",
    "K",
    "stack_num",
    "x_stride_0",
    "x_stride_1",
    "w_stride_0",
    "w_stride_1",
    "w_stride_2",
    "output_stride_0",
    "output_stride_1",
    "seg_lens",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "BLOCK_S",
    "BLOCK_N",
    "BLOCK_K"
  ],
  "sgemm_lora_a_fwd": [
    "x",
    "weights",
    "batch_info",
    "stack_num"
  ],
  "_sgemm_lora_b_kernel": [
    "x",
    "weights",
    "output",
    "N",
    "K",
    "x_stride_0",
    "x_stride_1",
    "w_stride_0",
    "w_stride_1",
    "w_stride_2",
    "output_stride_0",
    "output_stride_1",
    "seg_lens",
    "seg_indptr",
    "weight_indices",
    "lora_ranks",
    "BLOCK_S",
    "BLOCK_N",
    "BLOCK_K",
    "scalings"
  ],
  "sgemm_lora_b_fwd": [
    "x",
    "weights",
    "batch_info",
    "base_output"
  ],
  "AscendLoRABackend": {
    "name": [],
    "__init__": [
      "self",
      "max_loras_per_batch",
      "device"
    ],
    "run_lora_a_sgemm": [
      "self",
      "x",
      "weights"
    ],
    "run_lora_b_sgemm": [
      "self",
      "x",
      "weights",
      "base_output"
    ],
    "run_qkv_lora": [
      "self",
      "x",
      "qkv_lora_a",
      "qkv_lora_b",
      "output_offset",
      "output_offset_cpu",
      "max_qkv_out_dim",
      "base_output"
    ],
    "run_gate_up_lora": [
      "self",
      "x",
      "gate_up_lora_a",
      "gate_up_lora_b",
      "base_output"
    ],
    "init_cuda_graph_batch_info": [
      "self",
      "max_bs_in_cuda_graph",
      "num_tokens_per_bs"
    ],
    "prepare_lora_batch": [
      "self",
      "forward_batch",
      "weight_indices",
      "lora_ranks",
      "scalings",
      "use_cuda_graph"
    ]
  },
  "MIN_CHUNK_SIZE": [],
  "ChunkedSgmvLoRABackend": {
    "name": [],
    "__init__": [
      "self",
      "max_loras_per_batch",
      "device",
      "server_args"
    ],
    "run_lora_a_sgemm": [
      "self",
      "x",
      "weights"
    ],
    "run_lora_b_sgemm": [
      "self",
      "x",
      "weights",
      "output_offset",
      "base_output"
    ],
    "run_qkv_lora": [
      "self",
      "x",
      "qkv_lora_a",
      "qkv_lora_b",
      "output_offset",
      "max_qkv_out_dim",
      "base_output"
    ],
    "run_gate_up_lora": [
      "self",
      "x",
      "gate_up_lora_a",
      "gate_up_lora_b",
      "output_offset",
      "base_output"
    ],
    "_determine_chunk_size": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_batch_info": [
      "self",
      "max_bs_in_cuda_graph",
      "num_tokens_per_bs"
    ],
    "prepare_lora_batch": [
      "self",
      "forward_batch",
      "weight_indices",
      "lora_ranks",
      "scalings",
      "use_cuda_graph"
    ],
    "_get_permutation": [
      "seq_weight_indices",
      "forward_batch"
    ],
    "_get_segments_info": [
      "self",
      "weights_reordered",
      "chunk_size"
    ]
  },
  "TritonLoRABackend": {
    "name": [],
    "__init__": [
      "self",
      "max_loras_per_batch",
      "device"
    ],
    "run_lora_a_embedding": [
      "self",
      "input_ids",
      "weights",
      "vocab_size",
      "extra_embeddings"
    ],
    "run_lora_a_sgemm": [
      "self",
      "x",
      "weights"
    ],
    "run_lora_b_sgemm": [
      "self",
      "x",
      "weights",
      "base_output"
    ],
    "run_qkv_lora": [
      "self",
      "x",
      "qkv_lora_a",
      "qkv_lora_b",
      "output_offset",
      "max_qkv_out_dim",
      "base_output"
    ],
    "run_gate_up_lora": [
      "self",
      "x",
      "gate_up_lora_a",
      "gate_up_lora_b",
      "base_output"
    ],
    "init_cuda_graph_batch_info": [
      "self",
      "max_bs_in_cuda_graph",
      "num_tokens_per_bs"
    ],
    "prepare_lora_batch": [
      "self",
      "forward_batch",
      "weight_indices",
      "lora_ranks",
      "scalings",
      "use_cuda_graph"
    ]
  },
  "LORA_SUPPORTED_BACKENDS": [],
  "register_lora_backend": [
    "name"
  ],
  "create_triton_backend": [],
  "create_triton_csgmv_backend": [],
  "create_ascend_backend": [],
  "create_torch_native_backend": [],
  "create_flashinfer_backend": [],
  "get_backend_from_name": [
    "name"
  ],
  "BaseLoRABackend": {
    "__init__": [
      "self",
      "max_loras_per_batch",
      "device"
    ],
    "run_lora_a_embedding": [
      "self",
      "input_ids",
      "weights",
      "vocab_size",
      "extra_embeddings"
    ],
    "run_extra_token_embedding": [
      "self",
      "input_ids",
      "output",
      "extra_embeddings",
      "vocab_size"
    ],
    "run_lora_a_sgemm": [
      "self",
      "x",
      "weights"
    ],
    "run_lora_b_sgemm": [
      "self",
      "x",
      "weights"
    ],
    "run_qkv_lora": [
      "self",
      "x",
      "qkv_lora_a",
      "qkv_lora_b"
    ],
    "run_gate_up_lora": [
      "self",
      "x",
      "gate_up_lora_a",
      "gate_up_lora_b"
    ],
    "init_cuda_graph_batch_info": [
      "self",
      "max_bs_in_cuda_graph",
      "num_tokens_per_bs"
    ],
    "prepare_lora_batch": [
      "self",
      "forward_batch",
      "weight_indices",
      "lora_ranks",
      "scalings",
      "use_cuda_graph"
    ]
  },
  "TorchNativeLoRABatchInfo": {},
  "TorchNativeLoRABackend": {
    "name": [],
    "__init__": [
      "self",
      "max_loras_per_batch",
      "device"
    ],
    "run_lora_a_sgemm": [
      "self",
      "x",
      "weights"
    ],
    "run_lora_b_sgemm": [
      "self",
      "x",
      "weights",
      "base_output"
    ],
    "run_qkv_lora": [
      "self",
      "x",
      "qkv_lora_a",
      "qkv_lora_b",
      "output_offset",
      "output_offset_cpu",
      "max_qkv_out_dim",
      "base_output"
    ],
    "run_gate_up_lora": [
      "self",
      "x",
      "gate_up_lora_a",
      "gate_up_lora_b",
      "base_output"
    ],
    "init_cuda_graph_batch_info": [
      "self",
      "max_bs_in_cuda_graph",
      "num_tokens_per_bs"
    ],
    "prepare_lora_batch": [
      "self",
      "forward_batch",
      "weight_indices",
      "lora_ranks",
      "scalings",
      "use_cuda_graph"
    ]
  },
  "ensure_divisibility": [
    "numerator",
    "denominator"
  ],
  "divide": [
    "numerator",
    "denominator"
  ],
  "split_tensor_along_last_dim": [
    "tensor",
    "num_partitions",
    "contiguous_split_chunks"
  ],
  "get_pp_indices": [
    "num_hidden_layers",
    "pp_rank",
    "pp_size"
  ],
  "StatelessProcessGroup": {
    "__post_init__": [
      "self"
    ],
    "send_obj": [
      "self",
      "obj",
      "dst"
    ],
    "expire_data": [
      "self"
    ],
    "recv_obj": [
      "self",
      "src"
    ],
    "broadcast_obj": [
      "self",
      "obj",
      "src"
    ],
    "all_gather_obj": [
      "self",
      "obj"
    ],
    "barrier": [
      "self"
    ],
    "create": [
      "host",
      "port",
      "rank",
      "world_size",
      "data_expiration_seconds"
    ]
  },
  "NaiveDistributed": {
    "__init__": [
      "self",
      "rank",
      "world_size",
      "rendezvous"
    ],
    "get_rank": [
      "self"
    ],
    "get_world_size": [
      "self"
    ],
    "scatter": [
      "self",
      "tensor",
      "scatter_list",
      "src"
    ],
    "all_gather_object": [
      "self",
      "obj"
    ],
    "barrier": [
      "self"
    ]
  },
  "get_naive_distributed": [],
  "set_naive_distributed": [
    "instance"
  ],
  "_is_cpu": [],
  "TensorMetadata": [],
  "REDUCE_OP_SUM": [],
  "GraphCaptureContext": {},
  "P2PWork": {},
  "_split_tensor_dict": [
    "tensor_dict"
  ],
  "_get_unique_name": [
    "name"
  ],
  "_register_group": [
    "group"
  ],
  "inplace_all_reduce": [
    "tensor",
    "group_name"
  ],
  "outplace_all_reduce": [
    "tensor",
    "group_name",
    "outplace_all_reduce_method"
  ],
  "reg_all_gather_into_tensor": [
    "output",
    "input",
    "group_name"
  ],
  "reg_reduce_scatter_tensor": [
    "output",
    "input",
    "group_name"
  ],
  "GroupCoordinator": {
    "__init__": [
      "self",
      "group_ranks",
      "local_rank",
      "torch_distributed_backend",
      "use_pynccl",
      "use_pymscclpp",
      "use_custom_allreduce",
      "use_torch_symm_mem_all_reduce",
      "use_hpu_communicator",
      "use_xpu_communicator",
      "use_npu_communicator",
      "use_message_queue_broadcaster",
      "group_name",
      "pynccl_use_current_stream",
      "gloo_timeout"
    ],
    "__repr__": [
      "self"
    ],
    "first_rank": [
      "self"
    ],
    "last_rank": [
      "self"
    ],
    "is_first_rank": [
      "self"
    ],
    "is_last_rank": [
      "self"
    ],
    "next_rank": [
      "self"
    ],
    "prev_rank": [
      "self"
    ],
    "graph_capture": [
      "self",
      "graph_capture_context",
      "stream"
    ],
    "all_reduce": [
      "self",
      "input_"
    ],
    "_all_reduce_out_place": [
      "self",
      "input_",
      "outplace_all_reduce_method"
    ],
    "_all_reduce_in_place": [
      "self",
      "input_"
    ],
    "_reduce_scatter_tensor": [
      "self",
      "output",
      "input"
    ],
    "reduce_scatter_tensor": [
      "self",
      "output",
      "input"
    ],
    "reduce_scatter": [
      "self",
      "output",
      "input_list"
    ],
    "reduce_scatterv": [
      "self",
      "input_",
      "output",
      "sizes"
    ],
    "_all_gather_into_tensor": [
      "self",
      "output",
      "input"
    ],
    "all_gather_into_tensor": [
      "self",
      "output",
      "input"
    ],
    "cp_all_gather_into_tensor_async": [
      "self",
      "output",
      "input",
      "stream"
    ],
    "all_gather": [
      "self",
      "input_",
      "dim",
      "output_tensor_list"
    ],
    "all_gatherv": [
      "self",
      "input_",
      "sizes"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "broadcast": [
      "self",
      "input_",
      "src"
    ],
    "broadcast_object": [
      "self",
      "obj",
      "src"
    ],
    "broadcast_object_list": [
      "self",
      "obj_list",
      "src",
      "group"
    ],
    "all_gather_object": [
      "self",
      "obj"
    ],
    "send_object": [
      "self",
      "obj",
      "dst",
      "async_send"
    ],
    "recv_object": [
      "self",
      "src"
    ],
    "broadcast_tensor_dict": [
      "self",
      "tensor_dict",
      "src",
      "group",
      "metadata_group"
    ],
    "send_tensor_dict": [
      "self",
      "tensor_dict",
      "dst",
      "all_gather_group",
      "async_send"
    ],
    "recv_tensor_dict": [
      "self",
      "src",
      "all_gather_group"
    ],
    "barrier": [
      "self"
    ],
    "send": [
      "self",
      "tensor",
      "dst"
    ],
    "recv": [
      "self",
      "size",
      "dtype",
      "src"
    ],
    "destroy": [
      "self"
    ]
  },
  "get_world_group": [],
  "init_world_group": [
    "ranks",
    "local_rank",
    "backend"
  ],
  "init_model_parallel_group": [
    "group_ranks",
    "local_rank",
    "backend",
    "use_custom_allreduce",
    "use_message_queue_broadcaster",
    "group_name",
    "use_mscclpp_allreduce",
    "pynccl_use_current_stream",
    "use_torch_symm_mem_allreduce"
  ],
  "set_pdmux_status": [
    "enable_prefill_multiplexing"
  ],
  "get_tp_group": [],
  "get_moe_ep_group": [],
  "get_moe_tp_group": [],
  "get_tensor_model_parallel_group": [],
  "get_pp_group": [],
  "get_pipeline_model_parallel_group": [],
  "graph_capture": [
    "stream"
  ],
  "_ENABLE_CUSTOM_ALL_REDUCE": [],
  "_ENABLE_MSCCLPP_ALL_REDUCE": [],
  "_ENABLE_TORCH_SYMM_MEM_ALL_REDUCE": [],
  "set_custom_all_reduce": [
    "enable"
  ],
  "set_mscclpp_all_reduce": [
    "enable"
  ],
  "set_torch_symm_mem_all_reduce": [
    "enable"
  ],
  "init_distributed_environment": [
    "world_size",
    "rank",
    "distributed_init_method",
    "local_rank",
    "backend",
    "timeout"
  ],
  "initialize_model_parallel": [
    "tensor_model_parallel_size",
    "expert_model_parallel_size",
    "pipeline_model_parallel_size",
    "backend",
    "duplicate_tp_group"
  ],
  "create_custom_parallel_group": [
    "group_ranks",
    "backend"
  ],
  "ensure_model_parallel_initialized": [
    "tensor_model_parallel_size",
    "expert_model_parallel_size",
    "pipeline_model_parallel_size",
    "backend"
  ],
  "model_parallel_is_initialized": [],
  "_TP_STATE_PATCHED": [],
  "patch_tensor_parallel_group": [
    "tp_group"
  ],
  "get_world_size": [],
  "get_world_rank": [],
  "get_tensor_model_parallel_world_size": [],
  "get_tensor_model_parallel_rank": [],
  "get_pipeline_model_parallel_world_size": [],
  "get_pipeline_model_parallel_rank": [],
  "get_moe_expert_parallel_world_size": [],
  "get_moe_expert_parallel_rank": [],
  "get_moe_tensor_parallel_world_size": [],
  "get_moe_tensor_parallel_rank": [],
  "destroy_model_parallel": [],
  "destroy_distributed_environment": [],
  "cleanup_dist_env_and_memory": [
    "shutdown_ray"
  ],
  "in_the_same_node_as": [
    "pg",
    "source_rank"
  ],
  "vllm_get_pp_group": [],
  "vllm_get_tp_group": [],
  "vllm_get_world_group": [],
  "monkey_patch_vllm_parallel_state": [
    "reverse"
  ],
  "tensor_model_parallel_all_reduce": [
    "input_"
  ],
  "tensor_model_parallel_all_gather": [
    "input_",
    "dim"
  ],
  "tensor_model_parallel_gather": [
    "input_",
    "dst",
    "dim"
  ],
  "broadcast_tensor_dict": [
    "tensor_dict",
    "src"
  ],
  "IS_CUSTOM_AR_AVAILABLE": [],
  "IS_QUICK_AR_AVAILABLE": [],
  "IS_MSCCLPP_AR_AVAILABLE": [],
  "PyNcclCommunicator": {
    "__init__": [
      "self",
      "group",
      "device",
      "library_path",
      "use_current_stream"
    ],
    "_resolve_stream": [
      "self",
      "stream"
    ],
    "all_reduce": [
      "self",
      "tensor",
      "op",
      "stream"
    ],
    "all_gather": [
      "self",
      "output_tensor",
      "input_tensor",
      "stream",
      "sizes"
    ],
    "cp_all_gather_into_tensor": [
      "self",
      "output_tensor",
      "input_tensor",
      "stream",
      "sizes"
    ],
    "reduce_scatter": [
      "self",
      "output_tensor",
      "input_tensor",
      "op",
      "stream",
      "sizes"
    ],
    "send": [
      "self",
      "tensor",
      "dst",
      "stream"
    ],
    "recv": [
      "self",
      "tensor",
      "src",
      "stream"
    ],
    "broadcast": [
      "self",
      "tensor",
      "src",
      "stream"
    ],
    "register_comm_window_raw": [
      "self",
      "ptr",
      "size"
    ],
    "deregister_comm_window": [
      "self",
      "window"
    ],
    "group_start": [
      "self"
    ],
    "group_end": [
      "self"
    ],
    "change_state": [
      "self",
      "enable",
      "stream"
    ]
  },
  "_P": [],
  "_R": [],
  "update_environment_variables": [
    "envs"
  ],
  "producer": [
    "batch_src",
    "producer_queue",
    "consumer_queue",
    "result_queue",
    "cuda_visible_devices"
  ],
  "consumer": [
    "batch_tgt",
    "producer_queue",
    "consumer_queue",
    "result_queue",
    "cuda_visible_devices"
  ],
  "can_actually_p2p": [
    "batch_src",
    "batch_tgt"
  ],
  "gpu_p2p_access_check": [
    "src",
    "tgt"
  ],
  "with_nvml_context": [
    "fn"
  ],
  "is_full_nvlink": [
    "physical_device_ids",
    "world_size"
  ],
  "is_weak_contiguous": [
    "inp"
  ],
  "find_nccl_library": [],
  "ncclResult_t": [],
  "ncclComm_t": [],
  "ncclWindow_t": [],
  "ncclUniqueId": {
    "_fields_": []
  },
  "cudaStream_t": [],
  "buffer_type": [],
  "ncclDataType_t": [],
  "ncclDataTypeEnum": {
    "ncclInt8": [],
    "ncclChar": [],
    "ncclUint8": [],
    "ncclInt32": [],
    "ncclInt": [],
    "ncclUint32": [],
    "ncclInt64": [],
    "ncclUint64": [],
    "ncclFloat16": [],
    "ncclHalf": [],
    "ncclFloat32": [],
    "ncclFloat": [],
    "ncclFloat64": [],
    "ncclDouble": [],
    "ncclBfloat16": [],
    "ncclNumTypes": [],
    "from_torch": [
      "cls",
      "dtype"
    ]
  },
  "ncclRedOp_t": [],
  "ncclRedOpTypeEnum": {
    "ncclSum": [],
    "ncclProd": [],
    "ncclMax": [],
    "ncclMin": [],
    "ncclAvg": [],
    "ncclNumOps": [],
    "from_torch": [
      "cls",
      "op"
    ]
  },
  "NCCLLibrary": {
    "exported_functions": [],
    "exported_functions_symm_mem": [],
    "__init__": [
      "self",
      "so_file"
    ],
    "ncclGetErrorString": [
      "self",
      "result"
    ],
    "NCCL_CHECK": [
      "self",
      "result"
    ],
    "ncclGetRawVersion": [
      "self"
    ],
    "ncclGetVersion": [
      "self"
    ],
    "ncclGetUniqueId": [
      "self"
    ],
    "ncclCommInitRank": [
      "self",
      "world_size",
      "unique_id",
      "rank"
    ],
    "ncclAllReduce": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "op",
      "comm",
      "stream"
    ],
    "ncclReduce": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "op",
      "root",
      "comm",
      "stream"
    ],
    "ncclReduceScatter": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "op",
      "comm",
      "stream"
    ],
    "ncclAllGather": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "comm",
      "stream"
    ],
    "ncclSend": [
      "self",
      "sendbuff",
      "count",
      "datatype",
      "dest",
      "comm",
      "stream"
    ],
    "ncclRecv": [
      "self",
      "recvbuff",
      "count",
      "datatype",
      "src",
      "comm",
      "stream"
    ],
    "ncclBroadcast": [
      "self",
      "sendbuff",
      "recvbuff",
      "count",
      "datatype",
      "root",
      "comm",
      "stream"
    ],
    "ncclCommDestroy": [
      "self",
      "comm"
    ],
    "ncclCommWindowRegister": [
      "self",
      "comm",
      "buff",
      "size",
      "win_flags"
    ],
    "ncclCommWindowDeregister": [
      "self",
      "comm",
      "window"
    ],
    "ncclGroupStart": [
      "self"
    ],
    "ncclGroupEnd": [
      "self"
    ]
  },
  "HpuCommunicator": {
    "__init__": [
      "self",
      "group"
    ],
    "all_reduce": [
      "self",
      "x"
    ],
    "all_gather": [
      "self",
      "x",
      "dim"
    ]
  },
  "after_2_8_0": [],
  "nccl_allocator_source": [],
  "_allocator": [],
  "_mem_pool": [],
  "_graph_pool_id": [],
  "_cur_device": [],
  "_active_symmetric_memory_context": [],
  "is_symmetric_memory_enabled": [],
  "set_graph_pool_id": [
    "graph_pool_id"
  ],
  "disable_symmetric_memory_context": [],
  "restore_symmetric_memory_context": [
    "saved_context"
  ],
  "get_nccl_mem_pool": [],
  "SymmetricMemoryContext": {
    "__init__": [
      "self",
      "group_coordinator"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "use_symmetric_memory": [
    "group_coordinator",
    "disabled"
  ],
  "XpuCommunicator": {
    "__init__": [
      "self",
      "group"
    ],
    "all_reduce": [
      "self",
      "x"
    ],
    "gather": [
      "self",
      "input_",
      "rank_in_group",
      "dst",
      "dim"
    ]
  },
  "MiB": [],
  "TORCH_SYMM_MEM_ALL_REDUCE_MAX_SIZES": [],
  "NpuCommunicator": {
    "__init__": [
      "self",
      "group"
    ],
    "all_reduce": [
      "self",
      "x"
    ],
    "all_gather": [
      "self",
      "x",
      "dim"
    ]
  },
  "_can_p2p": [
    "rank",
    "world_size"
  ],
  "CustomAllreduce": {
    "_SUPPORTED_WORLD_SIZES": [],
    "_MAX_CAR_SIZE": [],
    "__init__": [
      "self",
      "group",
      "device",
      "max_size"
    ],
    "create_shared_buffer": [
      "size_in_bytes",
      "group"
    ],
    "free_shared_buffer": [
      "pointers",
      "group"
    ],
    "capture": [
      "self"
    ],
    "_get_ipc_meta": [
      "self",
      "inp"
    ],
    "_gather_ipc_meta": [
      "self",
      "shard_data"
    ],
    "register_buffer": [
      "self",
      "inp"
    ],
    "register_graph_buffers": [
      "self"
    ],
    "should_custom_ar": [
      "self",
      "inp"
    ],
    "all_reduce_reg": [
      "self",
      "inp",
      "out"
    ],
    "all_reduce_unreg": [
      "self",
      "inp",
      "out"
    ],
    "all_reduce": [
      "self",
      "inp"
    ],
    "deterministic_all_reduce": [
      "self",
      "inp"
    ],
    "custom_all_reduce": [
      "self",
      "input"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "dispatch_custom_allreduce": [],
  "qr_rocm_arch_available": [],
  "QuickReduceRegime": {
    "FP": [],
    "INT8": [],
    "INT6": [],
    "INT4": [],
    "NONE": []
  },
  "MB": [],
  "QuickAllReduce": {
    "_SUPPORTED_WORLD_SIZES": [],
    "_SUPPORTED_DTYPES": [],
    "_QR_MIN_SIZE": [],
    "__init__": [
      "self",
      "group",
      "device"
    ],
    "init_quick_all_reduce": [
      "self"
    ],
    "create_shared_buffer": [
      "self"
    ],
    "should_quick_allreduce": [
      "self",
      "inp"
    ],
    "quick_all_reduce": [
      "self",
      "inp"
    ],
    "close": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "cudaError_t": [],
  "cudaMemcpyKind": [],
  "cudaIpcMemHandle_t": {
    "_fields_": []
  },
  "find_loaded_library": [
    "lib_name"
  ],
  "CudaRTLibrary": {
    "exported_functions": [],
    "__init__": [
      "self",
      "so_file"
    ],
    "CUDART_CHECK": [
      "self",
      "result"
    ],
    "cudaGetErrorString": [
      "self",
      "error"
    ],
    "cudaSetDevice": [
      "self",
      "device"
    ],
    "cudaDeviceSynchronize": [
      "self"
    ],
    "cudaDeviceReset": [
      "self"
    ],
    "cudaMalloc": [
      "self",
      "size"
    ],
    "cudaFree": [
      "self",
      "devPtr"
    ],
    "cudaMemset": [
      "self",
      "devPtr",
      "value",
      "count"
    ],
    "cudaMemcpy": [
      "self",
      "dst",
      "src",
      "count"
    ],
    "cudaIpcGetMemHandle": [
      "self",
      "devPtr"
    ],
    "cudaIpcOpenMemHandle": [
      "self",
      "handle"
    ]
  },
  "TorchSymmMemCommunicator": {
    "_WORLD_SIZES_MULTIMEM": [],
    "__init__": [
      "self",
      "group",
      "device"
    ],
    "should_torch_symm_mem_allreduce": [
      "self",
      "inp"
    ],
    "all_reduce": [
      "self",
      "inp"
    ]
  },
  "MscclContextSelection": {
    "MSCCL1SHOT1NODELL": [],
    "MSCCL1SHOT2NODELL": []
  },
  "mscclpp_is_weak_contiguous": [
    "inp"
  ],
  "mscclpp_convert_to_bytes": [
    "size_str"
  ],
  "mscclpp_bench_time": [
    "func",
    "test_niter",
    "warmup_niter"
  ],
  "PyMscclppCommunicator": {
    "_SUPPORTED_WORLD_SIZES": [],
    "_MAX_BYTES": [],
    "_SUPPORTED_DTYPE": [],
    "__init__": [
      "self",
      "group",
      "device",
      "max_bytes"
    ],
    "pre_tune_config": [
      "self",
      "dtype"
    ],
    "should_mscclpp_allreduce": [
      "self",
      "inp",
      "op"
    ],
    "all_reduce": [
      "self",
      "tensor",
      "op"
    ],
    "change_state": [
      "self",
      "enable"
    ]
  },
  "SGLANG_RINGBUFFER_WARNING_INTERVAL": [],
  "ShmRingBuffer": {
    "__init__": [
      "self",
      "n_reader",
      "max_chunk_bytes",
      "max_chunks",
      "name"
    ],
    "__reduce__": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "get_data": [
      "self",
      "current_idx"
    ],
    "get_metadata": [
      "self",
      "current_idx"
    ]
  },
  "Handle": {},
  "MessageQueue": {
    "__init__": [
      "self",
      "n_reader",
      "n_local_reader",
      "local_reader_ranks",
      "max_chunk_bytes",
      "max_chunks",
      "connect_ip"
    ],
    "export_handle": [
      "self"
    ],
    "create_from_handle": [
      "handle",
      "rank"
    ],
    "wait_until_ready": [
      "self"
    ],
    "acquire_write": [
      "self"
    ],
    "acquire_read": [
      "self"
    ],
    "enqueue": [
      "self",
      "obj"
    ],
    "dequeue": [
      "self"
    ],
    "broadcast_object": [
      "self",
      "obj"
    ],
    "create_from_process_group": [
      "pg",
      "max_chunk_bytes",
      "max_chunks",
      "writer_rank"
    ]
  },
  "KimiK2Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "JsonArrayParser": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "Qwen3CoderDetector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "_get_arguments_config": [
      "self",
      "func_name",
      "tools"
    ],
    "_convert_param_value": [
      "self",
      "param_value",
      "param_name",
      "param_config",
      "func_name"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "Llama32Detector": {
    "__init__": [
      "self"
    ],
    "_convert_python_dict_to_json": [
      "self",
      "text"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "MistralDetector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_try_parse_compact_args_format": [
      "self",
      "text"
    ],
    "_extract_json_value": [
      "self",
      "text",
      "json_start"
    ],
    "_extract_json_array": [
      "self",
      "text"
    ],
    "structure_info": [
      "self"
    ]
  },
  "get_argument_type": [
    "func_name",
    "arg_key",
    "defined_tools"
  ],
  "parse_arguments": [
    "value"
  ],
  "Step3Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "_parse_steptml_invoke": [
      "self",
      "text",
      "tools"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_parse_partial_tool_call": [
      "self",
      "tools"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "PythonicDetector": {
    "__init__": [
      "self"
    ],
    "_text_strip": [
      "text"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "_find_matching_bracket": [
      "self",
      "buffer",
      "start"
    ],
    "_strip_and_split_buffer": [
      "self",
      "buffer"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_get_parameter_value": [
      "self",
      "val"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "_find_common_prefix": [
    "s1",
    "s2"
  ],
  "_partial_json_loads": [
    "input_str",
    "flags"
  ],
  "_is_complete_json": [
    "input_str"
  ],
  "_get_tool_schema_defs": [
    "tools"
  ],
  "_get_tool_schema": [
    "tool"
  ],
  "infer_type_from_json_schema": [
    "schema"
  ],
  "get_json_schema_constraint": [
    "tools",
    "tool_choice"
  ],
  "_get_param_type": [
    "func_name",
    "param_name",
    "tools"
  ],
  "_convert_param_value": [
    "param_value",
    "param_name",
    "func_name",
    "tools"
  ],
  "MiMoDetector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_parse_tool_call": [
      "self",
      "tool_call_body",
      "tools"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "DeepSeekV32Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "_parse_parameters_from_xml": [
      "self",
      "invoke_content",
      "allow_partial"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "TrinityDetector": {
    "_strip_think_tags": [
      "self",
      "text"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ]
  },
  "BaseFormatDetector": {
    "__init__": [
      "self"
    ],
    "_get_tool_indices": [
      "self",
      "tools"
    ],
    "parse_base_json": [
      "self",
      "action",
      "tools"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "_ends_with_partial_token": [
      "self",
      "buffer",
      "bot_token"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "DeepSeekV31Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "FunctionCallParser": {
    "__init__": [
      "self",
      "tools",
      "tool_call_parser"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "parse_non_stream": [
      "self",
      "full_text"
    ],
    "parse_stream_chunk": [
      "self",
      "chunk_text"
    ],
    "get_structure_tag": [
      "self"
    ],
    "get_structure_constraint": [
      "self",
      "tool_choice"
    ]
  },
  "StreamState": {
    "INIT": [],
    "BETWEEN": [],
    "IN_KEY": [],
    "WAITING_VALUE": [],
    "IN_VALUE": []
  },
  "_convert_to_number": [
    "value"
  ],
  "Glm47MoeDetector": {
    "__init__": [
      "self"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "_get_value_type": [
      "self",
      "func_name",
      "key",
      "tools"
    ],
    "_format_value_complete": [
      "self",
      "value",
      "value_type"
    ],
    "_process_xml_to_json_streaming": [
      "self",
      "raw_increment",
      "func_name",
      "tools"
    ],
    "_extract_match_groups": [
      "self",
      "match"
    ],
    "_send_tool_name_if_needed": [
      "self",
      "func_name",
      "has_arg_key",
      "is_tool_end"
    ],
    "_process_arguments_streaming": [
      "self",
      "func_name",
      "func_args_raw",
      "tools"
    ],
    "_finalize_tool_call": [
      "self",
      "func_name",
      "func_args_raw",
      "tools",
      "match_end_pos",
      "current_text"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_parse_argument_pairs": [
      "self",
      "pairs",
      "func_name",
      "tools"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "InternlmDetector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "get_arguments": [
      "self",
      "obj"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "ToolCallItem": {},
  "StructureInfo": {},
  "_GetInfoFunc": [],
  "DeepSeekV3Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "Qwen25Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "structure_info": [
      "self"
    ]
  },
  "Glm4MoeDetector": {
    "__init__": [
      "self"
    ],
    "_reset_streaming_state": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "_get_value_type": [
      "self",
      "func_name",
      "key",
      "tools"
    ],
    "_format_value_complete": [
      "self",
      "value",
      "value_type"
    ],
    "_process_xml_to_json_streaming": [
      "self",
      "raw_increment",
      "func_name",
      "tools"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_parse_argument_pairs": [
      "self",
      "pairs",
      "func_name",
      "tools"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "MinimaxM2Detector": {
    "__init__": [
      "self"
    ],
    "has_tool_call": [
      "self",
      "text"
    ],
    "detect_and_parse": [
      "self",
      "text",
      "tools"
    ],
    "_convert_param_value": [
      "self",
      "value",
      "param_type"
    ],
    "_extract_types_from_schema": [
      "self",
      "schema"
    ],
    "_convert_param_value_with_types": [
      "self",
      "value",
      "param_types"
    ],
    "_get_param_types_from_config": [
      "self",
      "param_name",
      "param_config"
    ],
    "parse_streaming_increment": [
      "self",
      "new_text",
      "tools"
    ],
    "_parse_and_stream_parameters": [
      "self",
      "text_to_parse",
      "tools"
    ],
    "_reset_streaming_state": [
      "self",
      "still_in_tool_call"
    ],
    "_extract": [
      "self",
      "text",
      "tools"
    ],
    "_parse_block": [
      "self",
      "block",
      "tools"
    ],
    "_parse_parameter": [
      "self",
      "fname",
      "pname",
      "pval",
      "tools"
    ],
    "supports_structural_tag": [
      "self"
    ],
    "structure_info": [
      "self"
    ]
  },
  "suppress_stdout_stderr": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "bench_kineto": [
    "fn",
    "kernel_names",
    "num_tests",
    "suppress_kineto_output",
    "trace_path",
    "flush_l2",
    "with_multiple_kernels"
  ],
  "FileInfo": {},
  "Manifest": {
    "from_dict": [
      "cls",
      "data"
    ],
    "to_dict": [
      "self"
    ]
  },
  "IGNORE_PATTERNS": [],
  "verify": [],
  "_compare_manifests": [],
  "generate_checksums": [],
  "_discover_files": [
    "model_path"
  ],
  "_load_checksums": [
    "source"
  ],
  "_load_file_infos_from_hf": [],
  "_get_filename_and_info_from_hf_file": [
    "fs",
    "file_info"
  ],
  "_compute_manifest_from_folder": [],
  "compute_sha256": [],
  "IntegrityError": {},
  "_add_common_args": [
    "parser"
  ],
  "execute": [],
  "_GemmExecutor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "_ElementwiseExecutor": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "_EXECUTOR_CLS_OF_BENCH": [],
  "_BENCH_NAMES": [],
  "_compute_local_metric": [
    "bench_name"
  ],
  "_analyze_metrics": [
    "all_metrics"
  ],
  "RWLock": {
    "__init__": [
      "self"
    ],
    "reader_lock": [
      "self"
    ],
    "writer_lock": [
      "self"
    ],
    "acquire_reader": [
      "self"
    ],
    "release_reader": [
      "self"
    ],
    "acquire_writer": [
      "self"
    ],
    "release_writer": [
      "self"
    ],
    "is_locked": [
      "self"
    ]
  },
  "_ReaderLock": {
    "__init__": [
      "self",
      "rwlock"
    ],
    "__aenter__": [
      "self"
    ],
    "__aexit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "_WriterLock": {
    "__init__": [
      "self",
      "rwlock"
    ],
    "__aenter__": [
      "self"
    ],
    "__aexit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "WHITELISTED_HEADERS": [],
  "_extract_whitelisted_headers": [
    "request"
  ],
  "RequestLogger": {
    "__init__": [
      "self",
      "log_requests",
      "log_requests_level",
      "log_requests_format",
      "log_requests_target"
    ],
    "_setup_targets": [
      "self"
    ],
    "configure": [
      "self",
      "log_requests",
      "log_requests_level",
      "log_requests_format",
      "log_requests_target"
    ],
    "log_received_request": [
      "self",
      "obj",
      "tokenizer",
      "request"
    ],
    "log_finished_request": [
      "self",
      "obj",
      "out",
      "is_multimodal_gen",
      "request"
    ],
    "_compute_metadata": [
      "self"
    ],
    "_log": [
      "self",
      "msg"
    ]
  },
  "disable_request_logging": [],
  "_dataclass_to_string_truncated": [
    "data",
    "max_length",
    "skip_names"
  ],
  "_transform_data_for_logging": [
    "data",
    "max_length",
    "skip_names"
  ],
  "is_hip": [],
  "FP8_E4M3_MIN": [],
  "BAR_FORMAT": [],
  "is_cuda": [],
  "is_cuda_alike": [],
  "is_hpu": [],
  "is_xpu": [],
  "is_host_cpu_x86": [],
  "is_host_cpu_arm64": [],
  "is_cpu": [],
  "is_float4_e2m1fn_x2": [
    "dtype"
  ],
  "get_cuda_version": [],
  "device_context": [
    "device"
  ],
  "_check_cuda_device_version": [
    "device_capability_majors",
    "cuda_version"
  ],
  "is_ampere_with_cuda_12_3": [],
  "is_hopper_with_cuda_12_3": [],
  "is_blackwell_supported": [],
  "is_blackwell": [],
  "is_sm120_supported": [],
  "is_sm100_supported": [],
  "is_sm90_supported": [],
  "cpu_has_amx_support": [],
  "use_intel_amx_backend": [
    "layer"
  ],
  "xpu_has_xmx_support": [],
  "is_flashinfer_available": [],
  "is_nvidia_cublas_cu12_version_ge_12_9": [],
  "random_uuid": [],
  "_warned_bool_env_var_keys": [],
  "get_bool_env_var": [
    "name",
    "default"
  ],
  "get_int_env_var": [
    "name",
    "default"
  ],
  "get_float_env_var": [
    "name",
    "default"
  ],
  "support_triton": [
    "backend"
  ],
  "_ENABLE_TORCH_INFERENCE_MODE": [],
  "DynamicGradMode": {
    "set_inference_mode": [
      "mode"
    ],
    "__init__": [
      "self",
      "mode"
    ],
    "__new__": [
      "cls",
      "mode_or_orig_func"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "clone": [
      "self"
    ]
  },
  "show_time_cost": [],
  "time_infos": [],
  "enable_show_time_cost": [],
  "TimeInfo": {
    "__init__": [
      "self",
      "name",
      "interval",
      "color",
      "indent"
    ],
    "check": [
      "self"
    ],
    "pretty_print": [
      "self"
    ]
  },
  "mark_start": [
    "name",
    "interval",
    "color",
    "indent"
  ],
  "mark_end": [
    "name"
  ],
  "calculate_time": [
    "show",
    "min_cost_ms"
  ],
  "get_available_gpu_memory": [
    "device",
    "gpu_id",
    "distributed",
    "empty_cache",
    "cpu_group"
  ],
  "is_pin_memory_available": [],
  "LayerFn": {
    "__call__": [
      "self",
      "idx",
      "prefix"
    ]
  },
  "make_layers": [
    "num_hidden_layers",
    "layer_fn",
    "pp_rank",
    "pp_size",
    "prefix",
    "return_tuple",
    "offloader_kwargs"
  ],
  "make_layers_non_pp": [
    "num_hidden_layers",
    "layer_fn",
    "prefix"
  ],
  "get_device_module": [],
  "set_random_seed": [
    "seed"
  ],
  "find_process_using_port": [
    "port"
  ],
  "wait_port_available": [
    "port",
    "port_name",
    "timeout_s",
    "raise_exception"
  ],
  "is_port_available": [
    "port"
  ],
  "get_free_port": [],
  "decode_video_base64": [
    "video_base64"
  ],
  "load_audio": [
    "audio_file",
    "sr",
    "mono"
  ],
  "ImageData": {},
  "load_image": [
    "image_file"
  ],
  "get_image_bytes": [
    "image_file"
  ],
  "load_video": [
    "video_file",
    "use_gpu"
  ],
  "sample_video_frames": [
    "video"
  ],
  "encode_video": [
    "video_path",
    "frame_count_limit"
  ],
  "suppress_other_loggers": [],
  "assert_pkg_version": [
    "pkg",
    "min_version",
    "message"
  ],
  "check_pkg_version_at_least": [
    "pkg",
    "min_version"
  ],
  "kill_process_tree": [
    "parent_pid",
    "include_parent",
    "skip_pid"
  ],
  "monkey_patch_p2p_access_check": [],
  "rank0_log": [
    "msg"
  ],
  "configure_logger": [
    "server_args",
    "prefix"
  ],
  "replace_submodule": [
    "model",
    "module_name",
    "new_module"
  ],
  "set_weight_attrs": [
    "weight",
    "weight_attrs"
  ],
  "broadcast_pyobj": [
    "data",
    "rank",
    "dist_group",
    "src",
    "force_cpu_device"
  ],
  "point_to_point_pyobj": [
    "data",
    "rank",
    "group",
    "src",
    "dst",
    "async_send"
  ],
  "step_counter": [],
  "pytorch_profile": [
    "name",
    "func"
  ],
  "get_zmq_socket": [
    "context",
    "socket_type",
    "endpoint",
    "bind"
  ],
  "get_zmq_socket_on_host": [
    "context",
    "socket_type",
    "host"
  ],
  "config_socket": [
    "socket",
    "socket_type"
  ],
  "dump_to_file": [
    "dirpath",
    "name",
    "value"
  ],
  "is_triton_3": [],
  "maybe_torch_compile": [],
  "delete_directory": [
    "dirpath"
  ],
  "set_prometheus_multiproc_dir": [],
  "add_prometheus_middleware": [
    "app"
  ],
  "RefCountedGauge": {
    "__init__": [
      "self",
      "gauge"
    ],
    "inc": [
      "self",
      "key"
    ],
    "dec": [
      "self",
      "key"
    ]
  },
  "add_prometheus_track_response_middleware": [
    "app"
  ],
  "_get_fastapi_request_path": [
    "request"
  ],
  "bind_port": [
    "port"
  ],
  "get_amdgpu_memory_capacity": [],
  "get_device_sm": [],
  "get_nvgpu_memory_capacity": [],
  "get_hpu_memory_capacity": [],
  "get_npu_memory_capacity": [],
  "get_cpu_memory_capacity": [],
  "get_xpu_memory_capacity": [],
  "get_device_memory_capacity": [
    "device"
  ],
  "init_custom_process_group": [
    "backend",
    "init_method",
    "timeout",
    "world_size",
    "rank",
    "store",
    "group_name",
    "pg_options",
    "device_id"
  ],
  "crash_on_warnings": [],
  "print_warning_once": [
    "msg"
  ],
  "print_info_once": [
    "msg"
  ],
  "get_device_name": [
    "device_id"
  ],
  "is_habana_available": [],
  "get_device": [
    "device_id"
  ],
  "get_device_count": [],
  "get_device_core_count": [
    "device_id"
  ],
  "get_device_capability": [
    "device_id"
  ],
  "get_compiler_backend": [
    "mode"
  ],
  "sglang_lib": [],
  "direct_register_custom_op": [
    "op_name",
    "op_func",
    "mutates_args",
    "fake_impl",
    "target_lib"
  ],
  "set_gpu_proc_affinity": [
    "pp_size",
    "tp_size",
    "nnodes",
    "gpu_id"
  ],
  "permute_weight": [
    "x"
  ],
  "MultiprocessingSerializer": {
    "serialize": [
      "obj",
      "output_str"
    ],
    "deserialize": [
      "data"
    ]
  },
  "SafeUnpickler": {
    "ALLOWED_MODULE_PREFIXES": [],
    "DENY_CLASSES": [],
    "find_class": [
      "self",
      "module",
      "name"
    ]
  },
  "debug_timing": [
    "func"
  ],
  "nullable_str": [
    "val"
  ],
  "pyspy_dump_schedulers": [],
  "kill_itself_when_parent_died": [],
  "UvicornAccessLogFilter": {
    "__init__": [
      "self",
      "excluded_path_prefixes"
    ],
    "filter": [
      "self",
      "record"
    ]
  },
  "set_uvicorn_logging_configs": [
    "server_args"
  ],
  "_configure_uvicorn_access_log_filter": [
    "uvicorn_logging_config",
    "server_args"
  ],
  "get_open_port": [],
  "is_valid_ipv6_address": [
    "address"
  ],
  "maybe_wrap_ipv6_address": [
    "address"
  ],
  "format_tcp_address": [
    "ip",
    "port"
  ],
  "configure_ipv6": [
    "dist_init_addr"
  ],
  "launch_dummy_health_check_server": [
    "host",
    "port",
    "enable_metrics"
  ],
  "set_cuda_arch": [],
  "cdiv": [
    "a",
    "b"
  ],
  "next_power_of_2": [
    "n"
  ],
  "EmptyContextManager": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "empty_context": [],
  "add_prefix": [
    "name",
    "prefix"
  ],
  "is_remote_url": [
    "url"
  ],
  "parse_connector_type": [
    "url"
  ],
  "retry": [
    "fn",
    "max_retry",
    "initial_delay",
    "max_delay",
    "should_retry"
  ],
  "has_hf_quant_config": [
    "model_path"
  ],
  "get_quantization_config": [
    "hf_config"
  ],
  "flatten_nested_list": [
    "nested_list"
  ],
  "is_non_idle_and_non_empty": [
    "forward_mode",
    "hidden_states"
  ],
  "fast_topk": [
    "values",
    "topk",
    "dim"
  ],
  "bind_or_assign": [
    "target",
    "source"
  ],
  "get_local_ip_by_nic": [
    "interface"
  ],
  "get_local_ip_by_remote": [],
  "get_local_ip_auto": [
    "fallback"
  ],
  "is_no_spec_infer_or_topk_one": [
    "server_args"
  ],
  "is_fa3_default_architecture": [
    "hf_config"
  ],
  "BumpAllocator": {
    "__init__": [
      "self",
      "buffer_size",
      "dtype",
      "device"
    ],
    "allocate": [
      "self",
      "size"
    ]
  },
  "log_info_on_rank0": [
    "logger",
    "msg"
  ],
  "load_json_config": [
    "data"
  ],
  "dispose_tensor": [
    "x"
  ],
  "T": [],
  "Withable": {
    "__init__": [
      "self"
    ],
    "value": [
      "self"
    ],
    "with_value": [
      "self",
      "new_value"
    ]
  },
  "require_mlp_tp_gather": [
    "server_args"
  ],
  "require_attn_tp_gather": [
    "server_args"
  ],
  "require_gathered_buffer": [
    "server_args"
  ],
  "require_mlp_sync": [
    "server_args"
  ],
  "find_local_repo_dir": [
    "repo_id",
    "revision"
  ],
  "read_system_prompt_from_file": [
    "model_name"
  ],
  "prepack_weight_if_needed": [
    "weight"
  ],
  "dim_is_supported": [
    "weight"
  ],
  "_process_weight_after_loading": [
    "module",
    "weight_names",
    "transpose_dims"
  ],
  "PackWeightMethod": {
    "__init__": [
      "self",
      "weight_names",
      "transpose_dims"
    ],
    "process_weights_after_loading": [
      "self",
      "module"
    ]
  },
  "LazyValue": {
    "__init__": [
      "self",
      "creator"
    ],
    "value": [
      "self"
    ]
  },
  "dynamic_import": [
    "func_path"
  ],
  "gc_object_counts": [],
  "configure_gc_warning": [
    "warn_threshold_secs"
  ],
  "configure_gc_logger": [],
  "ceil_align": [
    "x",
    "y"
  ],
  "ceil_div": [
    "x",
    "y"
  ],
  "parse_lscpu_topology": [],
  "get_physical_cpus_by_numa": [],
  "get_cpu_ids_by_node": [],
  "is_shm_available": [
    "dtype",
    "world_size",
    "local_size"
  ],
  "lru_cache_frozenset": [
    "maxsize"
  ],
  "apply_module_patch": [
    "target_module",
    "target_function",
    "wrappers"
  ],
  "parse_module_path": [
    "module_path",
    "function_name",
    "create_dummy"
  ],
  "mxfp_supported": [],
  "is_gfx95_supported": [],
  "SUPPORTED_LORA_TARGET_MODULES": [],
  "LORA_TARGET_ALL_MODULES": [],
  "ConcurrentCounter": {
    "__init__": [
      "self",
      "initial"
    ],
    "value": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "increment": [
      "self",
      "n",
      "notify_all"
    ],
    "decrement": [
      "self",
      "n",
      "notify_all"
    ],
    "wait_for": [
      "self",
      "condition"
    ],
    "wait_for_zero": [
      "self"
    ]
  },
  "is_triton_kernels_available": [],
  "check_cuda_result": [
    "raw_output"
  ],
  "get_physical_device_id": [
    "pytorch_device_id"
  ],
  "get_device_sm_nvidia_smi": [],
  "numa_bind_to_node": [
    "node"
  ],
  "json_list_type": [
    "value"
  ],
  "maybe_reindex_device_id": [
    "gpu_id"
  ],
  "get_extend_input_len_swa_limit": [
    "sliding_window_size",
    "chunked_prefill_size",
    "page_size"
  ],
  "get_num_new_pages": [
    "seq_lens",
    "page_size",
    "prefix_lens",
    "decode"
  ],
  "CachedKernel": {
    "__init__": [
      "self",
      "fn",
      "key_fn"
    ],
    "__getitem__": [
      "self",
      "grid"
    ],
    "_build_args": [
      "self",
      "args",
      "kwargs"
    ],
    "_clear_cache": [
      "self"
    ]
  },
  "cached_triton_kernel": [
    "key_fn"
  ],
  "reserve_rope_cache_for_long_sequences": [
    "model",
    "server_args",
    "model_config",
    "logger"
  ],
  "calc_diff": [
    "x",
    "y"
  ],
  "temp_attr_context": [
    "obj",
    "attr",
    "value"
  ],
  "cached_device_index": [],
  "get_current_device_stream_fast": [],
  "raise_error_or_warn": [
    "obj",
    "strict",
    "counter_name",
    "message",
    "log_interval"
  ],
  "get_or_create_event_loop": [],
  "get_numa_node_count": [],
  "is_numa_available": [],
  "get_system_nvgpu_count": [],
  "get_current_device_numa_node_cuda": [],
  "nvgpu_available": [],
  "bind_to_closest_numa_node_cuda": [],
  "WeightChecker": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "handle": [
      "self",
      "action"
    ],
    "_snapshot": [
      "self"
    ],
    "_reset_tensors": [
      "self"
    ],
    "_compare": [
      "self"
    ],
    "_model_state": [
      "self"
    ]
  },
  "_check_tensors": [
    "expect_tensors",
    "actual_tensors"
  ],
  "_random_like": [
    "t"
  ],
  "_postprocess_tensors": [
    "raw"
  ],
  "Watchdog": {
    "create": [
      "debug_name",
      "watchdog_timeout",
      "soft",
      "test_stuck_time"
    ],
    "feed": [
      "self"
    ],
    "disable": [
      "self"
    ]
  },
  "_WatchdogReal": {
    "__init__": [
      "self",
      "debug_name",
      "watchdog_timeout",
      "soft",
      "test_stuck_time"
    ],
    "feed": [
      "self"
    ],
    "disable": [
      "self"
    ]
  },
  "_WatchdogNoop": {},
  "WatchdogRaw": {
    "__init__": [
      "self",
      "debug_name",
      "get_counter",
      "is_active",
      "watchdog_timeout",
      "soft",
      "dump_info"
    ],
    "_watchdog_thread": [
      "self"
    ],
    "_watchdog_once": [
      "self"
    ]
  },
  "PollBasedBarrier": {
    "__init__": [
      "self",
      "noop"
    ],
    "local_arrive": [
      "self"
    ],
    "poll_global_arrived": [
      "self"
    ],
    "_compute_global_arrived": [
      "self"
    ]
  },
  "SchedulerStatusLogger": {
    "__init__": [
      "self",
      "targets",
      "dump_interval"
    ],
    "maybe_create": [],
    "maybe_dump": [
      "self",
      "running_batch",
      "waiting_queue"
    ]
  },
  "PytHooks": {
    "__init__": [
      "self"
    ],
    "print_tensor": [
      "tensor_obj",
      "prefix",
      "tensor_list"
    ],
    "process_layer_params": [
      "self",
      "module_obj"
    ],
    "module_fwd_hook": [
      "self",
      "module_obj",
      "in_tensor",
      "out_tensor"
    ],
    "module_fwd_pre_hook": [
      "self",
      "module_obj",
      "in_tensor"
    ],
    "register_hooks": [
      "self",
      "network_model",
      "module_prefix"
    ]
  },
  "ProfileManager": {
    "__init__": [
      "self",
      "tp_rank",
      "cpu_group",
      "gpu_id"
    ],
    "step": [
      "self",
      "forward_mode"
    ],
    "configure": [
      "self"
    ],
    "manual_start": [
      "self"
    ],
    "manual_stop": [
      "self"
    ],
    "_do_start": [
      "self",
      "stage"
    ],
    "_do_stop": [
      "self"
    ]
  },
  "_get_stage_from_forward_mode": [
    "forward_mode"
  ],
  "_StageBasedTrigger": {
    "__init__": [
      "self",
      "on_start",
      "on_stop"
    ],
    "configure": [
      "self",
      "num_steps",
      "interesting_stages"
    ],
    "step": [
      "self",
      "stage"
    ]
  },
  "_ProfilerBase": {
    "create": [
      "activities",
      "with_stack",
      "record_shapes"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "_ProfilerList": {
    "__init__": [
      "self",
      "inners"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "_ProfilerConcreteBase": {
    "__init__": [
      "self",
      "output_dir",
      "output_prefix",
      "output_suffix",
      "profile_id",
      "tp_rank",
      "cpu_group",
      "first_rank_in_node"
    ]
  },
  "_ProfilerTorch": {
    "__init__": [
      "self",
      "with_stack",
      "record_shapes",
      "activities"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "_ProfilerMemory": {
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "_ProfilerCudart": {
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "_ProfilerRPD": {
    "start": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "MM_FEATURE_CACHE_SIZE": [],
  "MM_ITEM_MEMORY_POOL_RECYCLE_INTERVAL": [],
  "SHM_LOCK_FILE": [],
  "ShmSyncBuffer": {
    "__init__": [
      "self",
      "byte_size"
    ],
    "__del__": [
      "self"
    ]
  },
  "MmItemMemoryChunk": {
    "__init__": [
      "self",
      "area",
      "sync_buffer"
    ],
    "mem_size": [
      "self"
    ],
    "start": [
      "self"
    ],
    "end": [
      "self"
    ],
    "try_to_recycle": [
      "self"
    ]
  },
  "MmItemMemoryPool": {
    "__init__": [
      "self",
      "memory_size",
      "recycle_interval"
    ],
    "shutdown": [
      "self"
    ],
    "_recycle_loop": [
      "self"
    ],
    "clear_sync_flag_list": [
      "self"
    ],
    "pop_sync_buffer": [
      "self"
    ],
    "push_sync_buffer": [
      "self",
      "sync_buffer"
    ],
    "get_available_chunk": [
      "self",
      "src_tensor"
    ],
    "return_a_slice_tensor_with_flag": [
      "self",
      "src_tensor"
    ],
    "recycle_chunks": [
      "self"
    ],
    "merge_chunks": [
      "self"
    ]
  },
  "CudaIpcTensorTransportProxy": {
    "__init__": [
      "self",
      "data",
      "info_data",
      "sync_buffer_meta"
    ],
    "get_sync_flag": [
      "self"
    ],
    "close_shm": [
      "self"
    ],
    "get_proxy_state": [
      "self",
      "data",
      "info_data"
    ],
    "reconstruct_on_target_device": [
      "self",
      "rebuild_device_idx"
    ]
  },
  "TorchMemorySaverAdapter": {
    "create": [
      "enable"
    ],
    "check_validity": [
      "self",
      "caller_name"
    ],
    "configure_subprocess": [
      "self"
    ],
    "region": [
      "self",
      "tag",
      "enable_cpu_backup"
    ],
    "cuda_graph": [
      "self"
    ],
    "disable": [
      "self"
    ],
    "pause": [
      "self",
      "tag"
    ],
    "resume": [
      "self",
      "tag"
    ],
    "enabled": [
      "self"
    ]
  },
  "_TorchMemorySaverAdapterReal": {
    "configure_subprocess": [
      "self"
    ],
    "region": [
      "self",
      "tag",
      "enable_cpu_backup"
    ],
    "cuda_graph": [
      "self"
    ],
    "disable": [
      "self"
    ],
    "pause": [
      "self",
      "tag"
    ],
    "resume": [
      "self",
      "tag"
    ],
    "enabled": [
      "self"
    ]
  },
  "_TorchMemorySaverAdapterNoop": {
    "configure_subprocess": [
      "self"
    ],
    "region": [
      "self",
      "tag",
      "enable_cpu_backup"
    ],
    "cuda_graph": [
      "self"
    ],
    "disable": [
      "self"
    ],
    "pause": [
      "self",
      "tag"
    ],
    "resume": [
      "self",
      "tag"
    ],
    "enabled": [
      "self"
    ]
  },
  "create_log_targets": [],
  "_create_log_target": [
    "target",
    "name_prefix"
  ],
  "_create_log_target_stdout": [
    "name_prefix"
  ],
  "_create_log_target_file": [
    "directory",
    "name_prefix"
  ],
  "_create_logger_with_handler": [
    "name",
    "handler"
  ],
  "log_json": [
    "loggers",
    "event",
    "data"
  ],
  "_CONFIG_REGISTRY": [],
  "download_from_hf": [
    "model_path",
    "allow_patterns"
  ],
  "get_hf_text_config": [
    "config"
  ],
  "_load_deepseek_v32_model": [
    "model_path",
    "trust_remote_code",
    "revision"
  ],
  "_load_mistral_large_3_for_causal_LM": [
    "model_path",
    "trust_remote_code",
    "revision"
  ],
  "_is_deepseek_ocr_model": [
    "config"
  ],
  "_override_deepseek_ocr_v_head_dim": [
    "config"
  ],
  "get_config": [
    "model",
    "trust_remote_code",
    "revision",
    "model_override_args"
  ],
  "get_generation_config": [
    "model",
    "trust_remote_code",
    "revision"
  ],
  "get_sparse_attention_config": [
    "model",
    "sparse_attention_config_filename"
  ],
  "CONTEXT_LENGTH_KEYS": [],
  "get_context_length": [
    "config"
  ],
  "_FAST_LLAMA_TOKENIZER": [],
  "TokenizerWarningsFilter": {
    "filter": [
      "self",
      "record"
    ]
  },
  "get_tokenizer_from_processor": [
    "processor"
  ],
  "attach_additional_stop_token_ids": [
    "tokenizer"
  ],
  "check_gguf_file": [
    "model"
  ],
  "adapt_config_dict": [
    "config_dict",
    "model"
  ],
  "_remap_mistral_vision_args": [
    "config"
  ],
  "_remap_mistral_yarn_args": [
    "config"
  ],
  "_remap_general_mistral_args": [
    "config"
  ],
  "_remap_mistral_quantization_args": [
    "config"
  ],
  "_remap_mistral_audio_args": [
    "config"
  ],
  "_remap_moe_args": [
    "config"
  ],
  "MistralConfigParser": {
    "get_hf_file_to_dict": [
      "self",
      "file_name",
      "model",
      "revision"
    ],
    "_download_mistral_config_file": [
      "self",
      "model",
      "revision"
    ],
    "parse": [
      "self",
      "model",
      "revision"
    ]
  },
  "DeviceTimer": {
    "__init__": [
      "self",
      "reporter"
    ],
    "wrap": [
      "self",
      "metadata"
    ],
    "_report": [
      "self"
    ]
  },
  "_TimingInterval": {
    "create": [],
    "end": [
      "self",
      "metadata"
    ],
    "elapsed_time": [
      "self"
    ]
  },
  "BucketLabels": {
    "__init__": [
      "self",
      "upper_bounds"
    ],
    "__len__": [
      "self"
    ],
    "__iter__": [
      "self"
    ],
    "compute_bucket_counts": [
      "self",
      "observations"
    ]
  },
  "GaugeHistogram": {
    "__init__": [
      "self",
      "name",
      "documentation",
      "labelnames",
      "bucket_bounds",
      "multiprocess_mode"
    ],
    "set_raw": [
      "self",
      "labels",
      "values"
    ],
    "set_by_current_observations": [
      "self",
      "labels",
      "observations"
    ],
    "buckets": [
      "self"
    ]
  },
  "do_multi_stream_local": {
    "__init__": [
      "self"
    ]
  },
  "_local": [],
  "set_do_multi_stream": [
    "enable"
  ],
  "do_multi_stream": [],
  "with_multi_stream": [
    "enable"
  ],
  "maybe_execute_in_parallel": [
    "fn0",
    "fn1",
    "events",
    "aux_stream"
  ],
  "_SubmoduleAccessor": [],
  "_WhitelistParamNamesCreator": [],
  "BaseOffloader": {
    "wrap_modules": [
      "self",
      "all_modules_generator",
      "submodule_accessor",
      "whitelist_param_names_creator"
    ],
    "post_init": [
      "self"
    ],
    "forbid_copy_engine_usage": [
      "self"
    ]
  },
  "NoopOffloader": {},
  "get_offloader": [],
  "set_offloader": [
    "instance"
  ],
  "create_offloader_from_server_args": [
    "server_args",
    "dp_rank"
  ],
  "OffloaderV1": {
    "__init__": [
      "self",
      "cpu_offload_max_bytes"
    ],
    "wrap_modules": [
      "self",
      "all_modules_generator",
      "submodule_accessor",
      "whitelist_param_names_creator"
    ],
    "maybe_offload_to_cpu": [
      "self",
      "module"
    ]
  },
  "OffloaderV2": {
    "__init__": [
      "self",
      "group_size",
      "num_in_group",
      "prefetch_step",
      "mode",
      "dp_rank",
      "dp_size"
    ],
    "wrap_modules": [
      "self",
      "all_modules_generator",
      "submodule_accessor",
      "whitelist_param_names_creator"
    ],
    "post_init": [
      "self"
    ],
    "forbid_copy_engine_usage": [
      "self"
    ]
  },
  "_hook_module_forward_for_offloader": [
    "index",
    "module",
    "offloaders",
    "prefetch_step"
  ],
  "_hook_module_forward_raw": [
    "module",
    "on_forward_end",
    "get_parameter_and_buffer_dicts"
  ],
  "_ModuleOffloader": {
    "__init__": [
      "self",
      "mode",
      "module",
      "alt_stream",
      "whitelist_param_names"
    ],
    "post_init": [
      "self"
    ],
    "start_onload": [
      "self"
    ],
    "offload": [
      "self"
    ],
    "wait_and_get_device_tensors": [
      "self"
    ],
    "_create_device_tensors": [
      "self"
    ]
  },
  "_BaseParamOffloader": {
    "create": [
      "mode"
    ],
    "__init__": [
      "self",
      "module",
      "param_name"
    ],
    "_param": [
      "self"
    ],
    "post_init": [
      "self"
    ],
    "create_device_tensor": [
      "self"
    ]
  },
  "_MetaParamOffloader": {
    "__init__": [
      "self",
      "module",
      "param_name"
    ],
    "create_device_tensor": [
      "self"
    ]
  },
  "_CpuParamOffloader": {
    "__init__": [
      "self",
      "module",
      "param_name"
    ],
    "create_device_tensor": [
      "self"
    ]
  },
  "_ShmCpuParamOffloader": {
    "__init__": [
      "self",
      "module",
      "param_name"
    ],
    "post_init": [
      "self"
    ],
    "create_device_tensor": [
      "self"
    ]
  },
  "update_param": [
    "param",
    "new_tensor"
  ],
  "_move_param_to_cpu": [
    "param",
    "pin_memory"
  ],
  "_create_cpu_data": [
    "data",
    "pin_memory"
  ],
  "_move_param_to_meta": [
    "module",
    "param_name"
  ],
  "_empty_strided_like": [
    "x",
    "device",
    "pin_memory"
  ],
  "_ShardedGpuParamOffloader": {
    "__init__": [
      "self",
      "module",
      "param_name"
    ],
    "post_init": [
      "self"
    ],
    "create_device_tensor": [
      "self"
    ]
  },
  "_even_chunk": [
    "x",
    "chunks"
  ],
  "_create_shared_buffer_tensors": [
    "local_tensor"
  ],
  "rpd_to_chrome_trace": [
    "input_rpd",
    "output_json",
    "start",
    "end",
    "format"
  ],
  "AuthDecision": {},
  "AuthLevel": {
    "NORMAL": [],
    "ADMIN_OPTIONAL": [],
    "ADMIN_FORCE": []
  },
  "auth_level": [
    "level"
  ],
  "_get_auth_level_from_app_and_scope": [
    "app",
    "scope"
  ],
  "app_has_admin_force_endpoints": [
    "app"
  ],
  "decide_request_auth": [],
  "add_api_key_middleware": [
    "app"
  ],
  "patch_tokenizer": [
    "tokenizer"
  ],
  "unpatch_tokenizer": [
    "tokenizer"
  ],
  "_is_kimi_tiktoken_tokenizer": [
    "tokenizer"
  ],
  "_SpecialTokensCachePatcher": {
    "_PATCHED_FLAG": [],
    "_CACHED_TOKENS_ATTR": [],
    "_CACHED_IDS_ATTR": [],
    "patch": [
      "cls",
      "tokenizer"
    ],
    "unpatch": [
      "cls",
      "tokenizer"
    ]
  },
  "_make_cached_property": [
    "cache_attr",
    "original_fn"
  ],
  "HostSharedMemoryManager": {
    "__init__": [
      "self",
      "base_name"
    ],
    "malloc": [
      "self"
    ],
    "_malloc_raw": [
      "self"
    ]
  },
  "_Record": {},
  "get_host_shared_memory_manager": [],
  "set_host_shared_memory_manager": [
    "instance"
  ],
  "configure_subprocess": [
    "server_args",
    "gpu_id"
  ],
  "_create_numactl_executable": [
    "numactl_args"
  ],
  "_mp_set_executable": [
    "executable",
    "debug_str"
  ],
  "SGLANG_TP_RANK": [],
  "monkey_patch_torch_reductions": [],
  "_REDUCE_TENSOR_ARG_DEVICE_INDEX": [],
  "register_sgl_tp_rank": [
    "rank"
  ],
  "_reduce_tensor_modified": [],
  "_rebuild_cuda_tensor_modified": [],
  "_device_to_uuid": [
    "device"
  ],
  "_device_from_maybe_uuid": [
    "device_maybe_uuid"
  ],
  "_modify_tuple": [
    "t",
    "index",
    "modifier"
  ],
  "monkey_patch_torch_compile": [],
  "register_fake_if_exists": [
    "op_name"
  ],
  "F": [],
  "register_custom_op": [
    "fn"
  ],
  "CustomOpWrapper": {
    "__init__": [
      "self",
      "op_name",
      "op_func",
      "mutates_args"
    ],
    "__call__": [
      "self"
    ],
    "real_impl": [
      "self"
    ],
    "fake_impl": [
      "self"
    ]
  },
  "ProfileMerger": {
    "__init__": [
      "self",
      "output_dir",
      "profile_id"
    ],
    "merge_chrome_traces": [
      "self"
    ],
    "_discover_trace_files": [
      "self"
    ],
    "_extract_rank_info": [
      "self",
      "filename"
    ],
    "_create_rank_label": [
      "self",
      "rank_info"
    ],
    "_handle_file": [
      "self",
      "path",
      "rank_info"
    ],
    "_process_events": [
      "self",
      "events",
      "rank_info"
    ],
    "_calculate_sort_index": [
      "self",
      "rank_info",
      "pid"
    ],
    "_get_rank_sort_key": [
      "self",
      "path"
    ],
    "_maybe_cast_int": [
      "self",
      "x"
    ],
    "get_merge_summary": [
      "self"
    ]
  },
  "SchedulerUpdateWeightsMixin": {
    "update_weights_from_disk": [
      "self",
      "recv_req"
    ],
    "init_weights_update_group": [
      "self",
      "recv_req"
    ],
    "destroy_weights_update_group": [
      "self",
      "recv_req"
    ],
    "update_weights_from_distributed": [
      "self",
      "recv_req"
    ],
    "update_weights_from_tensor": [
      "self",
      "recv_req"
    ],
    "update_weights_from_ipc": [
      "self",
      "recv_req"
    ],
    "get_weights_by_name": [
      "self",
      "recv_req"
    ],
    "release_memory_occupation": [
      "self",
      "recv_req"
    ],
    "resume_memory_occupation": [
      "self",
      "recv_req"
    ],
    "check_weights": [
      "self",
      "recv_req"
    ],
    "save_remote_model": [
      "self",
      "params"
    ],
    "save_sharded_model": [
      "self",
      "params"
    ]
  },
  "_export_static_state": [
    "model"
  ],
  "_import_static_state": [
    "model",
    "static_params"
  ],
  "_DEBUG_LOG": [],
  "_State": {
    "bump_delayed_count": [
      "self"
    ]
  },
  "_NegotiateOutput": {},
  "PrefillDelayer": {
    "__init__": [
      "self",
      "dp_size",
      "attn_tp_size",
      "cpu_group",
      "server_args",
      "max_delay_passes",
      "token_usage_low_watermark",
      "metrics_collector"
    ],
    "_negotiate_should_allow_prefill": [
      "self",
      "local_prefillable",
      "token_usage"
    ],
    "_negotiate_should_allow_prefill_pure": [
      "self",
      "prev_state",
      "local_prefillable",
      "token_usage"
    ],
    "_gather_info": [
      "self",
      "local_prefillable",
      "local_token_watermark_force_allow"
    ]
  },
  "PrefillDelayerSinglePassExecutor": {
    "__init__": [
      "self",
      "prefill_delayer",
      "token_usage"
    ],
    "_called": [
      "self"
    ],
    "finalize": [
      "self"
    ],
    "negotiate_should_allow_prefill": [
      "self",
      "local_prefillable"
    ]
  },
  "_record_single_pass_result": [
    "actual_execution",
    "output",
    "metrics_collector"
  ],
  "DETOKENIZER_MAX_STATES": [],
  "DecodeStatus": {},
  "DetokenizerManager": {
    "__init__": [
      "self",
      "server_args",
      "port_args"
    ],
    "init_ipc_channels": [
      "self",
      "port_args"
    ],
    "init_tokenizer": [
      "self",
      "server_args"
    ],
    "init_running_status": [
      "self",
      "server_args"
    ],
    "init_request_dispatcher": [
      "self"
    ],
    "event_loop": [
      "self"
    ],
    "trim_matched_stop": [
      "self",
      "output",
      "finished_reason",
      "no_stop_trim"
    ],
    "handle_batch_embedding_out": [
      "self",
      "recv_obj"
    ],
    "_grouped_batch_decode": [
      "self",
      "ids_list",
      "skip_list",
      "space_list"
    ],
    "_decode_batch_token_id_output": [
      "self",
      "recv_obj"
    ],
    "_extract_routed_experts": [
      "self",
      "recv_obj"
    ],
    "handle_batch_token_id_out": [
      "self",
      "recv_obj"
    ],
    "handle_multimodal_decode_req": [
      "self",
      "recv_obj"
    ],
    "handle_freeze_gc_req": [
      "self",
      "recv_req"
    ]
  },
  "LimitedCapacityDict": {
    "__init__": [
      "self",
      "capacity"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "run_detokenizer_process": [
    "server_args",
    "port_args",
    "detokenizer_manager_class"
  ],
  "DEFAULT_FORCE_STREAM_INTERVAL": [],
  "SchedulerOutputProcessorMixin": {
    "process_batch_result_prebuilt": [
      "self",
      "batch"
    ],
    "maybe_collect_routed_experts": [
      "self",
      "req"
    ],
    "maybe_collect_customized_info": [
      "self",
      "i",
      "req",
      "logits_output"
    ],
    "process_batch_result_prefill": [
      "self",
      "batch",
      "result"
    ],
    "_resolve_spec_overlap_token_ids": [
      "self",
      "result",
      "batch"
    ],
    "process_batch_result_idle": [
      "self",
      "batch",
      "result"
    ],
    "process_batch_result_dllm": [
      "self",
      "batch",
      "result"
    ],
    "process_batch_result_decode": [
      "self",
      "batch",
      "result"
    ],
    "_mamba_prefix_cache_update": [
      "self",
      "req",
      "batch",
      "result",
      "i"
    ],
    "_process_input_token_logprobs": [
      "self",
      "req",
      "input_token_logprobs"
    ],
    "_process_input_top_logprobs": [
      "self",
      "req"
    ],
    "_process_input_token_ids_logprobs": [
      "self",
      "req"
    ],
    "_calculate_relevant_tokens_len": [
      "self",
      "req"
    ],
    "_calculate_num_input_logprobs": [
      "self",
      "req",
      "extend_input_len",
      "extend_logprob_start_len"
    ],
    "_is_multi_item_scoring": [
      "self",
      "req"
    ],
    "add_input_logprob_return_values": [
      "self",
      "i",
      "req",
      "output",
      "logprob_pt",
      "num_input_logprobs",
      "last_prefill_chunk"
    ],
    "add_logprob_return_values": [
      "self",
      "i",
      "req",
      "pt",
      "next_token_ids",
      "num_input_logprobs",
      "output"
    ],
    "_initialize_empty_logprob_containers": [
      "self",
      "req"
    ],
    "stream_output": [
      "self",
      "reqs",
      "return_logprob",
      "skip_req"
    ],
    "_trigger_crash_for_tests": [
      "self",
      "crash_threshold"
    ],
    "stream_output_generation": [
      "self",
      "reqs",
      "return_logprob",
      "skip_req",
      "is_idle_batch"
    ],
    "stream_output_embedding": [
      "self",
      "reqs"
    ]
  },
  "_REQUEST_STATE_WAIT_TIMEOUT": [],
  "ReqState": {},
  "InputFormat": {
    "SINGLE_STRING": [],
    "BATCH_STRINGS": [],
    "CROSS_ENCODER_PAIRS": []
  },
  "TokenizerManager": {
    "__init__": [
      "self",
      "server_args",
      "port_args"
    ],
    "init_model_config": [
      "self"
    ],
    "init_tokenizer_and_processor": [
      "self"
    ],
    "init_ipc_channels": [
      "self",
      "port_args"
    ],
    "init_running_status": [
      "self"
    ],
    "init_request_logging_and_dumping": [
      "self"
    ],
    "init_weight_update": [
      "self"
    ],
    "init_lora": [
      "self"
    ],
    "init_disaggregation": [
      "self"
    ],
    "init_metric_collector_watchdog": [
      "self"
    ],
    "init_request_dispatcher": [
      "self"
    ],
    "generate_request": [
      "self",
      "obj",
      "request"
    ],
    "_detect_input_format": [
      "self",
      "texts",
      "is_cross_encoder"
    ],
    "_prepare_tokenizer_input": [
      "self",
      "texts",
      "input_format"
    ],
    "_extract_tokenizer_results": [
      "self",
      "input_ids",
      "token_type_ids",
      "input_format",
      "original_batch_size"
    ],
    "_tokenize_texts": [
      "self",
      "texts",
      "is_cross_encoder"
    ],
    "_tokenize_one_request": [
      "self",
      "obj"
    ],
    "_validate_one_request": [
      "self",
      "obj",
      "input_ids"
    ],
    "_validate_mm_limits": [
      "self",
      "obj"
    ],
    "_validate_for_matryoshka_dim": [
      "self",
      "obj"
    ],
    "_validate_input_ids_in_vocab": [
      "self",
      "input_ids",
      "vocab_size"
    ],
    "_create_tokenized_object": [
      "self",
      "obj",
      "input_text",
      "input_ids",
      "input_embeds",
      "mm_inputs",
      "token_type_ids"
    ],
    "_batch_tokenize_and_process": [
      "self",
      "batch_size",
      "obj"
    ],
    "_validate_batch_tokenization_constraints": [
      "self",
      "batch_size",
      "obj"
    ],
    "_batch_has_text": [
      "self",
      "batch_size",
      "obj"
    ],
    "_should_use_batch_tokenization": [
      "self",
      "batch_size",
      "requests"
    ],
    "_send_one_request": [
      "self",
      "obj",
      "tokenized_obj",
      "created_time"
    ],
    "_send_batch_request": [
      "self",
      "obj",
      "tokenized_objs",
      "created_time"
    ],
    "_wait_one_response": [
      "self",
      "obj",
      "state",
      "request"
    ],
    "_handle_batch_request": [
      "self",
      "obj",
      "request",
      "created_time"
    ],
    "abort_request": [
      "self",
      "rid",
      "abort_all"
    ],
    "pause_generation": [
      "self",
      "obj"
    ],
    "continue_generation": [
      "self",
      "obj"
    ],
    "update_weights_from_disk": [
      "self",
      "obj",
      "request"
    ],
    "_update_model_path_info": [
      "self",
      "model_path",
      "load_format"
    ],
    "_wait_for_model_update_from_disk": [
      "self",
      "obj"
    ],
    "configure_logging": [
      "self",
      "obj"
    ],
    "freeze_gc": [
      "self"
    ],
    "create_abort_task": [
      "self",
      "obj"
    ],
    "auto_create_handle_loop": [
      "self"
    ],
    "handle_loop": [
      "self"
    ],
    "_handle_batch_output": [
      "self",
      "recv_obj"
    ],
    "add_logprob_to_meta_info": [
      "self",
      "meta_info",
      "state",
      "top_logprobs_num",
      "token_ids_logprob",
      "return_text_in_logprobs"
    ],
    "convert_logprob_style": [
      "self",
      "meta_info",
      "state",
      "top_logprobs_num",
      "token_ids_logprob",
      "return_text_in_logprobs",
      "recv_obj",
      "recv_obj_index"
    ],
    "detokenize_logprob_tokens": [
      "self",
      "token_logprobs_val",
      "token_logprobs_idx",
      "decode_to_text"
    ],
    "detokenize_top_logprobs_tokens": [
      "self",
      "token_logprobs_val",
      "token_logprobs_idx",
      "decode_to_text"
    ],
    "_calculate_spec_decoding_metrics": [
      "self",
      "meta_info",
      "recv_obj",
      "i"
    ],
    "_calculate_timing_metrics": [
      "self",
      "meta_info",
      "state",
      "recv_obj",
      "i"
    ],
    "_add_metric_if_present": [
      "self",
      "recv_obj",
      "attr_name",
      "meta_info",
      "index"
    ],
    "_request_has_grammar": [
      "self",
      "obj"
    ],
    "collect_metrics": [
      "self",
      "state",
      "recv_obj",
      "i"
    ],
    "dump_requests": [
      "self",
      "state",
      "out_dict"
    ],
    "record_request_for_crash_dump": [
      "self",
      "state",
      "out_dict"
    ],
    "_dump_data_to_file": [
      "self",
      "data_list",
      "filename",
      "log_message"
    ],
    "dump_requests_before_crash": [
      "self",
      "hostname"
    ],
    "sigterm_watchdog": [
      "self"
    ],
    "force_exit_handler": [
      "self"
    ],
    "_handle_abort_req": [
      "self",
      "recv_obj"
    ],
    "update_active_ranks": [
      "self",
      "ranks"
    ],
    "_handle_open_session_req_output": [
      "self",
      "recv_obj"
    ],
    "_handle_update_weights_from_disk_req_output": [
      "self",
      "recv_obj"
    ],
    "_resolve_lora_path": [
      "self",
      "obj"
    ],
    "_trace_request_start": [
      "self",
      "obj",
      "created_time",
      "request"
    ],
    "_handle_epd_disaggregation_encode_request": [
      "self",
      "obj"
    ]
  },
  "ServerStatus": {
    "Up": [],
    "Starting": [],
    "UnHealthy": []
  },
  "print_exception_wrapper": [
    "func"
  ],
  "_get_processor_wrapper": [
    "server_args"
  ],
  "_determine_tensor_transport_mode": [
    "server_args"
  ],
  "SignalHandler": {
    "__init__": [
      "self",
      "tokenizer_manager"
    ],
    "sigterm_handler": [
      "self",
      "signum",
      "frame"
    ],
    "running_phase_sigquit_handler": [
      "self",
      "signum",
      "frame"
    ]
  },
  "AsyncMMDataProcessor": {
    "__init__": [
      "self",
      "mm_processor"
    ],
    "process": [
      "self"
    ],
    "shutdown": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "SchedulerRecvSkipper": {
    "maybe_create": [
      "server_args"
    ],
    "__init__": [
      "self",
      "server_args"
    ],
    "handle": [
      "self",
      "last_forward_mode"
    ]
  },
  "TokenizerManagerMultiItemMixin": {
    "score_prompts": [
      "self",
      "prompts",
      "label_token_ids",
      "apply_softmax",
      "request"
    ],
    "_initialize_multi_item_delimiter_text": [
      "self"
    ],
    "_build_multi_item_token_sequence": [
      "self",
      "query",
      "items",
      "delimiter_token_id"
    ],
    "_process_multi_item_scoring_results": [
      "self",
      "results",
      "items",
      "label_token_ids",
      "apply_softmax",
      "batch_request"
    ],
    "_process_single_item_scoring_results": [
      "self",
      "results",
      "label_token_ids",
      "apply_softmax"
    ],
    "score_request": [
      "self",
      "query",
      "items",
      "label_token_ids",
      "apply_softmax",
      "item_first",
      "request"
    ],
    "_convert_logprobs_to_scores": [
      "self",
      "logprobs",
      "label_token_ids",
      "apply_softmax"
    ],
    "_extract_logprobs_for_tokens": [
      "self",
      "logprobs_data",
      "label_token_ids"
    ]
  },
  "start_disagg_service": [
    "server_args"
  ],
  "LoadBalanceMethod": {
    "ROUND_ROBIN": [],
    "FOLLOW_BOOTSTRAP_ROOM": [],
    "TOTAL_REQUESTS": [],
    "TOTAL_TOKENS": [],
    "from_str": [
      "cls",
      "method"
    ]
  },
  "DPBudget": {
    "__init__": [
      "self",
      "dp_size"
    ],
    "update_budget": [
      "self",
      "load_update"
    ],
    "dispatch": [
      "self",
      "method"
    ]
  },
  "DataParallelController": {
    "__init__": [
      "self",
      "server_args",
      "port_args",
      "run_scheduler_process_func"
    ],
    "send_to_all_workers": [
      "self",
      "obj"
    ],
    "send_control_message": [
      "self",
      "obj"
    ],
    "handle_load_update_req": [
      "self",
      "obj"
    ],
    "update_active_ranks": [
      "self",
      "ranks"
    ],
    "dispatching_with_trace": [
      "self",
      "req"
    ],
    "init_dispatcher": [
      "self"
    ],
    "launch_dp_schedulers": [
      "self",
      "server_args",
      "port_args"
    ],
    "launch_tensor_parallel_group_thread": [
      "self",
      "server_args",
      "port_args",
      "base_gpu_id",
      "dp_rank",
      "ready_event"
    ],
    "_broadcast_worker_ports": [
      "self",
      "server_args",
      "worker_ports"
    ],
    "_broadcast_ports_as_server": [
      "self",
      "endpoint",
      "expected_clients",
      "worker_ports"
    ],
    "_receive_ports_as_client": [
      "self",
      "endpoint",
      "node_rank"
    ],
    "launch_dp_attention_schedulers": [
      "self",
      "server_args",
      "port_args"
    ],
    "launch_tensor_parallel_group": [
      "self",
      "server_args",
      "port_args",
      "base_gpu_id",
      "dp_rank",
      "worker_ports"
    ],
    "maybe_external_dp_rank_routing": [
      "self",
      "req"
    ],
    "round_robin_scheduler": [
      "self",
      "req"
    ],
    "follow_bootstrap_room_scheduler": [
      "self",
      "req"
    ],
    "total_requests_scheduler": [
      "self",
      "req"
    ],
    "total_tokens_scheduler": [
      "self",
      "req"
    ],
    "event_loop": [
      "self"
    ]
  },
  "run_data_parallel_controller_process": [
    "server_args",
    "port_args",
    "pipe_writer",
    "run_scheduler_process_func"
  ],
  "TEST_RETRACT": [],
  "TEST_RETRACT_INTERVAL": [],
  "TEST_RETRACT_NO_PREFILL_BS": [],
  "EmbeddingBatchResult": {
    "copy_to_cpu": [
      "self"
    ]
  },
  "Scheduler": {
    "__init__": [
      "self",
      "server_args",
      "port_args",
      "gpu_id",
      "tp_rank",
      "moe_ep_rank",
      "pp_rank",
      "dp_rank"
    ],
    "init_model_config": [
      "self"
    ],
    "init_ipc_channels": [
      "self",
      "port_args"
    ],
    "init_tokenizer": [
      "self"
    ],
    "init_moe_gemm_config": [
      "self"
    ],
    "init_tp_model_worker": [
      "self"
    ],
    "maybe_init_draft_worker": [
      "self"
    ],
    "init_model_worker": [
      "self"
    ],
    "init_cache_with_memory_pool": [
      "self"
    ],
    "init_running_status": [
      "self"
    ],
    "init_chunked_prefill": [
      "self"
    ],
    "init_diffusion_llm": [
      "self"
    ],
    "init_schedule_policy": [
      "self"
    ],
    "init_soft_watchdog": [
      "self",
      "server_args"
    ],
    "init_watch_dog_memory_saver_input_blocker": [
      "self"
    ],
    "init_disaggregation": [
      "self"
    ],
    "init_overlap": [
      "self"
    ],
    "init_deterministic_inference_config": [
      "self"
    ],
    "init_request_dispatcher": [
      "self"
    ],
    "event_loop_normal": [
      "self"
    ],
    "event_loop_overlap": [
      "self"
    ],
    "is_disable_overlap_for_batch": [
      "self",
      "batch"
    ],
    "recv_limit_reached": [
      "self",
      "num_recv_reqs"
    ],
    "recv_requests": [
      "self"
    ],
    "_split_work_and_control_reqs": [
      "self",
      "recv_reqs"
    ],
    "process_input_requests": [
      "self",
      "recv_reqs"
    ],
    "init_req_max_new_tokens": [
      "self",
      "req"
    ],
    "_process_and_broadcast_mm_inputs": [
      "self",
      "raw_mm_inputs"
    ],
    "_get_multimodal_inputs": [
      "self",
      "mm_inputs_dict"
    ],
    "_maybe_clear_mm_inputs": [
      "self",
      "batch"
    ],
    "handle_generate_request": [
      "self",
      "recv_req"
    ],
    "handle_batch_generate_request": [
      "self",
      "recv_req"
    ],
    "_prefetch_kvcache": [
      "self",
      "req"
    ],
    "_add_request_to_queue": [
      "self",
      "req",
      "is_retracted"
    ],
    "_set_or_validate_priority": [
      "self",
      "req"
    ],
    "_abort_on_queued_limit": [
      "self",
      "recv_req"
    ],
    "_abort_on_queued_timeout": [
      "self"
    ],
    "handle_embedding_request": [
      "self",
      "recv_req"
    ],
    "handle_batch_embedding_request": [
      "self",
      "recv_req"
    ],
    "stash_chunked_request": [
      "self",
      "req"
    ],
    "get_next_batch_to_run": [
      "self"
    ],
    "get_num_allocatable_reqs": [
      "self",
      "running_bs"
    ],
    "get_new_batch_prefill": [
      "self"
    ],
    "_get_new_batch_prefill_raw": [
      "self",
      "prefill_delayer_single_pass"
    ],
    "update_running_batch": [
      "self",
      "batch"
    ],
    "record_batch_in_overlap": [
      "self",
      "model_worker_batch"
    ],
    "run_batch": [
      "self",
      "batch",
      "pp_proxy_tensors"
    ],
    "launch_batch_sample_if_needed": [
      "self",
      "batch_result"
    ],
    "process_batch_result": [
      "self",
      "batch",
      "result"
    ],
    "maybe_send_health_check_signal": [
      "self"
    ],
    "flush_cache_wrapped": [
      "self",
      "recv_req"
    ],
    "clear_hicache_storage_wrapped": [
      "self",
      "recv_req"
    ],
    "_is_no_request": [
      "self"
    ],
    "flush_cache": [
      "self"
    ],
    "get_internal_state": [
      "self",
      "recv_req"
    ],
    "set_internal_state": [
      "self",
      "recv_req"
    ],
    "handle_rpc_request": [
      "self",
      "recv_req"
    ],
    "abort_request": [
      "self",
      "recv_req"
    ],
    "_pause_engine": [
      "self"
    ],
    "pause_generation": [
      "self",
      "recv_req"
    ],
    "continue_generation": [
      "self",
      "recv_req"
    ],
    "load_lora_adapter": [
      "self",
      "recv_req"
    ],
    "load_lora_adapter_from_tensors": [
      "self",
      "recv_req"
    ],
    "unload_lora_adapter": [
      "self",
      "recv_req"
    ],
    "init_weights_send_group_for_remote_instance": [
      "self",
      "recv_req"
    ],
    "send_weights_to_remote_instance": [
      "self",
      "recv_req"
    ],
    "slow_down": [
      "self",
      "recv_req"
    ],
    "expert_distribution_handle": [
      "self",
      "recv_req"
    ],
    "open_session": [
      "self",
      "recv_req"
    ],
    "close_session": [
      "self",
      "recv_req"
    ],
    "maybe_sleep_on_idle": [
      "self"
    ],
    "handle_freeze_gc": [
      "self",
      "recv_req"
    ],
    "update_cache_from_scheduler": [
      "self",
      "schedule_batch",
      "batch_result"
    ],
    "get_remote_instance_transfer_engine_info": [
      "self"
    ]
  },
  "IdleSleeper": {
    "__init__": [
      "self",
      "sockets"
    ],
    "maybe_sleep": [
      "self"
    ]
  },
  "is_health_check_generate_req": [
    "recv_req"
  ],
  "is_work_request": [
    "recv_req"
  ],
  "SenderWrapper": {
    "__init__": [
      "self",
      "socket"
    ],
    "send_output": [
      "self",
      "output",
      "recv_obj"
    ]
  },
  "run_scheduler_process": [
    "server_args",
    "port_args",
    "gpu_id",
    "tp_rank",
    "moe_ep_rank",
    "pp_rank",
    "dp_rank",
    "pipe_writer"
  ],
  "TensorTransportMode": [],
  "_BUFFER_OFFSET": [],
  "_EXTRA_PRE_TOKENS": [],
  "_EXTRA_POST_TOKENS": [],
  "init_feature_buffer": [
    "device"
  ],
  "reset_buffer_offset": [],
  "is_feature_buffer_initialized": [],
  "try_add_to_buffer": [
    "tensor"
  ],
  "TransportProxyTensor": {
    "__new__": [
      "cls",
      "data",
      "name",
      "fields",
      "transport_mode"
    ],
    "__getstate__": [
      "self"
    ],
    "__setstate__": [
      "self",
      "state"
    ],
    "name": [
      "self"
    ],
    "fields": [
      "self"
    ],
    "transport_mode": [
      "self"
    ]
  },
  "MultiModalityDataPaddingPattern": {
    "pad_input_tokens": [
      "self",
      "input_ids",
      "mm_inputs"
    ]
  },
  "MultiModalityDataPaddingPatternTokenPairs": {
    "__init__": [
      "self",
      "data_token_pairs",
      "data_start_token_ids"
    ],
    "pad_input_tokens": [
      "self",
      "input_ids",
      "mm_inputs"
    ]
  },
  "MultiModalityDataPaddingPatternMultimodalTokens": {
    "pad_input_tokens": [
      "self",
      "input_ids",
      "mm_inputs"
    ]
  },
  "init_mm_embedding_cache": [
    "max_size"
  ],
  "get_embedding_chunk": [
    "embedding",
    "extend_prefix_len",
    "extend_seq_len",
    "items_offset"
  ],
  "_get_precomputed_embedding": [
    "items",
    "prefix_length",
    "extend_length",
    "items_offset_list"
  ],
  "DataEmbeddingFunc": [],
  "get_embedding_items_per_chunk_with_extra_padding": [
    "embedding_items_per_req",
    "extend_prefix_len",
    "extend_seq_len",
    "items_offset"
  ],
  "_get_chunked_prefill_embedding": [
    "data_embedding_func",
    "embedding_items",
    "items_size",
    "prefix_length",
    "extend_length",
    "items_offset_list",
    "input_ids"
  ],
  "get_embedding_chunk_remove_extra_padding": [
    "embedding",
    "extend_prefix_len",
    "extend_seq_len",
    "items_offset"
  ],
  "_get_chunked_prefill_embedding_for_chunked_items": [
    "data_embedding_func",
    "embedding_items",
    "items_size",
    "prefix_length",
    "extend_length",
    "items_offset_list"
  ],
  "_get_multimodal_mask": [
    "input_ids",
    "placeholder_tensor"
  ],
  "_adjust_embedding_length": [
    "embedding",
    "mask",
    "logger"
  ],
  "get_embedding_and_mask": [
    "data_embedding_func",
    "embedding_items",
    "placeholder_tensor",
    "input_ids",
    "items_size",
    "prefix_length",
    "extend_length",
    "items_offset_list"
  ],
  "embed_mm_inputs": [
    "mm_inputs_list",
    "extend_prefix_lens",
    "extend_seq_lens",
    "input_ids",
    "input_embedding",
    "multimodal_model",
    "data_embedding_func_mapping",
    "placeholder_tokens",
    "use_deepstack"
  ],
  "general_mm_embed_routine": [
    "input_ids",
    "forward_batch",
    "language_model",
    "multimodal_model",
    "data_embedding_funcs",
    "placeholder_tokens",
    "use_deepstack"
  ],
  "get_multimodal_data_bounds": [
    "input_ids",
    "pad_values",
    "token_pairs"
  ],
  "data_hash": [
    "data"
  ],
  "tensor_hash": [
    "tensor_list"
  ],
  "hash_feature": [
    "f"
  ],
  "extend_mrope_positions_for_retracted_request": [
    "mrope_positions",
    "output_ids_len"
  ],
  "_get_length": [
    "value"
  ],
  "_slice_value": [
    "value",
    "start",
    "end"
  ],
  "_slice_model_data": [
    "data",
    "index",
    "start",
    "end",
    "num_items",
    "total_feature_len"
  ],
  "get_new_expanded_mm_items": [
    "original_mm_items"
  ],
  "INIT_INCREMENTAL_DETOKENIZATION_OFFSET": [],
  "BaseFinishReason": {
    "__init__": [
      "self",
      "is_error"
    ],
    "to_json": [
      "self"
    ]
  },
  "FINISH_MATCHED_TOKEN": {
    "__init__": [
      "self",
      "matched"
    ],
    "to_json": [
      "self"
    ]
  },
  "FINISH_MATCHED_STR": {
    "__init__": [
      "self",
      "matched"
    ],
    "to_json": [
      "self"
    ]
  },
  "FINISHED_MATCHED_REGEX": {
    "__init__": [
      "self",
      "matched"
    ],
    "to_json": [
      "self"
    ]
  },
  "FINISH_LENGTH": {
    "__init__": [
      "self",
      "length"
    ],
    "to_json": [
      "self"
    ]
  },
  "FINISH_ABORT": {
    "__init__": [
      "self",
      "message",
      "status_code",
      "err_type"
    ],
    "to_json": [
      "self"
    ]
  },
  "Modality": {
    "IMAGE": [],
    "MULTI_IMAGES": [],
    "VIDEO": [],
    "AUDIO": [],
    "from_str": [
      "modality_str"
    ],
    "all": []
  },
  "MultimodalInputFormat": {
    "NORMAL": [],
    "PROCESSOR_OUTPUT": [],
    "PRECOMPUTED_EMBEDDING": []
  },
  "MultimodalDataItem": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ],
    "set": [
      "self",
      "key",
      "value"
    ],
    "is_empty_list": [
      "l"
    ],
    "set_pad_value": [
      "self"
    ],
    "is_modality": [
      "self",
      "modality"
    ],
    "is_audio": [
      "self"
    ],
    "is_image": [
      "self"
    ],
    "is_video": [
      "self"
    ],
    "is_valid": [
      "self"
    ],
    "validate": [
      "self"
    ],
    "is_precomputed_embedding": [
      "self"
    ],
    "from_dict": [
      "obj"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "MultimodalInputs": {
    "from_dict": [
      "obj"
    ],
    "contains_image_inputs": [
      "self"
    ],
    "contains_video_inputs": [
      "self"
    ],
    "contains_audio_inputs": [
      "self"
    ],
    "contains_mm_input": [
      "self"
    ],
    "merge": [
      "self",
      "other"
    ]
  },
  "RequestStage": {
    "TOKENIZE": [],
    "TOKENIZER_DISPATCH": [],
    "DC_DISPATCH": [],
    "PREFILL_WAITING": [],
    "REQUEST_PROCESS": [],
    "DECODE_LOOP": [],
    "PREFILL_FORWARD": [],
    "PREFILL_CHUNKED_FORWARD": [],
    "PREFILL_PREPARE": [],
    "PREFILL_BOOTSTRAP": [],
    "PREFILL_TRANSFER_KV_CACHE": [],
    "DECODE_PREPARE": [],
    "DECODE_BOOTSTRAP": [],
    "DECODE_WAITING": [],
    "DECODE_TRANSFERRED": [],
    "DECODE_FAKE_OUTPUT": [],
    "DECODE_QUICK_FINISH": []
  },
  "Req": {
    "__init__": [
      "self",
      "rid",
      "origin_input_text",
      "origin_input_ids",
      "sampling_params",
      "return_logprob",
      "top_logprobs_num",
      "dllm_config",
      "token_ids_logprob",
      "stream",
      "origin_input_ids_unpadded",
      "lora_id",
      "input_embeds",
      "token_type_ids",
      "session_id",
      "custom_logit_processor",
      "require_reasoning",
      "return_hidden_states",
      "return_routed_experts",
      "eos_token_ids",
      "bootstrap_host",
      "bootstrap_port",
      "bootstrap_room",
      "disagg_mode",
      "data_parallel_rank",
      "vocab_size",
      "priority",
      "metrics_collector",
      "extra_key",
      "routing_key",
      "dimensions",
      "http_worker_ipc"
    ],
    "seqlen": [
      "self"
    ],
    "is_prefill_only": [
      "self"
    ],
    "output_ids_through_stop": [
      "self"
    ],
    "pop_committed_kv_cache": [
      "self"
    ],
    "pop_overallocated_kv_cache": [
      "self"
    ],
    "add_latency": [
      "self",
      "stage"
    ],
    "extend_image_inputs": [
      "self",
      "image_inputs"
    ],
    "finished": [
      "self"
    ],
    "is_dllm": [
      "self"
    ],
    "_init_fill_ids_for_dllm": [
      "self"
    ],
    "init_next_round_input": [
      "self",
      "tree_cache"
    ],
    "init_incremental_detokenize": [
      "self"
    ],
    "tail_str": [
      "self"
    ],
    "check_match_stop_str_prefix": [
      "self"
    ],
    "_check_token_based_finish": [
      "self",
      "new_accepted_tokens"
    ],
    "_check_str_based_finish": [
      "self"
    ],
    "_check_vocab_boundary_finish": [
      "self",
      "new_accepted_tokens"
    ],
    "check_finished": [
      "self",
      "new_accepted_len"
    ],
    "reset_for_retract": [
      "self"
    ],
    "offload_kv_cache": [
      "self",
      "req_to_token_pool",
      "token_to_kv_pool_allocator"
    ],
    "load_kv_cache": [
      "self",
      "req_to_token_pool",
      "token_to_kv_pool_allocator"
    ],
    "log_time_stats": [
      "self"
    ],
    "set_extend_input_len": [
      "self",
      "extend_input_len"
    ],
    "set_finish_with_abort": [
      "self",
      "error_msg"
    ],
    "__repr__": [
      "self"
    ]
  },
  "DllmStagingReqs": {
    "__init__": [
      "self",
      "dllm_config"
    ],
    "add_reqs": [
      "self",
      "req"
    ],
    "check_redundant_reqs": [
      "self",
      "reqs"
    ],
    "init_next_round": [
      "self"
    ],
    "non_empty": [
      "self"
    ],
    "empty": [
      "self"
    ],
    "update_chunked_status": [
      "self"
    ],
    "filter_finished_reqs": [
      "self"
    ],
    "__iter__": [
      "self"
    ]
  },
  "ScheduleBatch": {
    "init_new": [
      "cls",
      "reqs",
      "req_to_token_pool",
      "token_to_kv_pool_allocator",
      "tree_cache",
      "model_config",
      "enable_overlap",
      "spec_algorithm",
      "chunked_req",
      "dllm_staging_reqs",
      "dllm_config"
    ],
    "batch_size": [
      "self"
    ],
    "is_empty": [
      "self"
    ],
    "is_dllm": [
      "self"
    ],
    "prepare_encoder_info_extend": [
      "self",
      "input_ids",
      "seq_lens"
    ],
    "prepare_for_extend": [
      "self"
    ],
    "_mamba_radix_cache_v2_req_prepare_for_extend": [
      "self",
      "req",
      "mamba_track_mask_cpu",
      "mamba_track_indices_cpu",
      "mamba_track_seqlens_cpu"
    ],
    "prepare_for_split_prefill": [
      "self"
    ],
    "mix_with_running": [
      "self",
      "running_batch"
    ],
    "new_page_count_next_decode": [
      "self",
      "selected_indices"
    ],
    "check_decode_mem": [
      "self",
      "buf_multiplier",
      "selected_indices"
    ],
    "retract_all": [
      "self",
      "server_args"
    ],
    "retract_decode": [
      "self",
      "server_args",
      "buf_multiplier"
    ],
    "release_req": [
      "self",
      "idx",
      "remaing_req_count",
      "server_args"
    ],
    "prepare_encoder_info_decode": [
      "self"
    ],
    "prepare_for_idle": [
      "self"
    ],
    "is_spec_v2": [
      "self"
    ],
    "prepare_for_decode": [
      "self"
    ],
    "maybe_wait_verify_done": [
      "self"
    ],
    "filter_batch": [
      "self",
      "chunked_req_to_exclude",
      "keep_indices",
      "v1_spec_info_filtered"
    ],
    "merge_batch": [
      "self",
      "other"
    ],
    "get_model_worker_batch": [
      "self",
      "seq_lens_cpu_cache"
    ],
    "copy": [
      "self"
    ],
    "maybe_evict_swa": [
      "self"
    ],
    "_evict_swa": [
      "self",
      "req",
      "pre_len"
    ],
    "_is_available_size_sufficient": [
      "self",
      "num_tokens"
    ],
    "__str__": [
      "self"
    ]
  },
  "ModelWorkerBatch": {},
  "GenerationBatchResult": {
    "copy_to_cpu": [
      "self",
      "return_logprob"
    ],
    "from_pp_proxy": [
      "cls",
      "logits_output",
      "next_pp_outputs",
      "can_run_cuda_graph"
    ]
  },
  "validate_input_length": [
    "req",
    "max_req_input_len",
    "allow_auto_truncate"
  ],
  "get_logprob_dict_from_result": [
    "result"
  ],
  "get_logprob_from_pp_outputs": [
    "next_pp_outputs"
  ],
  "TemplateManager": {
    "__init__": [
      "self"
    ],
    "chat_template_name": [
      "self"
    ],
    "completion_template_name": [
      "self"
    ],
    "jinja_template_content_format": [
      "self"
    ],
    "force_reasoning": [
      "self"
    ],
    "_detect_reasoning_pattern": [
      "self",
      "template"
    ],
    "load_chat_template": [
      "self",
      "tokenizer_manager",
      "chat_template_arg",
      "model_path"
    ],
    "_load_explicit_chat_template": [
      "self",
      "tokenizer_manager",
      "chat_template_arg"
    ],
    "guess_chat_template_from_model_path": [
      "self",
      "model_path"
    ],
    "load_completion_template": [
      "self",
      "completion_template_arg"
    ],
    "initialize_templates": [
      "self",
      "tokenizer_manager",
      "model_path",
      "chat_template",
      "completion_template"
    ],
    "_load_jinja_template": [
      "self",
      "tokenizer_manager",
      "template_path"
    ],
    "_load_json_chat_template": [
      "self",
      "template_path"
    ],
    "_load_json_completion_template": [
      "self",
      "template_path"
    ],
    "_resolve_hf_chat_template": [
      "self",
      "tokenizer_manager"
    ],
    "_select_named_template": [
      "self",
      "templates",
      "tokenizer_manager"
    ]
  },
  "BaseTpWorker": {
    "forward_batch_generation": [
      "self",
      "forward_batch"
    ],
    "model_runner": [
      "self"
    ],
    "sliding_window_size": [
      "self"
    ],
    "is_hybrid_swa": [
      "self"
    ],
    "get_tokens_per_layer_info": [
      "self"
    ],
    "get_pad_input_ids_func": [
      "self"
    ],
    "get_memory_pool": [
      "self"
    ],
    "update_weights_from_disk": [
      "self",
      "recv_req"
    ],
    "init_weights_update_group": [
      "self",
      "recv_req"
    ],
    "destroy_weights_update_group": [
      "self",
      "recv_req"
    ],
    "init_weights_send_group_for_remote_instance": [
      "self",
      "recv_req"
    ],
    "send_weights_to_remote_instance": [
      "self",
      "recv_req"
    ],
    "update_weights_from_distributed": [
      "self",
      "recv_req"
    ],
    "update_weights_from_tensor": [
      "self",
      "recv_req"
    ],
    "update_weights_from_ipc": [
      "self",
      "recv_req"
    ],
    "get_weights_by_name": [
      "self",
      "recv_req"
    ],
    "load_lora_adapter": [
      "self",
      "recv_req"
    ],
    "unload_lora_adapter": [
      "self",
      "recv_req"
    ],
    "load_lora_adapter_from_tensors": [
      "self",
      "recv_req"
    ],
    "can_run_lora_batch": [
      "self",
      "lora_ids"
    ],
    "forward_batch_embedding": [
      "self",
      "model_worker_batch"
    ]
  },
  "TpModelWorker": {
    "__init__": [
      "self",
      "server_args",
      "gpu_id",
      "tp_rank",
      "moe_ep_rank",
      "pp_rank",
      "dp_rank",
      "nccl_port",
      "is_draft_worker",
      "req_to_token_pool",
      "token_to_kv_pool_allocator",
      "is_multi_layer_eagle"
    ],
    "_init_model_config": [
      "self"
    ],
    "_init_model_runner": [
      "self"
    ],
    "_init_multi_layer_eagle_model_runners": [
      "self"
    ],
    "_init_dllm_algorithm": [
      "self"
    ],
    "model_runner": [
      "self"
    ],
    "register_hicache_layer_transfer_counter": [
      "self",
      "counter"
    ],
    "set_hicache_consumer": [
      "self",
      "consumer_index"
    ],
    "get_worker_info": [
      "self"
    ],
    "is_dllm": [
      "self"
    ],
    "_forward_batch_generation_dllm": [
      "self",
      "forward_batch"
    ],
    "get_remote_instance_transfer_engine_info": [
      "self"
    ],
    "forward_batch_generation": [
      "self",
      "model_worker_batch",
      "forward_batch",
      "pp_proxy_tensors",
      "is_verify",
      "skip_attn_backend_init"
    ],
    "forward_batch_split_prefill": [
      "self",
      "batch"
    ]
  },
  "BaseReq": {
    "regenerate_rid": [
      "self"
    ]
  },
  "BaseBatchReq": {
    "regenerate_rids": [
      "self"
    ]
  },
  "RequestTimingMetricsMixin": {},
  "SpeculativeDecodingMetricsMixin": {},
  "APIServingTimingMixin": {},
  "_API_SERVING_TIMING_MIXIN_FIELDS": [],
  "SessionParams": {},
  "ImageDataInputItem": [],
  "AudioDataInputItem": [],
  "VideoDataInputItem": [],
  "MultimodalDataInputItem": [],
  "MultimodalDataInputFormat": [],
  "GenerateReqInput": {
    "contains_mm_input": [
      "self"
    ],
    "normalize_batch_and_arguments": [
      "self"
    ],
    "_validate_inputs": [
      "self"
    ],
    "_determine_batch_size": [
      "self"
    ],
    "_handle_parallel_sampling": [
      "self"
    ],
    "_normalize_single_inputs": [
      "self"
    ],
    "_normalize_batch_inputs": [
      "self"
    ],
    "_expand_inputs": [
      "self",
      "num"
    ],
    "_normalize_lora_paths": [
      "self",
      "num"
    ],
    "_normalize_image_data": [
      "self",
      "num"
    ],
    "_normalize_video_data": [
      "self",
      "num"
    ],
    "_normalize_audio_data": [
      "self",
      "num"
    ],
    "_normalize_sampling_params": [
      "self",
      "num"
    ],
    "_normalize_rid": [
      "self",
      "num"
    ],
    "_normalize_logprob_params": [
      "self",
      "num"
    ],
    "_normalize_custom_logit_processor": [
      "self",
      "num"
    ],
    "_normalize_bootstrap_params": [
      "self",
      "num"
    ],
    "_validate_session_params": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "TokenizedGenerateReqInput": {},
  "BatchTokenizedGenerateReqInput": {
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__iter__": [
      "self"
    ]
  },
  "EmbeddingReqInput": {
    "normalize_batch_and_arguments": [
      "self"
    ],
    "contains_mm_input": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ]
  },
  "TokenizedEmbeddingReqInput": {},
  "BatchTokenizedEmbeddingReqInput": {
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__iter__": [
      "self"
    ]
  },
  "BatchTokenIDOutput": {},
  "BatchMultimodalDecodeReq": {},
  "BatchStrOutput": {},
  "BatchMultimodalOutput": {},
  "BatchEmbeddingOutput": {},
  "ClearHiCacheReqInput": {},
  "ClearHiCacheReqOutput": {},
  "FlushCacheReqInput": {},
  "FlushCacheReqOutput": {},
  "PauseGenerationReqInput": {
    "__post_init__": [
      "self"
    ]
  },
  "ContinueGenerationReqInput": {},
  "UpdateWeightFromDiskReqInput": {},
  "UpdateWeightFromDiskReqOutput": {},
  "UpdateWeightsFromDistributedReqInput": {},
  "UpdateWeightsFromDistributedReqOutput": {},
  "UpdateWeightsFromTensorReqInput": {},
  "UpdateWeightsFromTensorReqOutput": {},
  "InitWeightsSendGroupForRemoteInstanceReqInput": {},
  "UpdateWeightsFromIPCReqInput": {},
  "UpdateWeightsFromIPCReqOutput": {},
  "InitWeightsSendGroupForRemoteInstanceReqOutput": {},
  "SendWeightsToRemoteInstanceReqInput": {},
  "SendWeightsToRemoteInstanceReqOutput": {},
  "InitWeightsUpdateGroupReqInput": {},
  "InitWeightsUpdateGroupReqOutput": {},
  "DestroyWeightsUpdateGroupReqInput": {},
  "DestroyWeightsUpdateGroupReqOutput": {},
  "UpdateWeightVersionReqInput": {},
  "GetWeightsByNameReqInput": {},
  "GetWeightsByNameReqOutput": {},
  "ReleaseMemoryOccupationReqInput": {},
  "ReleaseMemoryOccupationReqOutput": {},
  "ResumeMemoryOccupationReqInput": {},
  "ResumeMemoryOccupationReqOutput": {},
  "CheckWeightsReqInput": {},
  "CheckWeightsReqOutput": {},
  "SlowDownReqInput": {},
  "SlowDownReqOutput": {},
  "AbortReq": {
    "__post_init__": [
      "self"
    ]
  },
  "ActiveRanksOutput": {},
  "GetInternalStateReq": {},
  "GetInternalStateReqOutput": {},
  "SetInternalStateReq": {},
  "SetInternalStateReqOutput": {},
  "ProfileReqInput": {},
  "ProfileReqType": {
    "START_PROFILE": [],
    "STOP_PROFILE": []
  },
  "ProfileReq": {},
  "ProfileReqOutput": {},
  "FreezeGCReq": {},
  "ConfigureLoggingReq": {},
  "OpenSessionReqInput": {},
  "CloseSessionReqInput": {},
  "OpenSessionReqOutput": {},
  "HealthCheckOutput": {},
  "ExpertDistributionReqType": {
    "START_RECORD": [],
    "STOP_RECORD": [],
    "DUMP_RECORD": []
  },
  "ExpertDistributionReq": {},
  "ExpertDistributionReqOutput": {},
  "ParseFunctionCallReq": {},
  "SeparateReasoningReqInput": {},
  "VertexGenerateReqInput": {},
  "RpcReqInput": {},
  "RpcReqOutput": {},
  "LoadLoRAAdapterReqInput": {
    "to_ref": [
      "self"
    ]
  },
  "UnloadLoRAAdapterReqInput": {
    "to_ref": [
      "self"
    ]
  },
  "LoadLoRAAdapterFromTensorsReqInput": {
    "to_ref": [
      "self"
    ]
  },
  "LoRAUpdateOutput": {},
  "LoadLoRAAdapterReqOutput": [],
  "UnloadLoRAAdapterReqOutput": [],
  "LoadLoRAAdapterFromTensorsReqOutput": [],
  "BlockReqType": {
    "BLOCK": [],
    "UNBLOCK": []
  },
  "BlockReqInput": {},
  "GetLoadReqInput": {},
  "GetLoadReqOutput": {},
  "MemoryMetrics": {},
  "SpeculativeMetrics": {},
  "LoRAMetrics": {},
  "DisaggregationMetrics": {},
  "QueueMetrics": {},
  "GetLoadsReqInput": {
    "VALID_SECTIONS": [],
    "__post_init__": [
      "self"
    ]
  },
  "GetLoadsReqOutput": {},
  "WatchLoadUpdateReq": {},
  "SetInjectDumpMetadataReqInput": {},
  "SetInjectDumpMetadataReqOutput": {},
  "LazyDumpTensorsReqInput": {},
  "LazyDumpTensorsReqOutput": {},
  "_check_all_req_types": [],
  "SocketMapping": {
    "__init__": [
      "self"
    ],
    "clear_all_sockets": [
      "self"
    ],
    "_register_ipc_mapping": [
      "self",
      "ipc_name",
      "is_tokenizer"
    ],
    "send_output": [
      "self",
      "ipc_name",
      "output"
    ]
  },
  "_extract_field_by_index": [
    "output",
    "field_name",
    "index",
    "check_length"
  ],
  "_handle_output_by_index": [
    "output",
    "i"
  ],
  "MultiHttpWorkerDetokenizerMixin": {
    "maybe_clear_socket_mapping": [
      "self"
    ],
    "multi_http_worker_event_loop": [
      "self"
    ]
  },
  "MultiTokenizerRouter": {
    "__init__": [
      "self",
      "server_args",
      "port_args"
    ],
    "_run_loop": [
      "self"
    ],
    "router_worker_obj": [
      "self"
    ],
    "handle_loop": [
      "self"
    ],
    "_distribute_result_to_workers": [
      "self",
      "recv_obj"
    ]
  },
  "TokenizerWorker": {
    "__init__": [
      "self",
      "server_args",
      "port_args"
    ],
    "_attach_multi_http_worker_info": [
      "self",
      "req"
    ]
  },
  "get_main_process_id": [],
  "write_to_shared_memory": [
    "obj",
    "name"
  ],
  "read_from_shared_memory": [
    "name"
  ],
  "write_data_for_multi_tokenizer": [
    "port_args",
    "server_args",
    "scheduler_info"
  ],
  "monkey_patch_uvicorn_multiprocessing": [
    "timeout"
  ],
  "_resolve_future_token_ids": [
    "input_ids",
    "future_token_ids_map"
  ],
  "FutureIndices": {},
  "FutureMap": {
    "__init__": [
      "self",
      "max_running_requests",
      "chunked_prefill_size",
      "context_len",
      "device",
      "spec_algo"
    ],
    "_lazy_init_buf": [
      "self",
      "draft_input"
    ],
    "alloc_future_indices": [
      "self",
      "bs"
    ],
    "resolve_future": [
      "self",
      "model_worker_batch"
    ],
    "is_empty_slice": [
      "self",
      "s"
    ],
    "store_to_map": [
      "self",
      "future_indices",
      "batch_result"
    ],
    "store_to_map_for_new_batch": [
      "self",
      "future_indices",
      "draft_input"
    ]
  },
  "PPBatchMetadata": {},
  "SchedulerPPMixin": {
    "event_loop_pp": [
      "self"
    ],
    "event_loop_pp_disagg_prefill": [
      "self"
    ],
    "event_loop_pp_disagg_decode": [
      "self"
    ],
    "init_pp_loop_state": [
      "self"
    ],
    "profile_and_init_predictor": [
      "self"
    ],
    "predict_next_chunk_size": [
      "self",
      "history_len"
    ],
    "process_bootstrapped_queue": [
      "self",
      "bootstrapped_rids"
    ],
    "_pp_pd_get_bootstrapped_ids": [
      "self"
    ],
    "_pp_pd_get_prefill_transferred_ids": [
      "self"
    ],
    "_pp_pd_send_consensus_bootstrapped_ids": [
      "self",
      "bmbs",
      "next_first_rank_mb_id",
      "consensus_bootstrapped_rids",
      "bootstrapped_rids"
    ],
    "_pp_pd_send_consensus_release_ids": [
      "self",
      "tmbs",
      "next_first_rank_mb_id",
      "release_rids",
      "transferred_rids"
    ],
    "_pp_commit_comm_work": [
      "self",
      "work"
    ],
    "_pp_commit_send_output_work_and_preprocess_output_tensors": [
      "self",
      "next_first_rank_mb_id",
      "next_mb_id"
    ],
    "_pp_send_pyobj_to_next_stage": [
      "self",
      "data",
      "async_send"
    ],
    "_pp_recv_pyobj_from_prev_stage": [
      "self"
    ],
    "_pp_prepare_tensor_dict": [
      "self",
      "result",
      "batch"
    ],
    "_pp_send_dict_to_next_stage": [
      "self",
      "tensor_dict",
      "async_send"
    ],
    "_pp_recv_proxy_tensors": [
      "self"
    ],
    "_pp_recv_dict_from_prev_stage": [
      "self"
    ],
    "_pp_prep_batch_result": [
      "self",
      "batch",
      "mb_metadata",
      "pp_outputs"
    ],
    "_pp_process_batch_result": [
      "self",
      "batch",
      "output_result"
    ],
    "_pp_send_output_to_next_stage": [
      "self",
      "next_first_rank_mb_id",
      "mbs",
      "last_rank_comm_queue",
      "pp_outputs"
    ],
    "_pp_send_recv_and_preprocess_output_tensors": [
      "self",
      "next_first_rank_mb_id",
      "next_mb_id",
      "mbs",
      "mb_metadata",
      "last_rank_comm_queue",
      "pp_outputs"
    ],
    "_pp_launch_batch": [
      "self",
      "mb_id",
      "pp_proxy_tensors",
      "mb_metadata",
      "last_rank_comm_queue"
    ],
    "get_rids": [
      "self",
      "req_queue",
      "is_send"
    ],
    "_pp_pd_get_retract_ids": [
      "self",
      "mb_id"
    ],
    "_pp_pd_get_prealloc_ids": [
      "self"
    ],
    "_pp_pd_get_decode_transferred_ids": [
      "self"
    ],
    "process_retract_queue": [
      "self",
      "retract_rids"
    ],
    "process_prealloc_queue": [
      "self",
      "prealloc_rids"
    ],
    "process_decode_transfer_queue": [
      "self",
      "release_rids"
    ]
  },
  "ChunkSizePredictor": {
    "__init__": [
      "self"
    ],
    "fit": [
      "self",
      "seq_lens",
      "latencies"
    ],
    "set_target_latency": [
      "self",
      "base_chunk_size"
    ],
    "predict_next_chunk_size": [
      "self",
      "history_len",
      "base_chunk_size",
      "page_size",
      "context_len",
      "max_chunk_size"
    ]
  },
  "ALWAYS_EXCLUDE_FIELDS": [],
  "RequestMetricsExporter": {
    "__init__": [
      "self",
      "server_args",
      "obj_skip_names",
      "out_skip_names"
    ],
    "_format_output_data": [
      "self",
      "obj",
      "out_dict"
    ],
    "write_record": [
      "self",
      "obj",
      "out_dict"
    ]
  },
  "FileRequestMetricsExporter": {
    "__init__": [
      "self",
      "server_args",
      "obj_skip_names",
      "out_skip_names"
    ],
    "_ensure_file_handler": [
      "self",
      "hour_suffix"
    ],
    "close": [
      "self"
    ],
    "write_record": [
      "self",
      "obj",
      "out_dict"
    ]
  },
  "RequestMetricsExporterManager": {
    "__init__": [
      "self",
      "server_args",
      "obj_skip_names",
      "out_skip_names"
    ],
    "_create_exporters": [
      "self"
    ],
    "exporter_enabled": [
      "self"
    ],
    "write_record": [
      "self",
      "obj",
      "out_dict"
    ]
  },
  "create_request_metrics_exporters": [
    "server_args",
    "obj_skip_names",
    "out_skip_names"
  ],
  "SchedulerInputBlocker": {
    "__init__": [
      "self",
      "noop"
    ],
    "handle": [
      "self",
      "recv_reqs"
    ],
    "_handle_recv_req": [
      "self",
      "recv_req"
    ],
    "_execute_block_req": [
      "self"
    ],
    "_execute_unblock_req": [
      "self"
    ],
    "_handle_arrive_unblock_barrier": [
      "self"
    ],
    "_change_state": [
      "self",
      "original",
      "target"
    ]
  },
  "input_blocker_guard_region": [
    "send_to_scheduler"
  ],
  "SchedulerProfilerMixin": {
    "init_profiler": [
      "self"
    ],
    "init_profile": [
      "self",
      "output_dir",
      "start_step",
      "num_steps",
      "activities",
      "with_stack",
      "record_shapes",
      "profile_by_stage",
      "profile_id",
      "merge_profiles",
      "profile_prefix",
      "profile_stages"
    ],
    "start_profile": [
      "self",
      "stage"
    ],
    "_merge_profile_traces": [
      "self"
    ],
    "stop_profile": [
      "self",
      "stage"
    ],
    "_profile_batch_predicate": [
      "self",
      "batch"
    ],
    "profile": [
      "self",
      "recv_req"
    ]
  },
  "_ROUTING_KEY_POLICY_DEBUG_LOG": [],
  "CLIP_MAX_NEW_TOKENS": [],
  "IN_BATCH_PREFIX_CACHING_CHECK_THRESHOLD": [],
  "IN_BATCH_PREFIX_CACHING_DEPRIORITIZE_THRESHOLD": [],
  "IGNORE_EOS_RESERVE_TOKENS": [],
  "CacheAwarePolicy": {
    "LPM": [],
    "DFS_WEIGHT": []
  },
  "CacheAgnosticPolicy": {
    "FCFS": [],
    "LOF": [],
    "RANDOM": [],
    "ROUTING_KEY": []
  },
  "SchedulePolicy": {
    "Policy": [],
    "__init__": [
      "self",
      "policy",
      "tree_cache",
      "enable_hierarchical_cache",
      "enable_priority_scheduling",
      "schedule_low_priority_values_first"
    ],
    "calc_priority": [
      "self",
      "waiting_queue",
      "running_batch"
    ],
    "_determine_active_policy": [
      "self",
      "waiting_queue"
    ],
    "_validate_and_adjust_policy": [
      "self",
      "policy",
      "tree_cache"
    ],
    "_compute_prefix_matches": [
      "self",
      "waiting_queue",
      "policy"
    ],
    "_sort_by_longest_prefix": [
      "waiting_queue",
      "temporary_deprioritized"
    ],
    "_sort_by_dfs_weight": [
      "waiting_queue",
      "tree_cache"
    ],
    "_sort_by_longest_output": [
      "waiting_queue",
      "enable_priority_scheduling",
      "priority_sign"
    ],
    "_sort_randomly": [
      "waiting_queue"
    ],
    "_sort_by_priority_and_fcfs": [
      "waiting_queue",
      "priority_sign"
    ],
    "_sort_by_routing_key": [
      "waiting_queue",
      "running_batch"
    ],
    "_calc_weight": [
      "cur_node",
      "node_to_weight"
    ],
    "_get_dfs_priority": [
      "cur_node",
      "node_to_priority",
      "last_node_to_reqs",
      "q"
    ]
  },
  "AddReqResult": {
    "CONTINUE": [],
    "NO_TOKEN": [],
    "OTHER": []
  },
  "PrefillAdder": {
    "__init__": [
      "self",
      "page_size",
      "tree_cache",
      "token_to_kv_pool_allocator",
      "running_batch",
      "new_token_ratio",
      "rem_input_tokens",
      "rem_chunk_tokens",
      "mixed_with_decode_tokens",
      "priority_scheduling_preemption_threshold",
      "prefill_max_requests",
      "prefill_delayer_single_pass",
      "dllm_config"
    ],
    "_init_dllm_meta": [
      "self",
      "dllm_config"
    ],
    "_get_running_request_total_token_offset": [
      "self",
      "req"
    ],
    "rem_total_tokens": [
      "self"
    ],
    "cur_rem_tokens": [
      "self"
    ],
    "ceil_paged_tokens": [
      "self",
      "tokens"
    ],
    "budget_state": [
      "self"
    ],
    "_update_prefill_budget": [
      "self",
      "prefix_len",
      "extend_input_len",
      "max_new_tokens"
    ],
    "_get_dllm_remain_tokens": [
      "self"
    ],
    "_add_dllm_req": [
      "self",
      "req",
      "prefix_len"
    ],
    "_req_inc_lock_ref": [
      "self",
      "req"
    ],
    "add_chunked_req": [
      "self",
      "req"
    ],
    "_lock_node": [
      "self",
      "last_node"
    ],
    "add_one_req_ignore_eos": [
      "self",
      "req"
    ],
    "add_one_req": [
      "self",
      "req",
      "has_chunked_req",
      "truncation_align_size"
    ],
    "preempt_to_schedule": [
      "self",
      "req",
      "server_args"
    ]
  },
  "_ENABLE_METRICS_DP_ATTENTION": [],
  "MLPSyncBatchInfo": {
    "_get_local_tensor": [
      "self",
      "device",
      "dtype"
    ],
    "_get_fallback_tensor": [
      "self",
      "device",
      "dtype"
    ],
    "all_gather": [
      "self",
      "device",
      "group"
    ]
  },
  "_update_gather_batch": [
    "batch",
    "mlp_sync_info",
    "require_mlp_tp_gather",
    "skip_all_gather"
  ],
  "prepare_mlp_sync_batch_raw": [
    "local_batch",
    "dp_size",
    "attn_tp_size",
    "tp_group",
    "get_idle_batch",
    "disable_cuda_graph",
    "require_mlp_tp_gather",
    "disable_overlap_schedule",
    "offload_tags"
  ],
  "SchedulerDPAttnMixin": {
    "prepare_mlp_sync_batch": [
      "self",
      "local_batch"
    ],
    "maybe_prepare_mlp_sync_batch_and_log_stats": [
      "self",
      "batch",
      "need_sync",
      "log_stats"
    ],
    "get_idle_batch": [
      "self"
    ]
  },
  "PROCESSOR_MAPPING": [],
  "import_processors": [
    "package_name",
    "overwrite"
  ],
  "get_mm_processor": [
    "hf_config",
    "server_args",
    "processor",
    "transport_mode"
  ],
  "_Communicator": {
    "__init__": [
      "self",
      "sender",
      "fan_out",
      "mode"
    ],
    "queueing_call": [
      "self",
      "obj"
    ],
    "watching_call": [
      "self",
      "obj"
    ],
    "__call__": [
      "self",
      "obj"
    ],
    "handle_recv": [
      "self",
      "recv_obj"
    ],
    "merge_results": [
      "results"
    ]
  },
  "TokenizerCommunicatorMixin": {
    "init_communicators": [
      "self",
      "server_args"
    ],
    "_get_communicator_dispatcher": [
      "self"
    ],
    "flush_cache": [
      "self"
    ],
    "clear_hicache_storage": [
      "self"
    ],
    "start_profile": [
      "self",
      "output_dir",
      "start_step",
      "num_steps",
      "activities",
      "with_stack",
      "record_shapes",
      "profile_by_stage",
      "merge_profiles",
      "profile_prefix",
      "profile_stages"
    ],
    "stop_profile": [
      "self"
    ],
    "_execute_profile": [
      "self",
      "req"
    ],
    "start_expert_distribution_record": [
      "self"
    ],
    "stop_expert_distribution_record": [
      "self"
    ],
    "dump_expert_distribution_record": [
      "self"
    ],
    "init_weights_update_group": [
      "self",
      "obj",
      "request"
    ],
    "destroy_weights_update_group": [
      "self",
      "obj",
      "request"
    ],
    "update_weights_from_distributed": [
      "self",
      "obj",
      "request"
    ],
    "init_weights_send_group_for_remote_instance": [
      "self",
      "obj",
      "request"
    ],
    "send_weights_to_remote_instance": [
      "self",
      "obj",
      "request"
    ],
    "update_weights_from_tensor": [
      "self",
      "obj",
      "request"
    ],
    "update_weights_from_ipc": [
      "self",
      "obj",
      "request"
    ],
    "_unload_lora_adapter_locked": [
      "self",
      "obj"
    ],
    "load_lora_adapter": [
      "self",
      "obj",
      "_"
    ],
    "load_lora_adapter_from_tensors": [
      "self",
      "obj",
      "_"
    ],
    "unload_lora_adapter": [
      "self",
      "obj",
      "_"
    ],
    "get_weights_by_name": [
      "self",
      "obj",
      "request"
    ],
    "release_memory_occupation": [
      "self",
      "obj",
      "request"
    ],
    "resume_memory_occupation": [
      "self",
      "obj",
      "request"
    ],
    "check_weights": [
      "self",
      "obj",
      "request"
    ],
    "slow_down": [
      "self",
      "obj",
      "request"
    ],
    "get_internal_state": [
      "self"
    ],
    "set_internal_state": [
      "self",
      "obj"
    ],
    "get_load": [
      "self"
    ],
    "get_loads": [
      "self",
      "include",
      "dp_rank"
    ],
    "open_session": [
      "self",
      "obj",
      "request"
    ],
    "close_session": [
      "self",
      "obj",
      "request"
    ],
    "_update_weight_version_if_provided": [
      "self",
      "weight_version"
    ]
  },
  "SchedulerRuntimeCheckerMixin": {
    "_get_token_info": [
      "self"
    ],
    "_get_mamba_token_info": [
      "self"
    ],
    "_get_swa_token_info": [
      "self"
    ],
    "_check_hybrid_memory": [
      "self"
    ],
    "_check_mamba_memory": [
      "self"
    ],
    "_check_radix_cache_memory": [
      "self"
    ],
    "_get_batch_uncached_size": [
      "self",
      "batch"
    ],
    "self_check_during_busy": [
      "self"
    ],
    "_check_req_pool": [
      "self"
    ],
    "check_memory": [
      "self"
    ],
    "check_tree_cache": [
      "self"
    ],
    "self_check_during_idle": [
      "self"
    ]
  },
  "create_scheduler_watchdog": [
    "scheduler",
    "watchdog_timeout",
    "soft"
  ],
  "SessionReqNode": {
    "__init__": [
      "self",
      "req",
      "parent",
      "childs"
    ],
    "clear_childs": [
      "self",
      "req_dict"
    ],
    "clear": [
      "self",
      "req_dict"
    ],
    "abort": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "_str_helper": [
      "self",
      "prefix"
    ]
  },
  "Session": {
    "__init__": [
      "self",
      "capacity_of_str_len",
      "session_id"
    ],
    "create_req": [
      "self",
      "req",
      "tokenizer",
      "vocab_size"
    ]
  },
  "device_module": [],
  "LayerLoadingEvent": {
    "__init__": [
      "self",
      "num_layers"
    ],
    "complete": [
      "self",
      "layer_index"
    ],
    "wait": [
      "self",
      "layer_index"
    ],
    "finish_event": [
      "self"
    ]
  },
  "LayerDoneCounter": {
    "__init__": [
      "self",
      "num_layers"
    ],
    "update_producer": [
      "self"
    ],
    "set_consumer": [
      "self",
      "index"
    ],
    "wait_until": [
      "self",
      "threshold"
    ],
    "reset": [
      "self"
    ]
  },
  "CacheOperation": {
    "counter": [],
    "__init__": [
      "self",
      "host_indices",
      "device_indices",
      "node_id",
      "priority"
    ],
    "merge_ops": [
      "ops"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "HiCacheAck": {},
  "TransferBuffer": {
    "__init__": [
      "self",
      "stop_event",
      "buffer_count",
      "max_buffer_size"
    ],
    "full": [
      "self"
    ],
    "empty": [
      "self"
    ],
    "put": [
      "self",
      "item",
      "block",
      "timeout"
    ],
    "get": [
      "self",
      "block",
      "timeout"
    ],
    "clear": [
      "self"
    ]
  },
  "StorageOperation": {
    "counter": [],
    "__init__": [
      "self",
      "host_indices",
      "token_ids",
      "last_hash",
      "hash_value",
      "prefix_keys"
    ],
    "__lt__": [
      "self",
      "other"
    ]
  },
  "PrefetchOperation": {
    "__init__": [
      "self",
      "request_id",
      "host_indices",
      "token_ids",
      "last_hash",
      "prefix_keys"
    ],
    "increment": [
      "self",
      "num_tokens"
    ],
    "mark_terminate": [
      "self"
    ],
    "is_terminated": [
      "self"
    ]
  },
  "HiCacheController": {
    "__init__": [
      "self",
      "token_to_kv_pool_allocator",
      "mem_pool_host",
      "page_size",
      "tp_group",
      "load_cache_event",
      "write_policy",
      "io_backend",
      "storage_backend",
      "prefetch_threshold",
      "model_name",
      "storage_backend_extra_config",
      "pp_rank",
      "pp_size"
    ],
    "_generate_storage_config": [
      "self",
      "model_name",
      "storage_backend_extra_config"
    ],
    "reset": [
      "self"
    ],
    "write": [
      "self",
      "device_indices",
      "priority",
      "node_id"
    ],
    "start_writing": [
      "self"
    ],
    "load": [
      "self",
      "host_indices",
      "priority",
      "node_id"
    ],
    "move_indices": [
      "self",
      "op"
    ],
    "start_loading": [
      "self"
    ],
    "evict_device": [
      "self",
      "device_indices"
    ],
    "evict_host": [
      "self",
      "host_indices",
      "backup_only"
    ],
    "prefetch": [
      "self",
      "request_id",
      "host_indices",
      "new_input_tokens",
      "last_hash",
      "prefix_keys"
    ],
    "terminate_prefetch": [
      "self",
      "operation"
    ],
    "append_host_mem_release": [
      "self",
      "host_indices"
    ],
    "_page_get_zero_copy": [
      "self",
      "operation",
      "hash_values",
      "host_indices",
      "extra_info"
    ],
    "_generic_page_get": [
      "self",
      "operation",
      "hash_values",
      "host_indices",
      "extra_info"
    ],
    "_page_transfer": [
      "self",
      "operation"
    ],
    "prefetch_io_aux_func": [
      "self"
    ],
    "prefetch_rate_limited": [
      "self"
    ],
    "_storage_hit_query": [
      "self",
      "operation"
    ],
    "prefetch_thread_func": [
      "self"
    ],
    "write_storage": [
      "self",
      "host_indices",
      "token_ids",
      "hash_value",
      "prefix_keys"
    ],
    "_generic_page_set": [
      "self",
      "hash_values",
      "host_indices",
      "extra_info"
    ],
    "_page_set_zero_copy": [
      "self",
      "hash_values",
      "host_indices",
      "extra_info"
    ],
    "_page_backup": [
      "self",
      "operation"
    ],
    "backup_thread_func": [
      "self"
    ]
  },
  "RECORD_STEP_TIME": [],
  "LOG_FORWARD_ITERS": [],
  "ENABLE_METRICS_DEVICE_TIMER": [],
  "KvMetrics": {
    "__init__": [
      "self"
    ]
  },
  "SchedulerMetricsMixin": {
    "init_metrics": [
      "self",
      "tp_rank",
      "pp_rank",
      "dp_rank"
    ],
    "init_kv_events": [
      "self",
      "kv_events_config"
    ],
    "update_spec_metrics": [
      "self",
      "bs",
      "num_accepted_tokens"
    ],
    "reset_metrics": [
      "self"
    ],
    "log_prefill_stats": [
      "self",
      "adder",
      "can_run_list",
      "running_bs",
      "running_bs_offline_batch"
    ],
    "log_prefill_stats_late": [
      "self",
      "batch"
    ],
    "log_decode_stats": [
      "self",
      "can_run_cuda_graph",
      "running_batch"
    ],
    "log_decode_stats_every_iteration": [
      "self",
      "batch",
      "num_accepted_tokens"
    ],
    "log_batch_result_stats": [
      "self",
      "batch",
      "result"
    ],
    "_emit_kv_metrics": [
      "self"
    ],
    "_publish_kv_events": [
      "self"
    ],
    "update_lora_metrics": [
      "self"
    ],
    "calculate_utilization": [
      "self"
    ],
    "get_load": [
      "self",
      "_"
    ],
    "get_loads": [
      "self",
      "req"
    ],
    "record_forward_metrics": [
      "self",
      "batch"
    ]
  },
  "AsyncDynamicbatchTokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "max_batch_size",
      "batch_wait_timeout_s"
    ],
    "_ensure_initialized": [
      "self"
    ],
    "__call__": [
      "self",
      "prompt"
    ],
    "encode": [
      "self",
      "prompt"
    ],
    "_dynamic_batch_loop": [
      "self"
    ],
    "_process_dynamic_batch": [
      "self",
      "prompts",
      "kwargs_list",
      "result_futures"
    ],
    "__del__": [
      "self"
    ]
  },
  "FMIX32_C1": [],
  "FMIX32_C2": [],
  "POS_C1": [],
  "POS_C2": [],
  "_rotl32": [
    "x",
    "r"
  ],
  "_fmix32": [
    "x",
    "C1",
    "C2"
  ],
  "hash_tiles32_kernel_blocked": [
    "in_ptr",
    "out_ptr",
    "n_u32",
    "seed1",
    "seed2",
    "FM_C1",
    "FM_C2",
    "POS_A",
    "POS_B",
    "TILE",
    "BLOCK",
    "USE_CG"
  ],
  "add_tree_reduce_u64_kernel": [
    "in_ptr",
    "out_ptr",
    "n_elems",
    "CHUNK"
  ],
  "_as_uint32_words": [
    "t"
  ],
  "_final_splitmix64": [
    "x"
  ],
  "gpu_tensor_hash": [
    "tensor"
  ],
  "DEFAULT_VOCAB_PADDING_SIZE": [],
  "pad_vocab_size": [
    "vocab_size",
    "pad_to"
  ],
  "vocab_range_from_per_partition_vocab_size": [
    "per_partition_vocab_size",
    "rank",
    "offset"
  ],
  "vocab_range_from_global_vocab_size": [
    "global_vocab_size",
    "rank",
    "world_size",
    "offset"
  ],
  "VocabParallelEmbeddingShardIndices": {
    "num_org_elements": [
      "self"
    ],
    "num_added_elements": [
      "self"
    ],
    "num_org_elements_padded": [
      "self"
    ],
    "num_added_elements_padded": [
      "self"
    ],
    "num_org_vocab_padding": [
      "self"
    ],
    "num_added_vocab_padding": [
      "self"
    ],
    "num_elements_padded": [
      "self"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "get_masked_input_and_mask": [
    "input_",
    "org_vocab_start_index",
    "org_vocab_end_index",
    "num_org_vocab_padding",
    "added_vocab_start_index",
    "added_vocab_end_index"
  ],
  "VocabParallelEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "_get_indices": [
      "cls",
      "vocab_size_padded",
      "org_vocab_size_padded",
      "vocab_size",
      "org_vocab_size",
      "tp_rank",
      "tp_size"
    ],
    "get_sharded_to_full_mapping": [
      "self"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ParallelLMHead": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "tie_weights": [
      "self",
      "embed_tokens"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "_shard_tensor": [
    "full_tensor",
    "device_mesh",
    "placements"
  ],
  "ColwiseParallelSharded": {
    "_partition_linear_fn": [
      "self",
      "name",
      "module",
      "device_mesh"
    ]
  },
  "RowwiseParallelMaybeWait": {
    "_partition_linear_fn": [
      "self",
      "name",
      "module",
      "device_mesh"
    ],
    "_prepare_output_fn": [
      "output_layouts",
      "use_local_output",
      "mod",
      "outputs",
      "device_mesh"
    ]
  },
  "tensor_parallel": [
    "module",
    "device_mesh"
  ],
  "_flashinfer_comm": [],
  "_workspace_manager": [],
  "FlashInferWorkspaceManager": {
    "__init__": [
      "self"
    ],
    "initialize": [
      "self",
      "world_size",
      "rank",
      "max_token_num",
      "hidden_dim",
      "group",
      "use_fp32_lamport"
    ],
    "cleanup": [
      "self"
    ]
  },
  "ensure_workspace_initialized": [
    "max_token_num",
    "hidden_dim",
    "use_fp32_lamport"
  ],
  "fake_flashinfer_allreduce_residual_rmsnorm": [
    "input_tensor",
    "residual",
    "weight",
    "eps",
    "max_token_num",
    "use_oneshot",
    "trigger_completion_at_end",
    "fp32_acc"
  ],
  "flashinfer_allreduce_residual_rmsnorm": [
    "input_tensor",
    "residual",
    "weight",
    "eps",
    "max_token_num",
    "use_oneshot",
    "trigger_completion_at_end",
    "fp32_acc"
  ],
  "cleanup_flashinfer_workspace": [],
  "_dtype_rank": [
    "dtype"
  ],
  "copy_with_check": [
    "target",
    "loaded_weight"
  ],
  "BasevLLMParameter": {
    "__new__": [
      "cls",
      "data"
    ],
    "__init__": [
      "self",
      "data",
      "weight_loader"
    ],
    "weight_loader": [
      "self"
    ],
    "_assert_and_load": [
      "self",
      "loaded_weight"
    ],
    "load_column_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_row_parallel_weight": [
      "self",
      "loaded_weight"
    ],
    "load_merged_column_weight": [
      "self",
      "loaded_weight"
    ],
    "load_qkv_weight": [
      "self",
      "loaded_weight"
    ]
  },
  "_ColumnvLLMParameter": {
    "__init__": [
      "self",
      "output_dim"
    ],
    "output_dim": [
      "self"
    ],
    "load_column_parallel_weight": [
      "self",
      "loaded_weight",
      "tp_rank",
      "use_presharded_weights"
    ],
    "load_merged_column_weight": [
      "self",
      "loaded_weight"
    ],
    "load_qkv_weight": [
      "self",
      "loaded_weight",
      "tp_rank",
      "use_presharded_weights"
    ]
  },
  "RowvLLMParameter": {
    "__init__": [
      "self",
      "input_dim"
    ],
    "input_dim": [
      "self"
    ],
    "load_row_parallel_weight": [
      "self",
      "loaded_weight",
      "tp_rank",
      "use_presharded_weights"
    ]
  },
  "ModelWeightParameter": {},
  "GroupQuantScaleParameter": {},
  "ChannelQuantScaleParameter": {},
  "BlockQuantScaleParameter": {},
  "PerTensorScaleParameter": {
    "__init__": [
      "self"
    ],
    "_shard_id_as_int": [
      "self",
      "shard_id"
    ],
    "load_row_parallel_weight": [
      "self"
    ],
    "load_merged_column_weight": [
      "self"
    ],
    "load_qkv_weight": [
      "self"
    ],
    "load_column_parallel_weight": [
      "self"
    ],
    "_load_into_shard_id": [
      "self",
      "loaded_weight",
      "shard_id"
    ]
  },
  "PackedColumnParameter": {
    "__init__": [
      "self",
      "packed_factor",
      "packed_dim",
      "marlin_tile_size"
    ],
    "packed_dim": [
      "self"
    ],
    "packed_factor": [
      "self"
    ],
    "marlin_tile_size": [
      "self"
    ],
    "adjust_shard_indexes_for_packing": [
      "self",
      "shard_size",
      "shard_offset"
    ]
  },
  "PackedvLLMParameter": {
    "__init__": [
      "self",
      "packed_factor",
      "packed_dim",
      "marlin_tile_size"
    ],
    "packed_dim": [
      "self"
    ],
    "packed_factor": [
      "self"
    ],
    "marlin_tile_size": [
      "self"
    ],
    "adjust_shard_indexes_for_packing": [
      "self",
      "shard_size",
      "shard_offset"
    ]
  },
  "permute_param_layout_": [
    "param",
    "input_dim",
    "output_dim"
  ],
  "_adjust_shard_indexes_for_marlin": [
    "shard_size",
    "shard_offset",
    "marlin_tile_size"
  ],
  "_adjust_shard_indexes_for_packing": [
    "shard_size",
    "shard_offset",
    "packed_factor",
    "marlin_tile_size"
  ],
  "_is_flashinfer_available": [],
  "_is_sm90_supported": [],
  "_is_sm100_supported": [],
  "_use_aiter": [],
  "_is_gfx95_supported": [],
  "FUSE_ALLREDUCE_MAX_BATCH_SIZE": [],
  "apply_flashinfer_allreduce_fusion": [
    "batch_size"
  ],
  "ScatterMode": {
    "SCATTERED": [],
    "TP_ATTN_FULL": [],
    "FULL": [],
    "model_input_output": []
  },
  "AttentionInputs": {
    "__init__": [
      "self",
      "hidden_states",
      "forward_batch",
      "qkv_latent_func"
    ],
    "tp_all_gather_hidden_states": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "fetch_qkv_latent": [
      "self"
    ],
    "fetch_hidden_states": [
      "self"
    ]
  },
  "AttnTpContext": {
    "__init__": [
      "self"
    ],
    "init_context": [
      "self",
      "q_lora_rank",
      "is_nsa"
    ],
    "use_input_scattered": [
      "self",
      "forward_batch"
    ],
    "input_scattered": [
      "self"
    ],
    "set_attn_inputs": [
      "self",
      "attn_inputs"
    ],
    "fetch_qkv_latent": [
      "self"
    ],
    "fetch_hidden_states": [
      "self"
    ],
    "maybe_input_scattered": [
      "self",
      "forward_batch"
    ]
  },
  "ATTN_TP_CONTEXT": [],
  "get_attn_tp_context": [],
  "_LayerModeComputationContext": {
    "previous_layer": [
      "self"
    ]
  },
  "LayerScatterModes": {
    "init_new": [
      "cls"
    ],
    "_compute_layer_input_mode": [
      "cls",
      "context"
    ],
    "_compute_mlp_mode": [
      "cls",
      "context"
    ],
    "_should_gather_for_tbo": [
      "cls",
      "context"
    ],
    "_compute_middle_residual_mode": [
      "cls",
      "context"
    ],
    "_compute_layer_output_mode": [
      "cls",
      "context"
    ]
  },
  "enable_moe_dense_fully_dp": [],
  "LayerCommunicator": {
    "__init__": [
      "self",
      "layer_scatter_modes",
      "input_layernorm",
      "post_attention_layernorm",
      "allow_reduce_scatter",
      "is_last_layer",
      "qkv_latent_func"
    ],
    "_post_init_communicate": [
      "self"
    ],
    "prepare_attn_and_capture_last_layer_outputs": [
      "self",
      "hidden_states",
      "residual",
      "forward_batch",
      "captured_last_layer_outputs",
      "post_residual_addition"
    ],
    "prepare_attn": [
      "self",
      "hidden_states",
      "residual",
      "forward_batch",
      "quant_format",
      "post_residual_addition"
    ],
    "_tp_reduce_scatter": [
      "self",
      "hidden_states",
      "residual"
    ],
    "prepare_mlp": [
      "self",
      "hidden_states",
      "residual",
      "forward_batch",
      "cache"
    ],
    "postprocess_layer": [
      "self",
      "hidden_states",
      "residual",
      "forward_batch"
    ],
    "should_use_reduce_scatter": [
      "self",
      "forward_batch"
    ],
    "should_fuse_mlp_allreduce_with_next_layer": [
      "self",
      "forward_batch"
    ]
  },
  "CommunicateContext": {
    "cache": [],
    "is_same_group_size": [
      "self",
      "a",
      "b"
    ],
    "init_new": [
      "cls"
    ]
  },
  "CommunicateSimpleFn": {
    "get_fn": [
      "input_mode",
      "output_mode",
      "context"
    ],
    "_trivial": [
      "hidden_states",
      "forward_batch",
      "context"
    ],
    "_scattered_to_tp_attn_full": [
      "hidden_states",
      "forward_batch",
      "context"
    ]
  },
  "CommunicateWithAllReduceAndLayerNormFn": {
    "get_fn": [
      "hidden_states_input_mode",
      "residual_input_mode",
      "hidden_states_output_mode",
      "residual_output_mode",
      "context"
    ],
    "_simple": [
      "hidden_states",
      "residual",
      "forward_batch",
      "layernorm",
      "context"
    ],
    "_gather_hidden_states_and_residual": [
      "hidden_states",
      "residual",
      "forward_batch",
      "layernorm",
      "context"
    ],
    "_scatter_hidden_states_and_residual": [
      "hidden_states",
      "residual",
      "forward_batch",
      "layernorm",
      "context"
    ],
    "_tp_all_reduce_with_scattered_residual": [
      "hidden_states",
      "residual",
      "layernorm",
      "context"
    ]
  },
  "CommunicateSummableTensorPairFn": {
    "execute": [
      "cls",
      "hidden_states_input_mode",
      "residual_input_mode",
      "output_mode",
      "context"
    ],
    "get_fn": [
      "hidden_states_input_mode",
      "residual_input_mode",
      "output_mode",
      "context"
    ],
    "_trivial": [
      "hidden_states",
      "residual",
      "forward_batch",
      "context"
    ],
    "_scatter_hidden_states": [
      "hidden_states",
      "residual",
      "forward_batch",
      "context",
      "allow_reduce_scatter"
    ],
    "_gather": [
      "hidden_states",
      "residual",
      "forward_batch",
      "context"
    ],
    "_scatter": [
      "hidden_states",
      "residual",
      "forward_batch",
      "context"
    ]
  },
  "aiter_dsv3_router_gemm": [
    "hidden_states",
    "weight",
    "gemm_output_zero_allocator"
  ],
  "get_dsv3_gemm_output_zero_allocator_size": [
    "n_routed_experts",
    "num_moe_layers",
    "allocate_size",
    "embedding_dim"
  ],
  "SiluAndMul": {
    "__init__": [
      "self"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_cpu": [
      "self",
      "x"
    ],
    "forward_npu": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ]
  },
  "GeluAndMul": {
    "__init__": [
      "self",
      "approximate"
    ],
    "_forward_impl": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cpu": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_xpu": [
      "self",
      "x"
    ],
    "forward_npu": [
      "self",
      "x"
    ]
  },
  "NewGELU": {
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ]
  },
  "ReLU2": {
    "forward": [
      "self",
      "x"
    ]
  },
  "QuickGELU": {
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_hip": [
      "self",
      "x"
    ],
    "forward_npu": [
      "self",
      "x"
    ]
  },
  "XIELU": {
    "__init__": [
      "self",
      "alpha_p_init",
      "alpha_n_init",
      "beta",
      "eps",
      "dtype",
      "with_vector_loads"
    ],
    "_xielu_python": [
      "self",
      "x"
    ],
    "_xielu_cuda": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "ScaledActivation": {
    "__init__": [
      "self",
      "act_module",
      "intermediate_size",
      "input_is_parallel",
      "params_dtype"
    ],
    "forward": [
      "self",
      "x"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ]
  },
  "_ACTIVATION_REGISTRY": [],
  "get_act_fn": [
    "act_fn_name",
    "quant_config",
    "intermediate_size",
    "input_is_parallel",
    "params_dtype"
  ],
  "get_cross_encoder_activation_function": [
    "config"
  ],
  "_USE_ROCM700A_WA": [],
  "DpPaddingMode": {
    "MAX_LEN": [],
    "SUM_LEN": [],
    "is_max_len": [
      "self"
    ],
    "is_sum_len": [
      "self"
    ],
    "get_dp_padding_mode": [
      "cls",
      "is_extend_in_batch",
      "global_num_tokens"
    ],
    "get_default_mode_in_cuda_graph": [
      "cls"
    ]
  },
  "_DpGatheredBufferWrapper": {
    "set_metadata": [
      "cls",
      "hidden_size",
      "dtype",
      "device"
    ],
    "set_dp_buffer_len": [
      "cls",
      "global_dp_buffer_len",
      "local_dp_buffer_len",
      "dp_max_padding",
      "global_num_tokens"
    ],
    "get_global_dp_buffer": [
      "cls"
    ],
    "get_local_dp_buffer": [
      "cls"
    ],
    "get_global_dp_buffer_len": [
      "cls"
    ],
    "get_local_dp_buffer_len": [
      "cls"
    ],
    "get_dp_global_num_tokens": [
      "cls"
    ],
    "get_dp_hidden_size": [
      "cls"
    ],
    "get_dp_dtype": [
      "cls"
    ],
    "get_dp_device": [
      "cls"
    ],
    "set_is_extend_in_batch": [
      "cls",
      "is_extend_in_batch"
    ],
    "get_is_extend_in_batch": [
      "cls"
    ],
    "is_dp_max_padding": [
      "cls"
    ]
  },
  "set_dp_buffer_len": [
    "global_dp_buffer_len",
    "local_dp_buffer_len",
    "dp_max_padding",
    "global_num_tokens"
  ],
  "get_global_dp_buffer": [],
  "get_local_dp_buffer": [],
  "get_global_dp_buffer_len": [],
  "get_local_dp_buffer_len": [],
  "get_dp_global_num_tokens": [],
  "get_dp_hidden_size": [],
  "get_dp_dtype": [],
  "get_dp_device": [],
  "set_is_extend_in_batch": [
    "is_extend_in_batch"
  ],
  "get_is_extend_in_batch": [],
  "is_dp_max_padding": [],
  "compute_dp_attention_world_info": [
    "enable_dp_attention",
    "tp_rank",
    "tp_size",
    "dp_size"
  ],
  "compute_dp_attention_local_info": [
    "enable_dp_attention",
    "tp_rank",
    "tp_size",
    "dp_size",
    "moe_dense_tp_size"
  ],
  "initialize_dp_attention": [
    "server_args",
    "model_config"
  ],
  "is_dp_attention_enabled": [],
  "is_allocation_symmetric": [],
  "get_attention_tp_group": [],
  "get_attention_tp_rank": [],
  "get_attention_tp_size": [],
  "get_attention_dp_rank": [],
  "get_attention_dp_size": [],
  "get_local_attention_dp_rank": [],
  "get_local_attention_dp_size": [],
  "disable_dp_size": [],
  "get_dp_local_info": [
    "forward_batch"
  ],
  "memcpy_triton_kernel": [
    "dst_ptr",
    "src_ptr",
    "offset_ptr",
    "sz_ptr",
    "offset_src",
    "chunk_size",
    "BLOCK_SIZE"
  ],
  "prod": [
    "x"
  ],
  "memcpy_triton": [
    "dst",
    "src",
    "dim",
    "offset",
    "sz",
    "offset_src"
  ],
  "_dp_gather_via_all_reduce": [
    "global_tokens",
    "local_tokens",
    "forward_batch",
    "is_partial"
  ],
  "_dp_gather_via_all_gather": [
    "global_tokens",
    "local_tokens",
    "forward_batch",
    "is_partial"
  ],
  "_dp_gather": [
    "global_tokens",
    "local_tokens",
    "forward_batch",
    "is_partial"
  ],
  "dp_gather_partial": [
    "global_tokens",
    "local_tokens",
    "forward_batch"
  ],
  "dp_gather_replicate": [
    "global_tokens",
    "local_tokens",
    "forward_batch"
  ],
  "dp_scatter": [
    "local_tokens",
    "global_tokens",
    "forward_batch"
  ],
  "dp_reduce_scatter_tensor": [
    "output",
    "input"
  ],
  "attn_tp_reduce_scatter_tensor": [
    "output",
    "input"
  ],
  "attn_tp_all_reduce": [
    "input"
  ],
  "attn_tp_all_gather_into_tensor": [
    "output",
    "input"
  ],
  "attn_tp_all_gather": [
    "output_list",
    "input"
  ],
  "SparseEmbeddingOutput": {},
  "SparsePooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "state_dict"
    ]
  },
  "_rotate_neox": [
    "x"
  ],
  "_rotate_gptj": [
    "x"
  ],
  "_apply_rotary_emb": [
    "x",
    "cos",
    "sin",
    "is_neox_style"
  ],
  "RotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "_ensure_cos_sin_cache_length": [
      "self",
      "needed_max_pos"
    ],
    "get_cos_sin_with_position": [
      "self",
      "positions"
    ],
    "get_cos_sin": [
      "self",
      "seqlen"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "offsets",
      "fused_set_kv_buffer_arg"
    ],
    "forward_npu": [
      "self",
      "positions",
      "query",
      "key",
      "offsets",
      "fused_set_kv_buffer_arg"
    ],
    "forward_cpu": [
      "self",
      "positions",
      "query",
      "key",
      "offsets",
      "fused_set_kv_buffer_arg"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key",
      "offsets",
      "fused_set_kv_buffer_arg"
    ],
    "extra_repr": [
      "self"
    ],
    "forward_xpu": [
      "self",
      "positions",
      "query",
      "key",
      "offsets",
      "fused_set_kv_buffer_arg"
    ]
  },
  "LinearScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factors",
      "dtype"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "scaling_factor_to_offset": [
      "self"
    ]
  },
  "DynamicNTKScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "_yarn_find_correction_dim": [
    "num_rotations",
    "dim",
    "base",
    "max_position_embeddings"
  ],
  "_yarn_find_correction_range": [
    "low_rot",
    "high_rot",
    "dim",
    "base",
    "max_position_embeddings",
    "truncate"
  ],
  "_yarn_linear_ramp_mask": [
    "low",
    "high",
    "dim",
    "dtype",
    "device"
  ],
  "_yarn_get_mscale": [
    "scale"
  ],
  "YaRNScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "scaling_factor"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "Phi3LongRoPEScaledRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "original_max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "short_factor",
      "long_factor",
      "short_mscale",
      "long_mscale"
    ],
    "_compute_inv_freq": [
      "self",
      "rescale_factors"
    ],
    "_compute_cos_sin_cache": [
      "self",
      "max_position_embeddings",
      "rescale_factors",
      "mscale"
    ],
    "forward": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ]
  },
  "yarn_get_mscale": [
    "scale",
    "mscale"
  ],
  "DeepseekScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "scaling_factor"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "get_cos_cached_total": [
      "self"
    ],
    "get_sin_cached_total": [
      "self"
    ],
    "get_cos_sin_cache": [
      "self",
      "positions",
      "dtype",
      "offsets"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_npu": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "forward_cpu": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ]
  },
  "Llama3RotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "scaling_factor",
      "low_freq_factor",
      "high_freq_factor",
      "orig_max_position"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ]
  },
  "Llama4VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "forward": [
      "self",
      "query",
      "key"
    ]
  },
  "DynamicNTKAlphaRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_alpha",
      "dtype"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "apply_interleaved_rope": [
    "x",
    "mrope_section"
  ],
  "_triton_mrope_forward_fused": [
    "q_ptr",
    "k_ptr",
    "cos_sin_cache_ptr",
    "positions_ptr",
    "q_stride",
    "k_stride",
    "positions_stride",
    "n_qh",
    "n_kh",
    "hd",
    "rd",
    "pad_n_qh",
    "pad_n_kh",
    "pad_hd",
    "mrope_section_t",
    "mrope_section_h",
    "mrope_section_w",
    "is_interleaved",
    "is_neox_style"
  ],
  "triton_mrope_fused": [
    "q",
    "k",
    "cos_sin_cache",
    "positions",
    "mrope_section",
    "head_size",
    "rotary_dim",
    "mrope_interleaved",
    "is_neox_style"
  ],
  "MRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "mrope_section",
      "mrope_interleaved"
    ],
    "_match_cos_sin_cache_dtype": [
      "self",
      "query"
    ],
    "forward_native": [
      "self",
      "positions",
      "query",
      "key",
      "fused_set_kv_buffer_arg"
    ],
    "forward_cuda": [
      "self",
      "positions",
      "query",
      "key",
      "fused_set_kv_buffer_arg"
    ],
    "forward_triton": [
      "self",
      "positions",
      "query",
      "key"
    ],
    "forward_npu": [
      "self",
      "positions",
      "query",
      "key",
      "fused_set_kv_buffer_arg"
    ],
    "get_rope_index": [
      "spatial_merge_size",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "model_type",
      "tokens_per_second",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts"
    ],
    "get_rope_index_qwen3_omni": [
      "spatial_merge_size",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "tokens_per_second",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts"
    ],
    "get_rope_index_glm4v": [
      "input_ids",
      "hf_config",
      "image_grid_thw",
      "video_grid_thw",
      "attention_mask"
    ],
    "_get_feat_extract_output_lengths": [
      "input_lengths"
    ],
    "_get_llm_pos_ids_for_vision": [
      "st_idx",
      "vision_idx",
      "spatial_merge_size",
      "t_index",
      "grid_hs",
      "grid_ws",
      "device"
    ]
  },
  "DualChunkRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "dtype",
      "chunk_size",
      "local_size"
    ],
    "_compute_inv_freq": [
      "self",
      "base"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "query",
      "key",
      "offsets"
    ],
    "_apply_rotary_embedding": [
      "self",
      "cos_sin",
      "hidden_rot",
      "hidden_pass"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "get_rope": [
    "head_size",
    "rotary_dim",
    "max_position",
    "base",
    "is_neox_style",
    "rope_scaling",
    "dtype",
    "partial_rotary_factor",
    "dual_chunk_attention_config"
  ],
  "rotate_half": [
    "x"
  ],
  "apply_rotary_pos_emb_native": [
    "q",
    "k",
    "cos",
    "sin",
    "unsqueeze_dim"
  ],
  "apply_rotary_pos_emb_npu": [
    "q",
    "k",
    "cos",
    "sin",
    "unsqueeze_dim"
  ],
  "get_rope_cpu": [
    "head_size",
    "rotary_dim",
    "max_position",
    "base",
    "is_neox_style",
    "rope_scaling",
    "dtype",
    "partial_rotary_factor",
    "device"
  ],
  "get_rope_wrapper": [
    "head_size",
    "rotary_dim",
    "max_position",
    "base",
    "is_neox_style",
    "rope_scaling",
    "dtype",
    "partial_rotary_factor",
    "device"
  ],
  "nsa_enable_prefill_cp": [],
  "NSACPLayerCommunicator": {
    "__init__": [
      "self",
      "layer_scatter_modes",
      "input_layernorm",
      "post_attention_layernorm",
      "allow_reduce_scatter",
      "is_last_layer",
      "qkv_latent_func"
    ],
    "_post_init_communicate": [
      "self"
    ]
  },
  "NSACPCommunicateSimpleFn": {
    "get_fn": [
      "input_mode",
      "output_mode",
      "context"
    ]
  },
  "NSACPCommunicateWithAllReduceAndLayerNormFn": {
    "get_fn": [
      "hidden_states_input_mode",
      "residual_input_mode",
      "hidden_states_output_mode",
      "residual_output_mode",
      "context"
    ],
    "_gather_hidden_states_and_residual": [
      "hidden_states",
      "residual",
      "forward_batch",
      "layernorm",
      "context"
    ]
  },
  "NSACPCommunicateSummableTensorPairFn": {
    "get_fn": [
      "hidden_states_input_mode",
      "residual_input_mode",
      "output_mode",
      "context"
    ],
    "_scatter_hidden_states": [
      "hidden_states",
      "residual",
      "forward_batch",
      "context",
      "allow_reduce_scatter"
    ]
  },
  "AttentionType": {
    "DECODER": [],
    "ENCODER_ONLY": []
  },
  "RadixAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_dim",
      "scaling",
      "num_kv_heads",
      "layer_id",
      "logit_cap",
      "v_head_dim",
      "sliding_window_size",
      "is_cross_attention",
      "pos_encoding_mode",
      "logit_capping_method",
      "quant_config",
      "attn_type",
      "use_irope",
      "prefix"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "unified_attention_with_output": [
    "query",
    "key",
    "value",
    "output",
    "save_kv_cache",
    "layer_id"
  ],
  "QUANT_CFG_CHOICES": [],
  "amx_process_weight_after_loading": [
    "weight"
  ],
  "_amx_process_weight_after_loading": [
    "module",
    "weight_names",
    "transpose_dims"
  ],
  "_disable_hip_linear_quant": [],
  "WEIGHT_LOADER_V2_SUPPORTED": [],
  "adjust_marlin_shard": [
    "param",
    "shard_size",
    "shard_offset"
  ],
  "adjust_bitsandbytes_4bit_shard": [
    "param",
    "shard_offsets",
    "loaded_shard_id"
  ],
  "adjust_scalar_to_fused_array": [
    "param",
    "loaded_weight",
    "shard_id"
  ],
  "adjust_shard_offsets": [
    "shard_offsets",
    "loaded_weight",
    "dim"
  ],
  "LinearBase": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ReplicatedLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "bias",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "ColumnParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "bias",
      "gather_output",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "output_sizes",
      "prefix",
      "tp_rank",
      "tp_size",
      "use_presharded_weights",
      "skip_block_quant_check"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "input_"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MergedColumnParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_sizes",
      "bias",
      "gather_output",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix",
      "tp_rank",
      "tp_size",
      "use_presharded_weights"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ],
    "_load_fused_module_from_checkpoint": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ]
  },
  "QKVParallelLinear": {
    "__init__": [
      "self",
      "hidden_size",
      "head_size",
      "total_num_heads",
      "total_num_kv_heads",
      "bias",
      "skip_bias_add",
      "params_dtype",
      "quant_config",
      "prefix",
      "tp_rank",
      "tp_size",
      "load_presharded_attn",
      "v_head_size",
      "skip_block_quant_check"
    ],
    "_get_shard_offset_mapping": [
      "self",
      "loaded_shard_id"
    ],
    "_get_shard_size_mapping": [
      "self",
      "loaded_shard_id"
    ],
    "_load_fused_module_from_checkpoint": [
      "self",
      "param",
      "loaded_weight"
    ],
    "_load_qkv_block_scale": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "loaded_shard_id"
    ]
  },
  "RowParallelLinear": {
    "__init__": [
      "self",
      "input_size",
      "output_size",
      "bias",
      "input_is_parallel",
      "skip_bias_add",
      "params_dtype",
      "reduce_results",
      "quant_config",
      "prefix",
      "tp_rank",
      "tp_size",
      "use_presharded_weights"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight"
    ],
    "weight_loader_v2": [
      "self",
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "input_",
      "skip_all_reduce"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "SYNC_TOKEN_IDS_ACROSS_TP": [],
  "_BUILT_IN_SAMPLING_BACKENDS": [],
  "Sampler": {
    "__init__": [
      "self"
    ],
    "_preprocess_logits": [
      "self",
      "logits",
      "sampling_info"
    ],
    "forward": [
      "self",
      "logits_output",
      "sampling_info",
      "return_logprob",
      "top_logprobs_nums",
      "token_ids_logprobs",
      "positions"
    ],
    "compute_logprobs_only": [
      "self",
      "logits_output",
      "sampling_info",
      "return_logprob",
      "top_logprobs_nums",
      "token_ids_logprobs"
    ]
  },
  "register_sampler_backend": [
    "backend",
    "factory"
  ],
  "create_sampler": [
    "backend"
  ],
  "top_k_top_p_min_p_sampling_from_probs_torch": [
    "probs",
    "top_ks",
    "top_ps",
    "min_ps",
    "need_min_p_sampling",
    "sampling_seed",
    "positions"
  ],
  "top_k_top_p_min_p_sampling_from_probs_ascend": [
    "probs",
    "top_ks",
    "top_ps",
    "min_ps",
    "need_min_p_sampling"
  ],
  "multinomial_with_seed": [
    "inputs",
    "seed",
    "positions"
  ],
  "sampling_from_probs_torch": [
    "probs",
    "sampling_seed",
    "positions"
  ],
  "top_p_normalize_probs_torch": [
    "probs",
    "top_ps"
  ],
  "get_token_ids_logprobs_batch_optimized": [
    "logprobs",
    "token_ids_logprobs"
  ],
  "apply_custom_logit_processor": [
    "logits",
    "sampling_batch_info",
    "num_tokens_in_batch"
  ],
  "quantize_fp8_scale_tensorwise": [
    "w"
  ],
  "quantize_int4_scale_columnwise": [
    "w"
  ],
  "pack_int4_to_int32": [
    "to_pack",
    "reorder"
  ],
  "LogitsProcessorOutput": {},
  "LogitsMetadata": {
    "from_forward_batch": [
      "cls",
      "forward_batch"
    ],
    "compute_dp_attention_metadata": [
      "self"
    ]
  },
  "LogitsProcessor": {
    "__init__": [
      "self",
      "config",
      "skip_all_gather",
      "logit_scale",
      "return_full_logits"
    ],
    "compute_logprobs_for_multi_item_scoring": [
      "self",
      "input_ids",
      "hidden_states",
      "lm_head",
      "logits_metadata",
      "delimiter_token"
    ],
    "forward": [
      "self",
      "input_ids",
      "hidden_states",
      "lm_head",
      "logits_metadata",
      "aux_hidden_states",
      "hidden_states_before_norm"
    ],
    "process_input_logprobs": [
      "self",
      "input_logits",
      "logits_metadata"
    ],
    "process_input_logprobs_by_chunk": [
      "self",
      "pruned_states",
      "sample_indices",
      "input_logprob_indices",
      "token_to_seq_idx",
      "lm_head",
      "logits_metadata"
    ],
    "_get_logits": [
      "self",
      "hidden_states",
      "lm_head",
      "logits_metadata",
      "embedding_bias"
    ]
  },
  "fused_softcap_kernel": [
    "full_logits_ptr",
    "softcapping_value",
    "n_elements",
    "BLOCK_SIZE"
  ],
  "fused_softcap": [
    "full_logits",
    "final_logit_softcapping"
  ],
  "proj_filter": [
    "module",
    "fqn"
  ],
  "proj_filter_conv3d": [
    "module",
    "fqn"
  ],
  "apply_torchao_config_to_model": [
    "model",
    "torchao_config",
    "filter_fn"
  ],
  "fused_softcap_autotune": [],
  "fused_softcap_kernel_autotuned": [],
  "Softcap": {
    "__init__": [
      "self",
      "softcap_const"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x",
      "autotune"
    ]
  },
  "rmsnorm_autotune": [],
  "fused_dual_residual_rmsnorm_kernel": [
    "output_ptr",
    "mid_ptr",
    "activ_ptr",
    "residual_ptr",
    "weight1_ptr",
    "weight2_ptr",
    "eps",
    "hidden_dim",
    "BLOCK_SIZE"
  ],
  "fused_dual_residual_rmsnorm_kernel_autotune": [],
  "fused_dual_residual_rmsnorm": [
    "x",
    "residual",
    "weight1",
    "weight2",
    "eps",
    "autotune"
  ],
  "fused_rmsnorm_kernel": [
    "output_ptr",
    "activ_ptr",
    "weight_ptr",
    "eps",
    "hidden_dim",
    "BLOCK_SIZE"
  ],
  "fused_rmsnorm": [
    "x",
    "weight",
    "eps",
    "autotune",
    "inplace"
  ],
  "FusedDualResidualRMSNorm": {
    "__init__": [
      "self",
      "rmsnorm1",
      "rmsnorm2"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ],
    "forward_cuda": [
      "self",
      "x",
      "residual",
      "autotune"
    ],
    "forward_flashinfer": [
      "self",
      "x",
      "residual"
    ],
    "forward_native": [
      "self",
      "x",
      "residual"
    ]
  },
  "experts_combine_kernel": [
    "out_hidden_states",
    "moe_hidden_states",
    "mlp_hidden_states",
    "combine_k",
    "hidden_dim",
    "BLOCK_SIZE"
  ],
  "experts_combine_triton": [
    "moe_hidden_states",
    "mlp_hidden_states",
    "output_buffer"
  ],
  "gelu_and_mul_kernel": [
    "out_hidden_states_ptr",
    "out_scales_ptr",
    "hidden_states_ptr",
    "quant_max",
    "static_scale",
    "hidden_dim",
    "BLOCK_SIZE"
  ],
  "gelu_and_mul_triton": [
    "hidden_states",
    "scales",
    "quantize",
    "out"
  ],
  "silu_and_mul_kernel": [
    "out_hidden_states_ptr",
    "out_scales_ptr",
    "hidden_states_ptr",
    "quant_max",
    "static_scale",
    "hidden_dim",
    "BLOCK_SIZE"
  ],
  "silu_and_mul_triton": [
    "hidden_states",
    "scales",
    "quantize",
    "out"
  ],
  "_flashinfer_layernorm_available": [],
  "RMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "var_hidden_size",
      "cast_x_before_out_mul",
      "fp32_residual",
      "weight_dtype",
      "override_orig_dtype"
    ],
    "forward_cuda": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_npu": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_aiter": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_hip": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_native": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_cpu": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_xpu": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_with_allreduce_fusion": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps",
      "elementwise_affine",
      "bias",
      "dtype"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_hip": [
      "self",
      "x"
    ],
    "forward_npu": [
      "self",
      "x"
    ],
    "forward_cpu": [
      "self",
      "x"
    ]
  },
  "GemmaRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "_forward_impl": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_native": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_cuda": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_cpu": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_npu": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ],
    "forward_xpu": [
      "self",
      "x",
      "residual",
      "post_residual_addition"
    ]
  },
  "Gemma3RMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps"
    ],
    "_norm": [
      "self",
      "x"
    ],
    "forward_native": [
      "self",
      "x"
    ],
    "forward_cpu": [
      "self",
      "x"
    ],
    "forward_cuda": [
      "self",
      "x"
    ],
    "forward_npu": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "PoolingType": {
    "LAST": [],
    "CLS": []
  },
  "EmbeddingPoolerOutput": {},
  "Pooler": {
    "__init__": [
      "self",
      "pooling_type",
      "normalize"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "CrossEncodingPooler": {
    "__init__": [
      "self",
      "config",
      "classifier",
      "pooler"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "_compute_enable_deep_gemm": [],
  "ENABLE_JIT_DEEPGEMM": [],
  "DEEPGEMM_BLACKWELL": [],
  "DEEPGEMM_SCALE_UE8M0": [],
  "_BUILTIN_M_LIST": [],
  "_ENABLE_JIT_DEEPGEMM_PRECOMPILE": [],
  "_DO_COMPILE_ALL": [],
  "_IS_FIRST_RANK_ON_NODE": [],
  "_IN_PRECOMPILE_STAGE": [],
  "_FAST_WARMUP": [],
  "update_deep_gemm_config": [
    "gpu_id",
    "server_args"
  ],
  "DeepGemmKernelType": {
    "GROUPED_GEMM_NT_F8F8BF16_MASKED": [],
    "GROUPED_GEMM_NT_F8F8BF16_CONTIG": [],
    "GEMM_NT_F8F8BF16": []
  },
  "_maybe_compile_deep_gemm_one_type_all": [
    "kernel_type",
    "n",
    "k",
    "num_groups"
  ],
  "_compile_deep_gemm_one_type_all": [
    "kernel_type",
    "n",
    "k",
    "num_groups",
    "m_list"
  ],
  "_BaseWarmupExecutor": {
    "create": [
      "kernel_type"
    ],
    "get_memory_requirement": [
      "kernel_type",
      "max_m",
      "n",
      "k",
      "num_groups"
    ],
    "execute": [
      "self",
      "m"
    ]
  },
  "_empty_token_fp8": [
    "size"
  ],
  "_empty_block_fp8": [
    "size"
  ],
  "_BLOCK_SIZE": [],
  "_NormalWarmupExecutor": {
    "__init__": [
      "self",
      "max_m",
      "n",
      "k",
      "num_groups"
    ],
    "execute": [
      "self",
      "m"
    ]
  },
  "_GroupedContWarmupExecutor": {
    "__init__": [
      "self",
      "max_m",
      "n",
      "k",
      "num_groups"
    ],
    "execute": [
      "self",
      "m"
    ]
  },
  "_GroupedMaskedWarmupExecutor": {
    "__init__": [
      "self",
      "max_m",
      "n",
      "k",
      "num_groups"
    ],
    "execute": [
      "self",
      "m"
    ]
  },
  "deep_gemm_execution_hook": [
    "m",
    "n",
    "k",
    "num_groups",
    "kernel_type"
  ],
  "_SANITY_CHECK": [],
  "grouped_gemm_nt_f8f8bf16_masked": [
    "lhs",
    "rhs",
    "out",
    "masked_m",
    "expected_m",
    "overlap_args",
    "max_block_n"
  ],
  "grouped_gemm_nt_f8f8bf16_contig": [
    "lhs",
    "rhs",
    "out",
    "m_indices"
  ],
  "gemm_nt_f8f8bf16": [
    "lhs",
    "rhs",
    "out"
  ],
  "configure_deep_gemm_num_sms": [
    "num_sms"
  ],
  "_sanity_check_input": [
    "x_fp8"
  ],
  "get_layer_id": [
    "weight_name"
  ],
  "pad_or_narrow_weight": [
    "loaded_weight",
    "input_dim",
    "start_idx",
    "shard_size"
  ],
  "PPMissingLayer": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "LogprobStage": {
    "PREFILL": [],
    "DECODE": []
  },
  "InputLogprobsResult": {},
  "compute_temp_top_p_normalized_logprobs": [
    "last_logits",
    "logits_metadata",
    "top_p",
    "temperature"
  ],
  "get_top_logprobs_raw": [
    "logprobs",
    "top_logprobs_nums",
    "stage",
    "extend_logprob_pruned_lens_cpu"
  ],
  "get_top_logprobs_prefill": [
    "all_logprobs",
    "logits_metadata"
  ],
  "get_top_logprobs": [
    "logprobs",
    "top_logprobs_nums"
  ],
  "get_token_ids_logprobs_raw": [
    "logprobs",
    "token_ids_logprobs",
    "stage",
    "extend_logprob_pruned_lens_cpu",
    "delay_cpu_copy"
  ],
  "get_token_ids_logprobs_prefill": [
    "all_logprobs",
    "logits_metadata",
    "delay_cpu_copy"
  ],
  "get_token_ids_logprobs": [
    "logprobs",
    "token_ids_logprobs"
  ],
  "get_top_logprobs_chunk": [
    "logprobs",
    "logits_metadata",
    "top_k_nums",
    "pruned_lens",
    "input_top_logprobs_val",
    "input_top_logprobs_idx",
    "split_pruned_len"
  ],
  "get_token_ids_logprobs_chunk": [
    "logprobs",
    "token_ids_logprobs",
    "pruned_lens",
    "input_token_ids_logprobs_val",
    "input_token_ids_logprobs_idx",
    "split_pruned_len"
  ],
  "add_output_logprobs_for_spec_v1": [
    "batch",
    "res",
    "logits_output"
  ],
  "MultiPlatformOp": {
    "__init__": [
      "self"
    ],
    "enter_torch_compile": [
      "self",
      "num_tokens"
    ],
    "leave_torch_compile": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "forward_native": [
      "self"
    ],
    "forward_cuda": [
      "self"
    ],
    "forward_npu": [
      "self"
    ],
    "forward_hip": [
      "self"
    ],
    "forward_xpu": [
      "self"
    ],
    "forward_hpu": [
      "self"
    ],
    "forward_cpu": [
      "self"
    ],
    "dispatch_forward": [
      "self"
    ]
  },
  "KTConfig": {},
  "create_kt_config_from_server_args": [
    "server_args",
    "layer_idx"
  ],
  "mask_cpu_expert_ids": [
    "topk_ids",
    "num_gpu_experts"
  ],
  "KTEPWrapperMethod": {
    "__init__": [
      "self",
      "gpu_method",
      "kt_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "submit": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "sync": [
      "self",
      "x"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "__getattr__": [
      "self",
      "name"
    ]
  },
  "fused_moe_forward_native": [
    "layer",
    "dispatch_output"
  ],
  "moe_forward_native": [
    "layer",
    "x",
    "topk_output",
    "moe_runner_config"
  ],
  "ActivationMethod": {
    "SILU": [],
    "GELU": []
  },
  "rocm_aiter_asm_moe_tkw1": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "fc1_scale",
    "fc2_scale",
    "fc1_smooth_scale",
    "fc2_smooth_scale",
    "a16",
    "per_tensor_quant_scale",
    "expert_mask",
    "activation_method"
  ],
  "rocm_fused_experts_tkw1": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "per_channel_quant",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "block_shape"
  ],
  "TopKConfig": {},
  "TopKOutputChecker": {
    "format_is_standard": [
      "topk_output"
    ],
    "format_is_triton_kernels": [
      "topk_output"
    ],
    "format_is_bypassed": [
      "topk_output"
    ]
  },
  "TopKOutputFormat": {
    "STANDARD": [],
    "TRITON_KERNEL": [],
    "BYPASSED": []
  },
  "TopKOutput": {
    "format": [
      "self"
    ]
  },
  "StandardTopKOutput": {
    "format": [
      "self"
    ]
  },
  "TritonKernelTopKOutput": {
    "format": [
      "self"
    ]
  },
  "BypassedTopKOutput": {
    "format": [
      "self"
    ]
  },
  "TopK": {
    "__init__": [
      "self",
      "top_k"
    ],
    "forward_native": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "forward_cuda": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "forward_cpu": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "forward_npu": [
      "self",
      "hidden_states",
      "router_logits"
    ],
    "empty_topk_output": [
      "self",
      "device"
    ]
  },
  "fused_topk_torch_native": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "correction_bias",
    "scoring_func"
  ],
  "fused_topk_cpu": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "correction_bias",
    "scoring_func"
  ],
  "apply_topk_weights_cpu": [
    "need_apply",
    "topk_weights",
    "inputs"
  ],
  "fused_topk": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "correction_bias",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "scoring_func"
  ],
  "grouped_topk_gpu": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "num_expert_group",
    "topk_group",
    "num_fused_shared_experts",
    "routed_scaling_factor",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "apply_routed_scaling_factor_on_output"
  ],
  "grouped_topk_cpu": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "num_expert_group",
    "topk_group",
    "num_fused_shared_experts",
    "routed_scaling_factor",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "apply_routed_scaling_factor_on_output"
  ],
  "kimi_k2_biased_topk_impl": [
    "hidden_states",
    "gating_output",
    "correction_bias",
    "topk",
    "renormalize",
    "routed_scaling_factor",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "apply_routed_scaling_factor_on_output"
  ],
  "biased_grouped_topk_impl": [
    "hidden_states",
    "gating_output",
    "correction_bias",
    "topk",
    "renormalize",
    "num_expert_group",
    "topk_group",
    "num_fused_shared_experts",
    "routed_scaling_factor",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "apply_routed_scaling_factor_on_output"
  ],
  "is_power_of_two": [
    "n"
  ],
  "_mask_topk_ids_padded_region": [
    "topk_ids",
    "num_token_non_padded"
  ],
  "_biased_grouped_topk_postprocess": [
    "topk_ids",
    "expert_location_dispatch_info",
    "num_token_non_padded"
  ],
  "biased_grouped_topk_gpu": [
    "hidden_states",
    "gating_output",
    "correction_bias",
    "topk",
    "renormalize",
    "num_expert_group",
    "topk_group",
    "num_fused_shared_experts",
    "routed_scaling_factor",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "apply_routed_scaling_factor_on_output"
  ],
  "biased_grouped_topk_cpu": [
    "hidden_states",
    "gating_output",
    "correction_bias",
    "topk",
    "renormalize",
    "num_expert_group",
    "topk_group",
    "compiled",
    "num_fused_shared_experts",
    "routed_scaling_factor",
    "num_token_non_padded",
    "expert_location_dispatch_info",
    "apply_routed_scaling_factor_on_output"
  ],
  "select_experts": [
    "hidden_states",
    "router_logits",
    "topk_config"
  ],
  "get_cute_dtype": [
    "input"
  ],
  "flashinfer_cutedsl_moe_masked": [
    "hidden_states",
    "input_global_scale",
    "w1",
    "w1_blockscale",
    "w1_alpha",
    "w2",
    "a2_global_scale",
    "w2_blockscale",
    "w2_alpha",
    "masked_m",
    "down_sm_count",
    "down_signals",
    "down_start_event"
  ],
  "MoeA2ABackend": {
    "NONE": [],
    "DEEPEP": [],
    "MOONCAKE": [],
    "ASCEND_FUSEEP": [],
    "_missing_": [
      "cls",
      "value"
    ],
    "is_none": [
      "self"
    ],
    "is_deepep": [
      "self"
    ],
    "is_mooncake": [
      "self"
    ],
    "is_ascend_fuseep": [
      "self"
    ]
  },
  "MoeRunnerBackend": {
    "AUTO": [],
    "DEEP_GEMM": [],
    "TRITON": [],
    "TRITON_KERNELS": [],
    "FLASHINFER_TRTLLM": [],
    "FLASHINFER_CUTLASS": [],
    "FLASHINFER_MXFP4": [],
    "FLASHINFER_CUTEDSL": [],
    "CUTLASS": [],
    "MARLIN": [],
    "is_auto": [
      "self"
    ],
    "is_deep_gemm": [
      "self"
    ],
    "is_triton": [
      "self"
    ],
    "is_triton_kernels": [
      "self"
    ],
    "is_flashinfer_trtllm": [
      "self"
    ],
    "is_flashinfer_cutlass": [
      "self"
    ],
    "is_flashinfer_cutedsl": [
      "self"
    ],
    "is_flashinfer_mxfp4": [
      "self"
    ],
    "is_cutlass": [
      "self"
    ],
    "is_marlin": [
      "self"
    ]
  },
  "DeepEPMode": {
    "NORMAL": [],
    "LOW_LATENCY": [],
    "AUTO": [],
    "enable_normal": [
      "self"
    ],
    "enable_low_latency": [
      "self"
    ],
    "resolve": [
      "self",
      "is_extend_in_batch"
    ],
    "is_normal": [
      "self"
    ],
    "is_low_latency": [
      "self"
    ],
    "is_auto": [
      "self"
    ]
  },
  "initialize_moe_config": [
    "server_args"
  ],
  "get_moe_a2a_backend": [],
  "get_moe_runner_backend": [],
  "get_speculative_moe_runner_backend": [],
  "get_speculative_moe_a2a_backend": [],
  "get_deepep_mode": [],
  "get_deepep_config": [],
  "is_tbo_enabled": [],
  "is_sbo_enabled": [],
  "get_tbo_token_distribution_threshold": [],
  "filter_moe_weight_param_global_expert": [
    "name",
    "x",
    "num_local_experts"
  ],
  "should_use_flashinfer_cutlass_moe_fp4_allgather": [],
  "speculative_moe_backend_context": [],
  "speculative_moe_a2a_backend_context": [],
  "RoutingMethodType": {
    "Default": [],
    "Renormalize": [],
    "DeepSeekV3": [],
    "Llama4": [],
    "RenormalizeNaive": [],
    "TopK": [],
    "Unspecified": []
  },
  "CutlassMoEType": {
    "BlockscaledFP8": [],
    "BlockscaledFP4": []
  },
  "CutlassMoEParams": {
    "__init__": [
      "self",
      "cutlass_moe_type",
      "device",
      "num_experts",
      "intermediate_size_per_partition",
      "hidden_size"
    ],
    "to_gemm1_args": [
      "self"
    ],
    "to_gemm2_args": [
      "self"
    ]
  },
  "_GB": [],
  "_MB": [],
  "_RoutedExpertsDeviceCache": {
    "__init__": [
      "self",
      "max_running_requests",
      "num_hidden_layers",
      "num_experts_per_tok",
      "num_fused_shared_experts",
      "device"
    ],
    "get_buffer_size_bytes": [
      "self"
    ],
    "capture_fwd_routed_experts": [
      "self",
      "layer_id",
      "topk_ids"
    ],
    "_finalize_allocation_log": [
      "self"
    ]
  },
  "_RoutedExpertsHostCache": {
    "__init__": [
      "self",
      "num_tokens",
      "num_hidden_layers",
      "num_experts_per_tok"
    ],
    "get_buffer_size_bytes": [
      "self"
    ],
    "set_experts_buffer": [
      "self",
      "layer_id",
      "loc",
      "top_k"
    ],
    "_finalize_allocation_log": [
      "self"
    ]
  },
  "RoutedExpertsCapturer": {
    "create": [
      "enable",
      "model_config",
      "num_fused_shared_experts",
      "num_tokens",
      "max_running_requests",
      "device"
    ],
    "_sync_fwd_experts_buffer_DtoH": [
      "self",
      "forward_batch",
      "can_run_graph",
      "cuda_graph_batch"
    ],
    "capture": [
      "self",
      "layer_id",
      "topk_ids"
    ],
    "get_routed_experts": [
      "self",
      "req_pool_idx",
      "seqlen",
      "req_to_token_pool"
    ],
    "on_forward_end": [
      "self",
      "forward_batch",
      "can_run_graph",
      "cuda_graph_batch"
    ],
    "get_host_cache": [
      "self"
    ],
    "get_device_cache": [
      "self"
    ]
  },
  "_RoutedExpertsCapturerReal": {
    "__init__": [
      "self",
      "model_config",
      "num_tokens",
      "max_running_requests",
      "num_fused_shared_experts",
      "device"
    ],
    "_sync_fwd_experts_buffer_DtoH": [
      "self",
      "forward_batch",
      "can_run_graph",
      "cuda_graph_batch"
    ],
    "capture": [
      "self",
      "layer_id",
      "topk_ids"
    ],
    "get_routed_experts": [
      "self",
      "req_pool_idx",
      "seqlen",
      "req_to_token_pool"
    ],
    "on_forward_end": [
      "self",
      "forward_batch",
      "can_run_graph",
      "cuda_graph_batch"
    ],
    "get_host_cache": [
      "self"
    ],
    "get_device_cache": [
      "self"
    ]
  },
  "_RoutedExpertsCapturerNoop": {
    "__init__": [
      "self"
    ],
    "_sync_fwd_experts_buffer_DtoH": [
      "self",
      "forward_batch",
      "can_run_graph",
      "cuda_graph_batch"
    ],
    "capture": [
      "self",
      "layer_id",
      "topk_ids"
    ],
    "get_routed_experts": [
      "self",
      "req_pool_idx",
      "seqlen",
      "req_to_token_pool"
    ],
    "on_forward_end": [
      "self",
      "forward_batch",
      "can_run_graph",
      "cuda_graph_batch"
    ],
    "get_host_cache": [
      "self"
    ],
    "get_device_cache": [
      "self"
    ]
  },
  "get_global_experts_capturer": [],
  "set_global_experts_capturer": [
    "capturer"
  ],
  "extract_routed_experts_from_meta_info": [
    "data"
  ],
  "cutlass_fused_experts_fp8": [
    "a",
    "w1_q",
    "w2_q",
    "w1_scale",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "a1_strides",
    "c1_strides",
    "a2_strides",
    "c2_strides",
    "workspace",
    "a_ptrs",
    "b_ptrs",
    "out_ptrs",
    "a_scales_ptrs",
    "b_scales_ptrs",
    "expert_offsets",
    "problem_sizes1",
    "problem_sizes2",
    "use_fp8_blockscale",
    "output",
    "enable_es"
  ],
  "FLOAT4_E2M1_MAX": [],
  "FLOAT8_E4M3_MAX": [],
  "cutlass_moe_fp4": [
    "a",
    "a1_gscale",
    "w1_fp4",
    "w1_blockscale",
    "w1_alphas",
    "a2_gscale",
    "w2_fp4",
    "w2_blockscale",
    "w2_alphas",
    "topk_weights",
    "topk_ids",
    "params",
    "apply_router_weight_on_input"
  ],
  "cutlass_w4a8_moe": [
    "a",
    "w1_q",
    "w2_q",
    "w1_scale",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "a_strides1",
    "b_strides1",
    "c_strides1",
    "a_strides2",
    "b_strides2",
    "c_strides2",
    "s_strides13",
    "s_strides2",
    "expert_offsets",
    "problem_sizes1",
    "problem_sizes2",
    "a1_scale",
    "a2_scale",
    "apply_router_weight_on_input",
    "routed_scaling_factor"
  ],
  "cutlass_w4a8_moe_deepep_normal": [
    "a",
    "w1_q",
    "w2_q",
    "w1_scale",
    "w2_scale",
    "topk_weights",
    "topk_ids_",
    "a_strides1",
    "b_strides1",
    "c_strides1",
    "a_strides2",
    "b_strides2",
    "c_strides2",
    "s_strides13",
    "s_strides2",
    "expert_offsets",
    "problem_sizes1",
    "problem_sizes2",
    "a1_scale",
    "a2_scale"
  ],
  "cutlass_w4a8_moe_deepep_ll": [
    "a",
    "w1_q",
    "w2_q",
    "w1_scale",
    "w2_scale",
    "topk_ids_",
    "masked_m",
    "a_strides1",
    "b_strides1",
    "c_strides1",
    "a_strides2",
    "b_strides2",
    "c_strides2",
    "s_strides13",
    "s_strides2",
    "expert_offsets",
    "problem_sizes1",
    "problem_sizes2",
    "a1_scale",
    "a2_scale"
  ],
  "fused_moe_router_cudacore_kernel": [
    "input_ptr",
    "moe_router_weight_ptr",
    "topk_weights_ptr",
    "topk_ids_ptr",
    "correction_bias_ptr",
    "is_correction_bias",
    "num_experts",
    "topk",
    "moe_softcapping",
    "moe_renormalize",
    "hidden_dim",
    "BLOCK_SIZE"
  ],
  "fused_moe_router_cudacore": [
    "x",
    "router_weight",
    "topk",
    "moe_softcapping",
    "correction_bias"
  ],
  "fused_moe_router_tensorcore_kernel": [
    "a_ptr",
    "b_ptr",
    "topk_weights_ptr",
    "topk_ids_ptr",
    "bs",
    "num_experts",
    "topk",
    "moe_softcapping",
    "moe_renormalize",
    "correction_bias_ptr",
    "is_correction_bias",
    "K",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "stride_am",
    "stride_bn",
    "dp_attn_workaround_flag"
  ],
  "fused_moe_router_tensorcore": [
    "x",
    "router_weight",
    "topk",
    "moe_softcapping",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "correction_bias"
  ],
  "fused_moe_router_shim": [
    "moe_softcapping",
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize",
    "correction_bias",
    "enable_deterministic_inference"
  ],
  "FusedMoeRouter": {
    "__init__": [
      "self",
      "router_linear",
      "topk",
      "moe_softcapping"
    ],
    "__call__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ],
    "forward_cuda": [
      "self",
      "x",
      "autotune"
    ],
    "forward_torch": [
      "self",
      "x"
    ]
  },
  "align_fp8_moe_weights_for_flashinfer_trtllm": [
    "layer"
  ],
  "FlashInferTrtllmFp8MoeQuantInfo": {},
  "fused_experts_none_to_flashinfer_trtllm_fp8": [
    "dispatch_output",
    "quant_info",
    "runner_config"
  ],
  "MoeRunnerConfig": {},
  "RunnerInput": {
    "runner_backend": [
      "self"
    ],
    "runner_backend_is_triton": [
      "self"
    ]
  },
  "RunnerOutput": {
    "runner_backend": [
      "self"
    ],
    "runner_backend_is_triton": [
      "self"
    ]
  },
  "MoeQuantInfo": {},
  "MoeRunnerCore": {
    "__init__": [
      "self",
      "config"
    ],
    "run": [
      "self",
      "runner_input",
      "quant_info",
      "running_state"
    ],
    "runner_backend": [
      "self"
    ],
    "runner_backend_is_triton": [
      "self"
    ]
  },
  "FusedOpPool": {
    "register_fused_func": [
      "cls",
      "a2a_backend_name",
      "runner_backend_name",
      "fused_func"
    ],
    "get_fused_func": [
      "cls",
      "dispatch_name",
      "runner_name"
    ]
  },
  "PermuteMethodPool": {
    "register_pre_permute": [
      "cls",
      "dispatch_output_name",
      "runner_backend_name",
      "permute_func"
    ],
    "register_post_permute": [
      "cls",
      "runner_backend_name",
      "combine_input_name",
      "permute_func"
    ],
    "get_pre_permute": [
      "cls",
      "dispatch_output_format",
      "runner_input_format"
    ],
    "get_post_permute": [
      "cls",
      "runner_output_format",
      "combine_input_format"
    ]
  },
  "register_fused_func": [
    "a2a_backend_name",
    "runner_backend_name"
  ],
  "register_pre_permute": [
    "dispatch_output_name",
    "runner_backend_name"
  ],
  "register_post_permute": [
    "runner_backend_name",
    "combine_input_name"
  ],
  "TritonKernelsRunnerInput": {
    "runner_backend": [
      "self"
    ]
  },
  "TritonKernelsRunnerOutput": {
    "runner_backend": [
      "self"
    ]
  },
  "TritonKernelsQuantInfo": {},
  "TritonKernelsRunnerCore": {
    "run": [
      "self",
      "runner_input",
      "quant_info",
      "running_state"
    ],
    "runner_backend": [
      "self"
    ]
  },
  "pre_permute_standard_to_triton_kernels": [
    "dispatch_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "post_permute_triton_kernels_to_standard": [
    "runner_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "_MOE_PADDING_SIZE": [],
  "TritonRunnerInput": {
    "runner_backend": [
      "self"
    ]
  },
  "TritonRunnerOutput": {
    "runner_backend": [
      "self"
    ]
  },
  "TritonMoeQuantInfo": {},
  "TritonRunnerCore": {
    "__init__": [
      "self",
      "config"
    ],
    "run": [
      "self",
      "runner_input",
      "quant_info",
      "running_state"
    ],
    "runner_backend": [
      "self"
    ]
  },
  "fused_experts_none_to_triton": [
    "dispatch_output",
    "quant_info",
    "runner_config"
  ],
  "pre_permute_standard_to_triton": [
    "dispatch_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "post_permute_triton_to_standard": [
    "runner_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "MarlinRunnerInput": {
    "runner_backend": [
      "self"
    ]
  },
  "MarlinRunnerOutput": {
    "runner_backend": [
      "self"
    ]
  },
  "MarlinMoeQuantInfo": {},
  "fused_experts_none_to_marlin": [
    "dispatch_output",
    "quant_info",
    "runner_config"
  ],
  "_MASKED_GEMM_FAST_ACT": [],
  "_DEEPGEMM_ON_H20": [],
  "_cast_to_e8m0_with_rounding_up": [
    "x"
  ],
  "copy_list_to_gpu_no_ce": [
    "arr"
  ],
  "DeepGemmRunnerInput": {
    "runner_backend": [
      "self"
    ]
  },
  "DeepGemmRunnerOutput": {
    "runner_backend": [
      "self"
    ]
  },
  "DeepGemmMoeQuantInfo": {},
  "DeepGemmRunnerCore": {
    "__init__": [
      "self",
      "config"
    ],
    "run": [
      "self",
      "runner_input",
      "quant_info",
      "running_state"
    ],
    "_run_contiguous_gemm": [
      "self",
      "runner_input",
      "quant_info",
      "running_state"
    ],
    "_run_masked_gemm": [
      "self",
      "runner_input",
      "quant_info",
      "running_state"
    ],
    "runner_backend": [
      "self"
    ]
  },
  "pre_permute_standard_to_deep_gemm": [
    "dispatch_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "post_permute_deep_gemm_to_standard": [
    "runner_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "pre_permute_deepep_ll_to_deep_gemm": [
    "dispatch_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "post_permute_deep_gemm_to_deepep_ll": [
    "runner_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "pre_permute_deepep_normal_to_deep_gemm": [
    "dispatch_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "post_permute_deep_gemm_to_deepep_normal": [
    "runner_output",
    "quant_info",
    "runner_config",
    "running_state"
  ],
  "MoeRunner": {
    "__init__": [
      "self",
      "runner_backend",
      "config"
    ],
    "run": [
      "self",
      "dispatch_output",
      "quant_info"
    ],
    "set_overlap_args": [
      "self",
      "down_gemm_overlap_args",
      "meta_overlap_args"
    ],
    "clear_overlap_args": [
      "self"
    ]
  },
  "moe_align_block_size": [
    "topk_ids",
    "block_size",
    "num_experts"
  ],
  "get_scalar_type": [
    "num_bits",
    "has_zp"
  ],
  "fused_marlin_moe": [
    "hidden_states",
    "w1",
    "w2",
    "w1_scale",
    "w2_scale",
    "gating_output",
    "topk_weights",
    "topk_ids",
    "global_num_experts",
    "expert_map",
    "g_idx1",
    "g_idx2",
    "sort_indices1",
    "sort_indices2",
    "w1_zeros",
    "w2_zeros",
    "workspace",
    "num_bits",
    "is_k_full",
    "inplace",
    "routed_scaling_factor"
  ],
  "padding_size": [],
  "support_tensor_descriptor": [],
  "should_enable_swap_ab": [
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N"
  ],
  "write_zeros_to_output": [
    "c_ptr",
    "stride_cm",
    "stride_cn",
    "pid_n",
    "N",
    "offs_token",
    "token_mask",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "compute_type"
  ],
  "fused_moe_kernel_gptq_awq": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "b_scale_ptr",
    "b_zp_ptr",
    "topk_weights_ptr",
    "sorted_token_ids_ptr",
    "expert_ids_ptr",
    "num_tokens_post_padded_ptr",
    "N",
    "K",
    "EM",
    "num_valid_tokens",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "stride_bze",
    "stride_bzk",
    "stride_bzn",
    "group_size",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "MUL_ROUTED_WEIGHT",
    "top_k",
    "compute_type",
    "has_zp",
    "use_int4_w4a16",
    "use_int8_w8a16",
    "even_Ks",
    "filter_expert"
  ],
  "fused_moe_kernel": [
    "a_ptr",
    "a_desc",
    "b_ptr",
    "b_desc",
    "bias_ptr",
    "c_ptr",
    "a_scale_ptr",
    "b_scale_ptr",
    "topk_weights_ptr",
    "sorted_token_ids_ptr",
    "expert_ids_ptr",
    "num_tokens_post_padded_ptr",
    "N",
    "K",
    "EM",
    "num_valid_tokens",
    "stride_am",
    "stride_ak",
    "stride_be",
    "stride_bk",
    "stride_bn",
    "stride_bias_e",
    "stride_bias_n",
    "stride_cm",
    "stride_cn",
    "stride_asm",
    "stride_ask",
    "stride_bse",
    "stride_bsk",
    "stride_bsn",
    "group_n",
    "group_k",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "MUL_ROUTED_WEIGHT",
    "top_k",
    "compute_type",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "per_channel_quant",
    "even_Ks",
    "c_sorted",
    "filter_expert",
    "swap_ab"
  ],
  "invoke_fused_moe_kernel": [
    "A",
    "B",
    "bias",
    "C",
    "A_scale",
    "B_scale",
    "B_zp",
    "topk_weights",
    "topk_ids",
    "sorted_token_ids",
    "expert_ids",
    "num_tokens_post_padded",
    "mul_routed_weight",
    "top_k",
    "config",
    "compute_type",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "block_shape",
    "no_combine",
    "a_use_tma",
    "b_use_tma",
    "c_sorted",
    "filter_expert"
  ],
  "tanh": [
    "x"
  ],
  "_apply_activation": [
    "x",
    "ACTIVATION_TYPE"
  ],
  "act_and_mul_kernel": [
    "gateup_output",
    "down_input",
    "hidden_size",
    "expert_ids_ptr",
    "expert_step",
    "BLOCK_SIZE",
    "ACTIVATION_TYPE"
  ],
  "act_and_mul_triton": [
    "gateup_output",
    "down_input",
    "config",
    "topk_ids",
    "expert_ids",
    "down_moe_use_tma",
    "activation"
  ],
  "_moe_sum_reduce_kernel": [
    "input_ptr",
    "input_stride_0",
    "input_stride_1",
    "input_stride_2",
    "output_ptr",
    "output_stride_0",
    "output_stride_1",
    "token_num",
    "topk_num",
    "hidden_dim",
    "routed_scaling_factor",
    "BLOCK_M",
    "BLOCK_DIM",
    "NUM_STAGE"
  ],
  "moe_sum_reduce_triton": [
    "input",
    "output",
    "routed_scaling_factor"
  ],
  "_fused_append_shared_experts_kernel": [
    "topk_ids_ptr",
    "topk_weights_ptr",
    "out_ids_ptr",
    "out_weights_ptr",
    "N_BASE",
    "scale_factor",
    "K",
    "S"
  ],
  "fused_append_shared_experts": [
    "topk_ids",
    "topk_weights",
    "num_fused_shared_experts",
    "scale_factor",
    "N"
  ],
  "override_config": [
    "config"
  ],
  "get_config_file_name": [
    "E",
    "N",
    "dtype",
    "block_shape",
    "per_channel_quant",
    "down_moe"
  ],
  "get_moe_configs": [
    "E",
    "N",
    "dtype",
    "block_n",
    "block_k",
    "per_channel_quant",
    "down_moe"
  ],
  "get_default_config": [
    "M",
    "E",
    "N",
    "K",
    "topk",
    "dtype",
    "is_marlin",
    "block_shape"
  ],
  "try_get_optimal_moe_config": [
    "w1_shape",
    "w2_shape",
    "top_k",
    "dtype",
    "M",
    "is_marlin",
    "block_shape",
    "per_channel_quant",
    "return_down_config"
  ],
  "get_config_dtype_str": [
    "dtype",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "use_fp8_w8a8",
    "use_int8_w8a8"
  ],
  "trtllm_fp4_block_scale_moe": [],
  "create_moe_dispatcher": [
    "moe_runner_config"
  ],
  "FusedMoeWeightScaleSupported": {
    "TENSOR": [],
    "CHANNEL": [],
    "GROUP": [],
    "BLOCK": []
  },
  "FusedMoE": {
    "__init__": [
      "self",
      "num_experts",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "top_k",
      "num_fused_shared_experts",
      "params_dtype",
      "reduce_results",
      "quant_config",
      "prefix",
      "activation",
      "apply_router_weight_on_input",
      "use_presharded_weights",
      "inplace",
      "no_combine",
      "routed_scaling_factor",
      "gemm1_alpha",
      "gemm1_clamp_limit",
      "use_weight_loader_fused",
      "with_bias",
      "routing_method_type",
      "is_gated"
    ],
    "_load_per_tensor_weight_scale": [
      "self",
      "shard_id",
      "param",
      "loaded_weight",
      "expert_id"
    ],
    "_load_model_weight_or_group_weight_scale": [
      "self",
      "shard_dim",
      "expert_data",
      "shard_id",
      "loaded_weight",
      "tp_rank",
      "is_bias"
    ],
    "_load_per_channel_weight_scale": [
      "self",
      "expert_data",
      "shard_dim",
      "shard_id",
      "loaded_weight",
      "tp_rank"
    ],
    "_load_w13": [
      "self",
      "expert_data",
      "shard_dim",
      "shard_id",
      "loaded_weight",
      "tp_rank",
      "is_bias"
    ],
    "_load_w2": [
      "self",
      "expert_data",
      "shard_dim",
      "shard_id",
      "loaded_weight",
      "tp_rank",
      "is_bias"
    ],
    "_load_single_value": [
      "self",
      "param",
      "loaded_weight",
      "expert_id"
    ],
    "_load_g_idx": [
      "self",
      "shard_id",
      "expert_data",
      "shard_dim",
      "loaded_weight",
      "tp_rank"
    ],
    "_map_global_expert_id_to_local_expert_id": [
      "self",
      "expert_id"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "shard_id",
      "expert_id"
    ],
    "_weight_loader_physical": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "shard_id",
      "expert_id"
    ],
    "_weight_loader_impl": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "shard_id",
      "expert_id"
    ],
    "weight_loader_fused": [
      "self",
      "param",
      "loaded_weight",
      "weight_name",
      "shard_id"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "forward_impl": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "run_moe_core": [
      "self",
      "dispatch_output"
    ],
    "make_expert_params_mapping": [
      "cls",
      "ckpt_gate_proj_name",
      "ckpt_down_proj_name",
      "ckpt_up_proj_name",
      "num_experts"
    ],
    "make_expert_params_mapping_fused": [
      "cls",
      "ckpt_gate_up_proj_name",
      "ckpt_down_proj_name",
      "ckpt_gate_up_proj_bias_name",
      "ckpt_down_proj_bias_name"
    ],
    "make_expert_params_mapping_fused_mxfp4": [
      "cls",
      "ckpt_gate_up_proj_name",
      "ckpt_down_proj_name",
      "ckpt_gate_up_proj_bias_name",
      "ckpt_down_proj_bias_name",
      "ckpt_gate_up_proj_scale_name",
      "ckpt_down_proj_scale_name"
    ],
    "make_expert_input_scale_params_mapping": [
      "cls",
      "num_experts"
    ],
    "set_overlap_args": [
      "self",
      "down_gemm_overlap_args",
      "meta_overlap_args"
    ],
    "clear_overlap_args": [
      "self"
    ]
  },
  "FlashInferFusedMoE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "forward_impl": [
      "self",
      "hidden_states",
      "topk_output"
    ]
  },
  "FlashInferFP4MoE": {
    "__init__": [
      "self"
    ],
    "_quantize_hidden_states_fp4": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "forward_impl": [
      "self",
      "hidden_states",
      "topk_output"
    ]
  },
  "moe_forward_piecewise_cuda_graph_impl": [
    "hidden_states",
    "topk_weights",
    "topk_ids",
    "router_logits",
    "layer_id"
  ],
  "flashinfer_fp4_moe_forward_piecewise_cuda_graph_impl": [
    "hidden_states",
    "router_logits",
    "top_k",
    "topk_group",
    "num_expert_group",
    "correction_bias",
    "layer_id"
  ],
  "quantize": [
    "w",
    "dtype",
    "dev"
  ],
  "triton_kernel_moe_forward": [
    "hidden_states",
    "w1",
    "w2",
    "topk_output",
    "moe_runner_config",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "block_shape"
  ],
  "triton_kernel_fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "routing_data",
    "gather_indx",
    "scatter_indx",
    "inplace",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "block_shape"
  ],
  "triton_kernel_moe_with_bias_forward": [
    "hidden_states",
    "w1",
    "w1_pcg",
    "b1",
    "w2",
    "w2_pcg",
    "b2",
    "topk_output",
    "moe_runner_config",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "block_shape"
  ],
  "triton_kernel_fused_experts_with_bias": [
    "hidden_states",
    "w1",
    "w1_pcg",
    "b1",
    "w2",
    "w2_pcg",
    "b2",
    "routing_data",
    "gather_indx",
    "scatter_indx",
    "inplace",
    "activation",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "per_channel_quant",
    "global_num_experts",
    "expert_map",
    "w1_scale",
    "w2_scale",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "gemm1_alpha",
    "gemm1_clamp_limit"
  ],
  "inplace_fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "b1",
    "b2",
    "activation",
    "is_gated",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "routed_scaling_factor",
    "gemm1_alpha",
    "gemm1_limit",
    "filter_expert"
  ],
  "outplace_fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "b1",
    "b2",
    "activation",
    "is_gated",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "no_combine",
    "routed_scaling_factor",
    "gemm1_alpha",
    "gemm1_limit",
    "filter_expert"
  ],
  "fused_experts": [
    "hidden_states",
    "w1",
    "w2",
    "topk_output",
    "moe_runner_config",
    "b1",
    "b2",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape"
  ],
  "moe_sum_reduce_torch_compile": [
    "x",
    "out",
    "routed_scaling_factor"
  ],
  "swiglu_with_alpha_and_limit": [
    "x",
    "gemm1_alpha",
    "gemm1_limit"
  ],
  "_down_moe_use_tma": [],
  "fused_experts_impl": [
    "hidden_states",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "b1",
    "b2",
    "inplace",
    "activation",
    "is_gated",
    "apply_router_weight_on_input",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape",
    "no_combine",
    "routed_scaling_factor",
    "gemm1_alpha",
    "gemm1_limit",
    "filter_expert"
  ],
  "fused_moe": [
    "hidden_states",
    "w1",
    "w2",
    "topk_output",
    "moe_runner_config",
    "b1",
    "b2",
    "use_fp8_w8a8",
    "use_int8_w8a8",
    "use_int8_w8a16",
    "use_int4_w4a16",
    "per_channel_quant",
    "w1_scale",
    "w2_scale",
    "w1_zp",
    "w2_zp",
    "a1_scale",
    "a2_scale",
    "block_shape"
  ],
  "_get_launch_config_1d": [
    "device",
    "numel"
  ],
  "_get_launch_config_2d": [
    "device",
    "m",
    "n"
  ],
  "deepep_permute_triton_kernel": [
    "input_ptr",
    "gateup_input_ptr",
    "src2dst_ptr",
    "topk_ids_ptr",
    "a1_scales_ptr",
    "topk",
    "hidden_size",
    "BLOCK_SIZE"
  ],
  "deepep_post_reorder_triton_kernel": [
    "down_output_ptr",
    "output_ptr",
    "src2dst_ptr",
    "topk_ids_ptr",
    "topk_weights_ptr",
    "topk",
    "hidden_size",
    "BLOCK_SIZE"
  ],
  "compute_src2dst_triton_kernel": [
    "reorder_ids",
    "src2dst",
    "num_toks",
    "BLOCK_SIZE"
  ],
  "deepep_compute_src2dst_triton_kernel": [
    "reorder_ids",
    "src2dst",
    "num_toks",
    "num_minus_one",
    "BLOCK_SIZE"
  ],
  "deepep_run_moe_deep_preprocess": [
    "topk_ids",
    "num_experts"
  ],
  "compute_seg_indptr_triton_kernel": [
    "reorder_topk_ids",
    "seg_indptr",
    "num_toks"
  ],
  "cutlass_w4_run_moe_ep_preproess": [
    "topk_ids"
  ],
  "pre_reorder_triton_kernel_for_cutlass_moe": [
    "input_ptr",
    "gateup_input_ptr",
    "src2dst_ptr",
    "topk_ids_ptr",
    "a1_scales_ptr",
    "num_local_experts",
    "topk",
    "num_tokens",
    "hidden_size",
    "BLOCK_SIZE",
    "NUM_STAGES"
  ],
  "pre_reorder_for_cutlass_moe": [
    "input",
    "gateup_input",
    "src2dst",
    "topk_ids",
    "a1_scales",
    "num_local_experts",
    "topk",
    "num_tokens",
    "hidden_size"
  ],
  "_silu_and_mul_post_quant_kernel": [
    "input_ptr",
    "stride_input_0",
    "stride_input_1",
    "stride_input_2",
    "output_ptr",
    "stride_output_0",
    "stride_output_1",
    "stride_output_2",
    "output_scale_ptr",
    "stride_output_scale_0",
    "stride_output_scale_1",
    "stride_output_scale_2",
    "masked_m_ptr",
    "size_n",
    "fp8_max",
    "fp8_min",
    "BLOCK_N",
    "NUM_STAGE",
    "SCALE_UE8M0"
  ],
  "silu_and_mul_masked_post_quant_fwd": [
    "input",
    "output",
    "output_scale",
    "quant_group_size",
    "masked_m",
    "scale_ue8m0"
  ],
  "silu_mul_static_tensorwise_quant_triton_kernel_for_cutlass_moe": [
    "input_ptr",
    "output_ptr",
    "scale_ptr",
    "num_tokens_tensor_ptr",
    "intermediate_size",
    "BLOCK_SIZE",
    "NUM_STAGES"
  ],
  "silu_mul_static_tensorwise_quant_for_cutlass_moe": [
    "input",
    "output",
    "scale",
    "num_tokens_tensor",
    "expected_num_tokens",
    "intermediate_size"
  ],
  "post_reorder_triton_kernel_for_cutlass_moe": [
    "down_output_ptr",
    "output_ptr",
    "src2dst_ptr",
    "topk_ids_ptr",
    "topk_weights_ptr",
    "num_local_experts",
    "topk",
    "num_tokens",
    "hidden_size",
    "routed_scaling_factor",
    "BLOCK_SIZE",
    "NUM_STAGES"
  ],
  "post_reorder_for_cutlass_moe": [
    "down_output",
    "output",
    "src2dst",
    "topk_ids",
    "topk_weights",
    "num_local_experts",
    "topk",
    "num_tokens",
    "hidden_size",
    "routed_scaling_factor"
  ],
  "post_reorder_triton_kernel": [
    "down_output_ptr",
    "output_ptr",
    "src2dst_ptr",
    "topk_ids_ptr",
    "topk_weights_ptr",
    "topk",
    "hidden_size",
    "BLOCK_SIZE"
  ],
  "_fwd_kernel_ep_scatter_1": [
    "num_recv_tokens_per_expert",
    "expert_start_loc",
    "m_indices",
    "num_experts",
    "BLOCK_E",
    "BLOCK_EXPERT_NUM"
  ],
  "_fwd_kernel_ep_scatter_2": [
    "total_token_num",
    "expert_start_loc",
    "recv_x",
    "recv_x_stride0",
    "recv_x_stride1",
    "recv_x_scale",
    "recv_x_scale_stride0",
    "recv_x_scale_stride1",
    "recv_topk",
    "recv_topk_stride0",
    "recv_topk_stride1",
    "output_tensor",
    "output_tensor_stride0",
    "output_tensor_stride1",
    "output_tensor_scale",
    "output_tensor_scale_stride0",
    "output_tensor_scale_stride1",
    "output_index",
    "output_index_stride0",
    "output_index_stride1",
    "topk_num",
    "HIDDEN_SIZE",
    "HIDDEN_SIZE_PAD",
    "SCALE_HIDDEN_SIZE",
    "SCALE_HIDDEN_SIZE_PAD"
  ],
  "ep_scatter": [
    "recv_x",
    "recv_x_scale",
    "recv_topk",
    "num_recv_tokens_per_expert",
    "expert_start_loc",
    "output_tensor",
    "output_tensor_scale",
    "m_indices",
    "output_index",
    "scale_ue8m0"
  ],
  "_fwd_kernel_ep_gather": [
    "total_token_num",
    "input_tensor",
    "input_tensor_stride0",
    "input_tensor_stride1",
    "recv_topk_ids",
    "recv_topk_ids_stride0",
    "recv_topk_ids_stride1",
    "recv_topk_weight",
    "recv_topk_weight_stride0",
    "recv_topk_weight_stride1",
    "input_index",
    "input_index_stride0",
    "input_index_stride1",
    "output_tensor",
    "output_tensor_stride0",
    "output_tensor_stride1",
    "topk_num",
    "BLOCK_D"
  ],
  "ep_gather": [
    "input_tensor",
    "recv_topk_ids",
    "recv_topk_weight",
    "input_index",
    "output_tensor"
  ],
  "get_tma_aligned_size": [
    "x",
    "element_size"
  ],
  "_tma_align_input_scale_kernel": [
    "input_scale_ptr",
    "output_ptr",
    "m",
    "k_div_block_size",
    "input_scale_stride_m",
    "input_scale_stride_k",
    "output_stride_m",
    "output_stride_k",
    "BLOCK_SIZE_K"
  ],
  "tma_align_input_scale": [
    "input_scale"
  ],
  "compute_masked_m_triton_kernel": [
    "seg_indptr",
    "masked_m"
  ],
  "deepgemm_compute_src2dst_triton_kernel": [
    "topk_ids",
    "reorder_ids",
    "seg_indptr",
    "src2dst",
    "m_max",
    "num_toks",
    "BLOCK_SIZE"
  ],
  "fill_gateup_input_triton_kernel": [
    "input_ptr",
    "scale_ptr",
    "gateup_input_ptr",
    "gateup_input_scale_ptr",
    "src2dst_ptr",
    "topk_ids_ptr",
    "topk",
    "hidden_size",
    "scale_size",
    "BLOCK_SIZE"
  ],
  "moe_ep_deepgemm_preprocess": [
    "topk_ids",
    "num_local_experts",
    "hidden_states",
    "top_k",
    "block_shape",
    "output_dtype"
  ],
  "compute_identity_kernel": [
    "top_k",
    "hidden_states_ptr",
    "expert_scales_ptr",
    "num_tokens",
    "output_ptr",
    "hidden_dim",
    "scales_stride",
    "BLOCK_SIZE"
  ],
  "zero_experts_compute_triton": [
    "expert_indices",
    "expert_scales",
    "num_experts",
    "zero_expert_type",
    "hidden_states"
  ],
  "compute_problem_sizes_w4a8_kernel": [
    "masked_m_ptr",
    "problem_sizes1_ptr",
    "problem_sizes2_ptr",
    "n",
    "k",
    "num_experts",
    "BLOCK_SIZE"
  ],
  "compute_problem_sizes_w4a8": [
    "masked_m",
    "problem_sizes1",
    "problem_sizes2",
    "n",
    "k",
    "num_experts"
  ],
  "deepep_ll_get_cutlass_w4a8_moe_mm_data": [
    "masked_m",
    "problem_sizes1",
    "problem_sizes2",
    "num_experts",
    "n",
    "k"
  ],
  "_silu_and_mul_post_per_tensor_quant_kernel": [
    "input_ptr",
    "stride_input_expert",
    "stride_input_token",
    "stride_input_dim",
    "output_ptr",
    "stride_output_expert",
    "stride_output_token",
    "stride_output_dim",
    "scale_ptr",
    "masked_m_ptr",
    "inner_dim",
    "fp8_max",
    "fp8_min",
    "BLOCK_N",
    "NUM_STAGE"
  ],
  "silu_and_mul_masked_post_per_tensor_quant_fwd": [
    "input",
    "output",
    "masked_m",
    "scale"
  ],
  "_is_fp8_fnuz": [],
  "DeepEPMoE": {
    "_has_printed": [],
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "num_fused_shared_experts",
      "params_dtype",
      "quant_config",
      "prefix",
      "activation",
      "routed_scaling_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "forward_impl": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "run_moe_core": [
      "self",
      "dispatch_output"
    ],
    "combine": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights",
      "overlap_args"
    ],
    "forward_aiter": [
      "self",
      "dispatch_output"
    ],
    "forward_flashinfer_cutedsl": [
      "self",
      "dispatch_output"
    ],
    "forward_cutlass_w4afp8": [
      "self",
      "dispatch_output"
    ],
    "forward_cutlass_w4afp8_masked": [
      "self",
      "dispatch_output"
    ],
    "forward_npu": [
      "self",
      "dispatch_output"
    ]
  },
  "NpuFuseEPMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "num_fused_shared_experts",
      "params_dtype",
      "quant_config",
      "prefix",
      "activation",
      "routed_scaling_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "topk_output",
      "forward_shared_experts",
      "alt_stream",
      "disable_sbo"
    ],
    "release_weight_cache": [
      "self",
      "weight"
    ],
    "permute_w13_weight_scale": [
      "self",
      "w",
      "tile_n"
    ],
    "reshape_w13_weight": [
      "self",
      "weight",
      "dim",
      "chunk_size"
    ],
    "_process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "get_moe_impl_class": [
    "quant_config"
  ],
  "DeepEPPDispatchHooks": {
    "__call__": [
      "self",
      "dispatcher"
    ]
  },
  "DeepEPNormalDispatchOutput": {
    "format": [
      "self"
    ]
  },
  "DeepEPLLDispatchOutput": {
    "format": [
      "self"
    ]
  },
  "DeepEPNormalCombineInput": {
    "format": [
      "self"
    ]
  },
  "DeepEPLLCombineInput": {
    "format": [
      "self"
    ]
  },
  "DeepEPDispatchMode": {
    "NORMAL": [],
    "LOW_LATENCY": []
  },
  "DeepEPBuffer": {
    "_buffer": [],
    "get_deepep_buffer": [
      "cls",
      "group",
      "hidden_size",
      "param_bytes",
      "deepep_mode",
      "num_max_dispatch_tokens_per_rank",
      "num_experts"
    ],
    "clean_buffer": [
      "cls"
    ],
    "set_dispatch_mode_as_normal": [
      "cls"
    ],
    "set_dispatch_mode_as_low_latency": [
      "cls"
    ],
    "set_dispatch_mode": [
      "cls",
      "mode"
    ]
  },
  "DeepEPConfig": {
    "_instance": [],
    "__init__": [
      "self"
    ],
    "get_instance": [
      "cls"
    ]
  },
  "_DeepEPDispatcherImplBase": {
    "__init__": [
      "self",
      "group",
      "router_topk",
      "permute_fusion",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "deepep_mode"
    ],
    "dispatch_a": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_b": [
      "self"
    ],
    "combine_a": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ],
    "combine_b": [
      "self"
    ],
    "_get_buffer": [
      "self"
    ],
    "set_quant_config": [
      "self",
      "quant_config"
    ],
    "set_overlap_args": [
      "self",
      "combine_overlap_args",
      "meta_overlap_args"
    ],
    "clear_overlap_args": [
      "self"
    ]
  },
  "_DeepEPDispatcherImplNormal": {
    "__init__": [
      "self",
      "async_finish"
    ],
    "dispatch_a": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_b": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights",
      "previous_event"
    ],
    "_dispatch_core": [
      "self",
      "x",
      "topk_ids",
      "topk_weights",
      "previous_event"
    ],
    "combine_a": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ],
    "combine_b": [
      "self",
      "output",
      "previous_event"
    ],
    "_combine_core": [
      "self",
      "x",
      "previous_event"
    ],
    "_get_buffer": [
      "self"
    ]
  },
  "_DeepEPDispatcherImplLowLatency": {
    "__init__": [
      "self",
      "return_recv_hook"
    ],
    "dispatch_a": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_b": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights",
      "masked_m",
      "expected_m",
      "event",
      "hook"
    ],
    "_dispatch_core": [
      "self",
      "hidden_states",
      "topk_ids"
    ],
    "combine_a": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ],
    "combine_b": [
      "self",
      "hidden_states",
      "event",
      "hook"
    ],
    "_combine_core": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ],
    "_get_buffer": [
      "self"
    ]
  },
  "_Stage": {
    "INITIAL": [],
    "AFTER_DISPATCH_A": [],
    "AFTER_DISPATCH_B": [],
    "AFTER_COMBINE_A": []
  },
  "DeepEPDispatcher": {
    "__init__": [
      "self",
      "group",
      "router_topk",
      "permute_fusion",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "deepep_mode",
      "async_finish",
      "return_recv_hook"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_a": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_b": [
      "self"
    ],
    "combine": [
      "self",
      "combine_input"
    ],
    "combine_a": [
      "self",
      "combine_input"
    ],
    "combine_b": [
      "self"
    ],
    "_get_impl": [
      "self"
    ],
    "_update_stage": [
      "self",
      "old_stage",
      "new_stage"
    ],
    "set_quant_config": [
      "self",
      "quant_config"
    ],
    "set_overlap_args": [
      "self",
      "combine_overlap_args",
      "meta_overlap_args"
    ],
    "clear_overlap_args": [
      "self"
    ],
    "register_deepep_dispatch_hook": [
      "self",
      "hook"
    ]
  },
  "_RemovableDispatcherHandle": {
    "next_id": [],
    "__init__": [
      "self",
      "hooks_dict"
    ],
    "remove": [
      "self"
    ]
  },
  "DispatcherBaseHooks": {
    "__init__": [
      "self"
    ],
    "register_hook": [
      "self",
      "hook_fun"
    ],
    "__call__": [
      "self"
    ]
  },
  "_PreDispatchHooks": {
    "__call__": [
      "self",
      "dispatcher",
      "hidden_states",
      "topk_output"
    ]
  },
  "_PostDispatchHooks": {
    "__call__": [
      "self",
      "dispatcher",
      "dispatch_output"
    ]
  },
  "_PreCombineHooks": {
    "__call__": [
      "self",
      "dispatcher",
      "combine_input"
    ]
  },
  "_PostCombineHooks": {
    "__call__": [
      "self",
      "dispatcher",
      "hidden_states"
    ]
  },
  "DispatchOutputChecker": {
    "format_is_standard": [
      "dispatch_output"
    ],
    "format_is_triton_kernels": [
      "dispatch_output"
    ],
    "format_is_deepep_normal": [
      "dispatch_output"
    ],
    "format_is_deepep_ll": [
      "dispatch_output"
    ],
    "format_is_deepep": [
      "dispatch_output"
    ]
  },
  "DispatchOutputFormat": {
    "STANDARD": [],
    "DEEPEP_NORMAL": [],
    "DEEPEP_LL": [],
    "is_standard": [
      "self"
    ],
    "is_deepep_normal": [
      "self"
    ],
    "is_deepep_ll": [
      "self"
    ],
    "is_deepep": [
      "self"
    ]
  },
  "DispatchOutput": {
    "format": [
      "self"
    ]
  },
  "CombineInputChecker": {
    "format_is_standard": [
      "combine_input"
    ],
    "format_is_deepep_normal": [
      "combine_input"
    ],
    "format_is_deepep_ll": [
      "combine_input"
    ],
    "format_is_deepep": [
      "combine_input"
    ]
  },
  "CombineInputFormat": {
    "STANDARD": [],
    "DEEPEP_NORMAL": [],
    "DEEPEP_LL": []
  },
  "CombineInput": {
    "format": [
      "self"
    ]
  },
  "BaseDispatcherConfig": {},
  "BaseDispatcher": {
    "__init__": [
      "self"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "_dispatch_with_hook": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "_override_dispatch_func": [
      "self"
    ],
    "combine": [
      "self",
      "combine_input"
    ],
    "_combine_with_hook": [
      "self",
      "combine_input"
    ],
    "_override_combine_func": [
      "self"
    ],
    "register_pre_dispatch_hook": [
      "self",
      "hook"
    ],
    "register_post_dispatch_hook": [
      "self",
      "hook"
    ],
    "register_pre_combine_hook": [
      "self",
      "hook"
    ],
    "register_post_combine_hook": [
      "self",
      "hook"
    ],
    "set_quant_config": [
      "self",
      "quant_config"
    ],
    "set_overlap_args": [
      "self",
      "combine_overlap_args",
      "meta_overlap_args"
    ],
    "clear_overlap_args": [
      "self"
    ]
  },
  "StandardDispatchOutput": {
    "format": [
      "self"
    ]
  },
  "StandardCombineInput": {
    "format": [
      "self"
    ]
  },
  "StandardDispatcher": {
    "__init__": [
      "self",
      "moe_runner_config"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "combine": [
      "self",
      "combine_input"
    ]
  },
  "FuseEPDispatchOutput": {
    "format": [
      "self"
    ]
  },
  "FuseEPCombineInput": {
    "format": [
      "self"
    ]
  },
  "NpuFuseEPDispatcher": {
    "__init__": [
      "self",
      "group",
      "router_topk",
      "permute_fusion",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "deepep_mode"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "combine": [
      "self",
      "combine_input"
    ],
    "_get_buffer": [
      "self"
    ]
  },
  "MooncakeDispatchOutput": {
    "format": [
      "self"
    ]
  },
  "MooncakeCombineInput": {
    "format": [
      "self"
    ]
  },
  "EPBuffer": {
    "_buffer": [],
    "get_ep_buffer": [
      "cls",
      "group",
      "hidden_size",
      "param_bytes",
      "deepep_mode",
      "num_max_dispatch_tokens_per_rank",
      "num_experts"
    ]
  },
  "_MooncakeEPDispatcherImpl": {
    "__init__": [
      "self",
      "group",
      "router_topk",
      "permute_fusion",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "return_recv_hook",
      "deepep_mode"
    ],
    "dispatch_a": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_b": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights",
      "masked_m",
      "expected_m",
      "event",
      "hook"
    ],
    "_dispatch_core": [
      "self",
      "hidden_states",
      "topk_ids",
      "use_fp8"
    ],
    "combine_a": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ],
    "combine_b": [
      "self",
      "hidden_states",
      "event",
      "hook"
    ],
    "_combine_core": [
      "self",
      "hidden_states",
      "topk_ids",
      "topk_weights"
    ],
    "_get_buffer": [
      "self"
    ]
  },
  "MooncakeEPDispatcher": {
    "__init__": [
      "self",
      "group",
      "router_topk",
      "permute_fusion",
      "num_experts",
      "num_local_experts",
      "hidden_size",
      "params_dtype",
      "deepep_mode",
      "async_finish",
      "return_recv_hook"
    ],
    "dispatch": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_a": [
      "self",
      "hidden_states",
      "topk_output"
    ],
    "dispatch_b": [
      "self"
    ],
    "combine": [
      "self",
      "combine_input"
    ],
    "combine_a": [
      "self",
      "combine_input"
    ],
    "combine_b": [
      "self"
    ],
    "_get_impl": [
      "self"
    ],
    "_update_stage": [
      "self",
      "old_stage",
      "new_stage"
    ]
  },
  "HybridAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "prefill_backend",
      "decode_backend"
    ],
    "_select_backend": [
      "self",
      "forward_mode"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "get_indexer_metadata": [
      "self",
      "layer_id",
      "forward_batch"
    ]
  },
  "DEFAULT_WORKSPACE_SIZE_MB": [],
  "global_zero_init_workspace_buffer": [],
  "TRTLLMMHAMetadata": {},
  "TRTLLMHAAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf",
      "kv_last_page_len_buf",
      "speculative_step_id"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "_should_use_fused_fp8_path": [
      "self",
      "save_kv_cache",
      "k"
    ],
    "_fused_fp8_set_kv_buffer": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "TRTLLMHAAttnMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "DoubleSparseAttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "PAGE_SIZE": [],
  "FlashMLADecodeMetadata": {
    "__init__": [
      "self",
      "flashmla_metadata",
      "num_splits",
      "block_kv_indices"
    ]
  },
  "FlashMLABackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf",
      "kv_last_page_len_buf"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "block_kv_indices"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "FlashMLAMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "common_template": [
      "self",
      "forward_batch",
      "call_fn"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "FlashAttentionMetadata": {},
  "make_local_attention_virtual_batches": [
    "attn_chunk_size",
    "query_start_loc_np",
    "seq_lens_np",
    "block_table",
    "page_size"
  ],
  "merge_state_v2_wrapper": [
    "o",
    "s_a",
    "o_exp",
    "s_b"
  ],
  "FlashAttentionBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "speculative_step_id",
      "topk",
      "speculative_num_steps",
      "fa_impl_ver"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "sinks"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "sinks"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu",
      "out_cache_loc"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "_maybe_init_local_attn_metadata": [
      "self",
      "forwardbatch",
      "metadata",
      "device"
    ],
    "_maybe_update_local_attn_metadata_for_capture": [
      "self",
      "metadata",
      "bs"
    ],
    "_maybe_update_local_attn_metadata_for_replay": [
      "self",
      "metadata",
      "bs"
    ],
    "_init_sliding_window_attn_spec_metadata": [
      "self",
      "metadata",
      "metadata_expand",
      "metadata_swa"
    ]
  },
  "_prepare_swa_spec_page_table_kernel": [
    "dst_ptr",
    "src_a_ptr",
    "src_b_ptr",
    "seq_len_a_ptr",
    "seq_len_b_ptr",
    "dst_stride_m",
    "dst_stride_n",
    "a_stride_m",
    "a_stride_n",
    "b_stride_m",
    "b_stride_n",
    "LEN_A",
    "LEN_B",
    "REPEAT_STEP",
    "BLOCK_N"
  ],
  "prepare_swa_spec_page_table_triton": [
    "page_table_dst",
    "page_table_a",
    "page_table_b",
    "seq_len_a",
    "seq_len_b",
    "speculative_num_draft_tokens"
  ],
  "FlashAttentionMultiStepBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "normal_decode_set_metadata": [
    "cache_seqlens_int32",
    "cu_seqlens_k",
    "page_table",
    "req_to_token",
    "req_pool_indices",
    "strided_indices",
    "max_seq_pages",
    "seq_lens",
    "seq_len_delta",
    "page_size",
    "swa_page_table",
    "token_to_kv_pool"
  ],
  "draft_decode_set_expand_metadata": [
    "cache_seqlens_int32",
    "page_table",
    "last_page_lens",
    "decode_length",
    "cache_loc",
    "topk",
    "page_size"
  ],
  "_FLASHMLA_CREATE_KV_BLOCK_SIZE": [],
  "FLASHMLA_CREATE_KV_BLOCK_SIZE_TRITON": [],
  "create_flashinfer_kv_indices_triton": [
    "req_to_token_ptr",
    "req_pool_indices_ptr",
    "page_kernel_lens_ptr",
    "kv_indptr",
    "kv_start_idx",
    "kv_indices_ptr",
    "req_to_token_ptr_stride"
  ],
  "get_num_page_per_block_flashmla": [
    "page_size"
  ],
  "create_flashmla_kv_indices_triton": [
    "req_to_token_ptr",
    "req_pool_indices_ptr",
    "page_kernel_lens_ptr",
    "kv_start_idx",
    "kv_indices_ptr",
    "req_to_token_ptr_stride",
    "kv_indices_ptr_stride",
    "PAGED_SIZE"
  ],
  "concat_and_cast_mha_k_kernel": [
    "k_ptr",
    "k_nope_ptr",
    "k_rope_ptr",
    "head_cnt",
    "k_stride0",
    "k_stride1",
    "nope_stride0",
    "nope_stride1",
    "rope_stride0",
    "nope_dim",
    "rope_dim"
  ],
  "concat_and_cast_mha_k_triton": [
    "k",
    "k_nope",
    "k_rope"
  ],
  "pad_sequence_with_mask_kernel": [
    "input_ptr",
    "offsets_ptr",
    "lengths_ptr",
    "output_ptr",
    "mask_ptr",
    "max_len",
    "hidden_dim",
    "BLOCK_M",
    "BLOCK_D"
  ],
  "pad_sequence_with_mask": [
    "input_emb",
    "offsets",
    "lengths",
    "max_len"
  ],
  "track_mamba_state_if_needed_kernel": [
    "conv_states_ptr",
    "ssm_states_ptr",
    "cache_indices_ptr",
    "mamba_track_mask_ptr",
    "mamba_track_indices_ptr",
    "conv_state_stride_0",
    "ssm_state_stride_0",
    "conv_state_numel_per_row",
    "ssm_state_numel_per_row",
    "BLOCK_SIZE"
  ],
  "track_mamba_states_if_needed": [
    "conv_states",
    "ssm_states",
    "cache_indices",
    "mamba_track_mask",
    "mamba_track_indices",
    "batch_size"
  ],
  "MambaAttnBackendBase": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "_init_track_conv_indices": [
      "self",
      "query_start_loc",
      "forward_batch"
    ],
    "_init_track_ssm_indices": [
      "self",
      "mamba_cache_indices",
      "forward_batch"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "_capture_metadata": [
      "self",
      "bs",
      "req_pool_indices",
      "forward_mode",
      "spec_info"
    ],
    "_replay_metadata": [
      "self",
      "bs",
      "req_pool_indices",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "_track_mamba_state_decode": [
      "self",
      "forward_batch",
      "conv_states",
      "ssm_states",
      "cache_indices"
    ],
    "_track_mamba_state_extend": [
      "self",
      "forward_batch",
      "h",
      "ssm_states",
      "forward_metadata"
    ]
  },
  "KimiLinearAttnBackend": {
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "GDNAttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "Mamba2AttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "forward": [
      "self",
      "mixer",
      "hidden_states",
      "output",
      "layer_id",
      "mup_vector",
      "use_triton_causal_conv"
    ],
    "forward_decode": [
      "self"
    ],
    "forward_extend": [
      "self"
    ]
  },
  "HybridLinearAttnBackend": {
    "__init__": [
      "self",
      "full_attn_backend",
      "linear_attn_backend",
      "full_attn_layers"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "update_mamba_state_after_mtp_verify": [
      "self",
      "accepted_steps",
      "mamba_track_indices",
      "mamba_steps_to_track",
      "model"
    ]
  },
  "TorchNativeAttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "_run_sdpa_forward_extend": [
      "self",
      "query",
      "output",
      "k_cache",
      "v_cache",
      "req_to_token",
      "req_pool_indices",
      "seq_lens",
      "extend_prefix_lens",
      "extend_seq_lens",
      "scaling",
      "enable_gqa",
      "causal"
    ],
    "_run_sdpa_forward_decode": [
      "self",
      "query",
      "output",
      "k_cache",
      "v_cache",
      "req_to_token",
      "req_pool_indices",
      "seq_lens",
      "scaling",
      "enable_gqa",
      "causal"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "support_triton": [
      "self"
    ]
  },
  "XPUAttentionBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "speculative_step_id",
      "topk",
      "speculative_num_steps"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "sinks"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "sinks"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "_init_local_attn_metadata": [
      "self",
      "forwardbatch",
      "metadata",
      "device"
    ],
    "_init_sliding_window_attn_spec_metadata": [
      "self",
      "metadata",
      "metadata_expand",
      "metadata_swa"
    ]
  },
  "get_num_kv_splits_triton": [
    "num_kv_splits_ptr",
    "seq_lens_ptr",
    "num_seq",
    "num_group",
    "num_head",
    "num_kv_head",
    "max_kv_splits",
    "device_core_count",
    "MAX_NUM_SEQ"
  ],
  "WaveAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf"
    ],
    "get_num_kv_splits": [
      "self",
      "num_kv_splits",
      "seq_lens"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "DecodeMetadata": {},
  "PrefillMetadata": {},
  "global_workspace_buffer": [],
  "FlashInferMhaChunkKVRunner": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update_prefix_chunks": [
      "self",
      "num_prefix_chunks"
    ],
    "update_wrapper": [
      "self",
      "forward_batch",
      "disable_flashinfer_ragged"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch"
    ]
  },
  "FlashInferMLAAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf",
      "q_indptr_decode_buf"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "init_mha_chunk_metadata": [
      "self",
      "forward_batch",
      "disable_flashinfer_ragged"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope"
    ]
  },
  "FlashInferMLAIndicesUpdaterDecode": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "decode_wrapper",
      "init_metadata_replay",
      "spec_info"
    ],
    "call_begin_forward": [
      "self",
      "wrapper",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "q_indptr",
      "kv_indptr",
      "init_metadata_replay",
      "spec_info"
    ]
  },
  "FlashInferMLAIndicesUpdaterPrefill": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "prefix_lens",
      "prefill_wrapper_paged",
      "use_ragged",
      "spec_info"
    ],
    "call_begin_forward": [
      "self",
      "wrapper_ragged",
      "wrapper_paged",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "seq_lens",
      "prefix_lens",
      "kv_indptr",
      "qo_indptr",
      "use_ragged",
      "spec_info"
    ]
  },
  "FlashInferMLAMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "common_template": [
      "self",
      "forward_batch",
      "kv_indices_buffer",
      "call_fn"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "fast_mla_decode_plan": [
    "self",
    "qo_indptr_cpu",
    "kv_indptr_cpu",
    "kv_indices",
    "kv_len_arr_cpu",
    "num_heads",
    "head_dim_ckv",
    "head_dim_kpe",
    "page_size",
    "causal",
    "sm_scale",
    "q_data_type",
    "kv_data_type"
  ],
  "DualChunkFlashAttentionMetadata": {},
  "DualChunkFlashAttentionBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "get_sparse_attention_config": [
      "self",
      "layer_idx"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu",
      "out_cache_loc"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "_dual_chunk_flash_attn_prefill": [
      "self",
      "q",
      "q_succ",
      "q_inter",
      "q_succ_critical",
      "q_inter_critical",
      "k",
      "v",
      "cu_seqlens_q",
      "cu_seqlens_k",
      "orig_seq_lens",
      "scaling_factor",
      "softmax_scale",
      "causal",
      "window_size",
      "block_table",
      "chunk_size",
      "local_size"
    ],
    "_dual_chunk_flash_attn_prefill_func": [
      "self",
      "q",
      "q_succ",
      "q_inter",
      "q_succ_critical",
      "q_inter_critical",
      "k",
      "v",
      "block_table",
      "softmax_scale",
      "chunk_size",
      "local_size",
      "scaling_factor",
      "k_length",
      "sparse_attn_enabled",
      "heads_vertical_size",
      "heads_slash_size",
      "group_size"
    ],
    "_do_flash_attn": [
      "self",
      "query_states",
      "key_states",
      "value_states",
      "softmax_scale",
      "causal",
      "max_seqlen_k",
      "stage",
      "vertical_indices",
      "slash_indices",
      "vertical_indices_count",
      "slash_indices_count",
      "mergehead_softmax_scale",
      "sparse_attn_enabled"
    ],
    "_merge_attn_outputs": [
      "self",
      "flash_results",
      "return_lse"
    ],
    "_dual_chunk_flash_attn_decoding": [
      "self",
      "query",
      "query_succ",
      "query_inter",
      "key_cache",
      "value_cache",
      "block_table",
      "cache_seqlens",
      "softmax_scale",
      "causal",
      "chunk_size",
      "local_size",
      "original_max_position_embeddings",
      "decode_meta"
    ],
    "_dual_chunk_flash_attn_decoding_with_exp_sums": [
      "self",
      "query",
      "key_cache",
      "value_cache",
      "block_table",
      "cache_seqlens",
      "softmax_scale",
      "causal"
    ]
  },
  "_vertical_slash_sparse_attention": [
    "query",
    "key",
    "value",
    "v_idx",
    "s_idx",
    "softmax_scale",
    "causal",
    "stage",
    "block_size_M",
    "block_size_N",
    "vertical_indices_count",
    "slash_indices_count"
  ],
  "_sum_all_diagonal_matrix": [
    "mat"
  ],
  "_get_block": [
    "block_table",
    "block_size",
    "begin",
    "end"
  ],
  "_use_mla_ps_kernel": [],
  "fast_mode": [],
  "intra_batch_mode": [],
  "WrapperDispatch": {
    "SLIDING_WINDOW": [],
    "CROSS_ATTENTION": []
  },
  "_AITER_PARTITION_SIZE_ROCM": [],
  "AiterAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf"
    ],
    "make_mla_decode_meta_data_buffer": [
      "self",
      "max_seqlen_qo",
      "batch_size"
    ],
    "make_mla_meta_data": [
      "self",
      "qo_indptr",
      "kv_indptr",
      "work_metadata",
      "work_info_set",
      "work_indptr",
      "reduce_indptr",
      "reduce_final_map",
      "reduce_partial_map",
      "max_q_len",
      "fast_mode",
      "max_split_per_batch",
      "intra_batch_mode"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ]
  },
  "AiterIndicesUpdaterPrefill": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "prefix_lens",
      "encoder_lens",
      "spec_info"
    ],
    "update_single_wrapper": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "prefix_lens",
      "encoder_lens",
      "spec_info"
    ]
  },
  "AiterMlaIndicesUpdaterPrefill": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update": [
      "self",
      "req_pool_indices",
      "kv_lens",
      "kv_lens_sum",
      "extend_lens",
      "max_q_len",
      "max_kv_len",
      "spec_info"
    ],
    "update_single_wrapper": [
      "self",
      "req_pool_indices",
      "kv_lens",
      "kv_lens_sum",
      "extend_lens",
      "max_q_len",
      "max_kv_len",
      "spec_info"
    ]
  },
  "AiterMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "common_template": [
      "self",
      "forward_batch",
      "kv_indices_buffer",
      "call_fn"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "logit_capping_mod": [
    "logit_capping_method",
    "logit_cap"
  ],
  "TritonAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf"
    ],
    "get_num_kv_splits": [
      "self",
      "num_kv_splits",
      "seq_lens"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf",
      "cuda_graph_num_kv_splits_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "get_verify_buffers_to_fill_after_draft": [
      "self"
    ],
    "update_verify_buffers_to_fill_after_draft": [
      "self",
      "spec_info",
      "cuda_graph_bs"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "sinks"
    ],
    "_forward_extend_unified": [
      "self",
      "q",
      "o",
      "layer",
      "forward_batch",
      "causal",
      "logits_soft_cap",
      "sinks"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "sinks"
    ]
  },
  "TritonMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "common_template": [
      "self",
      "forward_batch",
      "kv_indices_buffer",
      "call_fn"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "update_sliding_window_buffer": [
    "window_kv_indptr",
    "req_to_token",
    "sliding_window_size",
    "seq_lens",
    "req_pool_indices",
    "bs",
    "device",
    "token_to_kv_pool_allocator"
  ],
  "update_sliding_window_buffer_cuda_graph": [
    "window_kv_indptr",
    "window_kv_indices",
    "req_to_token",
    "sliding_window_size",
    "seq_lens",
    "req_pool_indices",
    "bs",
    "token_to_kv_pool_allocator"
  ],
  "TorchFlexAttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "_causal_mask": [
      "self",
      "b",
      "h",
      "q_idx",
      "kv_idx"
    ],
    "_decode_mask": [
      "self",
      "b",
      "h",
      "q_idx",
      "kv_idx"
    ],
    "_run_flex_forward_extend": [
      "self",
      "query",
      "output",
      "k_cache",
      "v_cache",
      "req_to_token",
      "req_pool_indices",
      "seq_lens",
      "extend_prefix_lens",
      "extend_seq_lens",
      "scaling",
      "enable_gqa",
      "causal"
    ],
    "_run_flex_forward_decode": [
      "self",
      "query",
      "output",
      "k_cache",
      "v_cache",
      "req_to_token",
      "req_pool_indices",
      "seq_lens",
      "scaling",
      "enable_gqa",
      "causal"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "support_triton": [
      "self"
    ]
  },
  "CutlassMLADecodeMetadata": {
    "__init__": [
      "self",
      "workspace",
      "block_kv_indices"
    ]
  },
  "CutlassMLABackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf",
      "kv_last_page_len_buf"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "block_kv_indices"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope"
    ]
  },
  "MultiItemScoringParams": {
    "is_enabled": [
      "self"
    ]
  },
  "global_override_indptr_cpu": [],
  "FlashInferAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf",
      "kv_last_page_len_buf",
      "init_new_workspace"
    ],
    "_process_multi_item_scoring": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "_get_wrapper_idx": [
      "self",
      "layer"
    ]
  },
  "FlashInferIndicesUpdaterDecode": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "decode_wrappers",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "disable_split_kv"
    ],
    "update_single_wrapper": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "decode_wrappers",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "disable_split_kv"
    ],
    "update_sliding_window": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "decode_wrappers",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "disable_split_kv"
    ],
    "update_cross_attention": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "decode_wrappers",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "disable_split_kv"
    ],
    "call_begin_forward": [
      "self",
      "wrapper",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "kv_indptr",
      "kv_start_idx",
      "spec_info",
      "seq_lens_cpu",
      "use_sliding_window_kv_pool",
      "fixed_split_size",
      "disable_split_kv"
    ]
  },
  "FlashInferIndicesUpdaterPrefill": {
    "__init__": [
      "self",
      "model_runner",
      "attn_backend"
    ],
    "update": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "prefix_lens",
      "prefill_wrappers",
      "use_ragged",
      "encoder_lens",
      "spec_info",
      "fixed_split_size"
    ],
    "update_single_wrapper": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "prefix_lens",
      "prefill_wrappers",
      "use_ragged",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "multi_item_params"
    ],
    "update_sliding_window": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "prefix_lens",
      "prefill_wrappers",
      "use_ragged",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "multi_item_params"
    ],
    "update_cross_attention": [
      "self",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "seq_lens_sum",
      "prefix_lens",
      "prefill_wrappers",
      "use_ragged",
      "encoder_lens",
      "spec_info",
      "fixed_split_size",
      "multi_item_params"
    ],
    "call_begin_forward": [
      "self",
      "wrapper_ragged",
      "wrapper_paged",
      "req_pool_indices",
      "paged_kernel_lens",
      "paged_kernel_lens_sum",
      "seq_lens",
      "prefix_lens",
      "kv_start_idx",
      "kv_indptr",
      "qo_indptr",
      "use_ragged",
      "spec_info",
      "use_sliding_window_kv_pool",
      "fixed_split_size",
      "multi_item_params"
    ]
  },
  "FlashInferMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "common_template": [
      "self",
      "forward_batch",
      "kv_indices_buffer",
      "call_fn"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "should_use_tensor_core": [
    "kv_cache_dtype",
    "num_attention_heads",
    "num_kv_heads"
  ],
  "IntelAMXAttnBackend": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "get_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "support_triton": [
      "self"
    ]
  },
  "ROTARY_EMBED_CLASSES": [],
  "SingletonCache": {
    "set_data": [
      "self",
      "value"
    ],
    "get_data": [
      "self"
    ],
    "empty": [
      "self"
    ]
  },
  "_get_cu_seqlens_for_shape": [
    "batch_size",
    "seqlen",
    "device"
  ],
  "resolve_seqlens": [
    "cu_seqlens",
    "bsz",
    "seq_len"
  ],
  "VisionSdpaAttention": {
    "__init__": [
      "self",
      "head_dim",
      "num_heads",
      "num_kv_heads",
      "dropout",
      "flatten_batch",
      "softmax_in_single_precision"
    ],
    "_generate_mask_cache": [
      "s",
      "flatten_batch",
      "cu_seqlens"
    ],
    "generate_patch_attention_mask": [
      "self",
      "s",
      "cu_seqlens",
      "flatten_batch"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "bsz",
      "cu_seqlens",
      "attention_mask"
    ]
  },
  "VisionTritonAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens",
      "bsz",
      "seq_len"
    ]
  },
  "VisionFlash3Attention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens",
      "bsz",
      "seq_len"
    ]
  },
  "VisionAiterAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens",
      "bsz",
      "seq_len"
    ]
  },
  "VisionAscendAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "cu_seqlens",
      "bsz",
      "seq_len"
    ]
  },
  "QKV_BACKEND_IMPL": [],
  "VisionAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "projection_size",
      "use_qkv_parallel",
      "qkv_backend",
      "quant_config",
      "dropout",
      "softmax_in_single_precision",
      "flatten_batch",
      "prefix",
      "proj_bias",
      "num_dummy_heads",
      "qkv_bias",
      "qk_normalization",
      "layer_norm_eps",
      "customized_position_embedding_applier",
      "use_data_parallel",
      "aux_stream"
    ],
    "_determine_attention_backend": [
      "self",
      "passed_backend"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "position_embeddings",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "attention_mask"
    ]
  },
  "NSAFlashMLAMetadata": {
    "slice": [
      "self",
      "sli"
    ],
    "copy_": [
      "self",
      "other"
    ]
  },
  "NSAMetadata": {},
  "TopkTransformMethod": {
    "PAGED": [],
    "RAGGED": []
  },
  "_compiled_cat": [
    "tensors",
    "dim"
  ],
  "_cat": [
    "tensors",
    "dim"
  ],
  "NSAIndexerMetadata": {
    "get_seqlens_int32": [
      "self"
    ],
    "get_page_table_64": [
      "self"
    ],
    "get_page_table_1": [
      "self"
    ],
    "get_seqlens_expanded": [
      "self"
    ],
    "get_cu_seqlens_k": [
      "self"
    ],
    "get_indexer_kvcache_range": [
      "self"
    ],
    "get_indexer_seq_len_cpu": [
      "self"
    ],
    "get_token_to_batch_idx": [
      "self"
    ],
    "topk_transform": [
      "self",
      "logits",
      "topk",
      "ks",
      "cu_seqlens_q",
      "ke_offset",
      "batch_idx_list",
      "topk_indices_offset_override"
    ]
  },
  "NativeSparseAttnBackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "speculative_step_id",
      "topk",
      "speculative_num_steps"
    ],
    "get_device_int32_arange": [
      "self",
      "l"
    ],
    "_transform_table_1_to_real": [
      "self",
      "page_table"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "_cal_indexer_k_start_end": [
      "self",
      "forward_batch",
      "bs_idx"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu",
      "out_cache_loc"
    ],
    "init_forward_metadata_replay_cuda_graph_from_precomputed": [
      "self",
      "bs",
      "precomputed",
      "forward_mode"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "topk_indices"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "topk_indices"
    ],
    "_forward_fa3": [
      "self",
      "q_rope",
      "kv_cache",
      "v_head_dim",
      "q_nope",
      "page_table",
      "cache_seqlens",
      "cu_seqlens_q",
      "cu_seqlens_k",
      "max_seqlen_q",
      "sm_scale",
      "logit_cap",
      "page_size"
    ],
    "_forward_flashmla_sparse": [
      "self",
      "q_all",
      "kv_cache",
      "v_head_dim",
      "page_table_1",
      "sm_scale"
    ],
    "_forward_flashmla_kv": [
      "self",
      "q_all",
      "kv_cache",
      "v_head_dim",
      "sm_scale",
      "layer",
      "metadata",
      "page_table_1"
    ],
    "_forward_standard_mha": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "metadata"
    ],
    "_forward_tilelang": [
      "self",
      "q_all",
      "kv_cache",
      "v_head_dim",
      "page_table_1",
      "sm_scale"
    ],
    "_forward_aiter": [
      "self",
      "q_all",
      "kv_cache",
      "page_table_1",
      "layer",
      "metadata",
      "bs"
    ],
    "_pad_topk_indices": [
      "self",
      "topk_indices",
      "num_tokens"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "set_nsa_prefill_impl": [
      "self",
      "forward_batch"
    ],
    "get_topk_transform_method": [
      "self"
    ],
    "get_indexer_metadata": [
      "self",
      "layer_id",
      "forward_batch"
    ],
    "_compute_flashmla_metadata": [
      "self",
      "cache_seqlens",
      "seq_len_q"
    ]
  },
  "NativeSparseAttnMultiStepBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "forward_batch"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "forward_batch",
      "bs"
    ]
  },
  "TboAttnBackend": {
    "__init__": [
      "self",
      "primary",
      "children"
    ],
    "init_new": [
      "cls",
      "creator"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "_init_forward_metadata_cuda_graph_children": [
      "self",
      "fn_name",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "capture_num_tokens",
      "replay_seq_lens_sum",
      "replay_seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "forward_extend": [
      "self"
    ],
    "forward_decode": [
      "self"
    ],
    "get_indexer_metadata": [
      "self",
      "layer_id",
      "forward_batch"
    ]
  },
  "_init_forward_metadata_cuda_graph_split": [
    "fn_name",
    "seq_slice",
    "output_bs",
    "bs",
    "req_pool_indices",
    "seq_lens",
    "encoder_lens",
    "forward_mode",
    "spec_info",
    "capture_num_tokens",
    "replay_seq_lens_sum",
    "replay_seq_lens_cpu"
  ],
  "_supported_dtypes": [
    "o"
  ],
  "_supported_headdim": [
    "o"
  ],
  "merge_state": [
    "prefix_output",
    "prefix_lse",
    "suffix_output",
    "suffix_lse",
    "output",
    "output_lse"
  ],
  "TRTLLM_BLOCK_CONSTRAINT": [],
  "pad_draft_extend_query_kernel": [
    "q_ptr",
    "padded_q_ptr",
    "seq_lens_q_ptr",
    "cumsum_ptr",
    "batch_size",
    "max_seq_len",
    "num_heads",
    "head_dim",
    "BLOCK_SIZE"
  ],
  "unpad_draft_extend_output_kernel": [
    "raw_out_ptr",
    "output_ptr",
    "accept_length_ptr",
    "cumsum_ptr",
    "batch_size",
    "token_per_batch",
    "tp_q_head_num",
    "v_head_dim",
    "BLOCK_SIZE"
  ],
  "_quantize_fp8_qkv": [
    "q",
    "k",
    "v",
    "layer"
  ],
  "TRTLLMMLAPrefillMetadata": {},
  "TRTLLMMLADecodeMetadata": {},
  "TRTLLMMLABackend": {
    "__init__": [
      "self",
      "model_runner",
      "skip_prefill",
      "kv_indptr_buf",
      "q_indptr_decode_buf"
    ],
    "_calc_padded_blocks": [
      "self",
      "max_seq_len"
    ],
    "_create_block_kv_indices": [
      "self",
      "batch_size",
      "max_blocks",
      "req_pool_indices",
      "seq_lens",
      "device"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens",
      "kv_indices_buf"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_mha_chunk_metadata": [
      "self",
      "forward_batch"
    ],
    "quantize_and_rope_for_fp8": [
      "self",
      "q_nope",
      "q_rope",
      "k_nope",
      "k_rope",
      "forward_batch",
      "cos_sin_cache",
      "is_neox"
    ],
    "pad_draft_extend_query": [
      "self",
      "q",
      "padded_q",
      "seq_lens_q",
      "cu_seqlens_q"
    ],
    "unpad_draft_extend_output": [
      "self",
      "raw_out",
      "cu_seqlens_q",
      "seq_lens_q",
      "sum_seq_lens_q"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "cos_sin_cache",
      "is_neox",
      "llama_4_scaling"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache",
      "q_rope",
      "k_rope",
      "cos_sin_cache",
      "is_neox",
      "llama_4_scaling"
    ]
  },
  "TRTLLMMLAMultiStepDraftBackend": {
    "__init__": [
      "self",
      "model_runner",
      "topk",
      "speculative_num_steps"
    ]
  },
  "_concat_mla_absorb_q_general": [
    "q_nope",
    "q_rope"
  ],
  "update_vit_attn_dummy_heads_config": [
    "config"
  ],
  "pad_vit_attn_dummy_heads": [
    "config",
    "name",
    "loaded_weight"
  ],
  "ATTENTION_BACKENDS": [],
  "register_attention_backend": [
    "name"
  ],
  "create_trtllm_mla_backend": [
    "runner"
  ],
  "create_aiter_backend": [
    "runner"
  ],
  "create_wave_backend": [
    "runner"
  ],
  "create_nsa_backend": [
    "runner"
  ],
  "create_flex_attention_backend": [
    "runner"
  ],
  "create_flashmla_backend": [
    "runner"
  ],
  "create_flashattention_v3_backend": [
    "runner"
  ],
  "create_flashattention_v4_backend": [
    "runner"
  ],
  "create_cutlass_mla_backend": [
    "runner"
  ],
  "create_trtllm_mha_backend": [
    "runner"
  ],
  "create_intel_amx_backend": [
    "runner"
  ],
  "create_dual_chunk_flash_attn_backend": [
    "runner"
  ],
  "attn_backend_wrapper": [
    "runner",
    "full_attn_backend"
  ],
  "create_intel_xpu_backend": [
    "runner"
  ],
  "AttentionBackend": {
    "init_forward_metadata": [
      "self",
      "forward_batch"
    ],
    "init_cuda_graph_state": [
      "self",
      "max_bs",
      "max_num_tokens"
    ],
    "init_forward_metadata_capture_cuda_graph": [
      "self",
      "bs",
      "num_tokens",
      "req_pool_indices",
      "seq_lens",
      "encoder_lens",
      "forward_mode",
      "spec_info"
    ],
    "init_forward_metadata_replay_cuda_graph": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_sum",
      "encoder_lens",
      "forward_mode",
      "spec_info",
      "seq_lens_cpu"
    ],
    "get_cuda_graph_seq_len_fill_value": [
      "self"
    ],
    "get_verify_buffers_to_fill_after_draft": [
      "self"
    ],
    "update_verify_buffers_to_fill_after_draft": [
      "self",
      "spec_info",
      "cuda_graph_bs"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_decode": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_extend": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "forward_mixed": [
      "self",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "save_kv_cache"
    ],
    "support_triton": [
      "self"
    ],
    "get_indexer_metadata": [
      "self",
      "layer_id",
      "forward_batch"
    ]
  },
  "_fwd_grouped_kernel_stage1_rope": [
    "Q",
    "K_Buffer",
    "V_buffer",
    "cos_sin_cache",
    "positions",
    "sm_scale",
    "kv_indptr",
    "kv_indices",
    "Att_Out",
    "k_pe_t_out",
    "stride_qb",
    "stride_qh",
    "stride_buf_kbs",
    "stride_buf_vbs",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_kpe_tokens_out_b",
    "stride_cos_sin_cache_s",
    "stride_positions_b",
    "rotary_dim",
    "kv_lora_rank",
    "qk_rope_head_dim",
    "kv_group_num",
    "q_head_num",
    "BLOCK_C",
    "BLOCK_R",
    "BLOCK_N",
    "BLOCK_H",
    "NUM_KV_SPLITS",
    "logit_cap",
    "USE_ROPE",
    "IS_NEOX_STYLE"
  ],
  "_decode_grouped_att_m_fwd_rope": [
    "q",
    "k_buffer",
    "v_buffer",
    "att_out",
    "k_pe_tokens_out",
    "kv_lora_rank",
    "cos_sin_cache",
    "positions",
    "rotary_dim",
    "kv_indptr",
    "kv_indices",
    "num_kv_splits",
    "sm_scale",
    "logit_cap",
    "use_rope",
    "is_neox_style"
  ],
  "decode_attention_fwd_grouped_rope": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "kv_indptr",
    "kv_indices",
    "k_pe_tokens",
    "kv_lora_rank",
    "rotary_dim",
    "cos_sin_cache",
    "positions",
    "attn_logits",
    "num_kv_splits",
    "sm_scale",
    "logit_cap",
    "use_rope",
    "is_neox_style"
  ],
  "_process_kv_tensor": [
    "token_id",
    "head_block_id",
    "page_id",
    "page_offset",
    "input_ptr",
    "cache_ptr",
    "inv_scale",
    "use_provided_scale",
    "num_kv_heads",
    "head_dim",
    "input_stride_token",
    "input_stride_head",
    "input_stride_dim",
    "cache_stride_page",
    "cache_stride_offset",
    "cache_stride_head",
    "cache_stride_dim",
    "BLOCK_HEAD",
    "BLOCK_DIM"
  ],
  "_fused_fp8_set_kv_buffer_kernel": [
    "k_ptr",
    "v_ptr",
    "k_cache_ptr",
    "v_cache_ptr",
    "cache_loc_ptr",
    "inv_k_scale_ptr",
    "inv_v_scale_ptr",
    "use_provided_scale",
    "num_kv_heads",
    "head_dim",
    "page_size",
    "k_stride_token",
    "k_stride_head",
    "k_stride_dim",
    "k_cache_stride_page",
    "k_cache_stride_offset",
    "k_cache_stride_head",
    "k_cache_stride_dim",
    "v_stride_token",
    "v_stride_head",
    "v_stride_dim",
    "v_cache_stride_page",
    "v_cache_stride_offset",
    "v_cache_stride_head",
    "v_cache_stride_dim",
    "BLOCK_HEAD",
    "BLOCK_DIM"
  ],
  "fused_fp8_set_kv_buffer": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "cache_loc",
    "k_scale",
    "v_scale",
    "page_size",
    "use_triton"
  ],
  "_naive_fp8_set_kv_buffer": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "cache_loc",
    "k_scale",
    "v_scale",
    "page_size"
  ],
  "_get_block_sizes_for_extend_attention": [
    "Lq",
    "Lv"
  ],
  "_copy_unified_indices_kernel": [
    "prefix_kv_indptr",
    "prefix_kv_indices",
    "extend_start_loc",
    "extend_seq_lens",
    "extend_kv_indices",
    "unified_kv_indptr",
    "unified_kv_indices",
    "bs"
  ],
  "build_unified_kv_indices": [
    "prefix_kv_indptr",
    "prefix_kv_indices",
    "extend_start_loc",
    "extend_seq_lens",
    "extend_kv_indices",
    "bs"
  ],
  "_fwd_kernel": [
    "Q_Extend",
    "K_Extend",
    "V_Extend",
    "O_Extend",
    "K_Buffer",
    "V_Buffer",
    "qo_indptr",
    "kv_indptr",
    "kv_indices",
    "mask_ptr",
    "mask_indptr",
    "sink_ptr",
    "window_kv_offset_ptr",
    "sm_scale",
    "kv_group_num",
    "stride_qbs",
    "stride_qh",
    "stride_kbs",
    "stride_kh",
    "stride_vbs",
    "stride_vh",
    "stride_obs",
    "stride_oh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "stride_buf_vbs",
    "stride_buf_vh",
    "SLIDING_WINDOW_SIZE",
    "logit_cap",
    "xai_temperature_len",
    "Lq",
    "Lv",
    "BLOCK_DMODEL",
    "BLOCK_DPE",
    "BLOCK_DV",
    "BLOCK_M",
    "BLOCK_N",
    "USE_CUSTOM_MASK",
    "IS_CAUSAL",
    "SKIP_PREFIX_CUSTOM_MASK",
    "STORE_TRANSPOSE",
    "HAS_SINK"
  ],
  "extend_attention_fwd": [
    "q_extend",
    "k_extend",
    "v_extend",
    "o_extend",
    "k_buffer",
    "v_buffer",
    "qo_indptr",
    "kv_indptr",
    "kv_indices",
    "custom_mask",
    "is_causal",
    "mask_indptr",
    "max_len_extend",
    "sm_scale",
    "logit_cap",
    "skip_prefix_custom_mask",
    "sliding_window_size",
    "sinks",
    "window_kv_offsets",
    "xai_temperature_len"
  ],
  "redundant_attention": [
    "q_extend",
    "o_extend",
    "k_buffer",
    "v_buffer",
    "b_req_idx",
    "b_start_loc",
    "b_seq_len",
    "b_seq_len_prefix",
    "max_len_in_batch"
  ],
  "_fwd_kernel_unified": [
    "Q",
    "O",
    "K_Buffer",
    "V_Buffer",
    "qo_indptr",
    "kv_indptr",
    "kv_indices",
    "prefix_lens",
    "mask_ptr",
    "mask_indptr",
    "sink_ptr",
    "window_start_pos",
    "sm_scale",
    "kv_group_num",
    "stride_qbs",
    "stride_qh",
    "stride_obs",
    "stride_oh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "stride_buf_vbs",
    "stride_buf_vh",
    "SLIDING_WINDOW_SIZE",
    "logit_cap",
    "xai_temperature_len",
    "Lq",
    "Lv",
    "BLOCK_DMODEL",
    "BLOCK_DPE",
    "BLOCK_DV",
    "BLOCK_M",
    "BLOCK_N",
    "IS_CAUSAL",
    "USE_CUSTOM_MASK",
    "HAS_SINK"
  ],
  "extend_attention_fwd_unified": [
    "q",
    "o",
    "k_buffer",
    "v_buffer",
    "qo_indptr",
    "kv_indptr",
    "kv_indices",
    "prefix_lens",
    "max_len_extend",
    "custom_mask",
    "mask_indptr",
    "sm_scale",
    "logit_cap",
    "is_causal",
    "sliding_window_size",
    "sinks",
    "window_start_pos",
    "xai_temperature_len"
  ],
  "_fwd_kernel_flash_decode_stage1": [
    "Q",
    "K",
    "V",
    "sm_scale",
    "Req_to_tokens",
    "B_req_idx",
    "B_Seqlen",
    "Mid_O",
    "Mid_O_LogExpSum",
    "stride_req_to_tokens_b",
    "stride_req_to_tokens_s",
    "stride_qbs",
    "stride_qh",
    "stride_qd",
    "stride_kbs",
    "stride_kh",
    "stride_kd",
    "stride_vbs",
    "stride_vh",
    "stride_vd",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_mid_od",
    "stride_mid_o_eb",
    "stride_mid_o_eh",
    "stride_mid_o_es",
    "gqa_group_size",
    "BLOCK_SEQ",
    "BLOCK_DMODEL",
    "BLOCK_N"
  ],
  "_fwd_kernel_flash_decode_stage2": [
    "B_Seqlen",
    "Mid_O",
    "Mid_O_LogExpSum",
    "O",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_mid_od",
    "stride_mid_o_eb",
    "stride_mid_o_eh",
    "stride_mid_o_es",
    "stride_obs",
    "stride_oh",
    "stride_od",
    "BLOCK_SEQ",
    "BLOCK_DMODEL"
  ],
  "flash_decode_stage1": [
    "q",
    "k",
    "v",
    "Req_to_tokens",
    "B_req_idx",
    "B_Seqlen",
    "max_len_in_batch",
    "mid_out",
    "mid_out_logsumexp",
    "block_seq"
  ],
  "flash_decode_stage2": [
    "mid_out",
    "mid_out_logexpsum",
    "B_Seqlen",
    "O",
    "block_seq"
  ],
  "flash_decode_attention_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "req_to_token",
    "b_req_idx",
    "b_start_loc",
    "b_seq_len",
    "attn_logits",
    "max_len_in_batch",
    "sm_scale",
    "logit_cap"
  ],
  "_sparse_fwd_kernel_flash_decode_stage1": [
    "Q_Label",
    "K_Label_Buffer",
    "sm_scale",
    "Req_to_tokens",
    "B_Seqlen",
    "Att_Out",
    "stride_req_to_tokens_b",
    "stride_qbs",
    "stride_qh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "att_stride_h",
    "att_stride_b",
    "kv_group_num",
    "BLOCK_DMODEL",
    "BLOCK_N",
    "logit_cap"
  ],
  "_sparse_fwd_kernel_flash_decode_stage2": [
    "Q",
    "K",
    "V",
    "sm_scale",
    "Req_to_tokens",
    "Topk_token_indices",
    "Mid_O",
    "Mid_O_LogExpSum",
    "Heavy_token_num",
    "stride_req_to_tokens_b",
    "stride_topk_token_indices_h",
    "stride_topk_token_indices_b",
    "stride_qbs",
    "stride_qh",
    "stride_kbs",
    "stride_kh",
    "stride_vbs",
    "stride_vh",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_mid_o_eb",
    "stride_mid_o_eh",
    "gqa_group_size",
    "BLOCK_SEQ",
    "BLOCK_DMODEL",
    "BLOCK_N"
  ],
  "_sparse_fwd_kernel_flash_decode_stage3": [
    "Mid_O",
    "Mid_O_LogExpSum",
    "O",
    "seq_len",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_mid_o_eb",
    "stride_mid_o_eh",
    "stride_obs",
    "stride_oh",
    "BLOCK_SEQ",
    "BLOCK_DMODEL"
  ],
  "sparse_flash_decode_stage1": [
    "q_label",
    "k_label_buffer",
    "att_out",
    "Req_to_tokens",
    "B_Seqlen",
    "max_len_in_batch",
    "sm_scale",
    "logit_cap"
  ],
  "sparse_flash_decode_stage2": [
    "q",
    "k",
    "v",
    "Req_to_tokens",
    "Topk_token_indices",
    "heavy_token_num",
    "mid_out",
    "mid_out_logsumexp",
    "block_seq",
    "sm_scale"
  ],
  "sparse_flash_decode_stage3": [
    "Seqlen",
    "mid_out",
    "mid_out_logexpsum",
    "O",
    "block_seq"
  ],
  "flash_decode_sparse_attention_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "q_label",
    "k_label_buffer",
    "req_to_token",
    "b_seq_len",
    "max_len_in_batch",
    "sm_scale",
    "logit_cap",
    "heavy_token_num",
    "att_out_approx",
    "mid_out",
    "mid_o_logexpsum",
    "BLOCK_SEQ"
  ],
  "context_attention_fwd": [
    "q",
    "k",
    "v",
    "o",
    "b_start_loc",
    "b_seq_len",
    "max_input_len",
    "is_causal"
  ],
  "_MIN_BLOCK_KV": [],
  "_fwd_kernel_stage1": [
    "Q",
    "K_Buffer",
    "V_Buffer",
    "sm_scale",
    "kv_indptr",
    "kv_indices",
    "Att_Out",
    "Att_Lse",
    "num_kv_splits",
    "stride_qbs",
    "stride_qh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "stride_buf_vbs",
    "stride_buf_vh",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "kv_group_num",
    "BLOCK_DMODEL",
    "BLOCK_DV",
    "BLOCK_N",
    "MIN_BLOCK_KV",
    "logit_cap",
    "Lk",
    "Lv",
    "xai_temperature_len"
  ],
  "_decode_att_m_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "att_out",
    "att_lse",
    "kv_indptr",
    "kv_indices",
    "num_kv_splits",
    "max_kv_splits",
    "sm_scale",
    "logit_cap",
    "xai_temperature_len"
  ],
  "_fwd_grouped_kernel_stage1": [
    "Q",
    "K_Buffer",
    "V_Buffer",
    "sm_scale",
    "kv_indptr",
    "kv_indices",
    "Att_Out",
    "Att_Lse",
    "num_kv_splits",
    "stride_qbs",
    "stride_qh",
    "stride_buf_kbs",
    "stride_buf_kh",
    "stride_buf_vbs",
    "stride_buf_vh",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "kv_group_num",
    "q_head_num",
    "BLOCK_DMODEL",
    "BLOCK_DPE",
    "BLOCK_DV",
    "BLOCK_N",
    "BLOCK_H",
    "MIN_BLOCK_KV",
    "logit_cap",
    "xai_temperature_len",
    "Lk",
    "Lv"
  ],
  "_decode_grouped_att_m_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "att_out",
    "att_lse",
    "kv_indptr",
    "kv_indices",
    "num_kv_splits",
    "max_kv_splits",
    "sm_scale",
    "logit_cap",
    "xai_temperature_len"
  ],
  "_fwd_kernel_stage2": [
    "Mid_O",
    "Mid_O_1",
    "O",
    "kv_indptr",
    "num_kv_splits",
    "sink_ptr",
    "stride_mid_ob",
    "stride_mid_oh",
    "stride_mid_os",
    "stride_obs",
    "stride_oh",
    "MAX_KV_SPLITS",
    "MIN_BLOCK_KV",
    "BLOCK_DV",
    "Lv",
    "HAS_SINK"
  ],
  "_decode_softmax_reducev_fwd": [
    "logits",
    "lse",
    "q",
    "o",
    "v_buffer",
    "kv_indptr",
    "num_kv_splits",
    "max_kv_splits",
    "sinks"
  ],
  "decode_attention_fwd_normal": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "kv_indptr",
    "kv_indices",
    "attn_logits",
    "attn_lse",
    "num_kv_splits",
    "max_kv_splits",
    "sm_scale",
    "logit_cap",
    "sinks",
    "xai_temperature_len"
  ],
  "decode_attention_fwd_grouped": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "kv_indptr",
    "kv_indices",
    "attn_logits",
    "attn_lse",
    "num_kv_splits",
    "max_kv_splits",
    "sm_scale",
    "logit_cap",
    "sinks",
    "xai_temperature_len"
  ],
  "decode_attention_fwd": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "kv_indptr",
    "kv_indices",
    "attn_logits",
    "attn_lse",
    "num_kv_splits",
    "max_kv_splits",
    "sm_scale",
    "logit_cap",
    "sinks",
    "xai_temperature_len"
  ],
  "merge_state_kernel": [
    "output",
    "output_lse",
    "prefix_output",
    "prefix_lse",
    "suffix_output",
    "suffix_lse",
    "HEAD_SIZE",
    "PADDED_HEAD_SIZE",
    "OUTPUT_LSE"
  ],
  "merge_state_triton": [
    "prefix_output",
    "prefix_lse",
    "suffix_output",
    "suffix_lse",
    "output",
    "output_lse"
  ],
  "Mamba2Metadata": {
    "_query_start_loc_to_chunk_indices_offsets": [
      "query_start_loc",
      "chunk_size",
      "total_seqlens"
    ],
    "prepare_decode": [
      "forward_metadata",
      "seq_lens"
    ],
    "prepare_mixed": [
      "cls",
      "forward_metadata",
      "chunk_size",
      "forward_batch"
    ]
  },
  "PAD_SLOT_ID": [],
  "_causal_conv1d_fwd_kernel": [
    "x_ptr",
    "w_ptr",
    "bias_ptr",
    "initial_states_ptr",
    "cache_indices_ptr",
    "has_initial_states_ptr",
    "query_start_loc_ptr",
    "o_ptr",
    "dim",
    "seqlen",
    "num_cache_lines",
    "stride_x_seq",
    "stride_x_dim",
    "stride_x_token",
    "stride_w_dim",
    "stride_w_width",
    "stride_istate_seq",
    "stride_istate_dim",
    "stride_istate_token",
    "stride_o_seq",
    "stride_o_dim",
    "stride_o_token",
    "pad_slot_id",
    "HAS_BIAS",
    "KERNEL_WIDTH",
    "SILU_ACTIVATION",
    "HAS_INITIAL_STATES",
    "HAS_CACHE",
    "IS_CONTINUOUS_BATCHING",
    "USE_PAD_SLOT",
    "NP2_STATELEN",
    "BLOCK_M",
    "BLOCK_N"
  ],
  "causal_conv1d_fn": [
    "x",
    "weight",
    "bias",
    "conv_states",
    "query_start_loc",
    "seq_lens_cpu",
    "cache_indices",
    "has_initial_state",
    "activation",
    "pad_slot_id",
    "validate_data"
  ],
  "_causal_conv1d_update_kernel": [
    "x_ptr",
    "w_ptr",
    "bias_ptr",
    "conv_state_ptr",
    "cache_seqlens_ptr",
    "conv_state_indices_ptr",
    "num_accepted_tokens_ptr",
    "intermediate_conv_window_ptr",
    "intermediate_state_indices_ptr",
    "retrieve_next_token_ptr",
    "retrieve_next_sibling_ptr",
    "retrieve_parent_token_ptr",
    "o_ptr",
    "batch",
    "dim",
    "seqlen",
    "state_len",
    "num_cache_lines",
    "stride_x_seq",
    "stride_x_dim",
    "stride_x_token",
    "stride_w_dim",
    "stride_w_width",
    "stride_conv_state_seq",
    "stride_conv_state_dim",
    "stride_conv_state_tok",
    "stride_state_indices",
    "stride_inter_seq",
    "stride_inter_step",
    "stride_inter_dim",
    "stride_inter_win",
    "stride_intermediate_state_indices",
    "stride_retrieve_next_token_seq",
    "stride_retrieve_next_token_token",
    "stride_retrieve_next_sibling_seq",
    "stride_retrieve_next_sibling_token",
    "stride_retrieve_parent_token_seq",
    "stride_retrieve_parent_token_token",
    "stride_o_seq",
    "stride_o_dim",
    "stride_o_token",
    "pad_slot_id",
    "HAS_BIAS",
    "KERNEL_WIDTH",
    "SILU_ACTIVATION",
    "IS_CONTINUOUS_BATCHING",
    "IS_SPEC_DECODING",
    "NP2_STATELEN",
    "NP2_SEQLEN",
    "USE_PAD_SLOT",
    "BLOCK_N",
    "SAVE_INTERMEDIATE",
    "HAS_EAGLE_TREE_CUSTOM_ATTN_MASK"
  ],
  "causal_conv1d_update": [
    "x",
    "conv_state",
    "weight",
    "bias",
    "activation",
    "cache_seqlens",
    "conv_state_indices",
    "num_accepted_tokens",
    "intermediate_conv_window",
    "intermediate_state_indices",
    "retrieve_next_token",
    "retrieve_next_sibling",
    "retrieve_parent_token",
    "pad_slot_id",
    "metadata",
    "validate_data"
  ],
  "mamba_v2_sharded_weight_loader": [
    "shard_spec",
    "tp_size",
    "tp_rank"
  ],
  "MambaMixer2": {
    "__init__": [
      "self",
      "cache_params",
      "hidden_size",
      "use_conv_bias",
      "use_bias",
      "n_groups",
      "rms_norm_eps",
      "activation",
      "use_rms_norm",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self"
    ],
    "mamba_type": [
      "self"
    ]
  },
  "Mixer2RMSNormGated": {
    "__init__": [
      "self",
      "full_hidden_size",
      "full_n_groups",
      "use_rms_norm",
      "eps"
    ],
    "forward_native": [
      "self",
      "x",
      "gate"
    ],
    "forward_cuda": [
      "self",
      "x",
      "gate"
    ]
  },
  "TRITON_22": [],
  "is_int_pow_2": [
    "n"
  ],
  "_mamba_chunk_scan_combined_fwd": [
    "x",
    "dt",
    "A",
    "B",
    "C",
    "chunk_size",
    "D",
    "z",
    "dt_bias",
    "initial_states",
    "seq_idx",
    "chunk_indices",
    "chunk_offsets",
    "cu_seqlens",
    "dt_softplus",
    "dt_limit",
    "state_dtype",
    "out"
  ],
  "mamba_chunk_scan_combined": [
    "x",
    "dt",
    "A",
    "B",
    "C",
    "chunk_size",
    "D",
    "z",
    "dt_bias",
    "initial_states",
    "seq_idx",
    "chunk_indices",
    "chunk_offsets",
    "cu_seqlens",
    "dt_softplus",
    "dt_limit",
    "out",
    "return_final_states",
    "return_varlen_states",
    "state_dtype"
  ],
  "TRITON3": [],
  "_selective_scan_update_kernel": [
    "state_ptr",
    "x_ptr",
    "dt_ptr",
    "dt_bias_ptr",
    "A_ptr",
    "B_ptr",
    "C_ptr",
    "D_ptr",
    "z_ptr",
    "out_ptr",
    "state_batch_indices_ptr",
    "pad_slot_id",
    "intermediate_states_buffer",
    "cache_steps",
    "retrieve_parent_token_ptr",
    "intermediate_state_indices_ptr",
    "batch",
    "T",
    "nheads",
    "dim",
    "dstate",
    "nheads_ngroups_ratio",
    "stride_state_batch",
    "stride_state_head",
    "stride_state_dim",
    "stride_state_dstate",
    "stride_x_batch",
    "stride_x_T",
    "stride_x_head",
    "stride_x_dim",
    "stride_dt_batch",
    "stride_dt_T",
    "stride_dt_head",
    "stride_dt_dim",
    "stride_dt_bias_head",
    "stride_dt_bias_dim",
    "stride_A_head",
    "stride_A_dim",
    "stride_A_dstate",
    "stride_B_batch",
    "stride_B_T",
    "stride_B_group",
    "stride_B_dstate",
    "stride_C_batch",
    "stride_C_T",
    "stride_C_group",
    "stride_C_dstate",
    "stride_D_head",
    "stride_D_dim",
    "stride_z_batch",
    "stride_z_T",
    "stride_z_head",
    "stride_z_dim",
    "stride_out_batch",
    "stride_out_T",
    "stride_out_head",
    "stride_out_dim",
    "stride_retrieve_parent_token_batch",
    "stride_retrieve_parent_token_T",
    "DT_SOFTPLUS",
    "TIE_HDIM",
    "BLOCK_SIZE_M",
    "HAS_DT_BIAS",
    "HAS_D",
    "HAS_Z",
    "HAS_STATE_BATCH_INDICES",
    "DISABLE_STATE_UPDATE",
    "CACHE_INTERMEDIATE_STATES",
    "HAS_EAGLE_TREE_CUSTOM_ATTN_MASK",
    "HAS_INTERMEDIATE_STATE_INDICES",
    "BLOCK_SIZE_DSTATE"
  ],
  "selective_state_update": [
    "state",
    "x",
    "dt",
    "A",
    "B",
    "C",
    "D",
    "z",
    "dt_bias",
    "dt_softplus",
    "state_batch_indices",
    "pad_slot_id",
    "out",
    "disable_state_update",
    "intermediate_states_buffer",
    "cache_steps",
    "retrieve_parent_token",
    "intermediate_state_indices"
  ],
  "_bmm_chunk_fwd_kernel": [
    "a_ptr",
    "b_ptr",
    "out_ptr",
    "seq_idx_ptr",
    "seqlen",
    "chunk_size",
    "K",
    "ngroups",
    "stride_a_batch",
    "stride_a_seqlen",
    "stride_a_head",
    "stride_ak",
    "stride_b_batch",
    "stride_b_seqlen",
    "stride_b_head",
    "stride_bk",
    "stride_out_batch",
    "stride_out_chunk",
    "stride_out_head",
    "stride_outm",
    "stride_outn",
    "stride_seq_idx_batch",
    "stride_seq_idx_seqlen",
    "IS_CAUSAL",
    "dot_dtype",
    "HAS_SEQ_IDX",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K"
  ],
  "_bmm_chunk_fwd": [
    "a",
    "b",
    "chunk_size",
    "seq_idx",
    "causal",
    "output_dtype"
  ],
  "_chunk_scan_fwd_kernel": [
    "cb_ptr",
    "x_ptr",
    "z_ptr",
    "out_ptr",
    "out_x_ptr",
    "dt_ptr",
    "dA_cumsum_ptr",
    "seq_idx_ptr",
    "C_ptr",
    "states_ptr",
    "D_ptr",
    "initstates_ptr",
    "chunk_indices_ptr",
    "chunk_offsets_ptr",
    "chunk_meta_num",
    "chunk_size",
    "hdim",
    "dstate",
    "batch",
    "seqlen",
    "nheads_ngroups_ratio",
    "stride_cb_batch",
    "stride_cb_chunk",
    "stride_cb_head",
    "stride_cb_csize_m",
    "stride_cb_csize_k",
    "stride_x_batch",
    "stride_x_seqlen",
    "stride_x_head",
    "stride_x_hdim",
    "stride_z_batch",
    "stride_z_seqlen",
    "stride_z_head",
    "stride_z_hdim",
    "stride_out_batch",
    "stride_out_seqlen",
    "stride_out_head",
    "stride_out_hdim",
    "stride_dt_batch",
    "stride_dt_chunk",
    "stride_dt_head",
    "stride_dt_csize",
    "stride_dA_cs_batch",
    "stride_dA_cs_chunk",
    "stride_dA_cs_head",
    "stride_dA_cs_csize",
    "stride_seq_idx_batch",
    "stride_seq_idx_seqlen",
    "stride_C_batch",
    "stride_C_seqlen",
    "stride_C_head",
    "stride_C_dstate",
    "stride_states_batch",
    "stride_states_chunk",
    "stride_states_head",
    "stride_states_hdim",
    "stride_states_dstate",
    "stride_init_states_batch",
    "stride_init_states_head",
    "stride_init_states_hdim",
    "stride_init_states_dstate",
    "stride_D_head",
    "IS_CAUSAL",
    "HAS_D",
    "D_HAS_HDIM",
    "HAS_Z",
    "HAS_SEQ_IDX",
    "BLOCK_SIZE_DSTATE",
    "IS_TRITON_22",
    "HAS_INITSTATES",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K"
  ],
  "_chunk_scan_fwd": [
    "cb",
    "x",
    "dt",
    "dA_cumsum",
    "C",
    "states",
    "D",
    "z",
    "seq_idx",
    "chunk_indices",
    "chunk_offsets",
    "initial_states",
    "out"
  ],
  "_layer_norm_fwd_1pass_kernel": [
    "X",
    "Y",
    "W",
    "B",
    "Z",
    "Mean",
    "Rstd",
    "stride_x_row",
    "stride_y_row",
    "stride_z_row",
    "M",
    "N",
    "eps",
    "BLOCK_N",
    "HAS_BIAS",
    "HAS_Z",
    "NORM_BEFORE_GATE",
    "IS_RMS_NORM"
  ],
  "_layer_norm_fwd": [
    "x",
    "weight",
    "bias",
    "eps",
    "z",
    "out",
    "group_size",
    "norm_before_gate",
    "is_rms_norm"
  ],
  "rms_norm_gated": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate"
  ],
  "_chunk_cumsum_fwd_kernel": [
    "dt_ptr",
    "A_ptr",
    "dt_bias_ptr",
    "dt_out_ptr",
    "dA_cumsum_ptr",
    "batch",
    "seqlen",
    "nheads",
    "chunk_size",
    "dt_min",
    "dt_max",
    "stride_dt_batch",
    "stride_dt_seqlen",
    "stride_dt_head",
    "stride_A_head",
    "stride_dt_bias_head",
    "stride_dt_out_batch",
    "stride_dt_out_chunk",
    "stride_dt_out_head",
    "stride_dt_out_csize",
    "stride_dA_cs_batch",
    "stride_dA_cs_chunk",
    "stride_dA_cs_head",
    "stride_dA_cs_csize",
    "DT_SOFTPLUS",
    "HAS_DT_BIAS",
    "BLOCK_SIZE_CHUNK",
    "BLOCK_SIZE_H"
  ],
  "_chunk_state_fwd_kernel": [
    "x_ptr",
    "b_ptr",
    "states_ptr",
    "dt_ptr",
    "dA_cumsum_ptr",
    "seq_idx_ptr",
    "hdim",
    "dstate",
    "chunk_size",
    "batch",
    "seqlen",
    "nheads_ngroups_ratio",
    "stride_x_batch",
    "stride_x_seqlen",
    "stride_x_head",
    "stride_x_hdim",
    "stride_b_batch",
    "stride_b_seqlen",
    "stride_b_head",
    "stride_b_dstate",
    "stride_states_batch",
    "stride_states_chunk",
    "stride_states_head",
    "stride_states_hdim",
    "stride_states_dstate",
    "stride_dt_batch",
    "stride_dt_chunk",
    "stride_dt_head",
    "stride_dt_csize",
    "stride_dA_cs_batch",
    "stride_dA_cs_chunk",
    "stride_dA_cs_head",
    "stride_dA_cs_csize",
    "stride_seq_idx_batch",
    "stride_seq_idx_seqlen",
    "HAS_SEQ_IDX",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K"
  ],
  "_chunk_state_varlen_kernel": [
    "x_ptr",
    "b_ptr",
    "dt_ptr",
    "dA_cumsum_ptr",
    "chunk_states_ptr",
    "cu_seqlens_ptr",
    "states_ptr",
    "initstates_ptr",
    "hdim",
    "dstate",
    "chunk_size",
    "seqlen",
    "nheads_ngroups_ratio",
    "stride_x_seqlen",
    "stride_x_head",
    "stride_x_hdim",
    "stride_b_seqlen",
    "stride_b_head",
    "stride_b_dstate",
    "stride_dt_chunk",
    "stride_dt_head",
    "stride_dt_csize",
    "stride_dA_cs_chunk",
    "stride_dA_cs_head",
    "stride_dA_cs_csize",
    "stride_chunk_states_chunk",
    "stride_chunk_states_head",
    "stride_chunk_states_hdim",
    "stride_chunk_states_dstate",
    "stride_states_batch",
    "stride_states_head",
    "stride_states_hdim",
    "stride_states_dstate",
    "stride_init_states_batch",
    "stride_init_states_head",
    "stride_init_states_hdim",
    "stride_init_states_dstate",
    "HAS_INITSTATES",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K"
  ],
  "_chunk_cumsum_fwd": [
    "dt",
    "A",
    "chunk_size",
    "dt_bias",
    "dt_softplus",
    "dt_limit"
  ],
  "_chunk_state_fwd": [
    "B",
    "x",
    "dt",
    "dA_cumsum",
    "seq_idx",
    "states",
    "states_in_fp32"
  ],
  "chunk_state_varlen": [
    "B",
    "x",
    "dt",
    "dA_cumsum",
    "cu_seqlens",
    "chunk_states",
    "initial_states"
  ],
  "_state_passing_fwd_kernel": [
    "states_ptr",
    "out_ptr",
    "final_states_ptr",
    "dA_cs_ptr",
    "initstates_ptr",
    "seq_idx_ptr",
    "chunk_offsets_ptr",
    "chunk_meta_num",
    "dim",
    "nchunks",
    "seqlen",
    "chunk_size",
    "stride_states_batch",
    "stride_states_chunk",
    "stride_states_head",
    "stride_states_dim",
    "stride_out_batch",
    "stride_out_chunk",
    "stride_out_head",
    "stride_out_dim",
    "stride_final_states_batch",
    "stride_final_states_head",
    "stride_final_states_dim",
    "stride_dA_cs_batch",
    "stride_dA_cs_chunk",
    "stride_dA_cs_head",
    "stride_dA_cs_csize",
    "stride_initstates_batch",
    "stride_initstates_head",
    "stride_initstates_dim",
    "stride_seq_idx_batch",
    "stride_seq_idx_seqlen",
    "HAS_INITSTATES",
    "HAS_SEQ_IDX",
    "IS_CONT_BATCHED",
    "BLOCK_SIZE"
  ],
  "_state_passing_fwd": [
    "states",
    "dA_cumsum",
    "initial_states",
    "seq_idx",
    "chunk_size",
    "out_dtype",
    "is_cont_batched",
    "chunk_offsets"
  ],
  "dump_generated_mlir": [],
  "get_wave_kernel": [
    "shape",
    "q_shape",
    "k_shape",
    "v_shape",
    "k_cache_shape",
    "v_cache_shape",
    "o_shape",
    "input_dtype",
    "output_dtype",
    "size_dtype",
    "is_causal",
    "logit_cap",
    "layer_scaling"
  ],
  "extend_attention_wave": [
    "q_extend",
    "k_extend",
    "v_extend",
    "k_buffer",
    "v_buffer",
    "qo_indptr",
    "kv_indptr",
    "kv_indices",
    "custom_mask",
    "mask_indptr",
    "max_seq_len",
    "output",
    "is_causal",
    "layer_scaling",
    "logit_cap"
  ],
  "prefill_attention_wave": [
    "q",
    "k",
    "v",
    "o",
    "b_start_loc",
    "b_seq_len",
    "max_seq_len",
    "is_causal"
  ],
  "decode_attention_intermediate_arrays_shapes": [
    "num_seqs",
    "head_size_kv",
    "num_query_heads",
    "max_kv_splits"
  ],
  "decode_attention_wave": [
    "q",
    "k_buffer",
    "v_buffer",
    "o",
    "b_req_idx",
    "req_to_token",
    "attn_logits",
    "attn_logits_max",
    "num_kv_splits",
    "max_kv_splits",
    "sm_scale",
    "logit_cap"
  ],
  "PrecomputedMetadata": {},
  "compute_cu_seqlens": [
    "seqlens"
  ],
  "NativeSparseAttnBackendMTPPrecomputeMixin": {
    "_precompute_replay_metadata": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "forward_mode",
      "spec_info"
    ],
    "_precompute_decode_mode": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu"
    ],
    "_precompute_target_verify_mode": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu"
    ],
    "_precompute_draft_extend_mode": [
      "self",
      "bs",
      "req_pool_indices",
      "seq_lens",
      "seq_lens_cpu",
      "spec_info"
    ]
  },
  "transform_index_page_table_prefill": [],
  "transform_index_page_table_decode": [],
  "transform_index_page_table_decode_kernel": [
    "page_table_ptr",
    "topk_indices_ptr",
    "result_ptr",
    "page_size",
    "max_seqlen_k"
  ],
  "transform_index_page_table_decode_fast": [
    "page_table",
    "topk_indices",
    "result",
    "page_size"
  ],
  "transform_index_page_table_prefill_fast": [
    "page_table",
    "topk_indices",
    "extend_lens_cpu",
    "page_size"
  ],
  "transform_index_page_table_decode_ref": [
    "page_table",
    "topk_indices",
    "result",
    "page_size"
  ],
  "transform_index_page_table_prefill_ref": [
    "page_table",
    "topk_indices",
    "extend_lens_cpu",
    "page_size"
  ],
  "compute_nsa_seqlens": [
    "original_seq_lens",
    "nsa_index_topk"
  ],
  "is_nsa_enable_prefill_cp": [],
  "is_nsa_prefill_cp_in_seq_split": [],
  "is_nsa_prefill_cp_round_robin_split": [],
  "can_nsa_prefill_cp_round_robin_split": [
    "forward_batch"
  ],
  "nsa_cp_round_robin_split_data": [
    "input_"
  ],
  "pad_nsa_cache_seqlens": [
    "forward_batch",
    "nsa_cache_seqlens"
  ],
  "NSAContextParallelMetadata": {},
  "can_cp_split": [
    "seq_len",
    "cp_size",
    "use_nsa",
    "forward_batch"
  ],
  "cp_split_and_rebuild_data": [
    "forward_batch",
    "input_"
  ],
  "cp_split_and_rebuild_position": [
    "forward_batch",
    "positions"
  ],
  "nsa_cp_round_robin_split_q_seqs_kernel": [
    "in_seqs_ptr",
    "out_seqs_ptr",
    "bs_idx_ptr",
    "tokens",
    "cp_size",
    "cp_rank"
  ],
  "nsa_cp_round_robin_split_q_seqs_cpu": [
    "extend_seqs"
  ],
  "nsa_cp_round_robin_split_q_seqs": [
    "extend_seqs_cpu",
    "extend_seqs"
  ],
  "nsa_use_prefill_cp": [
    "forward_batch",
    "nsa_enable_prefill_cp"
  ],
  "cp_attn_tp_all_gather_reorganazied_into_tensor": [
    "input_",
    "total_len",
    "attn_tp_size",
    "forward_batch",
    "stream_op"
  ],
  "cp_all_gather_rerange_output": [
    "input_tensor",
    "cp_size",
    "forward_batch",
    "stream"
  ],
  "calculate_cp_seq_idx": [
    "cp_chunks_len",
    "seqs_len"
  ],
  "prepare_input_dp_with_cp_dsa": [
    "kv_len",
    "cp_rank",
    "cp_size",
    "seqs_len"
  ],
  "quantize_k_cache": [
    "cache_k"
  ],
  "quantize_k_cache_separate": [
    "k_nope",
    "k_rope",
    "tile_size"
  ],
  "_quantize_k_cache_ref": [
    "input_k_cache",
    "dv",
    "tile_size"
  ],
  "_quantize_k_cache_fast_wrapped": [
    "input_k_cache",
    "dv",
    "tile_size"
  ],
  "_quantize_k_cache_fast": [
    "k_nope",
    "k_rope",
    "group_size"
  ],
  "_quantize_k_cache_fast_separate": [
    "k_nope",
    "k_rope",
    "group_size"
  ],
  "_quantize_k_cache_fast_kernel": [
    "output_nope_q_ptr",
    "output_nope_s_ptr",
    "output_rope_ptr",
    "k_nope_ptr",
    "k_rope_ptr",
    "output_nope_q_stride_0",
    "output_nope_s_stride_0",
    "output_rope_stride_0",
    "k_nope_stride_0",
    "k_rope_stride_0",
    "NUM_NOPE_BLOCKS",
    "GROUP_SIZE",
    "DIM_NOPE",
    "DIM_ROPE",
    "FP8_MIN",
    "FP8_MAX"
  ],
  "DUAL_STREAM_TOKEN_THRESHOLD": [],
  "BaseIndexerMetadata": {
    "get_seqlens_int32": [
      "self"
    ],
    "get_page_table_64": [
      "self"
    ],
    "get_page_table_1": [
      "self"
    ],
    "get_seqlens_expanded": [
      "self"
    ],
    "get_indexer_kvcache_range": [
      "self"
    ],
    "get_indexer_seq_len_cpu": [
      "self"
    ],
    "get_token_to_batch_idx": [
      "self"
    ],
    "topk_transform": [
      "self",
      "logits",
      "topk"
    ]
  },
  "rotate_activation": [
    "x"
  ],
  "Indexer": {
    "__init__": [
      "self",
      "hidden_size",
      "index_n_heads",
      "index_head_dim",
      "rope_head_dim",
      "index_topk",
      "q_lora_rank",
      "max_position_embeddings",
      "rope_theta",
      "layer_id",
      "scale_fmt",
      "block_size",
      "rope_scaling",
      "prefix",
      "quant_config",
      "alt_stream"
    ],
    "_with_real_sm_count": [
      "self"
    ],
    "_project_and_scale_head_gates": [
      "self",
      "x"
    ],
    "_get_logits_head_gate": [
      "self",
      "x",
      "q_scale"
    ],
    "_get_q_k_bf16": [
      "self",
      "q_lora",
      "x",
      "positions",
      "enable_dual_stream",
      "forward_batch"
    ],
    "_get_k_bf16": [
      "self",
      "x",
      "positions",
      "enable_dual_stream"
    ],
    "_get_topk_paged": [
      "self",
      "forward_batch",
      "layer_id",
      "q_fp8",
      "weights",
      "metadata"
    ],
    "_should_chunk_mqa_logits": [
      "self",
      "num_q",
      "num_k",
      "device"
    ],
    "_get_topk_ragged": [
      "self",
      "forward_batch",
      "layer_id",
      "q_fp8",
      "weights",
      "metadata"
    ],
    "_forward_cuda_k_only": [
      "self",
      "x",
      "positions",
      "forward_batch",
      "layer_id",
      "act_quant",
      "enable_dual_stream",
      "metadata",
      "return_indices"
    ],
    "_get_topk_ragged_with_cp": [
      "self",
      "forward_batch",
      "layer_id",
      "q_fp8",
      "weights",
      "metadata",
      "kv_len",
      "actual_seq_q",
      "cp_index"
    ],
    "forward_indexer": [
      "self",
      "q_fp8",
      "weights",
      "forward_batch",
      "topk",
      "layer_id"
    ],
    "forward_cuda": [
      "self",
      "x",
      "q_lora",
      "positions",
      "forward_batch",
      "layer_id",
      "return_indices"
    ],
    "forward_npu": [
      "self",
      "x",
      "q_lora",
      "positions",
      "forward_batch",
      "layer_id"
    ],
    "do_npu_cp_balance_indexer": [
      "self",
      "q",
      "past_key_states",
      "indexer_weights",
      "actual_seq_lengths_q",
      "actual_seq_lengths_kv",
      "block_table"
    ]
  },
  "pass_configs": [],
  "BF16": [],
  "FP8": [],
  "FP32": [],
  "fast_log2_ceil": [
    "x"
  ],
  "fast_pow2": [
    "x"
  ],
  "fast_round_scale": [
    "amax",
    "fp8_max_inv"
  ],
  "act_quant_kernel": [
    "N",
    "in_dtype",
    "out_dtype",
    "scale_dtype",
    "round_scale"
  ],
  "act_quant": [
    "x",
    "block_size",
    "scale_fmt"
  ],
  "fp8_index_kernel": [
    "h",
    "d",
    "clear_accum"
  ],
  "fp8_index": [
    "q",
    "q_s",
    "k",
    "k_s"
  ],
  "sparse_attention_fwd_kernel_v1": [
    "num_heads",
    "dim",
    "tail_dim",
    "topk"
  ],
  "sparse_attention_fwd_kernel_v2": [
    "num_heads",
    "dim",
    "tail_dim",
    "topk"
  ],
  "tilelang_sparse_fwd": [
    "q",
    "kv",
    "indices",
    "sm_scale",
    "d_v"
  ],
  "dequantize_k_cache": [
    "quant_k_cache"
  ],
  "_dequantize_k_cache_ref": [
    "quant_k_cache",
    "dv",
    "tile_size",
    "d"
  ],
  "_dequantize_k_cache_fast_wrapped": [
    "quant_k_cache",
    "dv",
    "tile_size"
  ],
  "_dequantize_k_cache_fast": [
    "quant_k_cache",
    "group_size"
  ],
  "_dequantize_k_cache_fast_kernel": [
    "output_ptr",
    "input_nope_q_ptr",
    "input_nope_s_ptr",
    "input_rope_ptr",
    "output_stride_0",
    "input_nope_q_stride_0",
    "input_nope_s_stride_0",
    "input_rope_stride_0",
    "NUM_NOPE_BLOCKS",
    "GROUP_SIZE",
    "DIM_NOPE",
    "DIM_ROPE"
  ],
  "dequantize_k_cache_paged": [
    "quant_k_cache",
    "page_table_1_flattened",
    "group_size"
  ],
  "_dequantize_k_cache_paged_kernel": [
    "output_ptr",
    "input_nope_q_ptr",
    "input_nope_s_ptr",
    "input_rope_ptr",
    "page_table_1_ptr",
    "output_stride_0",
    "input_nope_q_stride_0",
    "input_nope_s_stride_0",
    "input_rope_stride_0",
    "NUM_NOPE_BLOCKS",
    "GROUP_SIZE",
    "DIM_NOPE",
    "DIM_ROPE"
  ],
  "GetK": {
    "execute": [
      "cls"
    ],
    "slow": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ],
    "torch_fast": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ],
    "triton": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ]
  },
  "GetS": {
    "execute": [
      "cls"
    ],
    "slow": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ],
    "torch_fast": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ],
    "triton": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ]
  },
  "GetKAndS": {
    "execute": [
      "cls"
    ],
    "triton": [
      "cls",
      "pool",
      "buf",
      "seq_len",
      "page_indices"
    ]
  },
  "SetK": {
    "execute": [
      "cls"
    ],
    "slow": [
      "cls",
      "pool",
      "buf",
      "loc",
      "index_k"
    ],
    "torch_fast": [
      "cls",
      "pool",
      "buf",
      "loc",
      "index_k"
    ]
  },
  "SetS": {
    "execute": [
      "cls"
    ],
    "slow": [
      "cls",
      "pool",
      "buf",
      "loc",
      "index_k_scale"
    ],
    "torch_fast": [
      "cls",
      "pool",
      "buf",
      "loc",
      "index_k_scale"
    ]
  },
  "SetKAndS": {
    "execute": [
      "cls"
    ],
    "vanilla": [
      "cls",
      "pool",
      "buf",
      "loc",
      "index_k",
      "index_k_scale"
    ],
    "triton": [
      "cls",
      "pool",
      "buf",
      "loc",
      "index_k",
      "index_k_scale"
    ]
  },
  "_set_k_and_s_triton": [
    "buf",
    "loc",
    "index_k",
    "index_k_scale",
    "page_size"
  ],
  "_set_k_and_s_triton_kernel": [
    "buf_fp8_ptr",
    "buf_fp32_ptr",
    "loc_ptr",
    "index_k_ptr",
    "index_k_scale_ptr",
    "index_k_ptr_stride_0",
    "PAGE_SIZE",
    "BUF_NUMEL_PER_PAGE",
    "NUM_K_ELEMS_PER_TOKEN",
    "S_OFFSET_NBYTES_IN_PAGE"
  ],
  "_get_k_triton": [
    "buf",
    "page_indices",
    "seq_len",
    "page_size",
    "index_head_dim"
  ],
  "_get_k_triton_kernel": [
    "buf_ptr",
    "page_indices_ptr",
    "out_ptr",
    "seq_len",
    "page_size",
    "buf_numel_per_page",
    "index_head_dim",
    "BLOCK_SIZE"
  ],
  "_get_s_triton": [
    "buf",
    "page_indices",
    "seq_len",
    "page_size",
    "index_head_dim"
  ],
  "_get_s_triton_kernel": [
    "buf_ptr",
    "page_indices_ptr",
    "out_ptr",
    "seq_len",
    "page_size",
    "buf_numel_per_page",
    "s_offset_in_page"
  ],
  "_get_k_and_s_triton": [
    "buf",
    "page_indices",
    "seq_len",
    "page_size",
    "index_head_dim"
  ],
  "_get_k_and_s_triton_kernel": [
    "buf_ptr",
    "page_indices_ptr",
    "k_out_ptr",
    "s_out_ptr",
    "seq_len",
    "page_size",
    "buf_numel_per_page",
    "index_head_dim",
    "s_offset_in_page",
    "BLOCK_SIZE_K"
  ],
  "_act_quant_kernel": [
    "X_ptr",
    "Y_ptr",
    "S_ptr",
    "M",
    "N",
    "group_size",
    "round_scale",
    "BLOCK_M",
    "BLOCK_N"
  ],
  "fused_gdn_gating_kernel": [
    "g",
    "beta_output",
    "A_log",
    "a",
    "b",
    "dt_bias",
    "seq_len",
    "NUM_HEADS",
    "beta",
    "threshold",
    "BLK_HEADS"
  ],
  "fused_gdn_gating": [
    "A_log",
    "a",
    "b",
    "dt_bias",
    "beta",
    "threshold"
  ],
  "NUM_WARPS": [],
  "CHUNK_SIZE": [],
  "chunk_gated_delta_rule_fwd_kernel_h_blockdim64": [
    "k",
    "v",
    "w",
    "v_new",
    "g",
    "gk",
    "h",
    "initial_state",
    "initial_state_indices",
    "cu_seqlens",
    "chunk_offsets",
    "T",
    "H",
    "Hg",
    "K",
    "V",
    "BT",
    "BV",
    "USE_G",
    "USE_GK",
    "USE_INITIAL_STATE",
    "INPLACE_UPDATE",
    "SAVE_NEW_VALUE",
    "IS_VARLEN"
  ],
  "chunk_gated_delta_rule_fwd_h": [
    "k",
    "w",
    "u",
    "g",
    "gk",
    "initial_state",
    "initial_state_indices",
    "save_new_value",
    "cu_seqlens"
  ],
  "prepare_lens": [
    "cu_seqlens"
  ],
  "prepare_chunk_indices": [
    "cu_seqlens",
    "chunk_size"
  ],
  "prepare_chunk_offsets": [
    "cu_seqlens",
    "chunk_size"
  ],
  "solve_tril_16x16_kernel": [
    "A",
    "Ad",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "BT",
    "IS_VARLEN"
  ],
  "merge_16x16_to_32x32_inverse_kernel": [
    "A",
    "Ad",
    "Ai",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "BT",
    "IS_VARLEN"
  ],
  "merge_16x16_to_64x64_inverse_kernel": [
    "A",
    "Ad",
    "Ai",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "BT",
    "IS_VARLEN"
  ],
  "solve_tril": [
    "A",
    "cu_seqlens",
    "output_dtype"
  ],
  "recompute_w_u_fwd_kernel": [
    "k",
    "v",
    "beta",
    "w",
    "u",
    "A",
    "g",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "Hg",
    "K",
    "V",
    "BT",
    "BK",
    "BV",
    "IS_VARLEN"
  ],
  "recompute_w_u_fwd": [
    "k",
    "v",
    "beta",
    "g_cumsum",
    "A",
    "cu_seqlens"
  ],
  "fwd_recompute_w_u": [],
  "chunk_scaled_dot_kkt_fwd_kernel": [
    "k",
    "beta",
    "g_cumsum",
    "A",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "Hg",
    "K",
    "BT",
    "BK",
    "IS_VARLEN",
    "USE_G"
  ],
  "chunk_scaled_dot_kkt_fwd": [
    "k",
    "beta",
    "g_cumsum",
    "cu_seqlens",
    "chunk_size",
    "output_dtype"
  ],
  "BT_LIST_AUTOTUNE": [],
  "NUM_WARPS_AUTOTUNE": [],
  "fused_recurrent_kda_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "inplace_final_state",
    "cu_seqlens",
    "num_accepted_tokens",
    "use_qk_l2norm_in_kernel"
  ],
  "fused_recurrent_kda": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "inplace_final_state",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens"
  ],
  "layer_norm_gated_fwd_kernel": [
    "x",
    "g",
    "y",
    "w",
    "b",
    "residual",
    "residual_out",
    "mean",
    "rstd",
    "eps",
    "T",
    "D",
    "BT",
    "BD",
    "ACTIVATION",
    "IS_RMS_NORM",
    "STORE_RESIDUAL_OUT",
    "HAS_RESIDUAL",
    "HAS_WEIGHT",
    "HAS_BIAS"
  ],
  "layer_norm_gated_fwd_kernel1": [
    "x",
    "g",
    "y",
    "w",
    "b",
    "residual",
    "residual_out",
    "mean",
    "rstd",
    "eps",
    "D",
    "BD",
    "ACTIVATION",
    "IS_RMS_NORM",
    "STORE_RESIDUAL_OUT",
    "HAS_RESIDUAL",
    "HAS_WEIGHT",
    "HAS_BIAS"
  ],
  "layer_norm_gated_fwd": [
    "x",
    "g",
    "weight",
    "bias",
    "activation",
    "eps",
    "residual",
    "out_dtype",
    "residual_dtype",
    "is_rms_norm"
  ],
  "FusedRMSNormGated": {
    "__init__": [
      "self",
      "hidden_size",
      "elementwise_affine",
      "eps",
      "activation",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x",
      "g",
      "residual",
      "prenorm",
      "residual_in_fp32"
    ]
  },
  "chunk_kda_scaled_dot_kkt_fwd_kernel_intra_sub_inter": [
    "q",
    "k",
    "g",
    "beta",
    "A",
    "Aqk",
    "scale",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "K",
    "BT",
    "BC",
    "BK",
    "NC",
    "IS_VARLEN"
  ],
  "chunk_kda_scaled_dot_kkt_fwd_kernel_intra_sub_intra": [
    "q",
    "k",
    "g",
    "beta",
    "A",
    "Aqk",
    "scale",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "H",
    "K",
    "BT",
    "BC",
    "BK",
    "IS_VARLEN"
  ],
  "chunk_kda_scaled_dot_kkt_fwd": [
    "q",
    "k",
    "gk",
    "beta",
    "scale",
    "cu_seqlens",
    "chunk_size",
    "output_dtype"
  ],
  "chunk_gla_fwd_kernel_o": [
    "q",
    "v",
    "g",
    "h",
    "o",
    "A",
    "cu_seqlens",
    "chunk_indices",
    "scale",
    "T",
    "H",
    "K",
    "V",
    "BT",
    "BK",
    "BV",
    "IS_VARLEN"
  ],
  "chunk_gla_fwd_o_gk": [
    "q",
    "v",
    "g",
    "A",
    "h",
    "o",
    "scale",
    "cu_seqlens",
    "chunk_size"
  ],
  "chunk_kda_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "initial_state_indices",
    "cu_seqlens"
  ],
  "chunk_kda": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "initial_state_indices",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens"
  ],
  "kda_gate_fwd_kernel": [
    "g",
    "A",
    "y",
    "g_bias",
    "beta",
    "threshold",
    "T",
    "H",
    "D",
    "BT",
    "BD",
    "HAS_BIAS"
  ],
  "fused_kda_gate": [
    "g",
    "A",
    "head_k_dim",
    "g_bias",
    "beta",
    "threshold"
  ],
  "COMPILER_MODE": [],
  "FLA_CI_ENV": [],
  "check_environments": [],
  "get_abs_err": [
    "x",
    "y"
  ],
  "get_err_ratio": [
    "x",
    "y"
  ],
  "assert_close": [
    "prefix",
    "ref",
    "tri",
    "ratio",
    "warning",
    "err_atol"
  ],
  "SUPPRESS_LEVEL": [],
  "tensor_cache": [
    "fn"
  ],
  "input_guard": [
    "fn"
  ],
  "contiguous": [],
  "require_version": [
    "version",
    "hint"
  ],
  "checkpoint": [
    "fn"
  ],
  "check_pytorch_version": [
    "version_s"
  ],
  "_cpu_device_warning": [],
  "get_multiprocessor_count": [
    "tensor_idx"
  ],
  "get_available_device": [],
  "_check_platform": [],
  "device": [],
  "device_torch_lib": [],
  "device_platform": [],
  "is_amd": [],
  "is_intel": [],
  "is_nvidia": [],
  "is_intel_alchemist": [],
  "is_nvidia_hopper": [],
  "use_cuda_graph": [],
  "is_tf32_supported": [],
  "is_gather_supported": [],
  "get_all_max_shared_mem": [],
  "Backend": {
    "ADA": [],
    "AMPERE": [],
    "HOPPER": [],
    "DEFAULT": [],
    "get_shared_memory": [
      "cls",
      "arch"
    ]
  },
  "check_shared_mem": [
    "arch",
    "tensor_idx"
  ],
  "BT_LIST": [],
  "l2norm_fwd_kernel1": [
    "x",
    "y",
    "D",
    "BD",
    "eps"
  ],
  "l2norm_fwd_kernel": [
    "x",
    "y",
    "eps",
    "NB",
    "T",
    "D",
    "BT",
    "BD"
  ],
  "l2norm_fwd": [
    "x",
    "eps",
    "output_dtype"
  ],
  "L2NormFunction": {
    "forward": [
      "ctx",
      "x",
      "eps",
      "output_dtype"
    ]
  },
  "l2norm": [
    "x",
    "eps",
    "output_dtype"
  ],
  "l2_norm": [],
  "L2Norm": {
    "__init__": [
      "self",
      "eps",
      "output_dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "chunk_gated_delta_rule_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "initial_state_indices",
    "cu_seqlens"
  ],
  "ChunkGatedDeltaRuleFunction": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "g",
      "beta",
      "scale",
      "initial_state",
      "initial_state_indices",
      "cu_seqlens",
      "use_qk_l2norm_in_kernel"
    ]
  },
  "chunk_gated_delta_rule": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "initial_state_indices",
    "cu_seqlens",
    "head_first",
    "use_qk_l2norm_in_kernel"
  ],
  "safe_exp": [
    "x"
  ],
  "rms_norm_ref": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate",
    "upcast"
  ],
  "_get_sm_count": [
    "device"
  ],
  "calc_rows_per_block": [
    "M",
    "device"
  ],
  "LayerNormFn": {
    "forward": [
      "ctx",
      "x",
      "weight",
      "bias",
      "z",
      "eps",
      "group_size",
      "norm_before_gate",
      "is_rms_norm"
    ]
  },
  "layernorm_fn": [
    "x",
    "weight",
    "bias",
    "z",
    "eps",
    "group_size",
    "norm_before_gate",
    "is_rms_norm"
  ],
  "fused_recurrent_gated_delta_rule_fwd_kernel": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "o",
    "h0",
    "ht",
    "cu_seqlens",
    "scale",
    "T",
    "B",
    "H",
    "HV",
    "K",
    "V",
    "BK",
    "BV",
    "USE_INITIAL_STATE",
    "STORE_FINAL_STATE",
    "IS_BETA_HEADWISE",
    "USE_QK_L2NORM_IN_KERNEL",
    "IS_VARLEN",
    "IS_KDA"
  ],
  "fused_recurrent_gated_delta_rule_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens"
  ],
  "FusedRecurrentFunction": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "g",
      "beta",
      "scale",
      "initial_state",
      "output_final_state",
      "cu_seqlens",
      "use_qk_l2norm_in_kernel"
    ],
    "backward": [
      "ctx",
      "do",
      "dht"
    ]
  },
  "fused_recurrent_gated_delta_rule": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state",
    "output_final_state",
    "cu_seqlens",
    "use_qk_l2norm_in_kernel"
  ],
  "fused_recurrent_gated_delta_rule_update_fwd_kernel": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "o",
    "h0_source",
    "h0_indices",
    "cu_seqlens",
    "scale",
    "intermediate_states_buffer",
    "intermediate_state_indices",
    "cache_steps",
    "retrieve_parent_token_ptr",
    "stride_retrieve_parent_token_seq",
    "stride_retrieve_parent_token_token",
    "T",
    "NP2_T",
    "B",
    "H",
    "HV",
    "K",
    "V",
    "BK",
    "BV",
    "USE_INITIAL_STATE",
    "IS_BETA_HEADWISE",
    "USE_QK_L2NORM_IN_KERNEL",
    "IS_VARLEN",
    "DISABLE_STATE_UPDATE",
    "DISABLE_OUTPUT_CALCULATION",
    "CACHE_INTERMEDIATE_STATES",
    "HAS_EAGLE_TREE_CUSTOM_ATTN_MASK"
  ],
  "fused_recurrent_gated_delta_rule_update_fwd": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state_source",
    "initial_state_indices",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens",
    "disable_state_update",
    "disable_output_calculation",
    "intermediate_states_buffer",
    "intermediate_state_indices",
    "cache_steps",
    "retrieve_parent_token"
  ],
  "FusedRecurrentUpdateFunction": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "g",
      "beta",
      "scale",
      "initial_state_source",
      "initial_state_indices",
      "cu_seqlens",
      "use_qk_l2norm_in_kernel",
      "disable_state_update",
      "disable_output_calculation",
      "intermediate_states_buffer",
      "intermediate_state_indices",
      "cache_steps",
      "retrieve_parent_token"
    ],
    "backward": [
      "ctx",
      "do",
      "dht"
    ]
  },
  "fused_recurrent_gated_delta_rule_update": [
    "q",
    "k",
    "v",
    "g",
    "beta",
    "scale",
    "initial_state_source",
    "initial_state_indices",
    "cu_seqlens",
    "use_qk_l2norm_in_kernel",
    "disable_state_update",
    "disable_output_calculation",
    "intermediate_states_buffer",
    "intermediate_state_indices",
    "cache_steps",
    "retrieve_parent_token"
  ],
  "BKV_LIST": [],
  "chunk_fwd_kernel_o": [
    "q",
    "k",
    "v",
    "h",
    "g",
    "o",
    "cu_seqlens",
    "chunk_indices",
    "scale",
    "T",
    "H",
    "Hg",
    "K",
    "V",
    "BT",
    "BK",
    "BV",
    "USE_G",
    "IS_VARLEN"
  ],
  "chunk_fwd_o": [
    "q",
    "k",
    "v",
    "h",
    "g",
    "scale",
    "cu_seqlens",
    "chunk_size"
  ],
  "fused_sigmoid_gating_delta_rule_update_kernel": [
    "A_log",
    "a",
    "dt_bias",
    "softplus_beta",
    "softplus_threshold",
    "q",
    "k",
    "v",
    "b",
    "o",
    "h0_source",
    "h0_indices",
    "cu_seqlens",
    "scale",
    "T",
    "B",
    "H",
    "HV",
    "K",
    "V",
    "BK",
    "BV",
    "USE_INITIAL_STATE",
    "USE_QK_L2NORM_IN_KERNEL",
    "IS_VARLEN",
    "IS_KDA"
  ],
  "fused_sigmoid_gating_delta_rule_update": [
    "A_log",
    "a",
    "dt_bias",
    "softplus_beta",
    "softplus_threshold",
    "q",
    "k",
    "v",
    "b",
    "initial_state_source",
    "initial_state_indices",
    "scale",
    "use_qk_l2norm_in_kernel",
    "cu_seqlens",
    "is_kda"
  ],
  "BS_LIST": [],
  "chunk_local_cumsum_scalar_kernel": [
    "s",
    "o",
    "scale",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "B",
    "H",
    "BT",
    "REVERSE",
    "HAS_SCALE",
    "IS_VARLEN",
    "HEAD_FIRST"
  ],
  "chunk_local_cumsum_vector_kernel": [
    "s",
    "o",
    "scale",
    "cu_seqlens",
    "chunk_indices",
    "T",
    "B",
    "H",
    "S",
    "BT",
    "BS",
    "REVERSE",
    "HAS_SCALE",
    "IS_VARLEN",
    "HEAD_FIRST"
  ],
  "chunk_local_cumsum_scalar": [
    "g",
    "chunk_size",
    "reverse",
    "scale",
    "cu_seqlens",
    "head_first",
    "output_dtype"
  ],
  "chunk_local_cumsum_vector": [
    "g",
    "chunk_size",
    "reverse",
    "scale",
    "cu_seqlens",
    "head_first",
    "output_dtype"
  ],
  "chunk_local_cumsum": [
    "g",
    "chunk_size",
    "reverse",
    "scale",
    "cu_seqlens",
    "head_first",
    "output_dtype"
  ],
  "W8A8Fp8Config": {
    "__init__": [
      "self",
      "is_checkpoint_fp8_serialized"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "self"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "W8A8Fp8LinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "W8A8FP8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "ACTIVATION_SCHEMES": [],
  "BlockInt8Config": {
    "__init__": [
      "self",
      "is_checkpoint_int8_serialized",
      "activation_scheme",
      "ignored_layers",
      "weight_block_size"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "BlockInt8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "BlockInt8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "use_vllm_cutlass_w8a8_fp8_kernel": [],
  "use_triton_w8a8_fp8_kernel": [],
  "TORCH_DEVICE_IDENTITY": [],
  "use_rowwise_torch_scaled_mm": [],
  "USE_ROWWISE_TORCH_SCALED_MM": [],
  "cutlass_fp8_supported": [],
  "normalize_e4m3fn_to_e4m3fnuz": [
    "weight",
    "weight_scale",
    "input_scale"
  ],
  "Fp8GemmRunnerBackend": {
    "AUTO": [],
    "FLASHINFER": [],
    "CUTLASS": [],
    "DEEP_GEMM": [],
    "TRITON": [],
    "AITER": [],
    "is_auto": [
      "self"
    ],
    "is_flashinfer": [
      "self"
    ],
    "is_cutlass": [
      "self"
    ],
    "is_deep_gemm": [
      "self"
    ],
    "is_triton": [
      "self"
    ],
    "is_aiter": [
      "self"
    ]
  },
  "_check_cutlass_block_fp8_hardware_support": [],
  "dispatch_w8a8_block_fp8_linear": [],
  "_dispatch_explicit_backend": [
    "backend"
  ],
  "_dispatch_auto_backend": [],
  "initialize_fp8_gemm_config": [
    "server_args"
  ],
  "get_fp8_gemm_runner_backend": [],
  "flashinfer_gemm_w8a8_block_fp8_linear_with_fallback": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "cutlass_w8a8_block_fp8_linear_with_fallback": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "deepgemm_w8a8_block_fp8_linear_with_fallback": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "_unpack_ue8m0_scale_for_triton": [
    "sf_packed",
    "weight_shape",
    "block_size"
  ],
  "aiter_w8a8_block_fp8_linear": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "triton_w8a8_block_fp8_linear": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "dequant_mxfp4": [
    "w_block",
    "w_scale",
    "out_dtype"
  ],
  "input_to_float8": [
    "x",
    "dtype"
  ],
  "block_quant_to_tensor_quant": [
    "x_q_block",
    "x_s",
    "block_size"
  ],
  "block_quant_dequant": [
    "x_q_block",
    "x_s",
    "block_size",
    "dtype"
  ],
  "requant_weight_ue8m0_inplace": [
    "weight",
    "weight_scale_inv",
    "weight_block_size"
  ],
  "requant_weight_ue8m0": [
    "weight",
    "weight_scale_inv",
    "weight_block_size"
  ],
  "quant_weight_ue8m0": [
    "weight_dequant",
    "weight_block_size"
  ],
  "transform_scale_ue8m0_inplace": [
    "param",
    "mn"
  ],
  "transform_scale_ue8m0": [
    "sf",
    "mn",
    "use_torch_impl"
  ],
  "_get_mn_major_tma_aligned_packed_ue8m0_tensor_torch_impl": [
    "x"
  ],
  "inverse_transform_scale_ue8m0": [
    "sf_packed",
    "mn"
  ],
  "_inverse_transform_scale_ue8m0_impl": [
    "sf_packed"
  ],
  "per_block_cast_to_fp8": [
    "x"
  ],
  "ceil_to_ue8m0": [
    "x"
  ],
  "channel_quant_to_tensor_quant": [
    "x_q_channel",
    "x_s"
  ],
  "_process_scaled_mm_output": [
    "output",
    "input_2d_shape",
    "output_shape"
  ],
  "_apply_fallback_scaled_mm": [
    "qinput",
    "weight",
    "x_scale",
    "weight_scale",
    "input_2d_shape",
    "output_shape",
    "bias",
    "input_dtype"
  ],
  "apply_fp8_linear": [
    "input",
    "weight",
    "weight_scale",
    "input_scale",
    "input_scale_ub",
    "bias",
    "cutlass_fp8_supported",
    "use_per_token_if_dynamic",
    "pad_output",
    "compressed_tensor_quant"
  ],
  "can_auto_enable_marlin_fp8": [],
  "apply_fp8_ptpc_linear": [
    "input",
    "weight",
    "weight_scale",
    "input_scale",
    "input_scale_ub",
    "bias",
    "cutlass_fp8_supported",
    "use_per_token_if_dynamic",
    "pad_output",
    "compressed_tensor_quant"
  ],
  "validate_fp8_block_shape": [
    "layer",
    "input_size",
    "output_size",
    "input_size_per_partition",
    "output_partition_sizes",
    "block_size"
  ],
  "BaseKVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "_use_hip_int4": [],
  "Fp8Config": {
    "__init__": [
      "self",
      "is_checkpoint_fp8_serialized",
      "activation_scheme",
      "ignored_layers",
      "weight_block_size"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "Fp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "validate_block_quant_shapes": [
      "self",
      "input_size",
      "input_size_per_partition",
      "output_size",
      "output_size_per_partition",
      "output_partition_sizes",
      "skip_block_quant_check"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype",
      "skip_block_quant_check"
    ],
    "process_weights_after_loading_block_quant": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "Fp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "is_deepgemm_moe_runner_backend_enabled": [],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading_block_quant": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "process_weights_hip_int4": [
      "self",
      "layer"
    ],
    "process_weights_hip_scale_padding": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "_ensure_cutlass_buffers_initialized": [
      "self",
      "layer"
    ],
    "maybe_apply_hip_fused_experts": [
      "self",
      "layer",
      "x",
      "topk_output",
      "activation",
      "no_combine"
    ]
  },
  "Fp8KVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "is_fp8_fnuz": [],
  "fp8_min": [],
  "deep_gemm_fp8_fp8_bf16_nt": [
    "A",
    "As",
    "B",
    "Bs",
    "C"
  ],
  "_per_token_group_quant_8bit": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "y_stride",
    "N",
    "eps",
    "bit8_min",
    "bit8_max",
    "BLOCK"
  ],
  "_per_token_group_quant_8bit_colmajor": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "group_size",
    "y_num_columns",
    "y_s_col_stride",
    "eps",
    "bit8_min",
    "bit8_max",
    "BLOCK",
    "SCALE_UE8M0"
  ],
  "_per_token_group_quant_8bit_raw": [
    "x",
    "group_size",
    "eps",
    "dtype",
    "column_major_scales",
    "scale_tma_aligned",
    "scale_ue8m0"
  ],
  "per_token_group_quant_fp8": [],
  "_per_token_group_quant_8bit_fuse_silu_and_mul": [
    "x",
    "group_size",
    "dst_dtype",
    "column_major_scales",
    "scale_tma_aligned",
    "scale_ue8m0",
    "masked_m"
  ],
  "per_token_group_quant_8bit": [
    "x",
    "group_size",
    "dst_dtype",
    "eps",
    "column_major_scales",
    "scale_tma_aligned",
    "scale_ue8m0",
    "fuse_silu_and_mul",
    "masked_m"
  ],
  "create_per_token_group_quant_fp8_output_scale": [
    "x_shape",
    "device",
    "group_size",
    "column_major_scales",
    "scale_tma_aligned",
    "scale_ue8m0"
  ],
  "sglang_per_token_group_quant_fp8": [
    "x",
    "group_size",
    "eps",
    "column_major_scales",
    "scale_tma_aligned",
    "scale_ue8m0",
    "fuse_silu_and_mul",
    "masked_m",
    "enable_v2"
  ],
  "sglang_per_token_group_quant_8bit": [
    "x",
    "group_size",
    "dst_dtype",
    "eps",
    "column_major_scales",
    "scale_tma_aligned",
    "scale_ue8m0",
    "fuse_silu_and_mul",
    "masked_m",
    "enable_v2"
  ],
  "sglang_per_token_quant_fp8": [
    "x",
    "dtype"
  ],
  "_static_quant_fp8": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "y_s_repeat_ptr",
    "y_stride",
    "N",
    "fp8_min",
    "fp8_max",
    "BLOCK",
    "REPEAT_SCALE"
  ],
  "static_quant_fp8": [
    "x",
    "x_s",
    "repeat_scale"
  ],
  "_w8a8_block_fp8_matmul": [
    "A",
    "B",
    "C",
    "As",
    "Bs",
    "M",
    "N",
    "K",
    "group_n",
    "group_k",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_As_m",
    "stride_As_k",
    "stride_Bs_k",
    "stride_Bs_n",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "needs_masking"
  ],
  "_w8a8_block_fp8_matmul_unrolledx4": [
    "A",
    "B",
    "C",
    "As",
    "Bs",
    "M",
    "N",
    "K",
    "group_n",
    "group_k",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_As_m",
    "stride_As_k",
    "stride_Bs_k",
    "stride_Bs_n",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M",
    "needs_masking"
  ],
  "get_w8a8_block_fp8_configs": [
    "N",
    "K",
    "block_n",
    "block_k"
  ],
  "select_w8a8_block_fp8_matmul_kernel": [
    "M",
    "N",
    "META"
  ],
  "prepare_block_fp8_matmul_inputs": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "w8a8_block_fp8_matmul_deepgemm": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "w8a8_block_fp8_matmul_triton": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "w8a8_block_fp8_matmul": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "_per_tensor_quant_mla_fp8_stage1": [
    "x_ptr",
    "x_s_ptr",
    "head_size",
    "x_stride_h",
    "x_stride_s",
    "eps",
    "fp8_max",
    "BLOCK_SIZE"
  ],
  "_per_tensor_quant_mla_fp8_stage2": [
    "x_ptr",
    "x_s_ptr",
    "x_q_ptr",
    "num_seq",
    "head_size",
    "x_stride_h",
    "x_stride_s",
    "fp8_min",
    "fp8_max",
    "BLOCK_SIZE"
  ],
  "per_tensor_quant_mla_fp8": [
    "x",
    "x_s_out",
    "eps"
  ],
  "_per_token_group_quant_mla_deep_gemm_masked_fp8": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "masked_m_ptr",
    "group_size",
    "y_stride_b",
    "y_stride_t",
    "y_q_stride_b",
    "y_q_stride_t",
    "y_s_stride_b",
    "y_s_stride_g",
    "eps",
    "fp8_min",
    "fp8_max",
    "NUM_GROUP",
    "BLOCK"
  ],
  "per_token_group_quant_mla_deep_gemm_masked_fp8": [
    "x",
    "group_size",
    "eps",
    "dtype"
  ],
  "fp8_autotune": [],
  "_per_token_group_quant_fp8_hopper_moe_mn_major": [
    "a",
    "expert_offsets",
    "problem_sizes",
    "a_fp8",
    "sfa",
    "K",
    "BLOCK_K",
    "M_ALIGNMENT",
    "BLOCK_M"
  ],
  "per_token_group_quant_fp8_hopper_moe_mn_major": [
    "A",
    "expert_offsets",
    "problem_sizes",
    "group_size",
    "expert_tokens_alignment"
  ],
  "_per_group_transpose": [
    "data_ptr",
    "trans_data_ptr",
    "expert_offsets",
    "k",
    "M_ALIGNMENT",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_K"
  ],
  "per_group_transpose": [
    "a",
    "expert_offsets",
    "M_ALIGNMENT"
  ],
  "scaled_mm_kernel": [
    "a_ptr",
    "b_ptr",
    "scale_a_ptr",
    "scale_b_ptr",
    "c_ptr",
    "bias_ptr",
    "M",
    "N",
    "K",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "ACCUMULATOR_DTYPE",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "BLOCK_SIZE_SCALE_A",
    "BLOCK_SIZE_SCALE_B"
  ],
  "triton_scaled_mm": [
    "input",
    "weight",
    "scale_a",
    "scale_b",
    "out_dtype",
    "bias",
    "block_size_m",
    "block_size_n",
    "block_size_k",
    "use_heuristic"
  ],
  "is_layer_skipped_awq": [
    "prefix",
    "modules_to_not_convert"
  ],
  "AWQConfig": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "zero_point",
      "modules_to_not_convert"
    ],
    "__repr__": [
      "self"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "AWQMarlinConfig": {
    "TYPE_MAP": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "zero_point",
      "lm_head_quantized",
      "modules_to_not_convert",
      "full_config"
    ],
    "__repr__": [
      "self"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "is_awq_marlin_compatible": [
      "cls",
      "quant_config"
    ]
  },
  "AWQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "AWQMarlinLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "AWQLinearAscendMethod": {
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "AWQMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "AWQMoEAscendMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "get_weight_perm": [
    "num_bits"
  ],
  "MoeWNA16Config": {
    "__init__": [
      "self",
      "linear_quant_method",
      "weight_bits",
      "group_size",
      "has_zp",
      "lm_head_quantized",
      "modules_to_not_convert",
      "full_config"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "is_moe_wna16_compatible": [
      "cls",
      "quant_config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "is_layer_skipped_quant": [
    "prefix",
    "modules_to_not_convert"
  ],
  "MoeWNA16Method": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "get_weight_loader": [
      "layer",
      "weight_loader"
    ]
  },
  "W8A8Int8Config": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "self"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "is_layer_skipped": [
      "self",
      "prefix",
      "fused_mapping"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "W8A8Int8LinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "W8A8Int8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "has_triton_kernels": [],
  "_is_shuffle_moe_mxfp4": [],
  "_swizzle_mxfp4": [
    "quant_tensor",
    "scale",
    "num_warps"
  ],
  "_dequant_mxfp4_fake": [
    "x",
    "scale",
    "float_dtype"
  ],
  "quant_dequant_mxfp4": [
    "x",
    "scale_calculation_mode"
  ],
  "Mxfp4Config": {
    "__init__": [
      "self",
      "ignored_layers",
      "is_checkpoint_mxfp4_serialized"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "is_static_cfg": [
      "self"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "Mxfp4MoEMethod": {
    "__init__": [
      "self",
      "prefix"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype",
      "with_bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "Mxfp4DynamicQuantMoEMethod": {
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "mxfp4_quantize": [
      "self",
      "w"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "GGUFConfig": {
    "__init__": [
      "self",
      "modules_to_not_convert"
    ],
    "__repr__": [
      "self"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "is_layer_skipped_gguf": [
    "prefix",
    "modules_to_not_convert"
  ],
  "UNQUANTIZED_TYPES": [],
  "STANDARD_QUANT_TYPES": [],
  "KQUANT_TYPES": [],
  "IMATRIX_QUANT_TYPES": [],
  "DEQUANT_TYPES": [],
  "MMVQ_QUANT_TYPES": [],
  "MMQ_QUANT_TYPES": [],
  "fused_mul_mat_gguf": [
    "x",
    "qweight",
    "qweight_type"
  ],
  "fused_moe_gguf": [
    "x",
    "w1",
    "w2",
    "topk_weights",
    "topk_ids",
    "qweight_type",
    "qweight_type2",
    "activation"
  ],
  "apply_gguf_embedding": [
    "x",
    "qweight",
    "qweight_type",
    "hidden_size",
    "dtype"
  ],
  "GGUFLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "_create_padded_weight_param": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GGUFMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "GGUFEmbeddingMethod": {
    "embedding": [
      "self",
      "layer",
      "x"
    ]
  },
  "GGUFUninitializedParameter": {
    "cls_to_become": []
  },
  "Fp4GemmRunnerBackend": {
    "AUTO": [],
    "FLASHINFER_CUDNN": [],
    "FLASHINFER_CUTLASS": [],
    "FLASHINFER_TRTLLM": [],
    "is_auto": [
      "self"
    ],
    "is_flashinfer_cudnn": [
      "self"
    ],
    "is_flashinfer_cutlass": [
      "self"
    ],
    "is_flashinfer_trtllm": [
      "self"
    ],
    "get_flashinfer_backend": [
      "self"
    ]
  },
  "initialize_fp4_gemm_config": [
    "server_args"
  ],
  "get_fp4_gemm_runner_backend": [],
  "get_scalar_types": [],
  "is_layer_skipped": [
    "prefix",
    "ignored_layers",
    "fused_mapping"
  ],
  "per_tensor_dequantize": [
    "tensor",
    "inv_scale"
  ],
  "all_close_1d": [
    "x"
  ],
  "convert_to_channelwise": [
    "weight_scale",
    "logical_widths"
  ],
  "requantize_with_max_scale": [
    "weight",
    "weight_scale",
    "logical_widths"
  ],
  "update_tensor_inplace": [
    "old",
    "new"
  ],
  "replace_parameter": [
    "mod",
    "name",
    "new"
  ],
  "assert_fp8_all_close": [
    "a",
    "b"
  ],
  "get_dynamic_override": [
    "config",
    "layer_name",
    "key",
    "default_value"
  ],
  "get_linear_quant_method": [
    "config",
    "layer",
    "prefix",
    "linear_method_cls"
  ],
  "get_pack_factor": [
    "num_bits"
  ],
  "permute_rows": [
    "q_w",
    "w_ref",
    "group_size",
    "test_perm"
  ],
  "pack_cols": [
    "q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "pack_rows": [
    "q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "unpack_cols": [
    "packed_q_w",
    "num_bits",
    "size_k",
    "size_n"
  ],
  "quantize_weights": [
    "w",
    "quant_type",
    "group_size",
    "zero_points",
    "ref_zero_points_after_scales"
  ],
  "SUPPORTED_GPTQ_QUANT_TYPES": [],
  "SUPPORTED_GROUP_SIZES": [],
  "gptq_quantize_weights": [
    "w",
    "quant_type",
    "group_size",
    "act_order",
    "test_perm"
  ],
  "sort_weights": [
    "q_w",
    "g_idx"
  ],
  "swizzle_blockscale": [
    "scale"
  ],
  "reorder_w1w3_to_w3w1": [
    "weight",
    "scale",
    "dim"
  ],
  "prepare_static_weights_for_trtllm_fp4_moe": [
    "gemm1_weights",
    "gemm2_weights",
    "gemm1_scales_linear_fp4_bytes",
    "gemm2_scales_linear_fp4_bytes",
    "hidden_size",
    "intermediate_size",
    "num_experts"
  ],
  "BitsAndBytesConfig": {
    "__init__": [
      "self",
      "load_in_8bit",
      "load_in_4bit",
      "bnb_4bit_compute_dtype",
      "bnb_4bit_quant_storage",
      "bnb_4bit_quant_type",
      "bnb_4bit_use_double_quant",
      "llm_int8_enable_fp32_cpu_offload",
      "llm_int8_has_fp16_weight",
      "llm_int8_skip_modules",
      "llm_int8_threshold"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "is_layer_skipped_bnb": [
    "prefix",
    "llm_int8_skip_modules"
  ],
  "calculate_quant_ratio": [
    "dtype"
  ],
  "BitsAndBytesLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_apply_8bit_weight": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "_apply_4bit_weight": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "_apply_bnb_4bit": [
    "x",
    "weight",
    "offsets",
    "out"
  ],
  "_apply_bnb_4bit_fake": [
    "x",
    "weight",
    "offsets",
    "out"
  ],
  "BitsAndBytesMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "_create_weights_4bit": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_create_weights_8bit": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_apply_4bit_dequant": [
      "self",
      "layer"
    ],
    "_apply_8bit_dequant": [
      "self",
      "layer"
    ]
  },
  "_check_petit_nvfp4_supported": [
    "quant_method",
    "group_size"
  ],
  "verify_petit_nvfp4_supported": [
    "quant_method",
    "group_size"
  ],
  "prepare_nvfp4_layer_for_petit": [
    "layer"
  ],
  "apply_petit_nvfp4_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_scale_2",
    "size_n",
    "size_k",
    "bias"
  ],
  "QoQ_SUPPORTED_WEIGHT_BITS": [],
  "QoQ_SUPPORTED_GROUP_SIZES": [],
  "QoQConfig": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size"
    ],
    "__repr__": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "QoQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "E2M1_MAX": [],
  "_device": [],
  "E2M1_VALUES": [],
  "E2M1_BOUNDS": [],
  "KVFP4QuantizeUtil": {
    "batched_quantize": [
      "tensor"
    ],
    "batched_dequantize": [
      "quant_tensor",
      "scale_factors",
      "dtype"
    ]
  },
  "DummyConfig": {
    "override_quantization_method": [
      "self"
    ]
  },
  "CompressedTensorsConfig": [],
  "_is_mxfp_supported": [],
  "QUANTIZATION_METHODS": [],
  "original_isinstance": [],
  "MXFP4QuantizeUtil": {
    "E2M1_max": [],
    "E2M1_values": [],
    "E2M1_bounds": [],
    "quantize": [
      "cls",
      "input",
      "block_size"
    ],
    "dequantize": [
      "cls",
      "quantized_data",
      "dtype",
      "scale",
      "block_sizes"
    ]
  },
  "GPTQ_MARLIN_TILE": [],
  "GPTQ_MARLIN_MIN_THREAD_N": [],
  "GPTQ_MARLIN_MIN_THREAD_K": [],
  "GPTQ_MARLIN_MAX_PARALLEL": [],
  "MARLIN_SUPPORTED_GROUP_SIZES": [],
  "USE_FP32_REDUCE_DEFAULT": [],
  "MarlinLinearLayerConfig": {},
  "query_marlin_supported_quant_types": [
    "has_zp",
    "include_fp_type",
    "device_capability"
  ],
  "_check_marlin_supported": [
    "quant_type",
    "group_size",
    "has_zp",
    "device_capability"
  ],
  "check_marlin_supported": [
    "quant_type",
    "group_size",
    "has_zp",
    "device_capability"
  ],
  "verify_marlin_supported": [
    "quant_type",
    "group_size",
    "has_zp"
  ],
  "verify_marlin_supports_shape": [
    "output_size_per_partition",
    "input_size_per_partition",
    "input_size",
    "group_size"
  ],
  "check_marlin_supports_shape": [
    "output_size_per_partition",
    "input_size_per_partition",
    "input_size",
    "group_size"
  ],
  "check_marlin_supports_layer": [
    "layer",
    "group_size"
  ],
  "check_moe_marlin_supports_layer": [
    "layer",
    "group_size"
  ],
  "marlin_make_workspace": [
    "device",
    "max_blocks_per_sm"
  ],
  "marlin_is_k_full": [
    "act_order",
    "is_row_parallel"
  ],
  "marlin_repeat_scales_on_all_ranks": [
    "act_order",
    "group_size",
    "is_row_parallel"
  ],
  "marlin_make_empty_g_idx": [
    "device"
  ],
  "marlin_make_empty_zp": [
    "device"
  ],
  "marlin_sort_g_idx": [
    "g_idx"
  ],
  "get_scale_perms": [],
  "marlin_permute_scales": [
    "s",
    "size_k",
    "size_n",
    "group_size"
  ],
  "marlin_permute_bias": [
    "s"
  ],
  "marlin_moe_permute_scales": [
    "s",
    "size_k",
    "size_n",
    "group_size"
  ],
  "marlin_zero_points": [
    "zp",
    "size_k",
    "size_n",
    "num_bits"
  ],
  "awq_to_marlin_zero_points": [
    "q_zp_packed",
    "size_k",
    "size_n",
    "num_bits"
  ],
  "moe_awq_to_marlin_zero_points": [
    "q_zp_packed",
    "size_k",
    "size_n",
    "num_bits"
  ],
  "maybe_warn_marlin_atomic_add": [
    "device",
    "dtype"
  ],
  "maybe_warn_marlin_atomic_add_env": [],
  "should_use_atomic_add_reduce": [
    "m",
    "n",
    "k",
    "device",
    "dtype"
  ],
  "apply_gptq_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "wtype",
    "output_size_per_partition",
    "input_size_per_partition",
    "is_k_full",
    "bias",
    "use_fp32_reduce"
  ],
  "apply_awq_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "quant_type",
    "output_size_per_partition",
    "input_size_per_partition",
    "bias",
    "use_fp32_reduce"
  ],
  "MarlinConfig": {
    "__init__": [
      "self",
      "group_size",
      "lm_head_quantized"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "MarlinLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "fake_unified_apply_gptq_marlin_gemm": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "output_size_per_partition",
    "input_size_per_partition",
    "use_atomic_add",
    "use_fp32_reduce",
    "is_zp_float"
  ],
  "unified_apply_gptq_marlin_gemm": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "output_size_per_partition",
    "input_size_per_partition",
    "use_atomic_add",
    "use_fp32_reduce",
    "is_zp_float"
  ],
  "fake_unified_apply_gptq_marlin_gemm_with_wtype": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "wtype_id",
    "output_size_per_partition",
    "input_size_per_partition",
    "is_k_full",
    "use_atomic_add",
    "use_fp32_reduce",
    "is_zp_float"
  ],
  "unified_apply_gptq_marlin_gemm_with_wtype": [
    "input",
    "weight",
    "weight_scale",
    "weight_zp",
    "g_idx",
    "g_idx_sort_indices",
    "workspace",
    "wtype_id",
    "output_size_per_partition",
    "input_size_per_partition",
    "is_k_full",
    "use_atomic_add",
    "use_fp32_reduce",
    "is_zp_float"
  ],
  "tqdm_reset_no_print": [
    "tqdm_bar",
    "total"
  ],
  "QuarkInt4Fp8Config": {
    "__init__": [
      "self",
      "is_checkpoint_fp8_serialized",
      "activation_scheme"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "self"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "QuarkInt4Fp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "get_weight_loader": [
      "self",
      "layer",
      "original_weight_loader"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "PetitNvFp4Config": {
    "__init__": [
      "self",
      "is_checkpoint_nvfp4_serialized",
      "kv_cache_quant_algo",
      "group_size",
      "exclude_modules"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "is_petit_nvfp4_compatible": [
      "cls",
      "quant_config"
    ],
    "is_layer_excluded": [
      "self",
      "prefix",
      "exclude_modules"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "PetitNvFp4LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuantizeMethodBase": {
    "create_weights": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "LinearMethodBase": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "FusedMoEMethodBase": {
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "QuantizationConfig": {
    "__init__": [
      "self"
    ],
    "get_name": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "_modelopt_override_quantization_method": [
      "cls",
      "hf_quant_config",
      "user_quant"
    ],
    "get_from_keys": [
      "config",
      "keys"
    ],
    "get_from_keys_or": [
      "config",
      "keys",
      "default"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "apply_weight_name_mapper": [
      "self",
      "hf_to_sglang_mapper"
    ]
  },
  "method_has_implemented_embedding": [
    "method_class"
  ],
  "AWQ_TRITON_SUPPORTED_GROUP_SIZES": [],
  "awq_dequantize_kernel": [
    "qweight_ptr",
    "scales_ptr",
    "zeros_ptr",
    "group_size",
    "result_ptr",
    "num_cols",
    "num_rows",
    "BLOCK_SIZE_X",
    "BLOCK_SIZE_Y"
  ],
  "awq_gemm_kernel": [
    "a_ptr",
    "b_ptr",
    "c_ptr",
    "zeros_ptr",
    "scales_ptr",
    "M",
    "N",
    "K",
    "group_size",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "SPLIT_K"
  ],
  "awq_dequantize_triton": [
    "qweight",
    "scales",
    "zeros",
    "block_size_x",
    "block_size_y"
  ],
  "awq_gemm_triton": [
    "input",
    "qweight",
    "scales",
    "qzeros",
    "split_k_iters",
    "block_size_m",
    "block_size_n",
    "block_size_k"
  ],
  "awq_dequantize_decomposition": [
    "qweight",
    "scales",
    "zeros"
  ],
  "FBGEMMFp8Config": {
    "__init__": [
      "self",
      "ignore_list",
      "input_scale_ub"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "FBGEMMFp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "fp8_fused_exponent_bias_into_scales": [
    "scales"
  ],
  "apply_fp8_marlin_linear": [
    "input",
    "weight",
    "weight_scale",
    "workspace",
    "size_n",
    "size_k",
    "bias",
    "use_fp32_reduce"
  ],
  "prepare_fp8_layer_for_marlin": [
    "layer",
    "size_k_first"
  ],
  "prepare_moe_fp8_layer_for_marlin": [
    "layer",
    "size_k_first"
  ],
  "pack_fp8_to_int32": [
    "fp8_tensor",
    "size_k_first"
  ],
  "marlin_quant_fp8_torch": [
    "weight",
    "group_size"
  ],
  "W4AFp8Config": {
    "__init__": [
      "self",
      "is_checkpoint_fp8_serialized",
      "is_checkpoint_w4afp8_serialized",
      "linear_activation_scheme",
      "moe_activation_scheme",
      "ignored_layers",
      "weight_block_size",
      "group_size"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "interleave_scales": [
    "scales"
  ],
  "W4AFp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_deepep_ll": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_deepep_normal": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "UnquantizedEmbeddingMethod": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "embedding": [
      "self",
      "layer",
      "input_"
    ]
  },
  "UnquantizedLinearMethod": {
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "UnquantizedFusedMoEMethod": {
    "__init__": [
      "self",
      "use_triton_kernels",
      "use_flashinfer_trtllm_moe"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype",
      "with_bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "load_up_proj_weight_first": [
      "self"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "forward_cuda": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "forward_cpu": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "forward_npu": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "forward_tpu": [
      "self"
    ],
    "forward_native": []
  },
  "check_marlin_format": [
    "hf_quant_cfg"
  ],
  "gptq_marlin_moe_repack": [
    "b_q_weight",
    "perm",
    "size_k",
    "size_n",
    "num_bits"
  ],
  "GPTQConfig": {
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "desc_act",
      "lm_head_quantized",
      "dynamic"
    ],
    "__repr__": [
      "self"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "GPTQMarlinConfig": {
    "TYPE_MAP": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "desc_act",
      "is_sym",
      "lm_head_quantized",
      "dynamic",
      "full_config"
    ],
    "__repr__": [
      "self"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_cfg",
      "user_quant"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "is_gptq_marlin_compatible": [
      "cls",
      "quant_config"
    ]
  },
  "GPTQLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GPTQMarlinLinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "GPTQMarlinMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "apply_w8a8_block_int8_linear": [
    "input",
    "weight",
    "block_size",
    "weight_scale",
    "input_scale",
    "bias"
  ],
  "input_to_int8": [
    "x",
    "dtype"
  ],
  "block_dequant": [
    "x_q_block",
    "x_s",
    "block_size"
  ],
  "_per_token_quant_int8": [
    "x_ptr",
    "xq_ptr",
    "scale_ptr",
    "x_sum_ptr",
    "stride_x",
    "stride_xq",
    "N",
    "CAL_SUM",
    "BLOCK"
  ],
  "per_token_quant_int8": [
    "x",
    "scale_dtype",
    "cal_sum"
  ],
  "_per_token_group_quant_int8": [
    "y_ptr",
    "y_q_ptr",
    "y_s_ptr",
    "y_stride",
    "N",
    "eps",
    "int8_min",
    "int8_max",
    "BLOCK"
  ],
  "per_token_group_quant_int8": [
    "x",
    "group_size",
    "eps",
    "dtype"
  ],
  "sglang_per_token_group_quant_int8": [
    "x",
    "group_size",
    "eps",
    "dtype",
    "enable_v2"
  ],
  "_w8a8_block_int8_matmul": [
    "A",
    "B",
    "C",
    "As",
    "Bs",
    "M",
    "N",
    "K",
    "group_n",
    "group_k",
    "stride_am",
    "stride_ak",
    "stride_bk",
    "stride_bn",
    "stride_cm",
    "stride_cn",
    "stride_As_m",
    "stride_As_k",
    "stride_Bs_k",
    "stride_Bs_n",
    "BLOCK_SIZE_M",
    "BLOCK_SIZE_N",
    "BLOCK_SIZE_K",
    "GROUP_SIZE_M"
  ],
  "get_w8a8_block_int8_configs": [
    "N",
    "K",
    "block_n",
    "block_k"
  ],
  "w8a8_block_int8_matmul": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "_sglang_fp4_gemm_fake": [
    "input",
    "weight",
    "input_sf",
    "weight_sf",
    "alpha",
    "out_dtype",
    "out_features"
  ],
  "fp4_gemm": [
    "input",
    "weight",
    "input_sf",
    "weight_sf",
    "alpha",
    "out_dtype",
    "out_features"
  ],
  "CUTEDSL_MOE_SCALAR_INPUT_SCALE": [],
  "MOE_NVFP4_DISPATCH": [],
  "ACT_STR_TO_TYPE_MAP": [],
  "ModelOptQuantConfig": {
    "__init__": [
      "self",
      "kv_cache_quant_algo",
      "exclude_modules",
      "packed_modules_mapping"
    ],
    "_get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "ModelOptFp8Config": {
    "__init__": [
      "self",
      "is_checkpoint_fp8_serialized",
      "kv_cache_quant_method",
      "exclude_modules",
      "packed_modules_mapping"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_config",
      "user_quant"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "is_layer_excluded": [
      "self",
      "prefix"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "ModelOptFp8LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelOptFp8KVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ]
  },
  "ModelOptFp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "ModelOptFp4Config": {
    "__init__": [
      "self",
      "is_checkpoint_nvfp4_serialized",
      "kv_cache_quant_algo",
      "group_size",
      "exclude_modules",
      "packed_modules_mapping"
    ],
    "override_quantization_method": [
      "cls",
      "hf_quant_config",
      "user_quant"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "common_group_size": [
      "cfg"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "is_layer_excluded": [
      "self",
      "prefix"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "ModelOptFp4LinearMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelOptNvFp4FusedMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "enable_flashinfer_cutlass_moe": [
      "self"
    ],
    "enable_flashinfer_cutedsl_moe": [
      "self"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "load_up_proj_weight_first": [
      "self"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "x",
      "masked_m",
      "moe_runner_config"
    ]
  },
  "AutoRoundConfig": {
    "SUPPORTED_BITS": [],
    "SUPPORTED_DTYPES": [],
    "SUPPORTED_FORMATS": [],
    "SUPPORTED_BACKENDS": [],
    "__init__": [
      "self",
      "weight_bits",
      "group_size",
      "sym",
      "packing_format",
      "block_name_to_quantize",
      "extra_config",
      "data_type",
      "backend"
    ],
    "__repr__": [
      "self"
    ],
    "get_name": [
      "cls"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_scaled_act_names": [
      "self"
    ],
    "get_layer_config": [
      "self",
      "layer",
      "layer_name"
    ],
    "check_quantized": [
      "self",
      "weight_bits"
    ],
    "apply_awq_quant_layer": [
      "self",
      "layer",
      "prefix",
      "backend"
    ],
    "apply_gptq_quant_layer": [
      "self",
      "layer",
      "prefix",
      "backend"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ]
  },
  "OCP_MX_BLOCK_SIZE": [],
  "QuarkMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "get_moe_method": [
      "quant_config",
      "module",
      "layer_name"
    ]
  },
  "QuarkW4A4MXFp4MoEMethod": {
    "__init__": [
      "self",
      "weight_config",
      "input_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "QuarkW8A8FP8MoEMethod": {
    "__init__": [
      "self",
      "weight_config",
      "input_config"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "QuarkConfig": {
    "__init__": [
      "self",
      "quant_config",
      "kv_cache_group",
      "kv_cache_config",
      "pack_method"
    ],
    "get_linear_method": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "self"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "_check_scheme_supported": [
      "self",
      "min_capability",
      "error"
    ],
    "_is_fp8_w8a8": [
      "self",
      "weight_quant",
      "input_quant"
    ],
    "_is_mx_fp4": [
      "self",
      "weight_quant",
      "input_quant"
    ],
    "_find_matched_config": [
      "self",
      "layer_name",
      "module"
    ],
    "_get_scheme_from_config": [
      "self",
      "config"
    ],
    "get_scheme": [
      "self",
      "layer",
      "layer_name"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "QuarkLinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuarkKVCacheMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "validate_kv_cache_config": [
      "kv_cache_config"
    ]
  },
  "deep_compare": [
    "dict1",
    "dict2"
  ],
  "should_ignore_layer": [
    "layer_name",
    "ignore",
    "fused_mapping"
  ],
  "check_equal_or_regex_match": [
    "layer_name",
    "targets"
  ],
  "_is_equal_or_regex_match": [
    "value",
    "target",
    "check_contains"
  ],
  "b_dynamic_mxfp4_quant": [
    "x"
  ],
  "mxfp4_to_f32": [
    "x",
    "is_threed"
  ],
  "e8m0_to_f32": [
    "x"
  ],
  "quark_post_load_weights": [
    "self_attn",
    "w",
    "quant_format"
  ],
  "QuarkW4A4MXFP4": {
    "__init__": [
      "self",
      "weight_quant_spec",
      "input_quant_spec"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QuarkScheme": {
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "QuarkW8A8Fp8": {
    "__init__": [
      "self",
      "weight_config",
      "input_config"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "QUANTIZATION_SCHEME_MAP_TYPE": [],
  "DeviceCapability": {
    "as_version_str": [
      "self"
    ],
    "to_int": [
      "self"
    ]
  },
  "CompressedTensorsLinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "is_activation_quantization_format": [
    "format"
  ],
  "find_matched_target": [
    "layer_name",
    "module",
    "targets",
    "fused_mapping"
  ],
  "_find_first_match": [
    "value",
    "targets",
    "check_contains"
  ],
  "_match_fused_layer": [
    "layer_name",
    "target_layers",
    "fused_mapping"
  ],
  "GPTQMarlinState": {
    "REPACK": [],
    "READY": []
  },
  "CompressedTensorsMoEMethod": {
    "__new__": [
      "cls"
    ],
    "get_moe_method": [
      "quant_config",
      "layer",
      "prefix"
    ]
  },
  "CompressedTensorsW4A4Nvfp4MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_with_router_logits": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "CompressedTensorsW8A8Fp8MoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "NPUCompressedTensorsW8A8Int8DynamicMoEMethod": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "CompressedTensorsWNA16MoEMethod": {
    "__init__": [
      "self",
      "quant_config",
      "num_gpu_experts"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "restore_weights_before_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ]
  },
  "NPUCompressedTensorsW4A8Int8DynamicMoEMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "_init_activation_clip_params": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "extra_weight_attrs"
    ],
    "_init_extra_scale_params": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "extra_weight_attrs"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "NPUCompressedTensorsW4A16Int4DynamicMoEMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "CompressedTensorsW4A4Fp4": {
    "__init__": [
      "self"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "strategy_to_parameter_type": [],
  "CompressedTensorsW8A8Fp8": {
    "__init__": [
      "self",
      "weight_quant",
      "is_static_input_scheme"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "WNA16_SUPPORTED_TYPES_MAP": [],
  "WNA16_ZP_SUPPORTED_TYPES_MAP": [],
  "WNA16_SUPPORTED_BITS": [],
  "CompressedTensorsWNA16": {
    "__init__": [
      "self",
      "strategy",
      "num_bits",
      "group_size",
      "symmetric",
      "actorder"
    ],
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_size",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsW8A8Int8": {
    "__init__": [
      "self",
      "strategy",
      "is_static_input_scheme",
      "input_symmetric"
    ],
    "create_weights": [
      "self",
      "layer",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "NPUCompressedTensorsW8A8Int8": {
    "__init__": [
      "self",
      "strategy",
      "is_static_input_scheme",
      "input_symmetric"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "SUPPORTED_STRATEGIES": [],
  "CompressedTensorsW8A16Fp8": {
    "__init__": [
      "self",
      "strategy",
      "is_static_input_scheme"
    ],
    "get_min_capability": [
      "cls"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size",
      "output_partition_sizes",
      "input_size_per_partition",
      "params_dtype",
      "weight_loader"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "CompressedTensorsScheme": {
    "get_min_capability": [
      "cls"
    ],
    "create_weights": [
      "self"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "npu_wrapper_rmsnorm_init": [
    "func"
  ],
  "npu_wrapper_rmsnorm_forward": [
    "func"
  ],
  "ModelSlimConfig": {
    "__init__": [
      "self",
      "quant_config"
    ],
    "get_linear_method": [
      "self"
    ],
    "get_supported_act_dtypes": [
      "cls"
    ],
    "get_min_capability": [
      "cls"
    ],
    "get_name": [
      "cls"
    ],
    "get_config_filenames": [
      "cls"
    ],
    "from_config": [
      "cls",
      "config"
    ],
    "get_quant_method": [
      "self",
      "layer",
      "prefix"
    ],
    "_get_scheme_from_parts": [
      "self",
      "layer_name"
    ],
    "get_scheme": [
      "self",
      "layer",
      "layer_name"
    ],
    "is_layer_skipped": [
      "self",
      "prefix",
      "fused_mapping"
    ],
    "get_scaled_act_names": [
      "self"
    ]
  },
  "ModelSlimLinearMethod": {
    "__init__": [
      "self",
      "quantization_config"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "apply": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelSlimMoEMethod": {
    "__new__": [
      "cls"
    ],
    "get_moe_method": [
      "quant_config",
      "layer",
      "prefix"
    ]
  },
  "ModelSlimW4A8Int8MoE": {
    "__init__": [
      "self",
      "quant_config",
      "prefix"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "ModelSlimW8A8Int8MoE": {
    "__init__": [
      "self",
      "quant_config",
      "prefix"
    ],
    "create_weights": [
      "self",
      "layer",
      "num_experts",
      "hidden_size",
      "intermediate_size_per_partition",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "create_moe_runner": [
      "self",
      "layer",
      "moe_runner_config"
    ],
    "apply": [
      "self",
      "layer",
      "dispatch_output"
    ],
    "apply_without_routing_weights": [
      "self",
      "layer",
      "hidden_states",
      "hidden_states_scale",
      "group_list_type",
      "group_list",
      "output_dtype"
    ]
  },
  "ModelSlimW8A8Int8": {
    "__init__": [
      "self",
      "quant_config",
      "prefix"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ModelSlimScheme": {
    "create_weights": [
      "self"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ]
  },
  "ModelSlimW4A4Int4": {
    "__init__": [
      "self",
      "quant_config",
      "prefix"
    ],
    "get_weight": [
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "get_perchannel_param": [
      "output_size",
      "params_dtype"
    ],
    "create_weights": [
      "self",
      "layer",
      "input_size_per_partition",
      "output_partition_sizes",
      "input_size",
      "output_size",
      "params_dtype"
    ],
    "process_weights_after_loading": [
      "self",
      "layer"
    ],
    "apply_weights": [
      "self",
      "layer",
      "x",
      "bias"
    ]
  },
  "ViTCudaGraphRunner": {
    "__init__": [
      "self",
      "vit"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "_ensure_sin_cos_ws": [
      "self",
      "seq_len",
      "head_dim"
    ],
    "_get_graph_key": [
      "self",
      "x_3d"
    ],
    "_create_graph": [
      "self",
      "graph_key",
      "position_embeddings",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin"
    ],
    "create_graph": [
      "self",
      "x_3d",
      "cu_seqlens",
      "cu_window_seqlens",
      "position_embeddings",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin"
    ],
    "replay": [
      "self",
      "graph_key",
      "x_3d",
      "position_embeddings",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "output_indices"
    ],
    "run": [
      "self",
      "x",
      "cu_seqlens",
      "cu_window_seqlens",
      "position_embeddings",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "output_indices"
    ]
  },
  "has_valid_data": [
    "data"
  ],
  "select_best_resolution": [
    "original_size",
    "possible_resolutions"
  ],
  "resize_and_pad_image": [
    "image",
    "target_resolution"
  ],
  "divide_to_patches": [
    "image",
    "patch_size"
  ],
  "get_anyres_image_grid_shape": [
    "image_size",
    "grid_pinpoints",
    "patch_size"
  ],
  "process_anyres_image": [
    "image",
    "processor",
    "grid_pinpoints"
  ],
  "load_image_from_base64": [
    "image"
  ],
  "expand2square": [
    "pil_img",
    "background_color"
  ],
  "unpad_image": [
    "tensor",
    "original_size"
  ],
  "unpad_image_shape": [
    "current_height",
    "current_width",
    "original_size"
  ],
  "process_images": [
    "images",
    "image_processor",
    "model_cfg"
  ],
  "get_dp_encoder_lb_assignment": [
    "sizes",
    "num_gpus"
  ],
  "run_dp_sharded_vision_model": [
    "image_input",
    "vision_model"
  ],
  "run_dp_sharded_mrope_vision_model": [
    "vision_model",
    "pixel_values",
    "grid_thw_list"
  ],
  "InternViTCudaGraphRunner": {
    "__init__": [
      "self",
      "encoder"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "_graph_key": [
      "self",
      "x"
    ],
    "_build_cu": [
      "self",
      "B",
      "S",
      "device"
    ],
    "_alloc_ws": [
      "self",
      "B",
      "S",
      "H",
      "device",
      "dtype"
    ],
    "_warmup_once": [
      "self",
      "key"
    ],
    "_capture_graph": [
      "self",
      "key"
    ],
    "create_graph": [
      "self",
      "x"
    ],
    "run": [
      "self",
      "x"
    ]
  },
  "register_customized_processor": [
    "processor_class"
  ],
  "IMAGENET_MEAN": [],
  "IMAGENET_STD": [],
  "build_transform": [
    "input_size"
  ],
  "find_closest_aspect_ratio": [
    "aspect_ratio",
    "target_ratios",
    "width",
    "height",
    "image_size"
  ],
  "dynamic_preprocess": [
    "image"
  ],
  "image_to_pixel_values": [
    "image"
  ],
  "DeepseekVL2ImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj",
      "max_req_input_len"
    ]
  },
  "Glm4vImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "Sarashina2VisionProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "InternVLProcessor": {
    "models": [],
    "IMAGENET_MEAN": [],
    "IMAGENET_STD": [],
    "IMAGE_MAX_NUM": [],
    "DEFAULT_VIDEO_NUM_FRAMES": [],
    "VIDEO_MAX_NUM": [],
    "VIDEO_USE_THUMBNAIL": [],
    "CONTEXT_FALLBACK": [],
    "CONTEXT_RESERVED": [],
    "IMAGE_PLACEHOLDER_TOKEN": [],
    "VIDEO_PLACEHOLDER_TOKEN": [],
    "IMG_START": [],
    "IMG_END": [],
    "IMG_CONTEXT": [],
    "_get_normalize_tensors": [
      "device",
      "dtype"
    ],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_image_processor"
    ],
    "dynamic_preprocess": [
      "tensor",
      "image_size",
      "max_num",
      "use_thumbnail"
    ],
    "_open_video_reader": [
      "path"
    ],
    "_ensure_placeholders_before_assistant": [
      "self",
      "prompt",
      "placeholder",
      "want"
    ],
    "_token_len": [
      "self",
      "text"
    ],
    "_resolve_video_num_frames": [
      "self"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ],
    "process_qwen_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ],
    "process_internlm2_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "GlmAsrProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "audio_data",
      "input_text"
    ]
  },
  "Qwen2AudioMultimodalProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "audio_data",
      "input_text"
    ]
  },
  "IMAGE_FACTOR": [],
  "MIN_PIXELS": [],
  "MAX_PIXELS": [],
  "MAX_RATIO": [],
  "RESIZE_RESAMPLE": [],
  "VIDEO_TOTAL_PIXELS": [],
  "VIDEO_MIN_PIXELS": [],
  "VIDEO_MAX_PIXELS": [],
  "FRAME_FACTOR": [],
  "FPS": [],
  "FPS_MIN_FRAMES": [],
  "FPS_MAX_FRAMES": [],
  "smart_resize": [
    "height",
    "width",
    "factor",
    "min_pixels",
    "max_pixels"
  ],
  "round_by_factor": [
    "number",
    "factor"
  ],
  "ceil_by_factor": [
    "number",
    "factor"
  ],
  "floor_by_factor": [
    "number",
    "factor"
  ],
  "smart_nframes": [
    "ele",
    "total_frames",
    "video_fps"
  ],
  "preprocess_video": [
    "vr",
    "image_factor",
    "video_config"
  ],
  "QwenVLImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "get_mm_data": [
      "self",
      "prompt",
      "embeddings",
      "img_grid_thw"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "Mllama4ImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text"
    ]
  },
  "PixtralProcessor": {
    "models": [],
    "PAD_TOKEN": [],
    "IMG_BREAK_TOKEN_ID": [],
    "IMG_END_TOKEN_ID": [],
    "get_patch_grid_size": [
      "self"
    ],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "_resize": [
      "self",
      "image"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "JanusProImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "DotsVLMImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj",
      "max_req_input_len"
    ]
  },
  "NUM_VIDEO_FRAMES": [],
  "NVILAMultimodalProcessor": {
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "audio_data",
      "input_text",
      "request_obj"
    ]
  },
  "MiDashengLMMultimodalProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data": [
      "self",
      "input_text",
      "images",
      "videos",
      "audios"
    ],
    "process_mm_data_async": [
      "self",
      "audio_data",
      "input_text"
    ]
  },
  "Gemma3nSGLangProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "audio_data",
      "input_text",
      "request_obj"
    ]
  },
  "Gemma3SGLangImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "ClipImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text"
    ]
  },
  "PaddleOCRVLImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ]
  },
  "DeepseekOCRProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text"
    ]
  },
  "MiniCPMMultimodalProcessor": {
    "models": [],
    "support_dynamic_frame_expansion": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "audio_data",
      "input_text",
      "request_obj"
    ]
  },
  "POINTSV15ChatProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "DEFAULT_NUM_TILES": [],
  "NUM_VIDEO_TILES": [],
  "DESIRED_FPS": [],
  "MAX_FRAMES": [],
  "NanoNemotronVLImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_image_processor"
    ],
    "preprocess_image": [
      "self",
      "image"
    ],
    "render_image": [
      "self"
    ],
    "render_frame": [
      "self",
      "frame_index"
    ],
    "parse_video": [
      "video"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "LlavaImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "_process_single_image_task": [
      "image_data",
      "image_aspect_ratio",
      "image_grid_pinpoints",
      "processor"
    ],
    "_process_single_image": [
      "self",
      "image_data",
      "aspect_ratio",
      "grid_pinpoints"
    ],
    "_process_precomputed_image_data": [
      "self",
      "image_data"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "LlavaMultimodalProcessor": {
    "models": [],
    "_get_sgl_processor_cls": [
      "self",
      "model_type"
    ],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self"
    ]
  },
  "SGL_USE_CUDA_IPC": [],
  "BaseMultiModalProcessorOutput": {
    "organize_results": [
      "self"
    ]
  },
  "MultimodalSpecialTokens": {
    "build": [
      "self",
      "processor"
    ],
    "convert_to_str": [
      "self",
      "token",
      "processor"
    ],
    "convert_to_strs": [
      "self",
      "processor"
    ],
    "get_modality_of_token": [
      "self",
      "token"
    ],
    "get_token_id_by_modality": [
      "self",
      "modality"
    ],
    "parse_regex": [
      "self"
    ],
    "get_combined_regex": [
      "self"
    ]
  },
  "BaseMultimodalProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor",
      "transport_mode"
    ],
    "spatial_merge_size": [
      "self"
    ],
    "build_input_ids": [
      "self",
      "prompt",
      "img_grid_thw"
    ],
    "get_mm_data": [
      "self",
      "prompt",
      "embeddings",
      "img_grid_thw"
    ],
    "process_mm_data": [
      "self",
      "input_text",
      "images",
      "videos",
      "audios"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "audio_data",
      "input_text",
      "request_obj"
    ],
    "get_estimated_frames_list": [
      "self",
      "image_data"
    ],
    "_load_single_item": [
      "data",
      "modality",
      "frame_count_limit",
      "audio_sample_rate",
      "discard_alpha_channel"
    ],
    "_submit_mm_data_loading_tasks_simple": [
      "self",
      "data_list",
      "modality",
      "audio_sample_rate",
      "discard_alpha_channel"
    ],
    "submit_data_loading_tasks": [
      "self",
      "text_parts",
      "multimodal_tokens",
      "data_iterators",
      "discard_alpha_channel",
      "image_estimated_frames_iter",
      "image_scaling_factor",
      "max_image_frames",
      "audio_sample_rate"
    ],
    "_validate_one_modality": [
      "modality",
      "data_list"
    ],
    "validate_mm_data": [
      "image_data",
      "video_data",
      "audio_data"
    ],
    "_process_loaded_mm_data": [
      "self",
      "modality",
      "raw_data",
      "result"
    ],
    "load_mm_data": [
      "self",
      "prompt",
      "multimodal_tokens",
      "image_data",
      "video_data",
      "audio_data",
      "return_text",
      "discard_alpha_channel",
      "audio_sample_rate"
    ],
    "fast_load_mm_data": [
      "self",
      "prompt",
      "multimodal_tokens",
      "image_data",
      "video_data",
      "audio_data",
      "return_text",
      "discard_alpha_channel",
      "audio_sample_rate"
    ],
    "legacy_load_mm_data": [
      "self",
      "prompt",
      "multimodal_tokens",
      "image_data",
      "video_data",
      "audio_data",
      "return_text",
      "discard_alpha_channel",
      "audio_sample_rate"
    ],
    "get_mm_items_offset": [
      "input_ids",
      "mm_token_id"
    ],
    "get_mm_items_offset_by_pair": [
      "input_ids",
      "mm_start_id",
      "mm_end_id"
    ],
    "collect_mm_items_from_processor_output": [
      "self",
      "data_dict",
      "modality"
    ],
    "_process_and_collect_mm_items": [
      "self",
      "input_text",
      "images",
      "audios",
      "videos"
    ],
    "process_and_combine_mm_data": [
      "self",
      "base_output",
      "mm_tokens"
    ]
  },
  "KimiVLImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "MllamaImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text"
    ]
  },
  "ImageWithPatches": [],
  "GPUToTensor": {
    "forward": [
      "self",
      "raw_image"
    ]
  },
  "Step3VisionProcessor": {
    "__init__": [
      "self",
      "size",
      "interpolation_mode",
      "patch_size"
    ],
    "__call__": [
      "self",
      "image",
      "is_patch"
    ]
  },
  "ImagePatcher": {
    "determine_window_size": [
      "self",
      "long",
      "short"
    ],
    "slide_window": [
      "self",
      "width",
      "height",
      "sizes",
      "steps",
      "img_rate_thr"
    ],
    "square_pad": [
      "self",
      "img"
    ],
    "get_image_size_for_padding": [
      "self",
      "img_width",
      "img_height"
    ],
    "get_image_size_for_preprocess": [
      "self",
      "img_width",
      "img_height"
    ],
    "get_image_size_for_crop": [
      "self",
      "img_width",
      "img_height",
      "window_size"
    ],
    "patch_crop": [
      "self",
      "img",
      "i",
      "j",
      "th",
      "tw"
    ],
    "get_num_patches": [
      "self",
      "img_width",
      "img_height"
    ],
    "__call__": [
      "self",
      "img"
    ]
  },
  "Step3VLProcessor": {
    "__init__": [
      "self",
      "config",
      "tokenizer"
    ],
    "image_token_id": [
      "self"
    ],
    "get_num_image_tokens": [
      "self",
      "img_width",
      "img_height"
    ],
    "_split_images": [
      "self",
      "images"
    ],
    "_convert_images_to_pixel_values": [
      "self",
      "images",
      "is_patch"
    ],
    "_get_patch_repl": [
      "self",
      "num_patches",
      "patch_newline_mask"
    ],
    "_get_image_repl": [
      "self",
      "num_images"
    ],
    "_get_image_repl_features": [
      "self",
      "num_images",
      "num_patches",
      "patch_new_line_idx"
    ],
    "replace_placeholder": [
      "self",
      "text",
      "placeholder",
      "repls"
    ],
    "__call__": [
      "self",
      "text",
      "images",
      "return_tensors"
    ]
  },
  "Step3VLImageProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "__call__": [
      "self",
      "image"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "input_text",
      "request_obj"
    ]
  },
  "Phi4MMProcessorAdapter": {
    "__init__": [
      "self",
      "_processor"
    ],
    "__call__": [
      "self"
    ]
  },
  "Phi4MMMultimodalProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ],
    "process_mm_data_async": [
      "self",
      "image_data",
      "audio_data",
      "input_text",
      "request_obj"
    ]
  },
  "EVSDataItem": {},
  "VideoEVSDataItem": {
    "__post_init__": [
      "self"
    ]
  },
  "EVSEmbeddingResult": {
    "redistribute_pruned_frames_placeholders": [
      "self",
      "input_ids",
      "offsets"
    ]
  },
  "EVSConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "EVS": {
    "create_evs_config": [
      "config"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "__init__": [
      "self",
      "config"
    ],
    "evs_video": [
      "self",
      "items"
    ]
  },
  "compute_retained_tokens_count": [
    "tokens_per_frame",
    "num_frames",
    "q"
  ],
  "compute_retention_mask": [
    "video_embeds",
    "video_size_thw",
    "spatial_merge_size",
    "q"
  ],
  "tokens_per_frame": [],
  "replace_offsets_with_tokens_per_frame": [],
  "_non_evs_data_items": [],
  "EVSProcessor": {
    "__init__": [
      "self",
      "hf_config",
      "config_to_evs_model"
    ],
    "static_size_data_items": [
      "self"
    ]
  },
  "_sym_db": [],
  "DESCRIPTOR": [],
  "_globals": [],
  "GRPC_GENERATED_VERSION": [],
  "GRPC_VERSION": [],
  "_version_not_supported": [],
  "SglangSchedulerStub": {
    "__init__": [
      "self",
      "channel"
    ]
  },
  "SglangSchedulerServicer": {
    "Generate": [
      "self",
      "request",
      "context"
    ],
    "Embed": [
      "self",
      "request",
      "context"
    ],
    "HealthCheck": [
      "self",
      "request",
      "context"
    ],
    "Abort": [
      "self",
      "request",
      "context"
    ],
    "GetModelInfo": [
      "self",
      "request",
      "context"
    ],
    "GetServerInfo": [
      "self",
      "request",
      "context"
    ],
    "GetLoads": [
      "self",
      "request",
      "context"
    ]
  },
  "add_SglangSchedulerServicer_to_server": [
    "servicer",
    "server"
  ],
  "SglangScheduler": {
    "Generate": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "Embed": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "HealthCheck": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "Abort": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "GetModelInfo": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "GetServerInfo": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ],
    "GetLoads": [
      "request",
      "target",
      "options",
      "channel_credentials",
      "call_credentials",
      "insecure",
      "compression",
      "wait_for_ready",
      "timeout",
      "metadata"
    ]
  },
  "get_file_mtime": [
    "path"
  ],
  "check_regeneration_needed": [
    "proto_file",
    "output_dir"
  ],
  "compile_proto": [
    "proto_file",
    "output_dir",
    "verbose"
  ],
  "fix_imports": [
    "output_dir",
    "proto_stem",
    "verbose"
  ],
  "add_generation_header": [
    "output_dir",
    "proto_stem"
  ],
  "run_scheduler_with_signal_handling": [],
  "launch_scheduler_process_only": [
    "server_args",
    "port_args"
  ],
  "SGLangHealthServicer": {
    "OVERALL_SERVER": [],
    "SGLANG_SERVICE": [],
    "__init__": [
      "self",
      "request_manager",
      "scheduler_info"
    ],
    "set_serving": [
      "self"
    ],
    "set_not_serving": [
      "self"
    ],
    "Check": [
      "self",
      "request",
      "context"
    ],
    "Watch": [
      "self",
      "request",
      "context"
    ]
  },
  "_GrpcCommunicator": {
    "DEFAULT_TIMEOUT": [],
    "__init__": [
      "self",
      "sender",
      "fan_out"
    ],
    "__call__": [
      "self",
      "obj",
      "timeout"
    ],
    "handle_recv": [
      "self",
      "recv_obj"
    ]
  },
  "GrpcSignalHandler": {
    "__init__": [
      "self",
      "grpc_manager"
    ],
    "sigterm_handler": [
      "self",
      "signum",
      "frame"
    ],
    "running_phase_sigquit_handler": [
      "self",
      "signum",
      "frame"
    ]
  },
  "GrpcReqState": {},
  "GrpcRequestManager": {
    "__init__": [
      "self",
      "server_args",
      "port_args",
      "bootstrap_server"
    ],
    "generate_request": [
      "self",
      "obj",
      "request_id",
      "grpc_context"
    ],
    "_handle_single_request": [
      "self",
      "obj",
      "request_id",
      "grpc_context"
    ],
    "_cleanup_request_state": [
      "self",
      "request_id"
    ],
    "embedding_request": [
      "self",
      "obj",
      "request_id"
    ],
    "abort_request": [
      "self",
      "request_id"
    ],
    "handle_loop": [
      "self"
    ],
    "_convert_logprob_style": [
      "self",
      "state",
      "batch_out",
      "batch_index"
    ],
    "_handle_batch_output": [
      "self",
      "batch_out"
    ],
    "_handle_embedding_output": [
      "self",
      "batch_out"
    ],
    "_handle_health_check_output": [
      "self",
      "health_out"
    ],
    "_handle_abort_req": [
      "self",
      "recv_obj"
    ],
    "_send_to_scheduler": [
      "self",
      "obj"
    ],
    "record_request_for_crash_dump": [
      "self",
      "obj"
    ],
    "shutdown": [
      "self"
    ],
    "get_server_info": [
      "self"
    ],
    "get_loads": [
      "self",
      "include",
      "dp_rank"
    ],
    "auto_create_handle_loop": [
      "self"
    ],
    "sigterm_watchdog": [
      "self"
    ]
  },
  "HybridLayerType": {
    "full_attention": [],
    "linear_attention": []
  },
  "Qwen3NextConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "partial_rotary_factor",
      "attention_bias",
      "attention_dropout",
      "head_dim",
      "linear_conv_kernel_dim",
      "linear_key_head_dim",
      "linear_value_head_dim",
      "linear_num_key_heads",
      "linear_num_value_heads",
      "decoder_sparse_step",
      "moe_intermediate_size",
      "shared_expert_intermediate_size",
      "num_experts_per_tok",
      "num_experts",
      "norm_topk_prob",
      "output_router_logits",
      "router_aux_loss_coef",
      "mlp_only_layers",
      "layer_types"
    ],
    "layers_block_type": [
      "self"
    ],
    "linear_layer_ids": [
      "self"
    ],
    "full_attention_layer_ids": [
      "self"
    ],
    "mamba2_cache_params": [
      "self"
    ]
  },
  "JetBlockConfig": {},
  "JetNemotronConfig": {
    "full_attention_layer_ids": [
      "self"
    ],
    "linear_layer_ids": [
      "self"
    ],
    "mamba2_cache_params": [
      "self"
    ]
  },
  "VOCAB_FILES_NAMES": [],
  "PRETRAINED_VOCAB_FILES_MAP": [],
  "InternLM2Config": {
    "model_type": [],
    "_auto_class": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "bias",
      "rope_theta",
      "rope_scaling",
      "attn_implementation"
    ],
    "_rope_scaling_validation": [
      "self"
    ]
  },
  "InternVisionConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "num_channels",
      "patch_size",
      "image_size",
      "qkv_bias",
      "hidden_size",
      "num_attention_heads",
      "intermediate_size",
      "qk_normalization",
      "num_hidden_layers",
      "use_flash_attn",
      "hidden_act",
      "layer_norm_eps",
      "dropout",
      "drop_path_rate",
      "attention_dropout",
      "initializer_range",
      "initializer_factor"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "InternVLChatConfig": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "vision_config",
      "llm_config",
      "use_backbone_lora",
      "use_llm_lora",
      "pad2square",
      "select_layer",
      "force_image_size",
      "downsample_ratio",
      "template",
      "dynamic_image_size",
      "use_thumbnail",
      "ps_version",
      "min_dynamic_patch",
      "max_dynamic_patch"
    ],
    "to_dict": [
      "self"
    ]
  },
  "InternLM2Tokenizer": {
    "vocab_files_names": [],
    "pretrained_vocab_files_map": [],
    "model_input_names": [],
    "_auto_class": [],
    "__init__": [
      "self",
      "vocab_file",
      "unk_token",
      "bos_token",
      "eos_token",
      "pad_token",
      "sp_model_kwargs",
      "add_bos_token",
      "add_eos_token",
      "decode_with_prefix_space",
      "clean_up_tokenization_spaces"
    ],
    "no_prefix_space_tokens": [
      "self"
    ],
    "vocab_size": [
      "self"
    ],
    "bos_token_id": [
      "self"
    ],
    "eos_token_id": [
      "self"
    ],
    "get_vocab": [
      "self"
    ],
    "_tokenize": [
      "self",
      "text"
    ],
    "_convert_token_to_id": [
      "self",
      "token"
    ],
    "_convert_id_to_token": [
      "self",
      "index"
    ],
    "_maybe_add_prefix_space": [
      "self",
      "tokens",
      "decoded"
    ],
    "convert_tokens_to_string": [
      "self",
      "tokens"
    ],
    "save_vocabulary": [
      "self",
      "save_directory",
      "filename_prefix"
    ],
    "build_inputs_with_special_tokens": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ],
    "get_special_tokens_mask": [
      "self",
      "token_ids_0",
      "token_ids_1",
      "already_has_special_tokens"
    ],
    "create_token_type_ids_from_sequences": [
      "self",
      "token_ids_0",
      "token_ids_1"
    ]
  },
  "KimiLinearConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "model_type",
      "vocab_size",
      "hidden_size",
      "head_dim",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "rope_theta",
      "rope_scaling",
      "tie_word_embeddings",
      "moe_intermediate_size",
      "moe_renormalize",
      "moe_router_activation_func",
      "num_experts",
      "num_experts_per_token",
      "num_shared_experts",
      "routed_scaling_factor",
      "first_k_dense_replace",
      "moe_layer_freq",
      "use_grouped_topk",
      "num_expert_group",
      "topk_group",
      "q_lora_rank",
      "kv_lora_rank",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "mla_use_nope",
      "num_nextn_predict_layers",
      "linear_attn_config"
    ],
    "is_mla": [
      "self"
    ],
    "is_moe": [
      "self"
    ],
    "is_linear_attn": [
      "self"
    ],
    "is_kda_layer": [
      "self",
      "layer_idx"
    ],
    "linear_layer_ids": [
      "self"
    ],
    "full_attention_layer_ids": [
      "self"
    ],
    "mamba2_cache_params": [
      "self"
    ]
  },
  "Qwen3VLVisionConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "depth",
      "hidden_size",
      "hidden_act",
      "intermediate_size",
      "num_heads",
      "in_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "out_hidden_size",
      "num_position_embeddings",
      "deepstack_visual_indexes",
      "initializer_range"
    ]
  },
  "Qwen3VLTextConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "attention_dropout"
    ]
  },
  "Qwen3VLConfig": {
    "model_type": [],
    "sub_configs": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "vision_end_token_id",
      "tie_word_embeddings"
    ]
  },
  "Qwen3VLMoeTextConfig": {
    "model_type": [],
    "base_config_key": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "attention_bias",
      "attention_dropout",
      "decoder_sparse_step",
      "moe_intermediate_size",
      "num_experts_per_tok",
      "num_experts",
      "norm_topk_prob",
      "mlp_only_layers",
      "rope_scaling",
      "head_dim"
    ]
  },
  "Qwen3VLMoeVisionConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "depth",
      "hidden_size",
      "hidden_act",
      "intermediate_size",
      "num_heads",
      "in_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "out_hidden_size",
      "num_position_embeddings",
      "deepstack_visual_indexes",
      "initializer_range"
    ]
  },
  "Qwen3VLMoeConfig": {
    "model_type": [],
    "sub_configs": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "vision_end_token_id",
      "tie_word_embeddings"
    ]
  },
  "Olmo3LayerType": {
    "full_attention": [],
    "sliding_attention": []
  },
  "Olmo3Config": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "attention_dropout",
      "rms_norm_eps",
      "sliding_window",
      "layer_types"
    ]
  },
  "MAMBA": [],
  "ATTENTION": [],
  "MLP": [],
  "MOE": [],
  "NemotronHConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "tie_word_embeddings",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "hybrid_override_pattern",
      "num_attention_heads",
      "head_dim",
      "num_key_value_heads",
      "mlp_hidden_act",
      "attention_bias",
      "mlp_bias",
      "use_bias",
      "initializer_range",
      "layer_norm_epsilon",
      "residual_in_fp32",
      "use_cache",
      "num_logits_to_keep",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "sliding_window",
      "max_position_embeddings",
      "attention_dropout",
      "hidden_dropout",
      "use_mamba_kernels",
      "ssm_state_size",
      "mamba_num_heads",
      "mamba_n_groups",
      "mamba_head_dim",
      "mamba_d_conv",
      "mamba_expand",
      "mamba_hidden_act",
      "mamba_dt_min",
      "mamba_dt_max",
      "mamba_dt_limit",
      "mamba_dt_init_floor",
      "mamba_conv_bias",
      "mamba_proj_bias",
      "mamba_chunk_size",
      "rescale_prenorm_residual",
      "n_routed_experts",
      "n_shared_experts",
      "moe_intermediate_size",
      "moe_shared_expert_intermediate_size",
      "moe_latent_size",
      "num_experts_per_tok",
      "routed_scaling_factor",
      "n_group",
      "topk_group",
      "norm_topk_prob"
    ],
    "mamba_layer_ids": [
      "self"
    ],
    "full_attention_layer_ids": [
      "self"
    ],
    "mamba2_cache_params": [
      "self"
    ]
  },
  "DeviceConfig": {
    "__init__": [
      "self",
      "device",
      "gpu_id"
    ]
  },
  "DictToObject": {
    "__init__": [
      "self",
      "dictionary"
    ]
  },
  "VisionConfig": {
    "model_type": [],
    "params": [],
    "__init__": [
      "self"
    ]
  },
  "GenAlignerConfig": {
    "model_type": [],
    "params": [],
    "__init__": [
      "self"
    ]
  },
  "GenHeadConfig": {
    "model_type": [],
    "params": [],
    "__init__": [
      "self"
    ]
  },
  "AlignerConfig": {
    "model_type": [],
    "params": [],
    "__init__": [
      "self"
    ]
  },
  "GenVisionConfig": {
    "model_type": [],
    "params": [],
    "__init__": [
      "self"
    ]
  },
  "SigLIPVisionCfg": {},
  "MultiModalityConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "VLMImageProcessor": {
    "model_input_names": [],
    "__init__": [
      "self",
      "image_size",
      "min_size",
      "image_mean",
      "image_std",
      "rescale_factor",
      "do_normalize"
    ],
    "resize": [
      "self",
      "pil_img"
    ],
    "preprocess": [
      "self",
      "images",
      "return_tensors"
    ],
    "default_shape": [
      "self"
    ]
  },
  "DictOutput": {
    "items": [
      "self"
    ],
    "keys": [
      "self"
    ],
    "__getitem__": [
      "self",
      "item"
    ],
    "__contains__": [
      "self",
      "key"
    ],
    "__setitem__": [
      "self",
      "key",
      "value"
    ]
  },
  "VLChatProcessorOutput": {
    "__len__": [
      "self"
    ]
  },
  "BatchedVLChatProcessorOutput": {},
  "VLChatProcessor": {
    "image_processor_class": [],
    "tokenizer_class": [],
    "attributes": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "image_tag",
      "image_start_tag",
      "image_end_tag",
      "pad_tag",
      "num_image_tokens",
      "add_special_token",
      "sft_format",
      "mask_prompt",
      "ignore_id"
    ],
    "image_token": [
      "self"
    ],
    "image_id": [
      "self"
    ],
    "image_start_id": [
      "self"
    ],
    "image_end_id": [
      "self"
    ],
    "image_start_token": [
      "self"
    ],
    "image_end_token": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "add_image_token": [
      "self",
      "image_indices",
      "input_ids"
    ],
    "process_one": [
      "self",
      "prompt",
      "images"
    ],
    "__call__": [
      "self"
    ],
    "batchify": [
      "self",
      "prepare_list"
    ]
  },
  "VLMImageProcessorConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "image_size",
      "min_size",
      "image_mean",
      "image_std",
      "rescale_factor",
      "do_normalize"
    ]
  },
  "JetVLMConfig": {
    "model_type": [],
    "sub_configs": [],
    "_auto_class": [],
    "__init__": [
      "self"
    ],
    "full_attention_layer_ids": [
      "self"
    ],
    "linear_layer_ids": [
      "self"
    ],
    "mamba2_cache_params": [
      "self"
    ]
  },
  "DotsVisionConfig": {
    "__init__": [
      "self",
      "embed_dim",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "rms_norm_eps",
      "use_bias",
      "attn_implementation",
      "initializer_range",
      "init_merger_std",
      "is_causal",
      "post_norm",
      "gradient_checkpointing"
    ]
  },
  "DotsVLMConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "DotsVLMProcessorKwargs": {
    "_defaults": []
  },
  "DotsVLMProcessor": {
    "attributes": [],
    "valid_kwargs": [],
    "tokenizer_class": [],
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "chat_template"
    ]
  },
  "register_image_processor": [
    "config",
    "image_processor"
  ],
  "register_processor": [
    "config",
    "processor"
  ],
  "DEFAULT_MOE_PADDING_SIZE": [],
  "may_get_weight_block_size": [
    "model_config",
    "load_config"
  ],
  "get_moe_padding_size": [
    "weight_block_size"
  ],
  "get_num_heads_padding_size": [
    "tp_size",
    "weight_block_size",
    "head_dim"
  ],
  "update_intermediate_size": [
    "model_config",
    "attr_name",
    "intermediate_padding_size"
  ],
  "adjust_config_with_unaligned_cpu_tp": [
    "model_config",
    "load_config",
    "tp_size"
  ],
  "FalconH1Config": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "tie_word_embeddings",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "num_logits_to_keep",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "max_position_embeddings",
      "attention_dropout",
      "mamba_d_ssm",
      "mamba_n_heads",
      "mamba_d_head",
      "mamba_n_groups",
      "mamba_d_state",
      "mamba_d_conv",
      "mamba_expand",
      "mamba_chunk_size",
      "mamba_conv_bias",
      "mamba_proj_bias",
      "mamba_norm_before_gate",
      "mamba_rms_norm",
      "projectors_bias",
      "rope_theta",
      "rope_scaling",
      "lm_head_multiplier",
      "embedding_multiplier",
      "mlp_multipliers",
      "key_multiplier",
      "attention_out_multiplier",
      "attention_in_multiplier",
      "ssm_multipliers",
      "ssm_in_multiplier",
      "ssm_out_multiplier"
    ],
    "layers_block_type": [
      "self"
    ],
    "full_attention_layer_ids": [
      "self"
    ],
    "linear_layer_ids": [
      "self"
    ],
    "mamba2_cache_params": [
      "self"
    ]
  },
  "BASE_SIZE": [],
  "IMAGE_SIZE": [],
  "CROP_MODE": [],
  "MIN_CROPS": [],
  "MAX_CROPS": [],
  "MAX_CONCURRENCY": [],
  "NUM_WORKERS": [],
  "PRINT_NUM_VIS_TOKENS": [],
  "SKIP_REPEAT": [],
  "MODEL_PATH": [],
  "NGRAM_NO_REPEAT_SIZE": [],
  "NGRAM_NO_REPEAT_WINDOW": [],
  "NGRAM_NO_REPEAT_WHITELIST": [],
  "DEFAULT_CUSTOM_LOGIT_PROCESSOR": [],
  "get_default_ngram_custom_params": [],
  "PROMPT": [],
  "ImageTransform": {
    "__init__": [
      "self",
      "mean",
      "std",
      "normalize"
    ],
    "__call__": [
      "self",
      "pil_img"
    ]
  },
  "VisionEncoderConfig": {
    "__init__": [
      "self",
      "model_name",
      "image_size",
      "patch_size",
      "width",
      "layers",
      "heads",
      "mlp_ratio",
      "global_pool",
      "ignore_head",
      "class_token",
      "num_classes",
      "use_checkpoint"
    ]
  },
  "MlpProjectorConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "projector_type",
      "input_dim",
      "n_embed",
      "depth",
      "mlp_ratio",
      "downsample_ratio"
    ]
  },
  "DeepseekV2Config": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "moe_intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "n_shared_experts",
      "n_routed_experts",
      "ep_size",
      "routed_scaling_factor",
      "kv_lora_rank",
      "q_lora_rank",
      "qk_rope_head_dim",
      "v_head_dim",
      "qk_nope_head_dim",
      "topk_method",
      "n_group",
      "topk_group",
      "num_experts_per_tok",
      "moe_layer_freq",
      "first_k_dense_replace",
      "norm_topk_prob",
      "scoring_func",
      "aux_loss_alpha",
      "seq_aux",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "pretraining_tp",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "attention_dropout",
      "use_mla"
    ]
  },
  "DeepseekVLV2Config": {
    "model_type": [],
    "__init__": [
      "self",
      "tile_tag",
      "global_view_pos",
      "candidate_resolutions"
    ]
  },
  "LoadFormat": {
    "AUTO": [],
    "PT": [],
    "SAFETENSORS": [],
    "NPCACHE": [],
    "DUMMY": [],
    "SHARDED_STATE": [],
    "GGUF": [],
    "BITSANDBYTES": [],
    "MISTRAL": [],
    "LAYERED": [],
    "FLASH_RL": [],
    "JAX": [],
    "REMOTE": [],
    "REMOTE_INSTANCE": [],
    "RDMA": [],
    "LOCAL_CACHED": [],
    "FASTSAFETENSORS": [],
    "PRIVATE": []
  },
  "LoadConfig": {
    "__post_init__": [
      "self"
    ],
    "_verify_load_format": [
      "self"
    ]
  },
  "ExaoneConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "vocab_size",
      "max_position_embeddings",
      "hidden_size",
      "num_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "intermediate_size",
      "activation_function",
      "rope_theta",
      "rope_scaling",
      "embed_dropout",
      "attention_dropout",
      "layer_norm_epsilon",
      "initializer_range",
      "use_cache",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings"
    ]
  },
  "DotsOCRConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "image_token_id",
      "video_token_id",
      "vision_config"
    ],
    "save_pretrained": [
      "self",
      "save_directory"
    ]
  },
  "DummyVideoProcessor": {
    "model_input_names": [],
    "__call__": [
      "self"
    ]
  },
  "DotsVLProcessor": {
    "__init__": [
      "self",
      "image_processor",
      "tokenizer",
      "video_processor",
      "chat_template"
    ]
  },
  "FLASH_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "LongcatFlashConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "ffn_hidden_size",
      "expert_ffn_hidden_size",
      "num_layers",
      "num_hidden_layers",
      "num_attention_heads",
      "ep_size",
      "kv_lora_rank",
      "q_lora_rank",
      "qk_rope_head_dim",
      "qk_nope_head_dim",
      "v_head_dim",
      "n_routed_experts",
      "moe_topk",
      "norm_topk_prob",
      "max_position_embeddings",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "pretraining_tp",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "attention_dropout",
      "mla_scale_q_lora",
      "mla_scale_kv_lora",
      "torch_dtype",
      "params_dtype",
      "rounter_params_dtype",
      "router_bias",
      "topk_method",
      "routed_scaling_factor",
      "zero_expert_num",
      "zero_expert_type",
      "nextn_use_scmoe",
      "num_nextn_predict_layers"
    ]
  },
  "POINTSV15ChatConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "llm_config"
    ]
  },
  "DBRX_PRETRAINED_CONFIG_ARCHIVE_MAP": [],
  "DbrxAttentionConfig": {
    "__init__": [
      "self",
      "attn_pdrop",
      "clip_qkv",
      "kv_n_heads",
      "rope_theta"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "DbrxFFNConfig": {
    "__init__": [
      "self",
      "ffn_act_fn",
      "ffn_hidden_size",
      "moe_num_experts",
      "moe_top_k",
      "moe_jitter_eps",
      "moe_loss_weight",
      "moe_normalize_expert_weights",
      "uniform_expert_assignment"
    ],
    "from_pretrained": [
      "cls",
      "pretrained_model_name_or_path"
    ]
  },
  "DbrxConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "d_model",
      "n_heads",
      "n_layers",
      "max_seq_len",
      "vocab_size",
      "resid_pdrop",
      "emb_pdrop",
      "attn_config",
      "ffn_config",
      "use_cache",
      "initializer_range",
      "output_router_logits",
      "router_aux_loss_coef"
    ]
  },
  "MoonViTConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "patch_size",
      "init_pos_emb_height",
      "init_pos_emb_width",
      "num_attention_heads",
      "num_hidden_layers",
      "hidden_size",
      "intermediate_size",
      "merge_kernel_size"
    ]
  },
  "float_triplet": [
    "seq"
  ],
  "NemotronH_Nano_VL_V2_Config": {
    "model_type": [],
    "is_composition": [],
    "__init__": [
      "self",
      "vision_config",
      "llm_config",
      "force_image_size",
      "patch_size",
      "downsample_ratio",
      "template",
      "ps_version",
      "image_tag_type",
      "projector_hidden_size",
      "vit_hidden_size",
      "video_pruning_rate",
      "video_context_token",
      "img_context_token",
      "img_start_token",
      "img_end_token",
      "norm_mean",
      "norm_std",
      "use_thumbnail"
    ],
    "create_radio_config": [
      "self"
    ]
  },
  "DeepseekVLV2Processor": {
    "tokenizer_class": [],
    "attributes": [],
    "__init__": [
      "self",
      "tokenizer",
      "candidate_resolutions",
      "patch_size",
      "downsample_ratio",
      "image_mean",
      "image_std",
      "normalize",
      "image_token",
      "pad_token",
      "add_special_token",
      "sft_format",
      "mask_prompt",
      "ignore_id"
    ],
    "format_messages_v2": [
      "self",
      "messages",
      "pil_images",
      "max_req_input_len"
    ],
    "bos_id": [
      "self"
    ],
    "eos_id": [
      "self"
    ],
    "pad_id": [
      "self"
    ],
    "encode": [
      "self",
      "text",
      "bos",
      "eos"
    ],
    "decode": [
      "self",
      "t"
    ],
    "process_one": [
      "self",
      "prompt",
      "conversations",
      "images",
      "apply_sft_format",
      "inference_mode",
      "system_prompt",
      "max_req_input_len"
    ],
    "__call__": [
      "self"
    ],
    "find_all_indices": [
      "self",
      "messages",
      "target_value"
    ],
    "tokenize_with_images": [
      "self",
      "conversation",
      "images",
      "bos",
      "eos",
      "cropping",
      "max_req_input_len"
    ]
  },
  "DeepseekVL2VisionEncoderConfig": {
    "__init__": [
      "self",
      "model_name",
      "image_size",
      "patch_size",
      "width",
      "layers",
      "heads",
      "mlp_ratio",
      "global_pool",
      "ignore_head",
      "class_token",
      "num_classes",
      "use_checkpoint"
    ]
  },
  "DeepseekVL2MlpProjectorConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "projector_type",
      "input_dim",
      "n_embed",
      "depth",
      "mlp_ratio",
      "downsample_ratio"
    ]
  },
  "DeepseekVL2Config": {
    "model_type": [],
    "__init__": [
      "self",
      "tile_tag",
      "global_view_pos",
      "candidate_resolutions"
    ]
  },
  "AttentionArch": {
    "MLA": [],
    "MHA": []
  },
  "ModelImpl": {
    "AUTO": [],
    "SGLANG": [],
    "TRANSFORMERS": [],
    "MINDSPORE": []
  },
  "is_deepseek_nsa": [
    "config"
  ],
  "get_nsa_index_head_dim": [
    "config"
  ],
  "get_nsa_index_topk": [
    "config"
  ],
  "get_nsa_index_n_heads": [
    "config"
  ],
  "ModelConfig": {
    "__init__": [
      "self",
      "model_path",
      "trust_remote_code",
      "revision",
      "context_length",
      "model_override_args",
      "is_embedding",
      "enable_multimodal",
      "dtype",
      "quantization",
      "override_config_file",
      "is_draft_model",
      "model_impl",
      "sampling_defaults",
      "quantize_and_serve",
      "is_multi_layer_eagle",
      "encoder_only",
      "language_only",
      "disable_hybrid_swa_memory"
    ],
    "from_server_args": [
      "server_args",
      "model_path",
      "model_revision",
      "is_draft_model"
    ],
    "_config_draft_model": [
      "self"
    ],
    "_derive_hybrid_model": [
      "self"
    ],
    "_derive_context_length": [
      "self",
      "context_length"
    ],
    "_derive_model_shapes": [
      "self"
    ],
    "get_total_num_attention_heads": [
      "self"
    ],
    "get_num_attention_heads": [
      "self",
      "tensor_parallel_size"
    ],
    "get_total_num_kv_heads": [
      "self"
    ],
    "get_num_kv_heads": [
      "self",
      "tensor_parallel_size"
    ],
    "get_swa_num_kv_heads": [
      "self",
      "tensor_parallel_size"
    ],
    "_parse_quant_hf_config": [
      "self"
    ],
    "_find_quant_modelslim_config": [
      "self"
    ],
    "_parse_modelopt_quant_config": [
      "self",
      "quant_config_dict"
    ],
    "_is_already_quantized": [
      "self"
    ],
    "_get_modelopt_quant_type": [
      "self"
    ],
    "_get_sliding_window_size": [
      "self"
    ],
    "_validate_quantize_and_serve_config": [
      "self"
    ],
    "_verify_quantization": [
      "self"
    ],
    "_verify_dual_chunk_attention_config": [
      "self"
    ],
    "_verify_transformers_version": [
      "self"
    ],
    "_get_hf_eos_token_id": [
      "self"
    ],
    "get_default_sampling_params": [
      "self"
    ],
    "_maybe_pull_model_tokenizer_from_remote": [
      "self"
    ]
  },
  "_STR_DTYPE_TO_TORCH_DTYPE": [],
  "_get_and_verify_dtype": [
    "config",
    "dtype"
  ],
  "is_generation_model": [
    "model_architectures",
    "is_embedding"
  ],
  "multimodal_model_archs": [],
  "is_multimodal_model": [
    "model_architectures"
  ],
  "is_multimodal_gen_model": [
    "model_architectures"
  ],
  "is_image_gen_model": [
    "model_architectures"
  ],
  "is_audio_model": [
    "model_architectures"
  ],
  "is_encoder_decoder_model": [
    "model_architectures"
  ],
  "is_local_attention_model": [
    "model_architectures"
  ],
  "is_multimodal_chunked_prefill_supported": [
    "model_architectures"
  ],
  "is_hybrid_swa_model": [
    "model_architectures"
  ],
  "get_hybrid_layer_ids": [
    "model_architectures",
    "hf_text_config"
  ],
  "OPENAI_CLIP_MEAN": [],
  "OPENAI_CLIP_STD": [],
  "RadioConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "model_name",
      "image_size",
      "patch_size",
      "qkv_bias",
      "qk_normalization",
      "norm_type",
      "layer_norm_eps",
      "initializer_factor",
      "hidden_act",
      "max_img_size",
      "norm_mean",
      "norm_std",
      "reg_tokens",
      "drop_path_rate",
      "dropout"
    ]
  },
  "KimiVLConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "text_config",
      "ignore_index",
      "media_placeholder_token_id",
      "pad_token_id"
    ]
  },
  "AfmoeConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "moe_intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "attention_dropout",
      "num_experts",
      "num_experts_per_tok",
      "num_shared_experts",
      "num_dense_layers",
      "score_func",
      "route_norm",
      "route_scale",
      "n_group",
      "topk_group",
      "sliding_window",
      "layer_types",
      "global_attn_every_n_layers",
      "mup_enabled"
    ]
  },
  "Qwen3OmniMoeAudioEncoderConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "num_mel_bins",
      "encoder_layers",
      "encoder_attention_heads",
      "encoder_ffn_dim",
      "d_model",
      "dropout",
      "attention_dropout",
      "activation_function",
      "activation_dropout",
      "scale_embedding",
      "initializer_range",
      "max_source_positions",
      "n_window",
      "output_dim",
      "n_window_infer",
      "conv_chunksize",
      "downsample_hidden_size"
    ]
  },
  "Qwen3OmniMoeVisionEncoderConfig": {
    "model_type": [],
    "base_config_key": [],
    "__init__": [
      "self",
      "depth",
      "hidden_size",
      "hidden_act",
      "intermediate_size",
      "num_heads",
      "in_channels",
      "patch_size",
      "spatial_merge_size",
      "temporal_patch_size",
      "out_hidden_size",
      "num_position_embeddings",
      "deepstack_visual_indexes",
      "initializer_range"
    ]
  },
  "Qwen3OmniMoeTextConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "sliding_window",
      "attention_dropout",
      "decoder_sparse_step",
      "moe_intermediate_size",
      "num_experts_per_tok",
      "num_experts",
      "norm_topk_prob",
      "output_router_logits",
      "router_aux_loss_coef",
      "mlp_only_layers"
    ]
  },
  "Qwen3OmniMoeThinkerConfig": {
    "model_type": [],
    "attribute_map": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "audio_config",
      "vision_config",
      "text_config",
      "audio_token_id",
      "image_token_id",
      "video_token_id",
      "position_id_per_seconds",
      "audio_start_token_id",
      "user_token_id",
      "initializer_range"
    ]
  },
  "Qwen3OmniMoeTalkerCodePredictorConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "sliding_window",
      "layer_types",
      "attention_dropout",
      "num_code_groups"
    ]
  },
  "Qwen3OmniMoeTalkerTextConfig": {
    "model_type": [],
    "keys_to_ignore_at_inference": [],
    "base_model_tp_plan": [],
    "base_model_pp_plan": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "tie_word_embeddings",
      "rope_theta",
      "rope_scaling",
      "attention_bias",
      "sliding_window",
      "attention_dropout",
      "decoder_sparse_step",
      "moe_intermediate_size",
      "num_experts_per_tok",
      "num_experts",
      "norm_topk_prob",
      "output_router_logits",
      "router_aux_loss_coef",
      "mlp_only_layers"
    ]
  },
  "Qwen3OmniMoeTalkerConfig": {
    "sub_configs": [],
    "__init__": [
      "self",
      "code_predictor_config",
      "text_config",
      "num_code_groups",
      "thinker_hidden_size",
      "codec_eos_token_id",
      "accept_hidden_layer",
      "codec_nothink_id",
      "codec_think_bos_id",
      "codec_think_eos_id",
      "codec_pad_id",
      "codec_bos_id",
      "audio_token_id",
      "image_token_id",
      "video_token_id",
      "vision_start_token_id",
      "position_id_per_seconds",
      "audio_start_token_id",
      "speaker_id"
    ]
  },
  "Qwen3OmniMoeCode2WavConfig": {
    "__init__": [
      "self",
      "codebook_size",
      "hidden_size",
      "max_position_embeddings",
      "rope_theta",
      "num_attention_heads",
      "num_key_value_heads",
      "attention_bias",
      "sliding_window",
      "intermediate_size",
      "hidden_act",
      "layer_scale_initial_scale",
      "rms_norm_eps",
      "num_hidden_layers",
      "num_quantizers",
      "upsample_rates",
      "upsampling_ratios",
      "decoder_dim",
      "attention_dropout"
    ],
    "layer_types": [
      "self"
    ]
  },
  "Qwen3OmniMoeConfig": {
    "model_type": [],
    "sub_configs": [],
    "__init__": [
      "self",
      "thinker_config",
      "talker_config",
      "code2wav_config",
      "enable_audio_output",
      "im_start_token_id",
      "im_end_token_id",
      "tts_pad_token_id",
      "tts_bos_token_id",
      "tts_eos_token_id",
      "system_token_id",
      "user_token_id",
      "assistant_token_id"
    ],
    "get_text_config": [
      "self",
      "decoder"
    ]
  },
  "ModelOptConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "extra_groups_for_head_shards": [
    "ngroups",
    "tp_size"
  ],
  "Mamba2StateDType": {},
  "CONV_DTYPE": [],
  "mamba2_state_dtype": [],
  "BaseLinearStateParams": {
    "mamba_cache_per_req": [
      "self"
    ]
  },
  "Mamba2StateShape": {
    "create": []
  },
  "Mamba2CacheParams": {},
  "KimiLinearStateShape": {
    "create": []
  },
  "KimiLinearCacheParams": {},
  "Step3VisionEncoderConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "output_hidden_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_channels",
      "image_size",
      "patch_size",
      "hidden_act",
      "layer_norm_eps"
    ]
  },
  "Step3TextConfig": {
    "model_type": [],
    "architectures": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "num_attention_heads",
      "num_attention_groups",
      "num_hidden_layers",
      "max_seq_len",
      "vocab_size",
      "rms_norm_eps",
      "moe_intermediate_size",
      "moe_num_experts",
      "moe_top_k",
      "rope_theta",
      "rope_scaling",
      "max_position_embedding",
      "share_expert_dim",
      "share_q_dim",
      "head_dim",
      "norm_expert_weight",
      "moe_layers_enum"
    ]
  },
  "Step3VLConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vision_config",
      "text_config",
      "understand_projector_stride",
      "projector_bias",
      "image_token_id"
    ]
  },
  "ChatGLMConfig": {
    "model_type": [],
    "attribute_map": [],
    "__init__": [
      "self",
      "num_layers",
      "padded_vocab_size",
      "hidden_size",
      "ffn_hidden_size",
      "kv_channels",
      "num_attention_heads",
      "seq_length",
      "hidden_dropout",
      "attention_dropout",
      "layernorm_epsilon",
      "rmsnorm",
      "apply_residual_connection_post_layernorm",
      "post_layer_norm",
      "add_bias_linear",
      "add_qkv_bias",
      "interleaved_qkv",
      "bias_dropout_fusion",
      "multi_query_attention",
      "multi_query_group_num",
      "apply_query_key_layer_scaling",
      "attention_softmax_in_fp32",
      "fp32_residual_connection",
      "quantization_bit",
      "pre_seq_len",
      "prefix_projection"
    ]
  },
  "_cache_from_str": [
    "json_str"
  ],
  "CustomLogitProcessor": {
    "__call__": [
      "self",
      "logits",
      "custom_param_list"
    ],
    "to_str": [
      "cls"
    ],
    "from_str": [
      "cls",
      "json_str"
    ]
  },
  "DisallowedTokensLogitsProcessor": {
    "__call__": [
      "self",
      "logits",
      "custom_param_list"
    ]
  },
  "ThinkingBudgetLogitProcessor": {
    "__call__": [
      "self",
      "logits",
      "custom_param_list"
    ]
  },
  "Glm4MoeThinkingBudgetLogitProcessor": {},
  "Qwen3ThinkingBudgetLogitProcessor": {},
  "DeepSeekR1ThinkingBudgetLogitProcessor": {},
  "DeepseekOCRNoRepeatNGramLogitProcessor": {
    "__call__": [
      "self",
      "logits",
      "custom_param_list"
    ]
  },
  "SamplingBatchInfo": {
    "from_schedule_batch": [
      "cls",
      "batch",
      "vocab_size"
    ],
    "adjusted_from_schedule_batch": [
      "self",
      "batch",
      "vocab_size"
    ],
    "adjusted_merge_batch": [
      "self",
      "other"
    ],
    "__len__": [
      "self"
    ],
    "update_regex_vocab_mask": [
      "self"
    ],
    "update_penalties": [
      "self"
    ],
    "apply_logits_bias": [
      "self",
      "logits"
    ],
    "filter_batch": [
      "self",
      "keep_indices",
      "keep_indices_device"
    ],
    "_filter_batch_custom_logit_processor": [
      "self",
      "keep_indices",
      "keep_indices_device"
    ],
    "merge_custom_logit_processor": [
      "lhs",
      "rhs",
      "bs1",
      "bs2",
      "device"
    ],
    "merge_batch": [
      "self",
      "other"
    ],
    "copy_for_forward": [
      "self"
    ]
  },
  "merge_bias_tensor": [
    "lhs",
    "rhs",
    "bs1",
    "bs2",
    "device",
    "default"
  ],
  "_SAMPLING_EPS": [],
  "TOP_K_ALL": [],
  "SamplingParams": {
    "__init__": [
      "self",
      "max_new_tokens",
      "stop",
      "stop_token_ids",
      "stop_regex",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "frequency_penalty",
      "presence_penalty",
      "repetition_penalty",
      "min_new_tokens",
      "n",
      "json_schema",
      "regex",
      "ebnf",
      "structural_tag",
      "ignore_eos",
      "skip_special_tokens",
      "spaces_between_special_tokens",
      "no_stop_trim",
      "custom_params",
      "stream_interval",
      "logit_bias",
      "sampling_seed"
    ],
    "verify": [
      "self",
      "vocab_size"
    ],
    "normalize": [
      "self",
      "tokenizer"
    ]
  },
  "get_max_seq_length": [
    "regex_str"
  ],
  "MAX_LEN": [],
  "_max_length_from_subpattern": [
    "subpattern"
  ],
  "BatchedPenalizerOrchestrator": {
    "__init__": [
      "self",
      "vocab_size",
      "batch",
      "penalizers"
    ],
    "batch": [
      "self",
      "value"
    ],
    "reqs": [
      "self"
    ],
    "cumulate_output_tokens": [
      "self",
      "output_ids"
    ],
    "apply": [
      "self",
      "logits"
    ],
    "filter": [
      "self",
      "keep_indices"
    ],
    "release": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc",
      "tb"
    ],
    "merge": [
      "self",
      "their"
    ]
  },
  "_BatchedPenalizer": {
    "__init__": [
      "self",
      "orchestrator"
    ],
    "orchestrator": [
      "self"
    ],
    "is_prepared": [
      "self"
    ],
    "is_required": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "prepare_if_required": [
      "self"
    ],
    "teardown": [
      "self"
    ],
    "cumulate_output_tokens": [
      "self",
      "output_ids"
    ],
    "apply": [
      "self",
      "logits"
    ],
    "filter": [
      "self",
      "keep_indices"
    ],
    "merge": [
      "self",
      "their"
    ],
    "_is_required": [
      "self"
    ],
    "_prepare": [
      "self"
    ],
    "_cumulate_output_tokens": [
      "self",
      "output_ids"
    ],
    "_apply": [
      "self",
      "logits"
    ],
    "_filter": [
      "self",
      "keep_indices"
    ],
    "_merge": [
      "self",
      "their"
    ],
    "_teardown": [
      "self"
    ]
  },
  "BatchedFrequencyPenalizer": {
    "_is_required": [
      "self"
    ],
    "_prepare": [
      "self"
    ],
    "_cumulate_output_tokens": [
      "self",
      "output_ids"
    ],
    "_apply": [
      "self",
      "logits"
    ],
    "_filter": [
      "self",
      "keep_indices"
    ],
    "_merge": [
      "self",
      "their"
    ],
    "_teardown": [
      "self"
    ]
  },
  "BatchedPresencePenalizer": {
    "_is_required": [
      "self"
    ],
    "_prepare": [
      "self"
    ],
    "_cumulate_output_tokens": [
      "self",
      "output_ids"
    ],
    "_apply": [
      "self",
      "logits"
    ],
    "_filter": [
      "self",
      "keep_indices"
    ],
    "_merge": [
      "self",
      "their"
    ],
    "_teardown": [
      "self"
    ]
  },
  "BatchedMinNewTokensPenalizer": {
    "_is_required": [
      "self"
    ],
    "_prepare": [
      "self"
    ],
    "_cumulate_output_tokens": [
      "self",
      "output_ids"
    ],
    "_apply": [
      "self",
      "logits"
    ],
    "_filter": [
      "self",
      "keep_indices"
    ],
    "_merge": [
      "self",
      "their"
    ],
    "_teardown": [
      "self"
    ]
  },
  "FlattenedTensorMetadata": {},
  "FlattenedTensorBucket": {
    "supports_multi_dtypes": [],
    "__init__": [
      "self",
      "named_tensors",
      "flattened_tensor",
      "metadata"
    ],
    "get_flattened_tensor": [
      "self"
    ],
    "get_metadata": [
      "self"
    ],
    "reconstruct_tensors": [
      "self"
    ]
  },
  "_preprocess_tensor_for_update_weights": [
    "tensor"
  ],
  "TiktokenProcessor": {
    "__init__": [
      "self",
      "name"
    ],
    "image_processor": [
      "self",
      "image"
    ]
  },
  "RESERVED_TOKEN_TEXTS": [],
  "CONTROL_TOKEN_TEXTS": [],
  "PAD": [],
  "EOS": [],
  "SEP": [],
  "DEFAULT_SPECIAL_TOKENS": [],
  "DEFAULT_CONTROL_TOKENS": [],
  "PAT_STR_B": [],
  "TiktokenTokenizer": {
    "__init__": [
      "self",
      "tokenizer_path"
    ],
    "encode": [
      "self",
      "x",
      "add_special_tokens"
    ],
    "decode": [
      "self",
      "x"
    ],
    "batch_decode": [
      "self",
      "batch",
      "skip_special_tokens",
      "spaces_between_special_tokens"
    ],
    "apply_chat_template": [
      "self",
      "messages",
      "tokenize",
      "add_generation_prompt",
      "tools",
      "reasoning_effort"
    ],
    "__call__": [
      "self",
      "text"
    ],
    "init_xgrammar": [
      "self"
    ]
  },
  "RawImageType": [],
  "get_1d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "pos",
    "version"
  ],
  "get_2d_sincos_pos_embed_from_grid": [
    "embed_dim",
    "grid",
    "version"
  ],
  "get_2d_sincos_pos_embed": [
    "embed_dim",
    "grid_size",
    "cls_token",
    "version"
  ],
  "MiniCPMVImagePixelInputs": {},
  "MiniCPMVImageEmbeddingInputs": {},
  "MiniCPMVImageInputs": [],
  "DEFAULT_LN": [],
  "BaseResampler": {
    "__init__": [
      "self",
      "num_queries",
      "embed_dim",
      "num_heads",
      "kv_dim",
      "norm_layer",
      "do_post_projection",
      "quant_config",
      "prefix"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "_repeat": [
      "self",
      "query",
      "N"
    ]
  },
  "Resampler2_5": {
    "__init__": [
      "self",
      "num_queries",
      "embed_dim",
      "num_heads",
      "kv_dim",
      "norm_layer",
      "max_size",
      "quant_config",
      "prefix"
    ],
    "_set_2d_pos_cache": [
      "self",
      "max_size",
      "device"
    ],
    "_adjust_pos_cache": [
      "self",
      "tgt_sizes",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "tgt_sizes"
    ]
  },
  "get_version_by_config": [
    "config"
  ],
  "MiniCPMBaseModel": {
    "__init__": [
      "self"
    ],
    "_get_image_bounds": [
      "self",
      "input_ids",
      "pad_values",
      "im_start_id",
      "im_end_id",
      "slice_start_id",
      "slice_end_id"
    ],
    "_parse_and_validate_inputs": [
      "self",
      "input_ids"
    ],
    "get_embedding": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "init_llm": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_embedding": [
      "self",
      "pixel_values",
      "patch_attn_mask",
      "tgt_sizes"
    ],
    "get_image_feature": [
      "self",
      "items"
    ]
  },
  "MiniCPMV2_6": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_llm": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_embedding": [
      "self",
      "pixel_values",
      "patch_attn_mask",
      "tgt_sizes"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ]
  },
  "MiniCPMV4_0": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_llm": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "get_vision_embedding": [
      "self",
      "pixel_values",
      "patch_attn_mask",
      "tgt_sizes"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ]
  },
  "_SUPPORT_VERSION": [],
  "MiniCPMV": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__call__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "EntryClass": [],
  "InternLM2ForRewardModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlavaVidForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "encode_images": [
      "self",
      "pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "num_patches_per_side": [
      "self"
    ]
  },
  "MM_HIDDEN_SIZE": [],
  "NVILALiteConfig": {
    "model_type": [],
    "sub_configs": [],
    "_auto_class": [],
    "__init__": [
      "self"
    ]
  },
  "NVILALiteMultiModalProjectorDownsampleBlock": {
    "forward": [
      "self",
      "x"
    ]
  },
  "NVILALiteMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NVILALiteForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "get_image_feature": [
      "self",
      "mm_input"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ]
  },
  "Qwen2Config": [],
  "Qwen2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "dual_chunk_attention_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Qwen2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "Qwen2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "decoder_layer_type",
      "alt_stream"
    ],
    "get_input_embedding": [
      "self",
      "input_ids"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "Qwen2ForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embedding": [
      "self",
      "input_ids"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "MistralLarge3ForCausalLM": {
    "remapping": [],
    "load_weights": [
      "self",
      "weights"
    ],
    "_iterable_remap_mistral_to_ds": [
      "self",
      "weights"
    ]
  },
  "Gemma3nCumulativeGroupNorm": {
    "__init__": [
      "self",
      "num_channels",
      "feature_dims",
      "eps"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "Gemma3nAudioRelativePositionEmbedding": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_get_timing_signal_1d_pos": [
      "self",
      "position",
      "dtype"
    ],
    "_relative_shift": [
      "self",
      "term_bd_before_shift",
      "batch_size",
      "num_heads",
      "num_query_blocks",
      "query_block_size",
      "key_context_size",
      "max_span_plus_1"
    ],
    "forward": [
      "self",
      "queries",
      "keys"
    ]
  },
  "Gemma3nAudioAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_pad_dim1": [
      "self",
      "x",
      "dim10_val",
      "dim11_val"
    ],
    "_convert_to_block": [
      "self",
      "x"
    ],
    "_extract_block_context": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "Gemma3nAudioSSCPConvBlock": {
    "__init__": [
      "self",
      "config",
      "idx",
      "input_freq_dim",
      "manual_padding",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_encodings"
    ]
  },
  "Gemma3nAudioSubSampleConvProjection": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_encodings"
    ]
  },
  "Gemma3nAudioConformerAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_encodings",
      "audio_mel_mask"
    ]
  },
  "Gemma3nAudioConformerFeedForward": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_encodings"
    ]
  },
  "Gemma3nAudioConformerLightConv1d": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_encodings"
    ]
  },
  "Gemma3nAudioConformerBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_encodings",
      "audio_mel_mask"
    ]
  },
  "Gemma3nAudioEncoder": {
    "config_class": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "audio_mel",
      "audio_mel_mask"
    ]
  },
  "fused_qkvzba_split_reshape_cat_kernel": [
    "mixed_qkv",
    "z",
    "b",
    "a",
    "mixed_qkvz",
    "mixed_ba",
    "NUM_HEADS_QK",
    "NUM_HEADS_V",
    "HEAD_QK",
    "HEAD_V"
  ],
  "fused_qkvzba_split_reshape_cat": [
    "mixed_qkvz",
    "mixed_ba",
    "num_heads_qk",
    "num_heads_v",
    "head_qk",
    "head_v"
  ],
  "Qwen3GatedDeltaNet": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "alt_stream",
      "prefix"
    ],
    "fix_query_key_value_ordering": [
      "self",
      "mixed_qkvz",
      "mixed_ba"
    ],
    "_forward_input_proj": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "_forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Qwen3HybridLinearDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "hidden_states",
      "residual"
    ]
  },
  "Qwen3HybridAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "self_attention": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "forward_batch"
    ]
  },
  "ALL_DECODER_LAYER_TYPES": [],
  "Qwen3NextModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ]
  },
  "Qwen3NextForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "routed_experts_weights_of_layer": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_mtp"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "gdn_with_output": [
    "hidden_states",
    "output",
    "layer_id"
  ],
  "Qwen2_5_VLMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "hidden_act",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "intermediate_dim",
      "num_heads",
      "hidden_act",
      "norm_layer",
      "quant_config",
      "prefix",
      "num_dummy_heads",
      "rms_norm_eps",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "position_embeddings",
      "output_ws"
    ]
  },
  "Qwen2_5_VisionPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2_5_VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix",
      "use_data_parallel",
      "max_context_len"
    ],
    "get_window_index": [
      "self",
      "grid_thw"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "forward_with_cuda_graph": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "Qwen2_5_VLForConditionalGeneration": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "hf_to_sglang_mapper": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "_lora_pattern": [],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "post_process": [
      "self",
      "inputs_embeds",
      "modalities",
      "embeddings",
      "indices",
      "forward_batch"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "ArceeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch"
    ]
  },
  "ArceeAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix",
      "bias"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "ArceeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "ArceeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "ArceeForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "column_parallel_weights_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "ColumnParallelConv2dPatch": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MllamaPrecomputedAspectRatioEmbedding": {
    "__init__": [
      "self",
      "config",
      "is_gated"
    ],
    "forward": [
      "self",
      "hidden_state",
      "aspect_ratio_ids"
    ]
  },
  "MllamaPrecomputedPositionEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_state",
      "aspect_ratio_ids"
    ]
  },
  "MllamaVisionMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MllamaVisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "is_gated",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_state",
      "attention_mask"
    ]
  },
  "MllamaVisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "num_layers",
      "is_gated",
      "output_hidden_states",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "MllamaVisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "apply_class_embedding": [
      "self",
      "hidden_state"
    ],
    "forward": [
      "self",
      "pixel_values",
      "aspect_ratio_ids",
      "aspect_ratio_mask"
    ]
  },
  "MllamaTextRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "MllamaTextCrossAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "cross_attention_states",
      "forward_batch"
    ]
  },
  "MllamaCrossAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cross_attention_states",
      "cross_attention_mask",
      "full_text_row_masked_out_mask",
      "forward_batch"
    ]
  },
  "MllamaTextModel": {
    "config_class": [],
    "base_model_prefix": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "cross_attention_states",
      "cross_attention_mask",
      "full_text_row_masked_out_mask",
      "forward_batch",
      "skip_cross_attention"
    ]
  },
  "MllamaForCausalLM": {
    "config_class": [],
    "base_model_prefix": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "cross_attention_states",
      "cross_attention_mask",
      "full_text_row_masked_out_mask",
      "forward_batch",
      "skip_cross_attention"
    ]
  },
  "MllamaForConditionalGeneration": {
    "default_bitsandbytes_target_modules": [],
    "column_parallel_weights_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "_batch_image_inputs": [
      "self",
      "forward_batch"
    ],
    "flat_encoder_result": [
      "self",
      "cross_attention_states",
      "encoder_lens_need"
    ],
    "get_full_text_row_masked_out_mask": [
      "self",
      "forward_batch"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MistralForCausalLM": {},
  "Mistral3ForConditionalGeneration": {
    "MULTIMODAL_PROJECTOR_TYPE": [],
    "__init__": [
      "self"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "__getattr__": [
      "self",
      "name"
    ],
    "__hasattr__": [
      "self",
      "name"
    ],
    "__call__": [
      "self"
    ]
  },
  "cached_get_processor": [],
  "Glm4vRMSNorm": {
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vVisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vVisionBlock": {
    "__init__": [
      "self",
      "dim",
      "intermediate_dim",
      "num_heads",
      "quant_config",
      "prefix",
      "attn_qkv_bias",
      "num_dummy_heads",
      "rms_norm_eps",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin"
    ]
  },
  "Glm4vVisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_channels",
      "hidden_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vPatchMerger": {
    "__init__": [
      "self",
      "d_model",
      "context_dim",
      "quant_config",
      "bias",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Glm4vVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "embeddings",
      "lengths",
      "image_shapes",
      "h_coords",
      "w_coords"
    ]
  },
  "Glm4vVisionModel": {
    "__init__": [
      "self",
      "vision_config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "Glm4vForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "_pad_vit_attn_dummy_heads": [
      "self",
      "name",
      "loaded_weight"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ]
  },
  "MistralLarge3Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "MistralLarge3ForCausalLMEagle": {
    "remapping": [],
    "__init__": [
      "self"
    ]
  },
  "GPTBigCodeAttention": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GPTBigMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPTBigCodeBlock": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GPTBigCodeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "forward_batch"
    ]
  },
  "GPTBigCodeForCausalLM": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GraniteMoeMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "params_dtype",
      "quant_config",
      "tp_size",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GraniteMoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "max_position",
      "layer_id",
      "rope_theta",
      "quant_config",
      "attention_multiplier",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GraniteMoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GraniteMoeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ]
  },
  "GraniteMoeForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Sarashina2VisionForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_image_embeds": [
      "self",
      "pixel_values",
      "image_grid_thw"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GemmaMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GemmaAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "layer_id",
      "max_position_embeddings",
      "rope_theta",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GemmaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "GemmaModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "GemmaForCausalLM": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DynamicShortConvolutionKernelGenerator": {
    "__init__": [
      "self",
      "input_size",
      "hidden_size",
      "output_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DynamicShortConvolution": {
    "__init__": [
      "self",
      "hidden_size",
      "kernel_size",
      "generator_input_size",
      "generator_reduction",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_batch_to_continuous": [
      "self",
      "x"
    ],
    "_continuous_to_seqs": [
      "self",
      "x"
    ],
    "_seqs_to_batch": [
      "self",
      "seqs"
    ]
  },
  "JetBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "JetNemotronAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "JetNemotronDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "alt_stream",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "JetNemotronForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "InternAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "use_data_parallel",
      "aux_stream"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "output_ws"
    ]
  },
  "InternVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "_get_pos_embed": [
      "self",
      "pos_embed",
      "H",
      "W"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "InternRMSNorm": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "InternMLP": {
    "__init__": [
      "self",
      "config",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NORM2FN": [],
  "InternVisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "drop_path_rate",
      "quant_config",
      "use_data_parallel",
      "aux_stream"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "output_ws"
    ]
  },
  "InternVisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "output_hidden_states",
      "return_dict"
    ]
  },
  "InternVisionModel": {
    "main_input_name": [],
    "_supports_flash_attn_2": [],
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "use_data_parallel"
    ],
    "resize_pos_embeddings": [
      "self",
      "old_size",
      "new_size",
      "patch_size"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "output_hidden_states",
      "return_dict",
      "pixel_embeds"
    ]
  },
  "InternVLChatModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "use_flash_attn"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "KimiMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "layer_idx",
      "alt_stream"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "KimiDeltaAttention": {
    "__init__": [
      "self",
      "layer_idx",
      "hidden_size",
      "config",
      "quant_config",
      "rms_norm_eps",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions",
      "forward_batch",
      "zero_allocator"
    ]
  },
  "KimiDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "zero_allocator"
    ]
  },
  "KimiLinearModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "pp_proxy_tensors"
    ]
  },
  "KimiLinearForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GlmAsrForConditionalGeneration": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3_VisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "bias",
      "hidden_act",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3VLVisionPatchEmbed": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Qwen3_VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "intermediate_dim",
      "hidden_act",
      "norm_layer",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "rotary_pos_emb_cos",
      "rotary_pos_emb_sin",
      "output_ws"
    ]
  },
  "Qwen3VLMoeVisionPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "norm_layer",
      "spatial_merge_size",
      "use_postshuffle_norm",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3VLMoeVisionModel": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "fast_pos_embed_interpolate": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ],
    "forward_with_cuda_graph": [
      "self",
      "x",
      "grid_thw"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3LLMModel": {
    "__init__": [
      "self"
    ],
    "get_deepstack_embeds": [
      "self",
      "layer_idx",
      "input_deepstack_embeds"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors",
      "input_deepstack_embeds"
    ]
  },
  "Qwen3VLForConditionalGeneration": {
    "hf_to_sglang_mapper": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "language_model_cls"
    ],
    "separate_deepstack_embeds": [
      "self",
      "embedding"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "_lora_pattern": [],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_device_sm": [],
  "Glm4MoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ]
  },
  "Glm4MoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "partial_rotary_factor",
      "rope_scaling",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "attention_bias",
      "quant_config",
      "use_qk_norm",
      "prefix",
      "alt_stream"
    ],
    "op_prepare": [
      "self",
      "state"
    ],
    "op_core": [
      "self",
      "state"
    ],
    "forward_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward_core": [
      "self",
      "intermediate_state"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Glm4MoeGate": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Glm4MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "get_moe_weights": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_normal_dual_stream": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "_forward_shared_experts": [
      "self",
      "hidden_states"
    ],
    "op_gate": [
      "self",
      "state"
    ],
    "op_select_experts": [
      "self",
      "state"
    ],
    "op_dispatch_a": [
      "self",
      "state"
    ],
    "op_dispatch_b": [
      "self",
      "state"
    ],
    "op_experts": [
      "self",
      "state"
    ],
    "op_combine_a": [
      "self",
      "state"
    ],
    "op_combine_b": [
      "self",
      "state"
    ],
    "op_output": [
      "self",
      "state"
    ]
  },
  "Glm4MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "is_nextn",
      "prefix",
      "alt_stream"
    ],
    "_is_layer_sparse": [
      "self",
      "layer_id",
      "is_nextn"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ],
    "op_comm_prepare_attn": [
      "self",
      "state",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "tbo_subbatch_index"
    ],
    "op_comm_prepare_mlp": [
      "self",
      "state"
    ],
    "op_mlp": [
      "self",
      "state"
    ],
    "op_comm_postprocess_layer": [
      "self",
      "state"
    ]
  },
  "Glm4MoeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "Glm4MoeForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "determine_num_fused_shared_experts": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "GraniteMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GraniteAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GraniteDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "GraniteModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "GraniteForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "get_module_name_from_weight_name": [
      "self",
      "name"
    ],
    "get_num_params": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_weights_by_name": [
      "self",
      "name",
      "truncate_size",
      "tp_size"
    ]
  },
  "ApertusMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "use_reduce_scatter"
    ]
  },
  "ApertusAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix",
      "bias",
      "bias_o_proj"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "ApertusDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "ApertusModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "ApertusForCausalLM": {
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "default_bitsandbytes_target_modules": [],
    "column_parallel_weights_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_module_name_from_weight_name": [
      "self",
      "name"
    ],
    "get_num_params": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_embed": [
      "self"
    ],
    "set_embed": [
      "self",
      "embed"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "Glm4MoeLiteMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter",
      "gemm_output_zero_allocator"
    ]
  },
  "Glm4MoeLiteGate": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "is_nextn"
    ],
    "forward": [
      "self",
      "hidden_states",
      "gemm_output_zero_allocator"
    ]
  },
  "Glm4MoeLiteSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream",
      "is_nextn"
    ]
  },
  "Glm4MoeLiteDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "is_nextn",
      "prefix",
      "alt_stream"
    ]
  },
  "Glm4MoeLiteModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "Glm4MoeLiteForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "determine_num_fused_shared_experts": [
      "self",
      "architecture"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn",
      "params_dict",
      "is_eagle"
    ]
  },
  "MiMoConfig": [],
  "MiMoModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "MiMoForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "InternLM2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "InternLM2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "InternLMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "InternLM2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "InternLM2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OlmoAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OlmoMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OlmoDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OlmoModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "OlmoForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "OlmoeMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "tp_size",
      "layer_id",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "OlmoeAttention": {
    "__init__": [
      "self",
      "layer_id",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OlmoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "OlmoeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "OlmoeForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "get_activation": [
    "name"
  ],
  "OPTLearnedPositionalEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim"
    ],
    "forward": [
      "self",
      "positions"
    ]
  },
  "OPTAttention": {
    "__init__": [
      "self",
      "embed_dim",
      "num_heads",
      "layer_id",
      "bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OPTDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OPTDecoder": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "pp_proxy_tensors",
      "input_embeds"
    ]
  },
  "OPTModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "pp_proxy_tensors",
      "input_embeds"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "OPTForCausalLM": {
    "column_parallel_weights_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "pp_proxy_tensors",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_module_name_from_weight_name": [
      "self",
      "name"
    ],
    "get_num_params": [
      "self"
    ],
    "get_weights_by_name": [
      "self",
      "name",
      "truncate_size",
      "tp_size"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_embed": [
      "self"
    ],
    "set_embed": [
      "self",
      "embed"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "Qwen2MoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "x",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ]
  },
  "Qwen2MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "alt_stream",
      "prefix"
    ],
    "get_moe_weights": [
      "self"
    ],
    "_forward_shared_experts": [
      "self",
      "hidden_states"
    ],
    "_forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "_forward_router_experts": [
      "self",
      "hidden_states"
    ],
    "forward_normal_dual_stream": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "use_reduce_scatter"
    ]
  },
  "Qwen2MoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "qkv_bias",
      "quant_config",
      "dual_chunk_attention_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Qwen2MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "captured_last_layer_outputs"
    ]
  },
  "Qwen2MoeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "decoder_layer_type",
      "alt_stream"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layers_to_capture"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "Qwen2MoeForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "DeepseekModelNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "DeepseekV3ForCausalLMNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_get_alibi_slopes": [
    "total_num_heads"
  ],
  "BaiChuanMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "BaiChuanAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "position_embedding",
      "rope_theta",
      "max_position_embeddings",
      "quant_config",
      "layer_id",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BaiChuanDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "position_embedding",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "BaiChuanModel": {
    "__init__": [
      "self",
      "config",
      "position_embedding",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ]
  },
  "BaiChuanBaseForCausalLM": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "position_embedding",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BaichuanForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "Qwen3OmniMoeAudioEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens"
    ]
  },
  "SinusoidsPositionEmbedding": {
    "__init__": [
      "self",
      "length",
      "channels",
      "max_timescale"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "_get_feat_extract_output_lengths": [
    "input_lengths"
  ],
  "Qwen3OmniMoeAudioEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "_freeze_parameters": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "forward": [
      "self",
      "input_features",
      "feature_lens",
      "aftercnn_lens"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ]
  },
  "Qwen3OmniMoeVisionPatchMerger": {
    "__init__": [
      "self",
      "dim",
      "context_dim",
      "spatial_merge_size",
      "quant_config",
      "prefix",
      "use_postshuffle_norm"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen3OmniMoeVisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "deepstack_merger_list": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ]
  },
  "Qwen3OmniMoeThinkerForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ]
  },
  "Qwen3OmniMoeForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma3ImagePixelInputs": {},
  "Gemma3MultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "vision_outputs"
    ]
  },
  "Gemma3ForConditionalGeneration": {
    "config_class": [],
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "supports_lora": [],
    "lora_pattern": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "prepare_attn_masks": [
      "self",
      "input_ids",
      "positions",
      "mask_dtype"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "tie_weights": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepseekMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pack_params": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DeepseekAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "DeepseekDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "DeepseekModel": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "DeepseekForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NemotronHMLP": {
    "__init__": [
      "self",
      "config",
      "intermediate_size",
      "quant_config",
      "bias",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_alt_stream": [],
  "_get_or_create_alt_stream": [
    "device_module"
  ],
  "NemotronHMoE": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "_forward_core": [
      "self",
      "hidden_states"
    ],
    "_forward_core_normal": [
      "self",
      "hidden_states"
    ],
    "_forward_core_shared_routed_overlap": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "NemotronHMLPDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self"
    ]
  },
  "NemotronHMoEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self"
    ]
  },
  "NemotronHMambaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self"
    ]
  },
  "NemotronHAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "NemotronHAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self"
    ]
  },
  "Layers": [],
  "NemotronHModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "pp_proxy_tensors",
      "inputs_embeds"
    ]
  },
  "NemotronHForCausalLM": {
    "stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "remap_prefix": [],
    "remap_substr": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "copy_inputs_before_cuda_graphs": [
      "self",
      "input_buffers"
    ],
    "get_seqlen_agnostic_capture_inputs": [
      "self",
      "batch_size"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_mtp"
    ]
  },
  "expert_distribution_recorder": [],
  "_is_moe": [
    "config"
  ],
  "_get_cla_factor": [
    "config"
  ],
  "HunYuanMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "HunYuanSparseMoeBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "layer_id"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "get_head_dim": [
    "config"
  ],
  "check_head_dim": [
    "config"
  ],
  "HunYuanAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "prefix",
      "attention_type",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "kv_states"
    ]
  },
  "HunYuanDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "kv_states"
    ]
  },
  "HunYuanModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "HunYuanMoEV1ForCausalLM": {
    "packed_modules_mapping": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "_split_qkv_weight": [
      "self",
      "qkv"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "HunYuanDenseV1ForCausalLM": {},
  "Gemma2ForSequenceClassification": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PhiAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "position_ids",
      "forward_batch",
      "hidden_states"
    ]
  },
  "PhiMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PhiLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "idx"
    ],
    "forward": [
      "self",
      "position_ids",
      "forward_batch",
      "hidden_states"
    ]
  },
  "PhiModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "forward_batch",
      "positions",
      "inputs_embeds"
    ]
  },
  "PhiForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "XverseMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "XverseAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "XverseDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "XverseModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "XverseForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights",
      "name",
      "loaded_weight"
    ]
  },
  "SolarMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SolarAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "forward_batch",
      "hidden_states"
    ]
  },
  "SolarDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "SolarModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "pp_proxy_tensors"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "SolarForCausalLM": {
    "packed_modules_mapping": [],
    "default_bitsandbytes_target_modules": [],
    "column_parallel_weights_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Llama4VisionMLP": {
    "__init__": [
      "self",
      "input_size",
      "intermediate_size",
      "output_size",
      "bias",
      "output_activation",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "pixel_shuffle": [
    "input_tensor",
    "shuffle_ratio"
  ],
  "Llama4VisionPixelShuffleMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "encoded_patches"
    ]
  },
  "apply_position_embedding": [
    "q",
    "k",
    "freqs_ci",
    "shape"
  ],
  "Llama4VisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_state",
      "freqs_ci"
    ]
  },
  "Llama4VisionEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states",
      "freqs_ci"
    ]
  },
  "Llama4UnfoldConvolution": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "use_data_parallel"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4VisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Llama4ForConditionalGeneration": {
    "packed_modules_mapping": [],
    "lora_pattern": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_has_vision_weights": [
      "self",
      "config"
    ],
    "_check_vision_weights_in_index": [
      "self",
      "index_file"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "permute_qk_weight_for_rotary": [
      "self",
      "name",
      "loaded_weight"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_should_skip_weight": [
      "self",
      "name"
    ],
    "_transform_weight_name": [
      "self",
      "name"
    ],
    "_handle_scale_remapping": [
      "self",
      "name",
      "params_dict"
    ],
    "_handle_stacked_params": [
      "self",
      "name",
      "loaded_weight",
      "stacked_params_mapping",
      "params_dict",
      "loaded_params"
    ],
    "_handle_expert_weights": [
      "self",
      "name",
      "loaded_weight",
      "expert_params_mapping",
      "params_dict",
      "num_experts",
      "loaded_params"
    ],
    "_handle_other_expert_params": [
      "self",
      "name",
      "loaded_weight",
      "expert_params_mapping",
      "params_dict",
      "loaded_params"
    ],
    "_transform_expert_name": [
      "self",
      "name",
      "is_weight"
    ],
    "_handle_expert_scale_params": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "num_experts",
      "loaded_params"
    ],
    "_handle_expert_weight_params": [
      "self",
      "name",
      "loaded_weight",
      "params_dict",
      "num_experts",
      "loaded_params"
    ],
    "_handle_default_weight": [
      "self",
      "name",
      "loaded_weight",
      "params_dict"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_embed": [
      "self"
    ],
    "set_embed": [
      "self",
      "embed"
    ],
    "get_hidden_dim": [
      "self",
      "module_name",
      "layer_idx"
    ]
  },
  "YiVLForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "YiVLMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "USE_XFORMERS_OPS": [],
  "PATCH_MERGE": [],
  "VisionEncoderArgs": {},
  "PixtralForConditionalGeneration": {
    "merge_by_field_config": [],
    "get_placeholder_str": [
      "cls",
      "modality",
      "i"
    ],
    "__init__": [
      "self"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_language_model": [
      "self"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "compute_logits": [
      "self",
      "hidden_states"
    ],
    "get_embed_and_head": [
      "self"
    ]
  },
  "PatchMerger": {
    "__init__": [
      "self",
      "vision_encoder_dim",
      "spatial_merge_size",
      "use_mlp_bias"
    ],
    "forward": [
      "self",
      "x",
      "image_sizes"
    ],
    "permute": [
      "self",
      "x",
      "image_sizes"
    ]
  },
  "get_sub_grids": [
    "x",
    "image_sizes",
    "spatial_merge_size"
  ],
  "VisionTransformer": {
    "__init__": [
      "self",
      "args"
    ],
    "max_patches_per_side": [
      "self"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "freqs_cis": [
      "self"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "position_meshgrid": [
    "patch_embeds_list"
  ],
  "PixtralHFMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VisionLanguageAdapter": {
    "__init__": [
      "self",
      "args",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PixtralHFTransformerBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_embeddings"
    ]
  },
  "_reshape_for_broadcast": [
    "freqs_cis",
    "x"
  ],
  "precompute_freqs_cis_2d": [
    "dim",
    "height",
    "width",
    "theta"
  ],
  "apply_rotary_emb_vit": [
    "xq",
    "xk",
    "freqs_cis"
  ],
  "FeedForward": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "freqs_cis"
    ]
  },
  "TransformerBlock": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "freqs_cis"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "args"
    ],
    "forward": [
      "self",
      "x",
      "mask",
      "freqs_cis"
    ]
  },
  "PixtralHFTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x",
      "attention_mask",
      "position_embeddings",
      "return_all_hidden_states"
    ]
  },
  "resolve_visual_encoder_outputs": [
    "outputs",
    "feature_sample_layers",
    "post_norm",
    "num_hidden_layers"
  ],
  "PixtralHFVisionModel": {
    "DEFAULT_IMAGE_TOKEN_ID": [],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "image_sizes",
      "output_hidden_states",
      "feature_sample_layers"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PixtralVisionModel": {},
  "Grok1MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "quant_config",
      "prefix",
      "reduce_results",
      "use_presharded_weights",
      "split_gate_up"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Grok1MoE": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "params_dtype",
      "quant_config",
      "tp_size",
      "reduce_results",
      "use_presharded_weights",
      "inplace",
      "no_combine",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "get_rope_scaling": [
    "config"
  ],
  "ScalingRotaryEmbedding": {
    "__init__": [
      "self",
      "head_size",
      "rotary_dim",
      "max_position_embeddings",
      "base",
      "is_neox_style",
      "scaling_factor",
      "dtype"
    ],
    "_compute_inv_freq": [
      "self",
      "scaling_factor"
    ],
    "_compute_cos_sin_cache": [
      "self"
    ]
  },
  "Grok1Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "max_position",
      "rope_theta",
      "quant_config",
      "reduce_results",
      "alt_stream",
      "load_presharded_attn",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Grok1DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "load_presharded_moe",
      "load_presharded_attn",
      "load_presharded_mlp",
      "alt_stream",
      "skip_moe",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "deferred_norm"
    ],
    "moe_with_rmoe": [
      "self",
      "x"
    ]
  },
  "Grok1Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "load_presharded_moe",
      "load_presharded_embedding",
      "load_presharded_attn",
      "load_presharded_mlp",
      "replicate_embedding",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Grok1ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights",
      "ignore_parent_name",
      "check_hit_names",
      "model_config"
    ],
    "get_num_params_analytical": [
      "self"
    ],
    "get_num_params_torch": [
      "self"
    ]
  },
  "old_prepare_weights": [],
  "_prepare_presharded_weights": [
    "self",
    "model_name_or_path",
    "revision",
    "fall_back_to_pt"
  ],
  "Grok1ModelForCausalLM": {},
  "Projector": {
    "__init__": [
      "self",
      "text_config",
      "vision_config",
      "prefix"
    ],
    "forward": [
      "self",
      "image_features",
      "image_grid_thw"
    ]
  },
  "SiglipVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "interpolate_pos_encoding": [
      "self",
      "embeddings",
      "height",
      "width",
      "is_after_patchify"
    ],
    "fetch_position_embedding_lfu_cache": [
      "self",
      "embeddings",
      "h",
      "w",
      "max_cache"
    ],
    "forward": [
      "self",
      "pixel_values",
      "position_ids",
      "image_grid_thw",
      "interpolate_pos_encoding"
    ]
  },
  "SigLIPRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "rope_init": [
      "self"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "SiglipMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "SiglipEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rope_emb"
    ]
  },
  "SiglipEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "flatten_list": [
      "image_grid_thw"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "cu_seqlens",
      "image_grid_thw",
      "height_position_ids",
      "width_position_ids"
    ]
  },
  "SiglipVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "position_ids",
      "height_position_ids",
      "width_position_ids",
      "cu_seqlens",
      "image_grid_thw"
    ]
  },
  "SiglipVisionModel": {
    "config_class": [],
    "main_input_name": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values",
      "interpolate_pos_encoding",
      "position_ids",
      "image_grid_thw",
      "cu_seqlens"
    ]
  },
  "PaddleOCRVLForConditionalGeneration": {
    "__init__": [
      "self"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "encode_image": [
      "self",
      "pixel_values",
      "image_grid_thw"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "get_input_embeddings": [
    "self"
  ],
  "_AUDIO_PLACEHOLDER_TOKEN_ID": [],
  "ConformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "ext_pw_out_channel",
      "depthwise_seperable_out_channel",
      "depthwise_multiplier",
      "n_head",
      "d_ffn",
      "ext_pw_kernel_size",
      "kernel_size",
      "dropout_rate",
      "causal",
      "batch_norm",
      "activation",
      "chunk_se",
      "chunk_size",
      "conv_activation",
      "conv_glu_type",
      "bias_in_glu",
      "linear_glu_in_convm",
      "attention_inner_dim",
      "attention_glu_type",
      "activation_checkpointing",
      "export",
      "use_pt_scaled_dot_product_attention",
      "attn_group_sizes"
    ],
    "forward": [
      "self",
      "x",
      "pos_k",
      "pos_v",
      "mask",
      "relative_attention_bias"
    ]
  },
  "TransformerEncoderBase": {
    "__init__": [
      "self",
      "input_size",
      "chunk_size",
      "left_chunk",
      "attention_dim",
      "attention_heads",
      "input_layer",
      "cnn_out",
      "cnn_layer_norm",
      "time_reduction",
      "dropout_rate",
      "padding_idx",
      "relative_attention_bias_args",
      "positional_dropout_rate",
      "nemo_conv_settings",
      "conv2d_extra_padding",
      "attention_group_size",
      "encoder_embedding_config"
    ],
    "compute_lens_change": [
      "self",
      "feature_lens"
    ],
    "forward": [
      "self"
    ],
    "_chunk_size_selection": [
      "self",
      "chunk_size",
      "left_chunk"
    ],
    "_get_embed_class": [
      "self",
      "embed"
    ],
    "_forward_embeddings_core": [
      "self",
      "input_tensor",
      "masks"
    ],
    "_position_embedding": [
      "self",
      "input_tensor"
    ],
    "_streaming_mask": [
      "self",
      "seq_len",
      "batch_size",
      "chunk_size",
      "left_chunk"
    ],
    "forward_embeddings": [
      "self",
      "xs_pad",
      "masks",
      "chunk_size_nc",
      "left_chunk_nc"
    ],
    "get_offset": [
      "self"
    ]
  },
  "ConformerEncoder": {
    "__init__": [
      "self",
      "input_size",
      "chunk_size",
      "left_chunk",
      "num_lang",
      "attention_dim",
      "attention_heads",
      "linear_units",
      "num_blocks",
      "dropout_rate",
      "input_layer",
      "causal",
      "batch_norm",
      "cnn_out",
      "cnn_layer_norm",
      "ext_pw_out_channel",
      "ext_pw_kernel_size",
      "depthwise_seperable_out_channel",
      "depthwise_multiplier",
      "chunk_se",
      "kernel_size",
      "activation",
      "conv_activation",
      "conv_glu_type",
      "bias_in_glu",
      "linear_glu_in_convm",
      "attention_glu_type",
      "export",
      "extra_layer_output_idx",
      "extra_multi_layer_output_idxs",
      "activation_checkpointing",
      "relative_attention_bias_args",
      "time_reduction",
      "use_pt_scaled_dot_product_attention",
      "nemo_conv_settings",
      "conv2d_extra_padding",
      "replication_pad_for_subsample_embedding",
      "attention_group_size",
      "encoder_embedding_config"
    ],
    "init_relative_attention_bias": [
      "self",
      "input_tensor"
    ],
    "calculate_hs_mask": [
      "self",
      "xs_pad",
      "device",
      "mask"
    ],
    "forward": [
      "self",
      "xs_pad",
      "masks"
    ]
  },
  "WindowQformer": {
    "__init__": [
      "self",
      "window_size",
      "num_queries",
      "num_blocks",
      "attention_dim",
      "attention_heads",
      "linear_units",
      "dropout_rate",
      "normalize_before"
    ],
    "forward": [
      "self",
      "audio_embed",
      "mask",
      "embed_len"
    ]
  },
  "AudioEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "set_audio_embeds": [
      "self",
      "input_embeds"
    ],
    "set_audio_embed_sizes": [
      "self",
      "audio_embed_sizes"
    ],
    "get_audio_features": [
      "self",
      "input_embeds",
      "audio_attention_mask",
      "audio_projection_mode"
    ],
    "forward": [
      "self",
      "audio_features",
      "audio_attention_mask",
      "audio_projection_mode"
    ]
  },
  "MixtralMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "params_dtype",
      "quant_config",
      "tp_size",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MixtralAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "max_position",
      "rope_theta",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "MixtralDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "MixtralModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "MixtralForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BertConfig": [],
  "BertEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ]
  },
  "BertPooler": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BertEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BertLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BertAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "layer_norm_eps",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BertSelfAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BertSelfOutput": {
    "__init__": [
      "self",
      "hidden_size",
      "layer_norm_eps",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BertIntermediate": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BertOutput": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "layer_norm_eps",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "input_tensor"
    ]
  },
  "BertModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Contriever": {},
  "BertForSequenceClassification": {
    "__init__": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ]
  },
  "Llama4MoE": {
    "custom_routing_function": [
      "hidden_states",
      "gating_output",
      "topk",
      "renormalize"
    ],
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "use_reduce_scatter"
    ],
    "_forward_core": [
      "self",
      "hidden_states",
      "forward_mode"
    ],
    "_forward_core_normal": [
      "self",
      "hidden_states"
    ],
    "_forward_core_shared_routed_overlap": [
      "self",
      "hidden_states"
    ]
  },
  "Llama4Attention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "bias",
      "bias_o_proj",
      "prefix"
    ],
    "_get_attn_scale": [
      "self",
      "positions"
    ],
    "_mul_attn_scale": [
      "self",
      "positions",
      "q"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Llama4DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "_is_moe_layer": [
      "self",
      "layer_id"
    ],
    "get_intermediate_size": [
      "self"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "Llama4Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "Llama4ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_layers": [
      "self"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "MixtralMLP": {
    "__init__": [
      "self",
      "num_experts",
      "hidden_size",
      "intermediate_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "QuantMixtralForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "JetVLMDownSample2x2BlockFix": {
    "forward": [
      "self",
      "x"
    ]
  },
  "JetVLMMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "JetVLMForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "get_image_feature": [
      "self",
      "mm_input"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ]
  },
  "get_attention_sliding_window_size": [
    "config"
  ],
  "Gemma2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "hidden_activation",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma2Attention": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "max_position_embeddings",
      "rope_theta",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Gemma2DecoderLayer": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "Gemma2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Gemma2ForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "supports_lora": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_get_llama_4_attn_scale": [
    "positions_ids",
    "beta",
    "max_position_embeddings"
  ],
  "Ministral3Attention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix",
      "bias"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Ministral3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ]
  },
  "Ministral3Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "Ministral3ForCausalLM": {
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "DotsVLMForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_pad_vit_attn_dummy_heads": [
      "self",
      "name",
      "loaded_weight"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "pp_proxy_tensors"
    ]
  },
  "NVILAConfig": {
    "model_type": [],
    "sub_configs": [],
    "_auto_class": [],
    "__init__": [
      "self"
    ]
  },
  "NVILAMultiModalProjectorDownsampleBlock": {
    "forward": [
      "self",
      "x"
    ]
  },
  "NVILAMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NVILAForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "get_image_feature": [
      "self",
      "mm_input"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ]
  },
  "merge_chessboard": [
    "x",
    "num_split_h",
    "num_split_w"
  ],
  "merge_features_for_dynamic_s2": [
    "image_features",
    "block_sizes"
  ],
  "split_chessboard": [
    "x",
    "num_split_h",
    "num_split_w"
  ],
  "WeightsMapping": [],
  "WeightsMapper": {
    "_map_name": [
      "self",
      "key"
    ],
    "apply": [
      "self",
      "weights"
    ],
    "apply_list": [
      "self",
      "values"
    ],
    "apply_dict": [
      "self",
      "values"
    ]
  },
  "enable_fused_set_kv_buffer": [
    "forward_batch"
  ],
  "create_fused_set_kv_buffer_arg": [
    "value",
    "layer",
    "forward_batch"
  ],
  "permute_inv": [
    "perm"
  ],
  "compute_cu_seqlens_from_grid_numpy": [
    "grid_thw"
  ],
  "RotaryPosMixin": {
    "rot_pos_ids": [
      "h",
      "w",
      "spatial_merge_size"
    ]
  },
  "apply_qk_norm": [
    "q",
    "k",
    "q_norm",
    "k_norm",
    "head_dim",
    "alt_stream",
    "allow_inplace"
  ],
  "fused_inplace_qknorm": [],
  "_resolve_tuple2": [
    "x"
  ],
  "calculate_mel_frames_dasheng": [
    "audio_length_samples",
    "n_fft",
    "hop_size",
    "dasheng_subsampling",
    "center",
    "model_subsampling"
  ],
  "AudioPatchEmbed": {
    "__init__": [
      "self",
      "input_size",
      "patch_size",
      "patch_stride",
      "in_chans",
      "embed_dim",
      "norm_layer",
      "flatten"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerScale": {
    "__init__": [
      "self",
      "dim",
      "init_values",
      "inplace"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DashengMlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DashengAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "qkv_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "DashengBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "init_values",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "DashengFrontend": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "waveform"
    ]
  },
  "DashengAudioTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward_features": [
      "self",
      "x",
      "mask"
    ],
    "_to_mask": [
      "self",
      "lengths",
      "max_length"
    ],
    "forward": [
      "self",
      "x",
      "x_length"
    ]
  },
  "AudioProjectorSubsample": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "downsample_rate",
      "dtype",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "MiDashengLMModel": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ]
  },
  "TConfig": [],
  "Qwen3MoeConfig": [],
  "compute_yarn_parameters": [
    "config"
  ],
  "Qwen3MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "get_moe_weights": [
      "self"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "op_gate": [
      "self",
      "state"
    ],
    "op_select_experts": [
      "self",
      "state"
    ],
    "op_dispatch_a": [
      "self",
      "state"
    ],
    "op_dispatch_b": [
      "self",
      "state"
    ],
    "op_experts": [
      "self",
      "state"
    ],
    "op_combine_a": [
      "self",
      "state"
    ],
    "op_combine_b": [
      "self",
      "state"
    ],
    "op_output": [
      "self",
      "state"
    ]
  },
  "Qwen3MoeAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "attention_bias",
      "config",
      "quant_config",
      "prefix",
      "dual_chunk_attention_config",
      "alt_stream"
    ],
    "op_prepare": [
      "self",
      "state"
    ],
    "op_core": [
      "self",
      "state"
    ],
    "forward_prepare_npu": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward_prepare_native": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "apply_qk_norm_rope": [
      "self",
      "qkv",
      "positions",
      "forward_batch"
    ],
    "forward_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward_core": [
      "self",
      "intermediate_state"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Qwen3MoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "captured_last_layer_outputs"
    ],
    "op_comm_prepare_attn": [
      "self",
      "state",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "tbo_subbatch_index"
    ],
    "op_comm_prepare_mlp": [
      "self",
      "state"
    ],
    "op_mlp": [
      "self",
      "state"
    ],
    "op_comm_postprocess_layer": [
      "self",
      "state"
    ]
  },
  "Qwen3MoeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "decoder_layer_type"
    ]
  },
  "Qwen3MoeForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "Ernie4ModelMTP": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "prefix",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Ernie4_5_MoeForCausalLMMTP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "mtp_layer_id"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ]
  },
  "maybe_prefix": [
    "prefix",
    "name"
  ],
  "sglang_flash_attention_forward": [
    "module",
    "query",
    "key",
    "value",
    "attention_mask",
    "forward_batch",
    "scaling",
    "attention_instances"
  ],
  "HFColumnParallelLinear": {
    "forward": [
      "self",
      "input"
    ]
  },
  "HFRowParallelLinear": {
    "forward": [
      "self",
      "input"
    ]
  },
  "replace_linear_class": [
    "linear",
    "style",
    "quant_config"
  ],
  "TransformersForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "log_replacement": [
      "self",
      "name",
      "old_module",
      "new_module"
    ],
    "tensor_parallel": [
      "self",
      "tp_size"
    ],
    "replace_vocab_embed_class": [
      "self",
      "module"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoV2FlashConfig": [],
  "MiMoV2MTPLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "MiMoV2ModelNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "MiMoV2MTP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn"
    ],
    "map_model_name_to_mtp_param_name": [
      "self",
      "name"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ]
  },
  "Glm4vMoeForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "determine_num_fused_shared_experts": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn"
    ]
  },
  "extract_layer_index": [
    "prefix"
  ],
  "Gemma3MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_activation",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3Attention": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "naive_attn_with_masks": [
      "self",
      "q",
      "k",
      "v",
      "out"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "forward_batch"
    ]
  },
  "Gemma3DecoderLayer": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "position_embeddings_global",
      "position_embeddings_local",
      "forward_batch"
    ]
  },
  "Gemma3RotaryEmbedding": {
    "__init__": [
      "self",
      "config",
      "device"
    ],
    "_dynamic_frequency_update": [
      "self",
      "position_ids",
      "device"
    ],
    "forward": [
      "self",
      "x",
      "position_ids"
    ]
  },
  "Gemma3TextScaledWordEmbedding": {
    "__init__": [
      "self",
      "num_embeddings",
      "embedding_dim",
      "padding_idx",
      "embed_scale"
    ],
    "forward": [
      "self",
      "input_ids"
    ]
  },
  "Gemma3TextModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Gemma3ForCausalLM": {
    "config_class": [],
    "_tied_weights_keys": [],
    "_tp_plan": [],
    "_pp_plan": [],
    "base_model_prefix": [],
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "supports_lora": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LoraConfig": [],
  "LLaDA2MoeMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "use_reduce_scatter"
    ]
  },
  "LLaDA2MoeGate": {
    "__init__": [
      "self",
      "config",
      "params_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LLaDA2MoeSparseMoeBlock": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "alt_stream",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "use_reduce_scatter"
    ],
    "get_moe_weights": [
      "self"
    ],
    "_forward_shared_experts": [
      "self",
      "hidden_states"
    ],
    "_forward_router_experts": [
      "self",
      "hidden_states"
    ],
    "forward_normal_dual_stream": [
      "self",
      "hidden_states"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "use_reduce_scatter"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "LLaDA2MoeAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "reduce_results",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "LLaDA2MoeBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "_is_layer_sparse": [
      "self",
      "config",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "LLaDA2MoeModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "alt_stream",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "LLaDA2MoeModelLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "GPT2Attention": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GPT2MLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GPT2Block": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GPT2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "forward_batch"
    ]
  },
  "GPT2LMHeadModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "FalconH1MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "layer_id",
      "mlp_multipliers",
      "quant_config",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "use_reduce_scatter"
    ]
  },
  "FalconH1HybridAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "_init_mup_vector": [
      "self"
    ],
    "self_attention": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "forward_batch"
    ]
  },
  "FalconH1Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ]
  },
  "FalconH1ForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_mtp"
    ]
  },
  "OrionMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OrionAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "layer_id",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OrionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "OrionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "pp_proxy_tensors"
    ]
  },
  "OrionForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MoEGate": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Ernie4Moe": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "forward_normal": [
      "self",
      "hidden_states"
    ]
  },
  "Ernie4DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "is_mtp"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "Ernie4Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Ernie4_5_ForCausalLM": {
    "packed_modules_mapping": [],
    "stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ]
  },
  "Ernie4_5_MoeForCausalLM": {
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2ForRewardModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "CLIPVisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "CLIPTextEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "inputs_embeds"
    ]
  },
  "CLIPMLP": {
    "__init__": [
      "self",
      "config",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CLIPEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "act_layer",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "causal_attention_mask"
    ]
  },
  "CLIPEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "attention_mask",
      "causal_attention_mask",
      "return_all_hidden_states"
    ]
  },
  "CLIPTextTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids"
    ]
  },
  "CLIPTextModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids"
    ]
  },
  "CLIPVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "CLIPVisionModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "device": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "CLIPModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "monkey_patch_weight_loader": [],
  "_flatten_embeddings": [
    "embeddings"
  ],
  "_embedding_count_expression": [
    "embeddings"
  ],
  "_merge_multimodal_embeddings": [
    "inputs_embeds",
    "multimodal_embeddings",
    "is_multimodal"
  ],
  "isin_list": [
    "elements",
    "test_elements_list"
  ],
  "merge_multimodal_embeddings": [
    "input_ids",
    "inputs_embeds",
    "multimodal_embeddings",
    "placeholder_token_id"
  ],
  "MlpProjector": {
    "__init__": [
      "self",
      "projector_type",
      "input_dim",
      "n_embed",
      "depth",
      "mlp_ratio",
      "downsample_ratio"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm2d": {
    "__init__": [
      "self",
      "num_channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MLPBlock": {
    "__init__": [
      "self",
      "embedding_dim",
      "mlp_dim",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "add_decomposed_rel_pos": [
    "q",
    "rel_pos_h",
    "rel_pos_w",
    "q_size",
    "k_size"
  ],
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_unpartition": [
    "windows",
    "window_size",
    "pad_hw",
    "hw"
  ],
  "Block": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "input_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "PatchEmbed": {
    "__init__": [
      "self",
      "kernel_size",
      "stride",
      "padding",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "get_abs_pos_sam": [
    "abs_pos",
    "tgt_size"
  ],
  "ImageEncoderViT": {
    "__init__": [
      "self",
      "img_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "depth",
      "num_heads",
      "mlp_ratio",
      "out_chans",
      "qkv_bias",
      "norm_layer",
      "act_layer",
      "use_abs_pos",
      "use_rel_pos",
      "rel_pos_zero_init",
      "window_size",
      "global_attn_indexes"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_build_sam": [
    "encoder_embed_dim",
    "encoder_depth",
    "encoder_num_heads",
    "encoder_global_attn_indexes",
    "checkpoint"
  ],
  "build_sam_vit_b": [
    "checkpoint"
  ],
  "get_abs_pos": [
    "abs_pos",
    "tgt_size"
  ],
  "NoTPAttention": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "quick_gelu": [
    "x"
  ],
  "NoTPFeedForward": {
    "__init__": [
      "self",
      "cfg",
      "dim",
      "hidden_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNormfp32": {
    "forward": [
      "self",
      "x"
    ]
  },
  "NoTPTransformerBlock": {
    "__init__": [
      "self",
      "cfg",
      "layer_id",
      "multiple_of"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NoTPTransformer": {
    "__init__": [
      "self",
      "cfg"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "VitModel": {
    "__init__": [
      "self",
      "cfg",
      "freeze_embed",
      "freeze_pre_norm"
    ],
    "dtype": [
      "self"
    ],
    "set_input_tensor": [
      "self",
      "input_tensor"
    ],
    "__str__": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "patch_embeds"
    ]
  },
  "vit_model_cfg": [],
  "build_clip_l": [],
  "DeepseekOCRForCausalLM": {
    "__init__": [
      "self"
    ],
    "_parse_and_validate_image_input": [
      "self"
    ],
    "_pixel_values_to_embedding": [
      "self",
      "pixel_values",
      "images_crop",
      "images_spatial_crop"
    ],
    "_process_image_input": [
      "self",
      "mm_items"
    ],
    "get_language_model": [
      "self"
    ],
    "get_multimodal_embeddings": [
      "self"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids",
      "multimodal_embeddings"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3MoeLLMModel": {
    "__init__": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_deepstack_embeds": [
      "self",
      "layer_idx",
      "input_deepstack_embeds"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors",
      "input_deepstack_embeds"
    ]
  },
  "load_fused_expert_weights": [
    "name",
    "params_dict",
    "loaded_weight",
    "shard_id",
    "num_experts"
  ],
  "Qwen3VLMoeForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "language_model_cls"
    ],
    "_lora_pattern_moe": [],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "QWenMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QWenAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "max_position_embeddings",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "QWenBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "QWenModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ]
  },
  "QWenLMHeadModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4MoeModelNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Glm4MoeForCausalLMNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaForSequenceClassification": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaForSequenceClassificationWithNormal_Weights": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "tensor_torch2ms": [
    "x"
  ],
  "tensor_ms2torch": [
    "x"
  ],
  "LowerTriangularMask": {
    "__init__": [
      "self",
      "dtype",
      "max_model_len",
      "decode_mask_coeff"
    ],
    "create_mask": [
      "self",
      "query_lens_np",
      "seq_lens_np"
    ],
    "gen_attention_mask": [
      "self",
      "is_prefill",
      "position_ids",
      "query_lens_np",
      "seq_lens_np"
    ]
  },
  "MindSporeForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_arch": [
      "self",
      "config"
    ],
    "use_mla": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_kvcache": [
      "self",
      "forward_batch"
    ],
    "prepare_inputs": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ]
  },
  "XverseMoE": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pack_params": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "XverseMoeForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LoopGateProjection": {
    "__init__": [
      "self",
      "total_num_heads",
      "head_dim",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "query"
    ]
  },
  "LoopCoderAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "max_position",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "loop_idx",
      "gate_proj"
    ]
  },
  "LoopCoderDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "loop_idx",
      "gate_proj"
    ]
  },
  "IQuestLoopCoderModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "IQuestLoopCoderForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoMultiTokenPredictorLayer": {
    "__init__": [
      "self",
      "config",
      "prefix",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "MiMoMTP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "map_model_name_to_mtp_param_name": [
      "self",
      "name"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ]
  },
  "ExaoneGatedMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ExaoneAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "ExaoneDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "ExaoneModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "ExaoneForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen2ForCausalLMEagle": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DeepseekVL2MlpProjector": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DeepseekVL2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_vision_module": [
      "self",
      "vision_config",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ]
  },
  "gate_up_proj_weight_loader": [
    "self",
    "param",
    "loaded_weight",
    "loaded_shard_id"
  ],
  "LlamaMLP": {
    "_tp_plan": [],
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "qkv_proj_weight_loader": [
    "self",
    "param",
    "loaded_weight",
    "loaded_shard_id"
  ],
  "LlamaAttention": {
    "_tp_plan": [],
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "rope_is_neox_style",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "LlamaDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "LlamaModel": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "TorchNativeLlamaForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "get_module_name_from_weight_name": [
      "self",
      "name"
    ],
    "get_num_params": [
      "self"
    ],
    "load_weights_to_module": [
      "self",
      "fqn",
      "weights"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "TorchNativePhi3ForCausalLM": {},
  "InternS1ForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "use_flash_attn"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "_mapping_interns1_name": [
      "self",
      "name"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiniCPMMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiniCPMAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "MiniCPMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "MiniCPMModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "MiniCPMForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DotsOCRForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "_pad_vit_attn_dummy_heads": [
      "self",
      "name",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ]
  },
  "Idefics2VisionMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Idefics2EncoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens"
    ]
  },
  "Idefics2Encoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "inputs_embeds",
      "cu_seqlens"
    ]
  },
  "Idefics2VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "get_position_ids": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "tgt_sizes"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "tgt_sizes"
    ]
  },
  "Idefics2VisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "require_post_norm",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "compute_cu_seqlens": [
      "self",
      "tgt_sizes",
      "input_embeds"
    ],
    "forward": [
      "self",
      "pixel_values",
      "patch_attention_mask",
      "tgt_sizes"
    ]
  },
  "LongcatFlashMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LongcatFlashRouter": {
    "__init__": [
      "self",
      "config",
      "zero_expert_num",
      "rounter_params_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "LongcatFlashMoE": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ],
    "get_moe_weights": [
      "self"
    ]
  },
  "LongcatFlashDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "zero_allocator"
    ],
    "forward_mlp": [
      "self",
      "hidden_states",
      "positions",
      "residual",
      "forward_batch",
      "zero_allocator"
    ]
  },
  "LongcatFlashModel": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "LongcatFlashForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "post_load_weights": [
      "self",
      "weight_names"
    ],
    "_weight_requant_ue8m0": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "MiniCPM3MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MiniCPM3AttentionMLA": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "layer_id",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "MiniCPM3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "MiniCPM3Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "MiniCPM3ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_ffn_mult_to_intermediate_size": [
    "ffn_mult",
    "n_embd"
  ],
  "_find_multiple": [
    "n",
    "k"
  ],
  "DeciLMDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "DeciModel": {
    "__init__": [
      "self"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "pp_proxy_tensors"
    ]
  },
  "DeciLMForCausalLM": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "mistral_mapping": [],
    "__init__": [
      "self"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaForCausalLMEagle": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MiMoV2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ]
  },
  "MiMoV2MoE": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "is_nextn"
    ],
    "get_moe_weights": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "MiMoV2Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "v_head_dim",
      "v_scale",
      "sliding_window_size",
      "attention_bias",
      "attention_sink_bias",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "partial_rotary_factor",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "MiMoV2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "captured_last_layer_outputs"
    ],
    "is_moe_layer": [
      "self",
      "layer_idx"
    ],
    "is_swa_layer": [
      "self"
    ]
  },
  "MiMoV2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "decoder_layer_type"
    ],
    "get_input_embedding": [
      "self",
      "input_ids"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layers_to_capture"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "MiMoV2FlashForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "routed_experts_weights_of_layer": [
      "self"
    ],
    "get_input_embedding": [
      "self",
      "input_ids"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "layer_norm_func": [
    "hidden_states",
    "weight",
    "variance_epsilon"
  ],
  "CohereMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CohereAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "CohereDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "CohereModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ]
  },
  "CohereForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Cohere2ForCausalLM": {},
  "ModelArgs": {},
  "named_apply": [
    "fn",
    "module",
    "name",
    "depth_first",
    "include_root"
  ],
  "VQ_16": [],
  "VQ_models": [],
  "_ntuple": [
    "n"
  ],
  "_trunc_normal_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "trunc_normal_tf_": [
    "tensor",
    "mean",
    "std",
    "a",
    "b"
  ],
  "to_2tuple": [],
  "Format": {
    "NCHW": [],
    "NHWC": [],
    "NCL": [],
    "NLC": []
  },
  "nchw_to": [
    "x",
    "fmt"
  ],
  "resample_patch_embed": [
    "patch_embed",
    "new_size",
    "interpolation",
    "antialias",
    "verbose"
  ],
  "Mlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "norm_layer",
      "bias",
      "drop",
      "use_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "drop_path": [
    "x",
    "drop_prob",
    "training",
    "scale_by_keep"
  ],
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob",
      "scale_by_keep"
    ],
    "forward": [
      "self",
      "x"
    ],
    "extra_repr": [
      "self"
    ]
  },
  "VisionTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "qkv_bias",
      "qk_norm",
      "proj_drop",
      "attn_drop",
      "init_values",
      "drop_path",
      "act_layer",
      "norm_layer",
      "mlp_layer"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerType": [],
  "PatchDropout": {
    "__init__": [
      "self",
      "prob",
      "num_prefix_tokens",
      "ordered",
      "return_indices"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "resample_abs_pos_embed": [
    "posemb",
    "new_size",
    "old_size",
    "num_prefix_tokens",
    "interpolation",
    "antialias",
    "verbose"
  ],
  "init_weights": [
    "self"
  ],
  "init_weights_vit_timm": [
    "module",
    "name"
  ],
  "model_name_to_cls": [
    "cls_name"
  ],
  "vision_head": {
    "__init__": [
      "self",
      "params"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SigLIP_MODEL_CONFIG": [],
  "create_siglip_vit": [
    "model_name",
    "image_size",
    "select_layer",
    "ckpt_path"
  ],
  "Normalize": [
    "in_channels",
    "norm_type"
  ],
  "CLIPVisionTower": {
    "__init__": [
      "self",
      "model_name",
      "image_size",
      "select_feature",
      "select_layer",
      "select_layers",
      "ckpt_path",
      "pixel_mean",
      "pixel_std"
    ],
    "device": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "build_vision_tower": [
      "self",
      "vision_tower_params"
    ],
    "feature_select": [
      "self",
      "image_forward_outs"
    ],
    "forward": [
      "self",
      "images"
    ]
  },
  "_HAS_FUSED_ATTN": [],
  "_EXPORTABLE": [],
  "use_fused_attn": [
    "experimental"
  ],
  "AttentionPoolLatent": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "embed_dim",
      "num_heads",
      "feat_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_norm",
      "latent_len",
      "latent_dim",
      "pos_embed",
      "pool_type",
      "norm_layer",
      "drop"
    ],
    "init_weights": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Encoder": {
    "__init__": [
      "self",
      "in_channels",
      "ch",
      "ch_mult",
      "num_res_blocks",
      "norm_type",
      "dropout",
      "resamp_with_conv",
      "z_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "z_channels",
      "ch",
      "ch_mult",
      "num_res_blocks",
      "norm_type",
      "dropout",
      "resamp_with_conv",
      "out_channels"
    ],
    "last_layer": [
      "self"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "VectorQuantizer": {
    "__init__": [
      "self",
      "n_e",
      "e_dim",
      "beta",
      "entropy_loss_ratio",
      "l2_norm",
      "show_usage"
    ],
    "forward": [
      "self",
      "z"
    ],
    "get_codebook_entry": [
      "self",
      "indices",
      "shape",
      "channel_first"
    ]
  },
  "ResnetBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "conv_shortcut",
      "dropout",
      "norm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AttnBlock": {
    "__init__": [
      "self",
      "in_channels",
      "norm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "nonlinearity": [
    "x"
  ],
  "Upsample": {
    "__init__": [
      "self",
      "in_channels",
      "with_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Downsample": {
    "__init__": [
      "self",
      "in_channels",
      "with_conv"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "compute_entropy_loss": [
    "affinity",
    "loss_type",
    "temperature"
  ],
  "VQModel": {
    "__init__": [
      "self",
      "config"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "quant"
    ],
    "decode_code": [
      "self",
      "code_b",
      "shape",
      "channel_first"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "MultiModalityPreTrainedModel": {
    "config_class": [],
    "base_model_prefix": [],
    "_no_split_modules": [],
    "_skip_keys_device_placement": []
  },
  "MultiModalityCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "prepare_gen_img_embeds": [
      "self",
      "image_ids"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "TeleFLMModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "TeleFLMForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "Qwen2VisionTransformerForNavitPOINTS": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "POINTSV15ChatModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "DbrxRouter": {
    "__init__": [
      "self",
      "config",
      "params_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DbrxExperts": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "params_dtype",
      "prefix"
    ],
    "weight_loader": [
      "self",
      "param",
      "loaded_weight",
      "weight_name"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "DbrxAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states",
      "forward_batch"
    ]
  },
  "DbrxFusedNormAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states",
      "forward_batch"
    ]
  },
  "DbrxBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "position_ids",
      "hidden_states",
      "forward_batch"
    ]
  },
  "DbrxModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "forward_batch",
      "input_embeds"
    ]
  },
  "DbrxForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "PhiMoEConfig": {
    "model_type": [],
    "__init__": [
      "self",
      "vocab_size",
      "hidden_size",
      "intermediate_size",
      "num_hidden_layers",
      "num_attention_heads",
      "num_key_value_heads",
      "head_dim",
      "hidden_act",
      "max_position_embeddings",
      "initializer_range",
      "rms_norm_eps",
      "use_cache",
      "pad_token_id",
      "bos_token_id",
      "eos_token_id",
      "tie_word_embeddings",
      "rope_theta",
      "sliding_window",
      "attention_dropout",
      "num_experts_per_tok",
      "num_local_experts",
      "output_router_logits",
      "router_aux_loss_coef",
      "router_jitter_noise",
      "attention_bias",
      "lm_head_bias"
    ]
  },
  "sparsemixer": [
    "scores",
    "jitter_eps"
  ],
  "phimoe_routing_function": [
    "hidden_states",
    "gating_output",
    "topk",
    "renormalize"
  ],
  "PhiMoE": {
    "__init__": [
      "self",
      "num_experts",
      "top_k",
      "hidden_size",
      "intermediate_size",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "PhiMoEAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "max_position",
      "rope_theta",
      "layer_id",
      "attention_bias",
      "quant_config",
      "rope_scaling",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "PhiMoEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "residual",
      "forward_batch"
    ]
  },
  "PhiMoEModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "PhiMoEForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LongcatFlashDenseDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "zero_allocator"
    ]
  },
  "LongcatFlashModelNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "LongcatFlashForCausalLMNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "post_load_weights": [
      "self"
    ],
    "_weight_requant_ue8m0": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "multihead_attention": [
    "q",
    "k",
    "v",
    "q_cu_seqlens",
    "k_cu_seqlens"
  ],
  "sdpa_attention": [
    "q",
    "k",
    "v",
    "q_cu_seqlens",
    "k_cu_seqlens"
  ],
  "VL_VISION_ATTENTION_FUNCTIONS": [],
  "_apply_rope_input_validation": [
    "x",
    "freqs_cis"
  ],
  "apply_rope": [
    "xq",
    "xk",
    "freqs_cis"
  ],
  "Learnable2DInterpPosEmb": {
    "__init__": [
      "self",
      "height",
      "width",
      "dim",
      "interpolation_mode"
    ],
    "reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "grid_hws"
    ]
  },
  "MoonVisionPatchEmbed": {
    "__init__": [
      "self",
      "out_dim",
      "in_dim",
      "patch_size",
      "pos_emb_height",
      "pos_emb_width"
    ],
    "forward": [
      "self",
      "x",
      "grid_hw"
    ]
  },
  "Rope2DPosEmb": {
    "__init__": [
      "self",
      "dim",
      "max_height",
      "max_width",
      "theta_base",
      "device"
    ],
    "extra_repr": [
      "self"
    ],
    "precomputed_freqs_cis": [
      "self"
    ],
    "get_freqs_cis_by_seqlens": [
      "self",
      "grid_hws"
    ],
    "get_freqs_cis_by_idx": [
      "self",
      "pos_idx",
      "pos_idx_mask"
    ]
  },
  "MLP2": {
    "__init__": [
      "self",
      "dims",
      "activation",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MoonVitEncoderLayer": {
    "__init__": [
      "self",
      "num_heads",
      "hidden_dim",
      "mlp_dim"
    ],
    "attention_qkvpacked": [
      "self",
      "x",
      "cu_seqlens",
      "rope_freqs_cis"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rope_freqs_cis"
    ]
  },
  "MoonVitEncoder": {
    "__init__": [
      "self",
      "hidden_dim",
      "num_layers",
      "block_cfg"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_hw"
    ]
  },
  "patch_merger": [
    "x",
    "grid_hw",
    "merge_kernel_size"
  ],
  "MoonVitVLProjector": {
    "__init__": [
      "self",
      "in_channels",
      "merge_kernel_size",
      "hidden_act",
      "ln_eps",
      "out_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "MoonVitPretrainedModel": {
    "config_class": [],
    "model_type": [],
    "_no_split_modules": [],
    "_supports_flash_attn_2": [],
    "_supports_sdpa": [],
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "grid_hw"
    ]
  },
  "NemotronH_Nano_VL_V2": {
    "create_evs_config": [
      "config"
    ],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "pixel_shuffle": [
      "self",
      "x",
      "scale_factor"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "extract_feature": [
      "self",
      "pixel_values"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "column_parallel_weights_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_init_model": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_module_name_from_weight_name": [
      "self",
      "name"
    ],
    "get_num_params": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_weights_by_name": [
      "self",
      "name",
      "truncate_size",
      "tp_size"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_embed": [
      "self"
    ],
    "set_embed": [
      "self",
      "embed"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "Phi3ForCausalLM": {},
  "InternLM3ForCausalLM": {},
  "IQuestCoderForCausalLM": {},
  "_is_cublas_ge_129": [],
  "FORWARD_ABSORB_CORE_ATTENTION_BACKENDS": [],
  "DeepseekV2MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter",
      "gemm_output_zero_allocator"
    ]
  },
  "DeepseekV2MoE": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream",
      "is_nextn"
    ],
    "get_moe_weights": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter",
      "gemm_output_zero_allocator"
    ],
    "forward_normal_dual_stream": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter",
      "gemm_output_zero_allocator"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter",
      "gemm_output_zero_allocator"
    ],
    "forward_cpu": [
      "self",
      "hidden_states",
      "should_allreduce_fusion"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "_forward_shared_experts": [
      "self",
      "hidden_states",
      "gemm_output_zero_allocator"
    ],
    "op_gate": [
      "self",
      "state"
    ],
    "op_shared_experts": [
      "self",
      "state"
    ],
    "op_select_experts": [
      "self",
      "state"
    ],
    "op_dispatch_a": [
      "self",
      "state"
    ],
    "op_dispatch_b": [
      "self",
      "state"
    ],
    "op_experts": [
      "self",
      "state"
    ],
    "op_combine_a": [
      "self",
      "state"
    ],
    "op_combine_b": [
      "self",
      "state"
    ],
    "op_output": [
      "self",
      "state"
    ]
  },
  "_get_llama_4_scaling": [
    "original_max_position_embeddings",
    "scaling_beta",
    "positions"
  ],
  "DeepseekV2AttentionMLA": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "qk_nope_head_dim",
      "qk_rope_head_dim",
      "v_head_dim",
      "q_lora_rank",
      "kv_lora_rank",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "reduce_results",
      "layer_id",
      "prefix",
      "alt_stream",
      "skip_rope"
    ],
    "dispatch_attn_forward_method": [
      "self",
      "forward_batch"
    ],
    "op_prepare": [
      "self",
      "state"
    ],
    "op_core": [
      "self",
      "state"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator",
      "llama_4_scaling"
    ],
    "forward_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator",
      "llama_4_scaling"
    ],
    "forward_core": [
      "self",
      "intermediate_state"
    ],
    "prepare_qkv_latent": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "_fuse_rope_for_trtllm_mla": [
      "self",
      "forward_batch"
    ],
    "rebuild_cp_kv_cache": [
      "self",
      "latent_cache",
      "forward_batch",
      "k_nope",
      "k_pe"
    ],
    "forward_absorb_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator",
      "llama_4_scaling"
    ],
    "forward_absorb_core": [
      "self",
      "q_pe",
      "k_pe",
      "q_nope_out",
      "k_nope",
      "forward_batch",
      "zero_allocator",
      "positions",
      "topk_indices",
      "llama_4_scaling"
    ],
    "forward_absorb_fused_mla_rope_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_absorb_fused_mla_rope_cpu_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_absorb_fused_mla_rope_core": [
      "self",
      "q_input",
      "key_cache_buf",
      "val_cache_buf",
      "attn_output",
      "kv_indptr",
      "kv_indices",
      "k_pe_output",
      "cos_sin_cache",
      "positions",
      "attn_logits",
      "num_kv_split",
      "sm_scale",
      "enable_rope_fusion",
      "k_input",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_absorb_fused_mla_rope_cpu_core": [
      "self",
      "q_input",
      "k_input",
      "v_input",
      "forward_batch",
      "zero_allocator"
    ],
    "_get_q_b_proj_quant_config": [
      "quant_config"
    ]
  },
  "DeepseekV2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "moe_quant_config_override",
      "is_nextn",
      "prefix",
      "alt_stream"
    ],
    "_is_layer_sparse": [
      "self",
      "layer_id",
      "is_nextn"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "zero_allocator",
      "gemm_output_zero_allocator",
      "llama_4_scaling"
    ],
    "op_comm_prepare_attn": [
      "self",
      "state",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "zero_allocator",
      "tbo_subbatch_index"
    ],
    "op_comm_prepare_mlp": [
      "self",
      "state"
    ],
    "op_mlp": [
      "self",
      "state"
    ],
    "op_comm_postprocess_layer": [
      "self",
      "state"
    ]
  },
  "DeepseekV2Model": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "DeepseekV2ForCausalLM": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "routed_experts_weights_of_layer": [
      "self"
    ],
    "determine_num_fused_shared_experts": [
      "self",
      "architecture"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "DeepseekV3ForCausalLM": {},
  "DeepseekV32ForCausalLM": {},
  "LlavaBaseForCausalLM": {
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "encode_images": [
      "self",
      "pixel_values"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "num_patches_per_side": [
      "self"
    ]
  },
  "LlavaLlamaForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "LlavaQwenForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "LlavaMistralForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "LlavaForConditionalGeneration": {
    "MULTIMODAL_PROJECTOR_TYPE": [],
    "dtype": [
      "self"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "image_inputs"
    ],
    "_get_sgl_model_cls": [
      "self",
      "config",
      "auto_model_type"
    ],
    "_config_cls_name_to_arch_name_mapping": [
      "self",
      "auto_model_type"
    ],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Olmo2Attention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Olmo2MLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Olmo2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Olmo2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Olmo2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3ForSequenceClassification": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BlockBase": {
    "__init__": [
      "self",
      "input_size",
      "output_size"
    ]
  },
  "adaptive_enc_mask": [
    "x_len",
    "chunk_start_idx",
    "left_window",
    "right_window"
  ],
  "Swish": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLU": {
    "__init__": [
      "self",
      "dim",
      "act_name"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLUPointWiseConv": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "kernel_size",
      "glu_type",
      "bias_in_glu",
      "causal"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DepthWiseSeperableConv1d": {
    "__init__": [
      "self",
      "input_dim",
      "depthwise_seperable_out_channel",
      "kernel_size",
      "depthwise_multiplier",
      "padding"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvModule": {
    "__init__": [
      "self",
      "input_dim",
      "ext_pw_out_channel",
      "depthwise_seperable_out_channel",
      "ext_pw_kernel_size",
      "kernel_size",
      "depthwise_multiplier",
      "dropout_rate",
      "causal",
      "batch_norm",
      "chunk_se",
      "chunk_size",
      "activation",
      "glu_type",
      "bias_in_glu",
      "linear_glu_in_convm",
      "export"
    ],
    "_add_ext_pw_layer": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "GLULinear": {
    "__init__": [
      "self",
      "input_dim",
      "output_dim",
      "glu_type",
      "bias_in_glu"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_pre_hook": [
    "state_dict",
    "prefix",
    "local_metadata",
    "strict",
    "missing_keys",
    "unexpected_keys",
    "error_msgs"
  ],
  "T5RelativeAttentionLogitBias": {
    "__init__": [
      "self",
      "num_heads",
      "num_buckets",
      "max_distance",
      "symmetric"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_bucket_relative_position": [
      "self",
      "relative_position"
    ]
  },
  "AbsolutePositionalEncoding": {
    "__init__": [
      "self",
      "d_model",
      "dropout_rate",
      "max_len"
    ],
    "extend_pe": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MeanVarianceNormLayer": {
    "__init__": [
      "self",
      "input_size"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "CausalConv1D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype"
    ],
    "update_cache": [
      "self",
      "x",
      "cache"
    ],
    "forward": [
      "self",
      "x",
      "cache"
    ]
  },
  "CausalConv2D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "groups",
      "bias",
      "padding_mode",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NemoConvSubsampling": {
    "__init__": [
      "self",
      "feat_in",
      "feat_out",
      "subsampling_factor",
      "subsampling",
      "conv_channels",
      "subsampling_conv_chunking_factor",
      "activation",
      "is_causal"
    ],
    "get_sampling_frames": [
      "self"
    ],
    "get_streaming_cache_size": [
      "self"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ],
    "reset_parameters": [
      "self"
    ],
    "conv_split_by_batch": [
      "self",
      "x"
    ],
    "conv_split_by_channel": [
      "self",
      "x"
    ],
    "channel_chunked_conv": [
      "self",
      "conv",
      "chunk_size",
      "x"
    ],
    "change_subsampling_conv_chunking_factor": [
      "self",
      "subsampling_conv_chunking_factor"
    ]
  },
  "calc_length": [
    "lengths",
    "all_paddings",
    "kernel_size",
    "stride",
    "ceil_mode",
    "repeat_num"
  ],
  "AttModule": {
    "__init__": [
      "self"
    ],
    "set_export": [
      "self",
      "mode"
    ],
    "forward": [
      "self",
      "x",
      "memory",
      "pos_emb",
      "att_mask"
    ]
  },
  "AttBlock": {
    "memory_dims": [
      "self",
      "max_len"
    ]
  },
  "masked_softmax": [
    "scores",
    "mask"
  ],
  "MultiHeadedAttention": {
    "__init__": [
      "self",
      "n_head",
      "n_feat",
      "dropout_rate",
      "attention_inner_dim",
      "glu_type",
      "bias_in_glu",
      "use_pt_scaled_dot_product_attention",
      "n_value",
      "group_size"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "pos_k",
      "pos_v",
      "mask",
      "relative_attention_bias"
    ]
  },
  "MultiSequential": {
    "forward": [
      "self"
    ]
  },
  "get_offset": [
    "input_layer",
    "time_reduction"
  ],
  "unfold_tensor": [
    "xs_pad",
    "max_seq_len"
  ],
  "gegelu": [
    "input",
    "limit"
  ],
  "Phi3SmallMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Phi3SmallSelfAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Phi3SmallDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Phi3SmallModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ]
  },
  "Phi3SmallForCausalLM": {
    "_tied_weights_keys": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "get_output_embeddings": [
      "self"
    ],
    "set_output_embeddings": [
      "self",
      "value"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "compute_logits": [
      "self",
      "input_ids",
      "hidden_states",
      "sampling_metadata"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3NextForCausalLMMTP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_mtp"
    ]
  },
  "Gemma3nRMSNorm": {
    "__init__": [
      "self",
      "dim",
      "eps",
      "with_scale"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3nTextScaledWordEmbedding": {},
  "Gemma3nTextMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_activation",
      "activation_sparsity",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_gaussian_topk": [
      "self",
      "inputs"
    ]
  },
  "Gemma3nLaurelBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Gemma3nAltUp": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "compute_router_modalities": [
      "self",
      "x"
    ],
    "predict": [
      "self",
      "hidden_states"
    ],
    "correct": [
      "self",
      "predictions",
      "activated"
    ],
    "scale_corrected_output": [
      "self",
      "corrected"
    ],
    "forward": [
      "self",
      "hidden_states",
      "activated"
    ]
  },
  "Gemma3nAttention": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "max_position_embeddings",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "positions",
      "forward_batch"
    ]
  },
  "Gemma3nDecoderLayer": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "per_layer_input",
      "forward_batch"
    ]
  },
  "Gemma3nTextModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "get_per_layer_inputs": [
      "self",
      "input_ids"
    ],
    "project_per_layer_inputs": [
      "self",
      "inputs_embeds",
      "per_layer_inputs"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "per_layer_inputs"
    ]
  },
  "Gemma3nForCausalLM": {
    "config_class": [],
    "_tied_weights_keys": [],
    "_tp_plan": [],
    "_pp_plan": [],
    "base_model_prefix": [],
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "supports_lora": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "dtype": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "per_layer_inputs"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Qwen3Config": [],
  "Qwen3Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "head_dim",
      "max_position_embeddings",
      "quant_config",
      "rms_norm_eps",
      "attention_bias",
      "prefix",
      "alt_stream"
    ],
    "forward_prepare_native": [
      "self",
      "positions",
      "hidden_states"
    ],
    "forward_prepare_npu": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Qwen3DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "post_residual_addition"
    ]
  },
  "Qwen3Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ]
  },
  "Qwen3ForCausalLM": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ]
  },
  "PersimmonMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "PersimmonAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "layer_id"
    ],
    "_split_heads": [
      "self",
      "x"
    ],
    "_merge_heads": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "position_ids",
      "forward_batch",
      "hidden_states"
    ]
  },
  "PersimmonDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "idx"
    ],
    "forward": [
      "self",
      "position_ids",
      "forward_batch",
      "hidden_states"
    ]
  },
  "PersimmonModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "forward_batch",
      "positions",
      "inputs_embeds"
    ]
  },
  "PersimmonForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "BailingMoEMLP": {
    "__init__": [
      "self",
      "intermediate_size",
      "config",
      "quant_config",
      "reduce_results",
      "prefix",
      "tp_rank",
      "tp_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ]
  },
  "BailingMoEGate": {
    "__init__": [
      "self",
      "config",
      "params_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "BailingMoESparseMoeBlock": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "alt_stream",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "get_moe_weights": [
      "self"
    ],
    "_forward_shared_experts": [
      "self",
      "hidden_states"
    ],
    "_forward_router_experts": [
      "self",
      "hidden_states"
    ],
    "forward_normal_dual_stream": [
      "self",
      "hidden_states"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "should_allreduce_fusion",
      "use_reduce_scatter"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BailingMoEAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "reduce_results",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "BailingMoEBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "_is_layer_sparse": [
      "self",
      "config",
      "layer_id",
      "is_nextn"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "captured_last_layer_outputs"
    ]
  },
  "BailingMoEModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "alt_stream",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "BailingMoEForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "BailingMoeForCausalLM": {},
  "BailingMoeV2ForCausalLM": {},
  "Qwen2AudioForConditionalGeneration": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "RobertaConfig": [],
  "RobertaClassificationHead": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "features"
    ]
  },
  "RobertaEmbedding": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "seq_lens",
      "position_ids",
      "forward_batch"
    ]
  },
  "XLMRobertaBaseModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "create_position_ids_from_input_ids": [
    "input_ids",
    "padding_idx",
    "past_key_values_length"
  ],
  "XLMRobertaModel": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_load_sparse_linear": [
      "model_path_or_dir",
      "sparse_head"
    ]
  },
  "XLMRobertaForSequenceClassification": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Gemma3nImagePixelInputs": {},
  "Gemma3nAudioInputs": {},
  "Gemma3nMultimodalEmbedder": {
    "__init__": [
      "self",
      "multimodal_config",
      "text_config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "inputs_embeds"
    ]
  },
  "Gemma3nForConditionalGeneration": {
    "config_class": [],
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "supports_lora": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ],
    "get_per_layer_inputs": [
      "self",
      "input_ids"
    ],
    "project_per_layer_inputs": [
      "self",
      "inputs_embeds",
      "per_layer_inputs"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "tie_weights": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "lora_pattern": [],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "get_hidden_dim": [
      "self",
      "module_name",
      "layer_idx"
    ]
  },
  "Qwen2VLImageInputs": {},
  "Qwen2VLVideoInputs": {},
  "Qwen2VisionMLP": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "act_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "mlp_ratio",
      "act_layer",
      "norm_layer",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "cu_seqlens",
      "position_embeddings"
    ]
  },
  "Qwen2VisionPatchEmbed": {
    "__init__": [
      "self",
      "patch_size",
      "temporal_patch_size",
      "in_chans",
      "embed_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionPatchMerger": {
    "__init__": [
      "self",
      "d_model",
      "context_dim",
      "norm_layer",
      "spatial_merge_size",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Qwen2VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "update_freqs_cache": [
      "self",
      "seqlen"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "Qwen2VisionTransformer": {
    "__init__": [
      "self",
      "vision_config",
      "norm_eps",
      "quant_config",
      "prefix"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "Qwen2VLForConditionalGeneration": {
    "default_bitsandbytes_target_modules": [],
    "bitsandbytes_stacked_params_mapping": [],
    "hf_to_sglang_mapper": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_video_feature": [
      "self",
      "items"
    ],
    "_process_video_input": [
      "self",
      "video_input"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "NemotronHMTPAttentionDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix",
      "has_start_projections",
      "has_end_norm"
    ],
    "forward": [
      "self"
    ]
  },
  "NemotronHMTPMoEDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx",
      "quant_config",
      "prefix",
      "has_start_projections",
      "has_end_norm"
    ],
    "forward": [
      "self"
    ]
  },
  "NemotronHMultiTokenPredictor": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "hidden_states",
      "forward_batch",
      "inputs_embeds"
    ]
  },
  "NemotronHForCausalLMMTP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_mtp"
    ]
  },
  "BailingMoEModelNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "BailingMoeForCausalLMNextN": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaForCausalLMEagle3": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_hot_token_id": [
      "self"
    ]
  },
  "_ModelRegistry": {
    "register": [
      "self",
      "package_name",
      "overwrite",
      "strict"
    ],
    "get_supported_archs": [
      "self"
    ],
    "_raise_for_unsupported": [
      "self",
      "architectures"
    ],
    "_try_load_model_cls": [
      "self",
      "model_arch"
    ],
    "_normalize_archs": [
      "self",
      "architectures"
    ],
    "resolve_model_cls": [
      "self",
      "architectures"
    ]
  },
  "import_model_classes": [
    "package_name",
    "strict"
  ],
  "ModelRegistry": [],
  "to_1tuple": [],
  "to_3tuple": [],
  "to_4tuple": [],
  "to_ntuple": [],
  "ClsToken": {
    "__init__": [
      "self",
      "ndim",
      "num_tokens",
      "enabled",
      "register_multiple",
      "num_registers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ViTPatchGenerator": {
    "__init__": [
      "self",
      "patch_size",
      "embed_dim",
      "input_dims",
      "abs_pos",
      "normalize_patches",
      "cls_token",
      "max_input_dims",
      "pos_dropout",
      "return_pos_enc",
      "num_cls_tokens",
      "register_multiple",
      "num_registers",
      "patch_bias",
      "device",
      "dtype"
    ],
    "forward": [
      "self",
      "x"
    ],
    "apply_cls_token": [
      "self"
    ],
    "num_cls_tokens": [
      "self"
    ],
    "num_cls_patches": [
      "self"
    ],
    "num_registers": [
      "self"
    ],
    "num_skip": [
      "self"
    ],
    "_load_embed": [
      "self",
      "src_embed",
      "targ_embed"
    ],
    "_load_projection": [
      "self",
      "src_proj_weight",
      "targ_proj_weight"
    ],
    "embed_patches": [
      "self",
      "x"
    ],
    "apply_pos_enc": [
      "self",
      "patches",
      "patch_idxs",
      "input_size"
    ],
    "get_pos_enc": [
      "self",
      "batch_size",
      "patch_idxs",
      "input_size"
    ],
    "_get_pos_embeddings": [
      "self",
      "batch_size",
      "input_dims"
    ]
  },
  "Im2Patches": {
    "__init__": [
      "self",
      "patch_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ViTPatchLinear": {
    "__init__": [
      "self",
      "patch_size",
      "embed_dim",
      "bias"
    ]
  },
  "RadioInternVisionModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_init_img_size": [
      "self",
      "patch_size",
      "img_size"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RadioModel": {
    "packed_modules_mapping": [],
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "pixel_values",
      "pixel_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "_extract_final": [
      "self",
      "y"
    ]
  },
  "MaxImageTokenMeta": {},
  "KimiVLMultiModalProjector": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "image_features"
    ]
  },
  "KimiVLForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "get_spec_layer_idx_from_weight_name": [
    "config",
    "weight_name"
  ],
  "AfmoeMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "reduce_results",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AfmoeMoE": {
    "_custom_routing_function": [
      "hidden_states",
      "gating_output",
      "topk",
      "renormalize"
    ],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "pack_params": [
      "self"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AfmoeAttention": {
    "__init__": [
      "self",
      "config",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "_apply_qk_norm": [
      "self",
      "q",
      "k"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "AfmoeDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "AfmoeModel": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "get_input_embeddings": [
      "self"
    ]
  },
  "AfmoeForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaEmbeddingModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "MistralModel": {},
  "apply_spk_emb": [
    "input_ids",
    "spk_emb",
    "input_embeds",
    "spk_emb_token_id",
    "num_spk_embs"
  ],
  "ConditionalChatTTSGenerationOutput": {},
  "make_streaming_chunk_mask_generation": [
    "inputs_embeds",
    "past_seen_tokens",
    "streaming_tts_text_mask",
    "streaming_reserved_length",
    "streaming_audio_chunk_size",
    "streaming_text_chunk_size",
    "num_spk_emb",
    "use_spk_emb"
  ],
  "ConvNeXtBlock": {
    "__init__": [
      "self",
      "dim",
      "intermediate_dim",
      "kernel",
      "dilation",
      "layer_scale_init_value"
    ],
    "forward": [
      "self",
      "x",
      "cond"
    ]
  },
  "DVAEDecoder": {
    "__init__": [
      "self",
      "idim",
      "odim",
      "n_layer",
      "bn_dim",
      "hidden",
      "kernel",
      "dilation",
      "up"
    ],
    "forward": [
      "self",
      "x",
      "conditioning"
    ]
  },
  "GFSQ": {
    "__init__": [
      "self",
      "dim",
      "levels",
      "G",
      "R",
      "eps",
      "transpose"
    ],
    "_embed": [
      "self",
      "x"
    ],
    "__call__": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DVAE": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inp",
      "mode"
    ]
  },
  "CustomRepetitionPenaltyLogitsProcessorRepeat": {
    "__init__": [
      "self",
      "penalty",
      "max_input_ids",
      "past_window"
    ],
    "__call__": [
      "self",
      "input_ids",
      "scores"
    ]
  },
  "ConditionalChatTTS": {
    "config_class": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "merge_inputs_embeds": [
      "self",
      "input_ids",
      "lm_spk_emb_last_hidden_states"
    ],
    "prefill_text": [
      "self",
      "input_ids",
      "position_ids",
      "past_key_values",
      "lm_spk_emb_last_hidden_states"
    ],
    "prefill_audio_ids": [
      "self",
      "input_ids",
      "past_key_values",
      "streaming_tts_text_mask",
      "add_audio_bos"
    ],
    "generate": [
      "self",
      "input_ids",
      "past_key_values",
      "temperature",
      "eos_token",
      "streaming_tts_text_mask",
      "force_no_stop",
      "min_new_token",
      "max_new_token",
      "logits_warpers",
      "logits_processors",
      "show_tqdm"
    ],
    "decode_to_mel_specs": [
      "self",
      "result_list"
    ]
  },
  "MiniCPMWhisperEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "layer_head_mask",
      "output_attentions",
      "past_key_values",
      "use_cache"
    ]
  },
  "MiniCPMWhisperEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_features",
      "attention_mask",
      "head_mask",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "past_key_values",
      "use_cache"
    ]
  },
  "MultiModalProjector": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim"
    ],
    "forward": [
      "self",
      "audio_features"
    ]
  },
  "MiniCPMO": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "init_tts_module": [
      "self"
    ],
    "init_audio_module": [
      "self"
    ],
    "init_llm": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_vision_module": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "init_resampler": [
      "self",
      "embed_dim",
      "vision_dim",
      "quant_config",
      "prefix"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_input"
    ],
    "_get_feat_extract_output_lengths": [
      "self",
      "input_lengths"
    ],
    "get_audio_embedding_streaming": [
      "self",
      "items"
    ],
    "subsequent_chunk_mask": [
      "self",
      "size",
      "chunk_size",
      "num_left_chunks",
      "device",
      "num_lookhead"
    ],
    "get_audio_embedding": [
      "self",
      "items",
      "chunk_length"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ],
    "get_omni_embedding": [
      "self",
      "items",
      "chunk_length",
      "stream_input"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "GptOssConfig": {
    "model_type": [],
    "__init__": [
      "self"
    ]
  },
  "GptOssSparseMoeBlock": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch",
      "should_allreduce_fusion"
    ],
    "get_moe_weights": [
      "self"
    ],
    "forward_normal": [
      "self",
      "hidden_states",
      "should_allreduce_fusion"
    ]
  },
  "GptOssAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "head_dim",
      "rms_norm_eps",
      "attention_bias",
      "quant_config",
      "prefix",
      "sliding_window_size",
      "layer_type",
      "params_dtype"
    ],
    "forward_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward_core": [
      "self",
      "intermediate_state"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "GptOssDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "sliding_window_size"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "GptOssModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "decoder_layer_type"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "GptOssForCausalLM": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "routed_experts_weights_of_layer": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "_get_default_weight_mapping": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights",
      "is_nextn",
      "weight_name_mapping"
    ],
    "_load_weights_mxfp4": [
      "self",
      "weights",
      "is_nextn",
      "weight_name_mapping"
    ],
    "_load_mxfp4_experts_weights": [
      "self",
      "weights"
    ],
    "_load_normal_weights": [
      "self",
      "weights",
      "is_nextn",
      "weight_name_mapping",
      "other_loaded_param_names"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ],
    "get_attention_sliding_window_size": [
      "self"
    ]
  },
  "_canonicalize_weights": [
    "config",
    "weights_in"
  ],
  "_dequant_mlp_weight": [
    "debug_name",
    "w_blocks",
    "w_scales"
  ],
  "_WeightCreator": {
    "__init__": [
      "self",
      "fn"
    ],
    "maybe_materialize": [
      "obj"
    ]
  },
  "Step3TextMLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Step3TextMoEMLP": {
    "__init__": [
      "self",
      "layer_id",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3TextAttention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "share_q_dim",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "rms_norm_eps",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Step3TextDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "moe_mlp_forward": [
      "self",
      "hidden_states"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "Step3TextModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "Step3VisionMLP": {
    "__init__": [
      "self",
      "dim",
      "intermediate_size",
      "bias",
      "hidden_act",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3VisionAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3VisionEmbeddings": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Step3VisionEncoderLayer": {
    "__init__": [
      "self",
      "config",
      "attn_implementation"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Step3VisionTransformer": {
    "__init__": [
      "self",
      "config"
    ],
    "dtype": [
      "self"
    ],
    "forward": [
      "self",
      "pixel_values"
    ]
  },
  "Step3VisionEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "inputs_embeds"
    ]
  },
  "Step3VLForConditionalGeneration": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_get_vision_model_output": [
      "self",
      "input_tensor"
    ],
    "_flatten_embeddings": [
      "self",
      "embeddings"
    ],
    "_process_image_features": [
      "self",
      "image_features"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "GLMAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "forward_batch"
    ]
  },
  "GLMMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GLMBlock": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "forward_batch"
    ]
  },
  "GLMTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_ids",
      "forward_batch"
    ]
  },
  "ChatGLMM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "forward_batch"
    ]
  },
  "ChatGLMForCausalLM": {
    "packed_modules_mapping": [],
    "supported_lora_modules": [],
    "embedding_modules": [],
    "embedding_padding_modules": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "ChatGLMModel": {},
  "Starcoder2Attention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "layer_id"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Starcoder2MLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "Starcoder2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Starcoder2Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ]
  },
  "Starcoder2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "inputs_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "LlamaForClassification": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "SIGLIP_NAME": [],
  "VISION_ENCODER_TO_PROCESSING_CONFIG": [],
  "Phi4MMImageEncoder": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "model_dir"
    ],
    "get_img_features": [
      "self",
      "img_embeds",
      "attention_mask"
    ],
    "forward": [
      "self",
      "pixel_values",
      "image_sizes",
      "image_attention_mask"
    ]
  },
  "Phi4MMForCausalLM": {
    "packed_modules_mapping": [],
    "lora_pattern": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_image_feature": [
      "self",
      "items"
    ],
    "get_audio_feature": [
      "self",
      "items"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch"
    ],
    "pad_input_ids": [
      "self",
      "input_ids",
      "mm_inputs"
    ],
    "should_apply_lora": [
      "self",
      "module_name"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "Glm4Config": [],
  "Glm4MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "prefix",
      "reduce_results"
    ],
    "forward": [
      "self",
      "x",
      "forward_batch",
      "use_reduce_scatter"
    ]
  },
  "Glm4Attention": {
    "__init__": [
      "self",
      "hidden_size",
      "num_heads",
      "num_kv_heads",
      "head_dim",
      "layer_id",
      "rope_theta",
      "rope_scaling",
      "max_position_embeddings",
      "quant_config",
      "dual_chunk_attention_config",
      "partial_rotary_factor",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "Glm4DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix",
      "alt_stream"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ]
  },
  "Glm4Model": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix",
      "decoder_layer_type",
      "alt_stream"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "Glm4ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embedding": [
      "self",
      "input_ids"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "get_embedding",
      "pp_proxy_tensors"
    ],
    "forward_split_prefill": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "split_interval",
      "input_embeds"
    ],
    "start_layer": [
      "self"
    ],
    "end_layer": [
      "self"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "set_embed_and_head": [
      "self",
      "embed",
      "head"
    ],
    "load_kv_cache_scales": [
      "self",
      "quantization_param_path"
    ]
  },
  "VisionRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "seqlen"
    ]
  },
  "DotsSwiGLUFFN": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DotsPatchEmbed": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "DotsViTPreprocessor": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "x",
      "grid_thw"
    ]
  },
  "DotsVisionBlock": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "cu_seqlens",
      "rotary_pos_emb"
    ]
  },
  "DotsVisionTransformer": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "_update_vision_config": [
      "self"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "dtype": [
      "self"
    ],
    "device": [
      "self"
    ],
    "get_pos_ids_by_grid": [
      "self",
      "grid_thw"
    ],
    "rot_pos_emb": [
      "self",
      "grid_thw"
    ],
    "calc_cos_sin": [
      "self",
      "rotary_pos_emb"
    ],
    "forward": [
      "self",
      "hidden_states",
      "grid_thw",
      "bf16"
    ]
  },
  "StablelmMLP": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "StablelmAttention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "StablelmDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ]
  },
  "StableLMEpochModel": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ]
  },
  "StableLmForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "rmsnorm_sumsq_kernel_serial": [
    "x1_ptr",
    "x2_ptr",
    "stride_x1",
    "stride_x2",
    "sum_sq_ptr",
    "B",
    "D1",
    "D2",
    "BLOCK_SIZE1",
    "BLOCK_SIZE2"
  ],
  "rmsnorm_apply_kernel_serial": [
    "x1_ptr",
    "x2_ptr",
    "w1_ptr",
    "w2_ptr",
    "sum_sq_ptr",
    "out1_ptr",
    "out2_ptr",
    "B",
    "D1",
    "D2",
    "stride_x1",
    "stride_x2",
    "tp_world",
    "eps",
    "BLOCK_SIZE1",
    "BLOCK_SIZE2"
  ],
  "rms_sumsq_serial": [
    "x1",
    "x2"
  ],
  "rms_apply_serial": [
    "x1",
    "x2",
    "w1",
    "w2",
    "sum_sq",
    "tp_world",
    "eps"
  ],
  "MiniMaxM2RMSNormTP": {
    "__init__": [
      "self",
      "hidden_size",
      "eps"
    ],
    "weight_loader": [
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "x",
      "residual"
    ],
    "forward_qk": [
      "q_norm",
      "k_norm",
      "q",
      "k"
    ]
  },
  "MiniMaxM2MoE": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "ebias_weight_loader": [
      "param",
      "loaded_weight"
    ],
    "forward": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "forward_normal": [
      "self",
      "hidden_states"
    ],
    "forward_deepep": [
      "self",
      "hidden_states",
      "forward_batch"
    ],
    "op_gate": [
      "self",
      "state"
    ],
    "op_select_experts": [
      "self",
      "state"
    ],
    "op_dispatch_a": [
      "self",
      "state"
    ],
    "op_dispatch_b": [
      "self",
      "state"
    ],
    "op_experts": [
      "self",
      "state"
    ],
    "op_combine_a": [
      "self",
      "state"
    ],
    "op_combine_b": [
      "self",
      "state"
    ],
    "op_output": [
      "self",
      "state"
    ]
  },
  "MiniMaxM2Attention": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "forward_core": [
      "self",
      "intermediate_state"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch"
    ],
    "op_prepare": [
      "self",
      "state"
    ],
    "op_core": [
      "self",
      "state"
    ]
  },
  "MiniMaxM2DecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_id",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual"
    ],
    "op_comm_prepare_attn": [
      "self",
      "state",
      "positions",
      "hidden_states",
      "forward_batch",
      "residual",
      "zero_allocator",
      "tbo_subbatch_index"
    ],
    "op_comm_prepare_mlp": [
      "self",
      "state"
    ],
    "op_mlp": [
      "self",
      "state"
    ],
    "op_comm_postprocess_layer": [
      "self",
      "state"
    ]
  },
  "MiniMaxM2Model": {
    "fall_back_to_pt_during_load": [],
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds",
      "pp_proxy_tensors"
    ]
  },
  "MiniMaxM2ForCausalLM": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self",
      "input_ids"
    ],
    "set_eagle3_layers_to_capture": [
      "self",
      "layer_ids"
    ],
    "get_embed_and_head": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "positions",
      "forward_batch",
      "input_embeds"
    ],
    "load_weights": [
      "self",
      "weights"
    ],
    "get_model_config_for_expert_location": [
      "cls",
      "config"
    ]
  },
  "_use_aiter_gfx95": [],
  "awq_dequantize_func": [],
  "enable_nextn_moe_bf16_cast_to_fp8": [
    "quant_config"
  ],
  "NVFP4_CKPT_FP8_ATTN_QUANT_MODULES": [],
  "DeepseekV2WeightLoaderMixin": {
    "do_load_weights": [
      "self",
      "weights",
      "is_nextn"
    ],
    "post_load_weights": [
      "self",
      "is_nextn",
      "weight_names"
    ],
    "_maybe_quant_weights_to_fp8_ue8m0": [
      "self",
      "weights",
      "attn_quant_modules",
      "is_nextn"
    ],
    "_mark_nextn_moe_weights_as_ue8m0": [
      "self"
    ]
  },
  "MHA_ONE_SHOT_SUPPORTED_BACKENDS": [],
  "AttentionBackendRegistry": {
    "_handlers": [],
    "register": [
      "cls",
      "backend_name",
      "handler_func"
    ],
    "get_handler": [
      "cls",
      "backend_name"
    ]
  },
  "_dispatch_mla_subtype": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_ascend": [
    "attn",
    "forward_batch"
  ],
  "_get_sum_extend_prefix_lens": [
    "forward_batch"
  ],
  "_support_mha_one_shot": [
    "attn",
    "forward_batch",
    "backend_name"
  ],
  "_handle_attention_backend": [
    "attn",
    "forward_batch",
    "backend_name"
  ],
  "handle_attention_flashinfer": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_fa3": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_flashmla": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_cutlass_mla": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_fa4": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_trtllm_mla": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_aiter": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_nsa": [
    "attn",
    "forward_batch"
  ],
  "handle_attention_triton": [
    "attn",
    "forward_batch"
  ],
  "DeepseekMHAForwardMixin": {
    "init_mha_forward": [
      "self"
    ],
    "forward_normal_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_normal_core": [
      "self",
      "q",
      "k",
      "v",
      "forward_batch"
    ],
    "forward_normal_chunked_kv_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_normal_chunked_kv_core": [
      "self",
      "q",
      "k",
      "v",
      "forward_batch"
    ],
    "forward_normal_one_shot_prepare": [
      "self",
      "positions",
      "hidden_states",
      "forward_batch",
      "zero_allocator"
    ],
    "forward_normal_one_shot_core": [
      "self",
      "q",
      "k",
      "v",
      "forward_batch"
    ],
    "_chunked_prefix_attn_mha": [
      "self",
      "q",
      "accum_output",
      "accum_lse",
      "forward_batch"
    ],
    "_set_mla_kv_buffer": [
      "self",
      "latent_cache",
      "kv_a",
      "k_pe",
      "forward_batch"
    ],
    "_get_mla_kv_buffer": [
      "self",
      "kv_indices",
      "dst_dtype",
      "forward_batch"
    ],
    "_get_mla_kv_buffer_from_fp8_for_nsa": [
      "self",
      "forward_batch"
    ],
    "_concat_and_cast_mha_k": [
      "self",
      "k_nope",
      "k_pe",
      "forward_batch"
    ]
  },
  "AttnForwardMethod": {
    "MHA": [],
    "MLA": [],
    "MHA_CHUNKED_KV": [],
    "MHA_ONE_SHOT": [],
    "MLA_FUSED_ROPE": [],
    "MLA_FUSED_ROPE_CPU": [],
    "MHA_NPU": [],
    "MLA_NPU": [],
    "DSA_NPU": []
  },
  "_tbo_debug": [],
  "get_token_num_per_seq": [
    "forward_mode",
    "spec_info"
  ],
  "compute_split_seq_index": [
    "forward_mode",
    "num_tokens",
    "extend_lens",
    "token_num_per_seq"
  ],
  "_is_two_chunk_split_enabled": [
    "extend_lens"
  ],
  "_split_extend_seqs": [
    "arr"
  ],
  "_split_array_by_cum_less_than_half": [
    "arr"
  ],
  "_split_array_by_balanced_sum": [
    "arr"
  ],
  "_update_device_and_sum_field_from_cpu_field": [
    "batch",
    "cpu_field",
    "device_field",
    "sum_field"
  ],
  "_compute_mask_offset": [
    "seq_index",
    "spec_info"
  ],
  "split_spec_info": [
    "spec_info",
    "start_seq_index",
    "end_seq_index",
    "start_token_index",
    "end_token_index"
  ],
  "compute_split_token_index": [
    "split_seq_index",
    "forward_mode",
    "extend_seq_lens",
    "token_num_per_seq"
  ],
  "compute_split_indices_for_cuda_graph_replay": [
    "forward_mode",
    "cuda_graph_num_tokens",
    "spec_info"
  ],
  "TboCudaGraphRunnerPlugin": {
    "__init__": [
      "self"
    ],
    "capture_one_batch_size": [
      "self",
      "batch",
      "num_tokens"
    ],
    "replay_prepare": [
      "self",
      "forward_mode",
      "bs",
      "num_token_non_padded",
      "spec_info"
    ]
  },
  "TboDPAttentionPreparer": {
    "prepare_all_gather": [
      "self",
      "local_batch"
    ],
    "compute_output": [
      "self",
      "partial_global_info"
    ],
    "_compute_local_forward_mode": [
      "local_batch"
    ],
    "_compute_global_forward_mode": [
      "forward_modes"
    ],
    "_is_all_same": [
      "x"
    ]
  },
  "TboForwardBatchPreparer": {
    "prepare": [
      "cls",
      "batch",
      "is_draft_worker"
    ],
    "prepare_raw": [
      "cls",
      "batch",
      "tbo_children_num_token_non_padded"
    ],
    "derive_fields_related_to_seq_len_for_two_chunk": [
      "cls",
      "batch"
    ],
    "filter_batch": [
      "cls",
      "batch"
    ],
    "compute_tbo_children_num_token_non_padded": [
      "cls",
      "batch"
    ],
    "compute_tbo_children_num_token_non_padded_raw": [
      "cls",
      "tbo_split_token_index",
      "num_token_non_padded"
    ],
    "_compute_split_token_index": [
      "cls",
      "batch"
    ]
  },
  "_compute_extend_num_tokens": [
    "input_ids",
    "forward_mode"
  ],
  "model_forward_maybe_tbo": [
    "layers",
    "enable_tbo",
    "positions",
    "forward_batch",
    "hidden_states",
    "input_data_scatter_mode",
    "residual",
    "zero_allocator"
  ],
  "_model_forward_tbo": [
    "inputs",
    "operations_strategy",
    "input_data_scatter_mode",
    "layer_input_scatter_mode"
  ],
  "_model_forward_non_tbo": [
    "inputs",
    "operations_strategy"
  ],
  "_model_forward_tbo_split_inputs": [
    "hidden_states",
    "residual",
    "positions",
    "forward_batch",
    "zero_allocator",
    "input_data_scatter_mode",
    "layer_input_scatter_mode"
  ],
  "_model_forward_tbo_split_inputs_raw": [
    "hidden_states",
    "residual",
    "positions",
    "forward_batch",
    "zero_allocator"
  ],
  "_model_forward_filter_inputs": [
    "hidden_states",
    "residual",
    "positions",
    "output_forward_batch",
    "tbo_subbatch_index"
  ],
  "_model_forward_tbo_merge_outputs": [
    "output_a",
    "output_b",
    "original_len"
  ],
  "MaybeTboDeepEPDispatcher": {
    "__init__": [
      "self"
    ],
    "_execute": [
      "self",
      "name",
      "tbo_subbatch_index"
    ],
    "dispatch": [
      "self"
    ],
    "dispatch_a": [
      "self"
    ],
    "dispatch_b": [
      "self"
    ],
    "combine": [
      "self"
    ],
    "combine_a": [
      "self"
    ],
    "combine_b": [
      "self"
    ],
    "register_deepep_dispatch_hook": [
      "self",
      "hook"
    ],
    "set_quant_config": [
      "self",
      "quant_config"
    ],
    "set_overlap_args": [
      "self",
      "combine_overlap_args",
      "meta_overlap_args"
    ],
    "clear_overlap_args": [
      "self"
    ]
  },
  "SboFlags": {
    "enable_combine_down_gemm_two_stream_overlap": [
      "cls"
    ],
    "enable_combine_shared_two_stream_overlap": [
      "cls"
    ],
    "enable_dispatch_shared_one_stream_overlap": [
      "cls"
    ],
    "fuse_shared_experts_inside_sbo": [
      "cls"
    ]
  },
  "CombineOverlapArgs": {},
  "DownGemmOverlapArgs": {},
  "compute_overlap_args": [
    "dispatch_output",
    "alt_stream"
  ],
  "_ENABLE_PROFILE": [],
  "execute_operations": [
    "inputs",
    "operations"
  ],
  "execute_overlapped_operations": [
    "inputs_arr",
    "operations_arr",
    "delta_stages"
  ],
  "YieldOperation": {},
  "ExecutionOperation": {},
  "Operation": [],
  "Stage": [],
  "_StageExecutor": {
    "__init__": [
      "self",
      "debug_name",
      "stages",
      "inputs"
    ],
    "next": [
      "self"
    ],
    "output": [
      "self"
    ],
    "done": [
      "self"
    ],
    "num_stages": [
      "self"
    ]
  },
  "_annotate_region": [
    "debug_name"
  ],
  "_StateDict": {
    "__init__": [
      "self"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ],
    "__getattr__": [
      "self",
      "item"
    ],
    "__delattr__": [
      "self",
      "item"
    ],
    "pop": [
      "self",
      "item"
    ],
    "update": [
      "self",
      "values"
    ],
    "get": [
      "self",
      "item"
    ],
    "clear": [
      "self",
      "expect_keys"
    ]
  },
  "_convert_operations_to_stages": [
    "operations"
  ],
  "_chunk_by_separator": [
    "items",
    "is_separator"
  ],
  "_decorate_operations": [
    "operations",
    "debug_name_prefix"
  ],
  "_decorate_operation": [
    "operation",
    "debug_name_prefix"
  ],
  "OperationsStrategy": {
    "concat": [
      "cls",
      "items"
    ],
    "init_new_tbo": [
      "layers",
      "forward_mode"
    ]
  },
  "_assert_all_same": [
    "items"
  ],
  "_compute_moe_deepseek_layer_operations_strategy_tbo": [
    "layer",
    "forward_mode"
  ],
  "_compute_moe_deepseek_blog_prefill": [
    "layer"
  ],
  "_compute_moe_deepseek_blog_decode": [
    "layer"
  ],
  "_compute_moe_qwen3_layer_operations_strategy_tbo": [
    "layer",
    "forward_mode"
  ],
  "_compute_moe_qwen3_prefill": [
    "layer"
  ],
  "_compute_moe_qwen3_decode": [
    "layer"
  ],
  "ElasticEPState": {
    "is_active_equal_last": [
      "self"
    ],
    "sync_active_to_cpu": [
      "self"
    ],
    "snapshot_active_to_last": [
      "self"
    ]
  },
  "ElasticEPStateManager": {
    "instance": [
      "cls"
    ],
    "init": [
      "cls",
      "server_args"
    ],
    "_select_device": [],
    "_build_state": [
      "cls"
    ],
    "healthy_rank_state": [
      "cls"
    ]
  },
  "EPLBManager": {
    "__init__": [
      "self",
      "model_runner"
    ],
    "on_forward_pass_end": [
      "self"
    ],
    "_entrypoint": [
      "self"
    ],
    "rebalance": [
      "self"
    ],
    "_check_rebalance_needed": [
      "self",
      "average_utilization_rate_over_window"
    ],
    "_compute_update_layer_ids_chunks": [
      "self"
    ]
  },
  "_chunk_list": [
    "items",
    "chunk_size"
  ],
  "ExpertLocationMetadata": {
    "num_layers": [
      "self"
    ],
    "num_physical_experts": [
      "self"
    ],
    "num_local_physical_experts": [
      "self"
    ],
    "num_logical_experts": [
      "self"
    ],
    "ep_size": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "init_trivial": [
      "server_args",
      "model_config",
      "moe_ep_rank"
    ],
    "init_by_mapping": [
      "server_args",
      "model_config",
      "physical_to_logical_map",
      "moe_ep_rank"
    ],
    "init_by_eplb": [
      "server_args",
      "model_config",
      "logical_count"
    ],
    "_init_common": [
      "server_args",
      "model_config"
    ],
    "_init_raw": [
      "server_args",
      "ep_size",
      "physical_to_logical_map",
      "logical_to_all_physical_map"
    ],
    "update": [
      "self",
      "other",
      "update_layer_ids"
    ],
    "logical_to_all_physical": [
      "self",
      "layer_id",
      "logical_expert_id",
      "require_global_experts"
    ]
  },
  "get_global_expert_location_metadata": [],
  "set_global_expert_location_metadata": [
    "value"
  ],
  "_compute_logical_to_all_physical_map": [
    "server_args",
    "physical_to_logical_map",
    "num_logical_experts",
    "ep_size",
    "moe_ep_rank"
  ],
  "_pad_nested_array": [
    "arr",
    "pad_value"
  ],
  "compute_logical_to_rank_dispatch_physical_map": [
    "server_args",
    "logical_to_all_physical_map",
    "ep_size",
    "num_physical_experts",
    "ep_rank",
    "seed"
  ],
  "_logical_to_all_physical_raw": [
    "logical_to_all_physical_map",
    "layer_id",
    "logical_expert_id"
  ],
  "_compute_gpu_id_of_physical_expert": [
    "physical_expert_id",
    "num_local_gpu_physical_experts"
  ],
  "_compute_node_id_of_physical_expert": [
    "physical_expert_id",
    "num_local_host_physical_experts"
  ],
  "_find_nearest_expert": [
    "candidate_physical_expert_ids",
    "num_local_gpu_physical_experts",
    "moe_ep_rank",
    "num_gpus_per_node",
    "num_local_node_physical_experts"
  ],
  "_fair_choices": [
    "arr",
    "k",
    "r"
  ],
  "ModelConfigForExpertLocation": {
    "from_model_config": [
      "model_config"
    ]
  },
  "compute_initial_expert_location_metadata": [
    "server_args",
    "model_config",
    "moe_ep_rank"
  ],
  "_LOG_INPUT": [],
  "ExpertLocationUpdater": {
    "__init__": [
      "self"
    ],
    "update": [
      "self",
      "routed_experts_weights_of_layer",
      "new_expert_location_metadata",
      "update_layer_ids",
      "nnodes",
      "rank"
    ]
  },
  "_update_expert_weights": [],
  "_update_expert_weights_with_canary": [
    "routed_experts_weights_of_layer",
    "old_expert_location_metadata",
    "new_expert_location_metadata",
    "update_layer_ids",
    "nnodes",
    "rank"
  ],
  "_update_expert_weights_raw": [
    "routed_experts_weights_of_layer",
    "old_expert_location_metadata",
    "new_expert_location_metadata",
    "update_layer_ids",
    "nnodes",
    "rank"
  ],
  "create_temp_buffers": [
    "sample_tensors"
  ],
  "update_expert_weights_single_layer": [
    "routed_experts_weights",
    "temp_buffers",
    "old_physical_to_logical_map",
    "new_physical_to_logical_map",
    "num_local_physical_experts",
    "num_gpu_per_node",
    "rank",
    "world_size",
    "debug",
    "log_metrics"
  ],
  "_ChunkUtils": {
    "__init__": [
      "self"
    ],
    "chunk_value_from_element_value": [
      "self",
      "element_value"
    ],
    "element_values_from_chunk_value": [
      "self",
      "chunk_value"
    ],
    "_chunk_index_from_element_index": [
      "num_elements",
      "num_chunks",
      "element_index"
    ],
    "_element_slice_from_chunk_index": [
      "num_elements",
      "num_chunks",
      "chunk_index"
    ]
  },
  "_deduplicate_ordered": [
    "arr"
  ],
  "_log_p2p_op_metrics": [
    "p2p_op_infos",
    "num_gpu_per_node",
    "world_size",
    "self_node_id"
  ],
  "_get_direction_from_op": [
    "op"
  ],
  "_group_by": [
    "items",
    "keyfunc"
  ],
  "ExpertLocationDispatchInfo": {
    "init_new": [
      "cls",
      "layer_id"
    ]
  },
  "transform_select_experts_inputs": [
    "router_logits",
    "correction_bias",
    "info"
  ],
  "topk_ids_logical_to_physical": [
    "topk_ids",
    "info"
  ],
  "_topk_ids_logical_to_physical_static": [
    "topk_ids",
    "info"
  ],
  "_topk_ids_logical_to_physical_dynamic": [
    "topk_ids",
    "info"
  ],
  "_OutputMode": [],
  "ExpertDistributionMetrics": {
    "copy_to_cpu": [
      "self"
    ]
  },
  "ExpertDistributionRecorder": {
    "init_new": [
      "server_args",
      "expert_location_metadata",
      "rank"
    ],
    "with_current_layer": [
      "self",
      "layer_idx"
    ],
    "with_debug_name": [
      "self",
      "debug_name"
    ],
    "disable_this_region": [
      "self"
    ],
    "with_forward_pass": [
      "self",
      "forward_pass_id",
      "forward_batch"
    ],
    "on_select_experts": [
      "self",
      "topk_ids"
    ],
    "on_deepep_dispatch_normal": [
      "self",
      "local_physical_count_of_layer",
      "num_tokens_per_rank",
      "num_tokens_per_rdma_rank",
      "num_tokens_per_expert"
    ],
    "on_deepep_dispatch_low_latency": [
      "self",
      "local_physical_count_of_layer"
    ],
    "start_record": [
      "self"
    ],
    "stop_record": [
      "self"
    ],
    "dump_record": [
      "self",
      "output_mode"
    ],
    "recording": [
      "self"
    ],
    "_on_not_implemented": [
      "self"
    ]
  },
  "_ExpertDistributionRecorderNoop": {},
  "_ExpertDistributionRecorderReal": {
    "__init__": [
      "self",
      "server_args",
      "expert_location_metadata",
      "rank"
    ],
    "with_current_layer": [
      "self",
      "layer_idx"
    ],
    "with_debug_name": [
      "self",
      "debug_name"
    ],
    "with_forward_pass": [
      "self",
      "forward_pass_id",
      "forward_batch"
    ],
    "disable_this_region": [
      "self"
    ],
    "_on_forward_pass_start": [
      "self",
      "forward_batch"
    ],
    "_on_forward_pass_end": [
      "self",
      "forward_pass_id",
      "outputs"
    ],
    "on_select_experts": [
      "self",
      "topk_ids"
    ],
    "on_deepep_dispatch_normal": [
      "self",
      "local_physical_count_of_layer",
      "num_tokens_per_rank",
      "num_tokens_per_rdma_rank",
      "num_tokens_per_expert"
    ],
    "on_deepep_dispatch_low_latency": [
      "self",
      "local_physical_count_of_layer"
    ],
    "_on_hook": [
      "self",
      "hook_name"
    ],
    "_reset": [
      "self"
    ],
    "start_record": [
      "self"
    ],
    "stop_record": [
      "self"
    ],
    "dump_record": [
      "self",
      "output_mode"
    ],
    "recording": [
      "self"
    ]
  },
  "get_global_expert_distribution_recorder": [],
  "set_global_expert_distribution_recorder": [
    "value"
  ],
  "_SinglePassGatherer": {
    "init_new": [
      "server_args",
      "expert_location_metadata",
      "rank"
    ],
    "__init__": [
      "self",
      "expert_location_metadata",
      "rank"
    ],
    "on_forward_pass_start": [
      "self",
      "forward_batch"
    ],
    "on_select_experts": [
      "self",
      "layer_idx",
      "topk_ids"
    ],
    "on_deepep_dispatch_normal": [
      "self",
      "layer_idx",
      "local_physical_count_of_layer",
      "num_tokens_per_rank",
      "num_tokens_per_rdma_rank",
      "num_tokens_per_expert"
    ],
    "on_deepep_dispatch_low_latency": [
      "self",
      "layer_idx",
      "local_physical_count_of_layer"
    ],
    "reset": [
      "self"
    ],
    "collect": [
      "self"
    ]
  },
  "_DetailSinglePassGatherer": {
    "_TOP_K_NUM": [],
    "__init__": [
      "self",
      "server_args",
      "expert_location_metadata",
      "rank"
    ],
    "on_forward_pass_start": [
      "self",
      "forward_batch"
    ],
    "on_select_experts": [
      "self",
      "layer_idx",
      "topk_ids"
    ],
    "on_deepep_dispatch_normal": [
      "self",
      "layer_idx",
      "local_physical_count_of_layer",
      "num_tokens_per_rank",
      "num_tokens_per_rdma_rank",
      "num_tokens_per_expert"
    ],
    "reset": [
      "self"
    ],
    "collect": [
      "self"
    ]
  },
  "_LayerBasedCpuSinglePassGatherer": {
    "__init__": [
      "self"
    ],
    "_on_layer_data": [
      "self",
      "layer_idx",
      "objects"
    ],
    "reset": [
      "self"
    ],
    "_collect_objects": [
      "self",
      "pad_len"
    ]
  },
  "_list_sum": [
    "a",
    "b"
  ],
  "_LayerBasedGpuSinglePassGatherer": {
    "__init__": [
      "self"
    ],
    "reset": [
      "self"
    ],
    "collect": [
      "self"
    ]
  },
  "_SelectExpertsSinglePassGatherer": {
    "__init__": [
      "self"
    ],
    "on_select_experts": [
      "self",
      "layer_idx",
      "topk_ids"
    ]
  },
  "_DeepepNormalSinglePassGatherer": {
    "__init__": [
      "self"
    ],
    "on_deepep_dispatch_normal": [
      "self",
      "layer_idx",
      "local_physical_count_of_layer",
      "num_tokens_per_rank",
      "num_tokens_per_rdma_rank",
      "num_tokens_per_expert"
    ],
    "collect": [
      "self"
    ]
  },
  "_DeepepLowLatencySinglePassGatherer": {
    "__init__": [
      "self"
    ],
    "on_deepep_dispatch_low_latency": [
      "self",
      "layer_idx",
      "local_physical_count_of_layer"
    ]
  },
  "_convert_per_token_to_global_physical_count": [
    "num_tokens",
    "num_layers",
    "num_physical_experts",
    "_topk_ids_of_layer"
  ],
  "_convert_local_to_global_physical_count": [
    "local_physical_count",
    "rank",
    "num_local_physical_experts",
    "num_physical_experts"
  ],
  "_SINGLE_PASS_GATHERER_KEY_PRIMARY": [],
  "_Accumulator": {
    "init_new": [
      "server_args",
      "expert_location_metadata",
      "rank"
    ],
    "get_class": [
      "server_args"
    ],
    "__init__": [
      "self",
      "server_args",
      "expert_location_metadata",
      "rank"
    ],
    "get_single_pass_gatherer_keys": [
      "self"
    ],
    "get_single_pass_gatherer_key": [
      "self",
      "debug_name"
    ],
    "append": [
      "self",
      "forward_pass_id",
      "gatherer_key",
      "single_pass_data",
      "outputs"
    ],
    "reset": [
      "self"
    ],
    "dump": [
      "self",
      "output_mode"
    ]
  },
  "_UtilizationRateAccumulatorMixin": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "forward_pass_id",
      "gatherer_key",
      "single_pass_data",
      "outputs"
    ],
    "reset": [
      "self"
    ],
    "_append_utilization_rate": [
      "self",
      "forward_pass_id",
      "single_pass_global_physical_count",
      "outputs"
    ],
    "_handle_metric_eplb_heatmap": [
      "self",
      "gpu_physical_count"
    ]
  },
  "_DequeCollection": {
    "__init__": [
      "self",
      "maxlens"
    ],
    "append": [
      "self",
      "value"
    ],
    "clear": [
      "self"
    ],
    "mean": [
      "self"
    ]
  },
  "_DetailAccumulator": {
    "__init__": [
      "self"
    ],
    "get_single_pass_gatherer_keys": [
      "self"
    ],
    "get_single_pass_gatherer_key": [
      "self",
      "debug_name"
    ],
    "append": [
      "self",
      "forward_pass_id",
      "gatherer_key",
      "single_pass_data",
      "outputs"
    ],
    "reset": [
      "self"
    ],
    "dump": [
      "self",
      "output_mode"
    ]
  },
  "_StatAccumulator": {
    "__init__": [
      "self"
    ],
    "append": [
      "self",
      "forward_pass_id",
      "gatherer_key",
      "single_pass_data",
      "outputs"
    ],
    "reset": [
      "self"
    ],
    "dump": [
      "self",
      "output_mode"
    ],
    "_get_global_average_utilization_rate": [
      "self"
    ]
  },
  "_dump_to_file": [
    "name",
    "data"
  ],
  "_Buffer": {
    "init_new": [
      "item_shape",
      "buffer_size",
      "dtype",
      "device"
    ],
    "append": [
      "self",
      "value"
    ],
    "get_all": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "_CircularBuffer": {
    "__init__": [
      "self",
      "item_shape",
      "buffer_size",
      "dtype",
      "device"
    ],
    "append": [
      "self",
      "value"
    ],
    "get_all": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "_InfiniteBuffer": {
    "__init__": [
      "self",
      "item_shape",
      "dtype",
      "device"
    ],
    "append": [
      "self",
      "value"
    ],
    "get_all": [
      "self"
    ],
    "reset": [
      "self"
    ]
  },
  "_convert_global_physical_count_to_logical_count": [
    "global_physical_count",
    "num_layers",
    "num_logical_experts",
    "physical_to_logical_map"
  ],
  "compute_gpu_physical_count": [
    "physical_count_of_whatever",
    "num_gpu"
  ],
  "compute_utilization_rate": [
    "gpu_physical_count_of_batch"
  ],
  "convert_global_physical_count_to_logical_count": [],
  "read_mode_per_pass": [
    "dir_data"
  ],
  "balanced_packing": [
    "weight",
    "num_packs"
  ],
  "replicate_experts": [
    "weight",
    "num_phy"
  ],
  "rebalance_experts_hierarchical": [
    "weight",
    "num_physical_experts",
    "num_groups",
    "num_nodes",
    "num_gpus"
  ],
  "rebalance_experts": [
    "weight",
    "num_replicas",
    "num_groups",
    "num_nodes",
    "num_gpus",
    "enable_hierarchical"
  ],
  "EplbAlgorithm": {
    "deepseek": [],
    "deepseek_hierarchical": [],
    "deepseek_vec": [],
    "deepseek_vec_hierarchical": [],
    "elasticity_aware": []
  },
  "compute_algorithm": [
    "raw_algorithm",
    "num_groups",
    "num_nodes"
  ],
  "pack_groups": [
    "tokens_per_group",
    "num_nodes"
  ],
  "make_redundant_experts_chunkwise": [
    "tokens_per_expert",
    "num_physical_experts",
    "num_local_physical_experts",
    "num_physical_experts_per_chunk"
  ],
  "decode_rebalance_experts": [
    "tokens_per_expert",
    "num_physical_experts",
    "num_local_physical_experts"
  ],
  "prefill_rebalance_experts": [
    "tokens_per_expert",
    "num_physical_experts",
    "num_local_physical_experts",
    "num_groups",
    "num_nodes"
  ],
  "ScheduleBatchDisaggregationDecodeMixin": {
    "prepare_for_prebuilt": [
      "self"
    ],
    "process_prebuilt": [
      "self",
      "server_args",
      "future_map"
    ]
  },
  "PrefillBootstrapQueue": {
    "__init__": [
      "self",
      "token_to_kv_pool",
      "draft_token_to_kv_pool",
      "req_to_metadata_buffer_idx_allocator",
      "metadata_buffers",
      "tp_rank",
      "tp_size",
      "gpu_id",
      "bootstrap_port",
      "gloo_group",
      "max_total_num_tokens",
      "decode_tp_size",
      "decode_dp_size",
      "scheduler",
      "pp_rank",
      "pp_size",
      "transfer_backend"
    ],
    "_init_kv_manager": [
      "self"
    ],
    "add": [
      "self",
      "req",
      "num_kv_heads"
    ],
    "extend": [
      "self",
      "reqs",
      "num_kv_heads"
    ],
    "_check_if_req_exceed_kv_capacity": [
      "self",
      "req"
    ],
    "_process_req": [
      "self",
      "req"
    ],
    "pop_bootstrapped": [
      "self",
      "return_failed_reqs",
      "rids_to_check"
    ]
  },
  "SchedulerDisaggregationPrefillMixin": {
    "get_next_disagg_prefill_batch_to_run": [
      "self"
    ],
    "event_loop_normal_disagg_prefill": [
      "self"
    ],
    "event_loop_overlap_disagg_prefill": [
      "self"
    ],
    "process_batch_result_disagg_prefill": [
      "self",
      "batch",
      "result"
    ],
    "process_disagg_prefill_inflight_queue": [
      "self",
      "rids_to_check"
    ],
    "get_transferred_rids": [
      "self"
    ],
    "process_prefill_chunk": [
      "self"
    ],
    "send_kv_chunk": [
      "self",
      "req",
      "last_chunk",
      "end_idx"
    ]
  },
  "CLIP_MAX_NEW_TOKEN": [],
  "DecodeReqToTokenPool": {
    "__init__": [
      "self",
      "size",
      "max_context_len",
      "device",
      "enable_memory_saver",
      "pre_alloc_size"
    ],
    "write": [
      "self",
      "indices",
      "values"
    ],
    "available_size": [
      "self"
    ],
    "alloc": [
      "self",
      "need_size"
    ],
    "free": [
      "self",
      "free_index"
    ],
    "clear": [
      "self"
    ]
  },
  "HybridMambaDecodeReqToTokenPool": {
    "__init__": [
      "self",
      "size",
      "max_context_len",
      "device",
      "enable_memory_saver",
      "cache_params",
      "speculative_num_draft_tokens",
      "enable_mamba_extra_buffer",
      "pre_alloc_size"
    ],
    "clear": [
      "self"
    ]
  },
  "DecodeRequest": {
    "seqlen": [
      "self"
    ]
  },
  "DecodePreallocQueue": {
    "__init__": [
      "self",
      "req_to_token_pool",
      "token_to_kv_pool_allocator",
      "draft_token_to_kv_pool",
      "req_to_metadata_buffer_idx_allocator",
      "metadata_buffers",
      "scheduler",
      "transfer_queue",
      "tree_cache",
      "gloo_group",
      "tp_rank",
      "tp_size",
      "dp_size",
      "gpu_id",
      "bootstrap_port",
      "max_total_num_tokens",
      "prefill_pp_size",
      "pp_rank",
      "num_reserved_decode_tokens",
      "transfer_backend"
    ],
    "_init_kv_manager": [
      "self"
    ],
    "add": [
      "self",
      "req",
      "is_retracted"
    ],
    "_check_if_req_exceed_kv_capacity": [
      "self",
      "req"
    ],
    "extend": [
      "self",
      "reqs",
      "is_retracted"
    ],
    "resume_retracted_reqs": [
      "self",
      "rids_to_check"
    ],
    "_update_handshake_waiters": [
      "self",
      "rids_to_check"
    ],
    "pop_preallocated": [
      "self",
      "rids_to_check"
    ],
    "num_tokens_pre_allocated": [
      "self"
    ],
    "_allocatable_tokens": [
      "self",
      "retractable_tokens",
      "count_retracted"
    ],
    "_pre_alloc": [
      "self",
      "req"
    ]
  },
  "DecodeTransferQueue": {
    "__init__": [
      "self",
      "gloo_group",
      "req_to_metadata_buffer_idx_allocator",
      "tp_rank",
      "metadata_buffers",
      "scheduler",
      "tree_cache"
    ],
    "add": [
      "self",
      "decode_req"
    ],
    "extend": [
      "self",
      "decode_reqs"
    ],
    "_commit_transfer_to_req": [
      "self",
      "decode_req"
    ],
    "pop_transferred": [
      "self",
      "rids_to_check"
    ]
  },
  "SchedulerDisaggregationDecodeMixin": {
    "event_loop_normal_disagg_decode": [
      "self"
    ],
    "event_loop_overlap_disagg_decode": [
      "self"
    ],
    "_run_batch_prebuilt": [
      "self",
      "batch"
    ],
    "get_next_disagg_decode_batch_to_run": [
      "self"
    ],
    "get_new_prebuilt_batch": [
      "self"
    ],
    "process_decode_queue": [
      "self"
    ]
  },
  "FAKE_BOOTSTRAP_HOST": [],
  "DisaggregationMode": {
    "NULL": [],
    "PREFILL": [],
    "DECODE": []
  },
  "FAILURE_PROB": [],
  "poll_and_all_reduce": [
    "pollers",
    "gloo_group"
  ],
  "ReqToMetadataIdxAllocator": {
    "__init__": [
      "self",
      "size"
    ],
    "available_size": [
      "self"
    ],
    "alloc": [
      "self"
    ],
    "free": [
      "self",
      "free_index"
    ]
  },
  "MetadataBuffers": {
    "__init__": [
      "self",
      "size",
      "hidden_size",
      "hidden_states_dtype",
      "max_top_logprobs_num",
      "custom_mem_pool"
    ],
    "get_buf_infos": [
      "self"
    ],
    "get_buf": [
      "self",
      "idx"
    ],
    "set_buf": [
      "self",
      "req"
    ]
  },
  "TransferBackend": {
    "MOONCAKE": [],
    "NIXL": [],
    "ASCEND": [],
    "FAKE": []
  },
  "KVClassType": {
    "KVARGS": [],
    "MANAGER": [],
    "SENDER": [],
    "RECEIVER": [],
    "BOOTSTRAP_SERVER": []
  },
  "get_kv_class": [
    "transfer_backend",
    "class_type"
  ],
  "kv_to_page_indices": [
    "kv_indices",
    "page_size"
  ],
  "kv_to_page_num": [
    "num_kv_indices",
    "page_size"
  ],
  "is_mla_backend": [
    "target_kv_pool"
  ],
  "prepare_abort": [
    "req",
    "error_message",
    "status_code"
  ],
  "DecodeKVCacheOffloadManager": {
    "__init__": [
      "self",
      "req_to_token_pool",
      "token_to_kv_pool_allocator",
      "tp_group",
      "tree_cache",
      "server_args"
    ],
    "offload_kv_cache": [
      "self",
      "req"
    ],
    "check_offload_progress": [
      "self"
    ],
    "_check_offload_progress": [
      "self",
      "finish_count"
    ],
    "_release_finished_req": [
      "self",
      "req",
      "prefill_offloaded_len"
    ],
    "_check_backup_progress": [
      "self",
      "finish_count"
    ],
    "_trigger_backup": [
      "self",
      "req",
      "host_indices",
      "incremental_tokens",
      "start_time",
      "prefill_offloaded_len"
    ],
    "_compute_prefix_hash": [
      "self",
      "tokens",
      "prior_hash"
    ]
  },
  "EmbeddingData": {
    "__init__": [
      "self",
      "req_id",
      "num_parts",
      "part_idx",
      "image_grid_dim",
      "embedding",
      "error_msg",
      "error_code"
    ],
    "add": [
      "self",
      "embedding_data"
    ],
    "get_embedding": [
      "self",
      "is_concat"
    ],
    "get_img_grid": [
      "self"
    ],
    "ready": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "copy_without_embedding": [
      "self"
    ]
  },
  "WaitingImageRequestStatus": {
    "FAIL": [],
    "PENDING": [],
    "SUCCESS": []
  },
  "WaitingImageRequest": {
    "__init__": [
      "self",
      "rid",
      "recv_req",
      "mm_processor",
      "encoder_urls",
      "host_name",
      "receive_count"
    ],
    "send_encode_request": [
      "self"
    ],
    "_try_recv_mm_data": [
      "self"
    ]
  },
  "MMReceiver": {
    "__init__": [
      "self",
      "server_args",
      "dtype",
      "hf_config",
      "pp_rank",
      "tp_rank",
      "tp_group",
      "scheduler"
    ],
    "create_req": [
      "self",
      "recv_req"
    ],
    "process_waiting_requests": [
      "self",
      "recv_reqs"
    ],
    "_run_encode_in_thread": [
      "self",
      "req_id",
      "img_data",
      "endpoint_encode",
      "num_items_assigned",
      "embedding_port"
    ],
    "encode": [
      "self",
      "req_id",
      "img_data",
      "embedding_port",
      "endpoint_encode",
      "endpoint_send",
      "num_items_assigned"
    ],
    "allocate_embedding_buffer": [
      "self",
      "req_id",
      "embedding_length",
      "embedding_dim"
    ],
    "send_encode_request": [
      "self",
      "obj"
    ],
    "recv_mm_data": [
      "self",
      "img_data",
      "mm_processor",
      "prompt"
    ],
    "_recv_mm_data": [
      "self",
      "req_id",
      "recv_socket",
      "mm_processor",
      "prompt"
    ]
  },
  "rid_lock": [],
  "use_image_processor_gpu": [],
  "MMError": {
    "__init__": [
      "self",
      "message",
      "code"
    ]
  },
  "BadRequestError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "InternalError": {
    "__init__": [
      "self",
      "message"
    ]
  },
  "TensorWrapper": {
    "__init__": [
      "self",
      "tensor"
    ],
    "__buffer__": [
      "self"
    ]
  },
  "_convert": [
    "data"
  ],
  "_image_grid_attrs": [],
  "_get_image_grid_dim": [
    "images_input"
  ],
  "MMEncoder": {
    "__init__": [
      "self",
      "server_args",
      "schedule_path",
      "dist_init_method",
      "rank"
    ],
    "_load_single_item": [
      "self",
      "data",
      "modality",
      "frame_count_limit",
      "audio_sample_rate",
      "discard_alpha_channel"
    ],
    "submit_data_loading_tasks": [
      "self",
      "items",
      "modalities"
    ],
    "_flatten_and_load_images": [
      "self",
      "mm_items"
    ],
    "_encode": [
      "self",
      "mm_items"
    ],
    "_send": [
      "self",
      "embedding",
      "mm_data",
      "session_id",
      "buffer_address",
      "prefill_host",
      "embedding_port",
      "url"
    ],
    "encode": [
      "self",
      "mm_items",
      "req_id",
      "num_parts",
      "part_idx"
    ],
    "send": [
      "self",
      "req_id",
      "prefill_host",
      "embedding_port",
      "session_id",
      "buffer_address"
    ],
    "send_with_url": [
      "self",
      "req_id"
    ],
    "get_embedding_port": [
      "self",
      "prefill_url"
    ]
  },
  "EncoderProfiler": {
    "__init__": [
      "self",
      "rank"
    ],
    "start": [
      "self",
      "obj"
    ],
    "step": [
      "self"
    ],
    "stop": [
      "self"
    ]
  },
  "run_encoder": [
    "server_args",
    "schedule_path",
    "dist_init_method",
    "rank"
  ],
  "launch_encoder": [
    "server_args",
    "schedule_path",
    "dist_init_method",
    "rank"
  ],
  "handle_encode_request": [
    "request"
  ],
  "handle_send_request": [
    "request"
  ],
  "handle_scheduler_receive_url_request": [
    "request"
  ],
  "EventBatch": {},
  "KVCacheEvent": {},
  "BlockStored": {},
  "BlockRemoved": {},
  "AllBlocksCleared": {},
  "KVEventBatch": {},
  "EventPublisher": {
    "__init__": [
      "self",
      "attn_dp_rank"
    ],
    "publish": [
      "self",
      "events"
    ],
    "shutdown": [
      "self"
    ]
  },
  "NullEventPublisher": {
    "publish": [
      "self",
      "events"
    ],
    "shutdown": [
      "self"
    ]
  },
  "ZmqEventPublisher": {
    "END_SEQ": [],
    "__init__": [
      "self",
      "attn_dp_rank",
      "endpoint",
      "replay_endpoint",
      "buffer_steps",
      "hwm",
      "max_queue_size",
      "topic"
    ],
    "publish": [
      "self",
      "events"
    ],
    "shutdown": [
      "self"
    ],
    "_socket_setup": [
      "self"
    ],
    "_publisher_thread": [
      "self"
    ],
    "_service_replay": [
      "self"
    ],
    "offset_endpoint_port": [
      "endpoint",
      "data_parallel_rank"
    ]
  },
  "KVEventsConfig": {
    "from_cli": [
      "cls",
      "cli_value"
    ]
  },
  "EventPublisherFactory": {
    "register_publisher": [
      "cls",
      "name",
      "ctor"
    ],
    "create": [
      "cls",
      "config",
      "attn_dp_rank"
    ]
  },
  "FastQueue": {
    "__init__": [
      "self"
    ],
    "put": [
      "self",
      "item"
    ],
    "get": [
      "self"
    ]
  },
  "group_concurrent_contiguous": [
    "src_indices",
    "dst_indices"
  ],
  "CommonKVManager": {
    "__init__": [
      "self",
      "args",
      "disaggregation_mode",
      "server_args",
      "is_mla_backend"
    ],
    "_register_to_bootstrap": [
      "self"
    ],
    "_connect": [
      "self",
      "endpoint",
      "is_ipv6"
    ],
    "get_mha_kv_ptrs_with_pp": [
      "self",
      "src_kv_ptrs",
      "dst_kv_ptrs"
    ],
    "get_mla_kv_ptrs_with_pp": [
      "self",
      "src_kv_ptrs",
      "dst_kv_ptrs"
    ]
  },
  "CommonKVSender": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "dest_tp_ranks",
      "pp_rank"
    ],
    "init": [
      "self",
      "num_kv_indices",
      "aux_index"
    ],
    "send": [
      "self",
      "kv_indices",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "CommonKVReceiver": {
    "_ctx": [],
    "_socket_cache": [],
    "_socket_locks": [],
    "_global_lock": [],
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "prefill_dp_rank"
    ],
    "_get_bootstrap_info_from_server": [
      "self",
      "engine_rank",
      "target_dp_group",
      "target_pp_rank"
    ],
    "_get_prefill_parallel_info_from_server": [
      "self"
    ],
    "_connect": [
      "cls",
      "endpoint",
      "is_ipv6"
    ],
    "_connect_to_bootstrap_server": [
      "cls",
      "bootstrap_info"
    ],
    "_register_kv_args": [
      "self"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "CommonKVBootstrapServer": {
    "__init__": [
      "self",
      "host",
      "port"
    ],
    "run": [
      "self"
    ],
    "_setup_routes": [
      "self"
    ],
    "_handle_health_check": [
      "self",
      "request"
    ],
    "_handle_route": [
      "self",
      "request"
    ],
    "_handle_route_put": [
      "self",
      "request"
    ],
    "_handle_route_get": [
      "self",
      "request"
    ],
    "_run_server": [
      "self"
    ],
    "close": [
      "self"
    ],
    "poll": [
      "self"
    ]
  },
  "FakeKVSender": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "dest_tp_ranks",
      "pp_rank"
    ],
    "poll": [
      "self"
    ],
    "init": [
      "self",
      "kv_indices",
      "aux_index"
    ],
    "send": [
      "self",
      "kv_indices",
      "state_indices"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "FakeKVReceiver": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "prefill_dp_rank"
    ],
    "poll": [
      "self"
    ],
    "init": [
      "self",
      "kv_indices",
      "aux_index",
      "state_indices"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "GUARD": [],
  "TransferInfo": {
    "is_dummy": [
      "self"
    ],
    "from_zmq": [
      "cls",
      "msg"
    ]
  },
  "KVArgsRegisterInfo": {
    "from_zmq": [
      "cls",
      "msg"
    ]
  },
  "TransferStatus": {
    "is_done": [
      "self"
    ],
    "is_failed": [
      "self"
    ]
  },
  "NixlKVManager": {
    "__init__": [
      "self",
      "args",
      "disaggregation_mode",
      "server_args",
      "is_mla_backend"
    ],
    "_start_heartbeat_checker_thread": [
      "self"
    ],
    "_handle_node_failure": [
      "self",
      "failed_bootstrap_addr"
    ],
    "check_status": [
      "self",
      "bootstrap_room"
    ],
    "update_status": [
      "self",
      "bootstrap_room",
      "status"
    ],
    "record_failure": [
      "self",
      "bootstrap_room",
      "failure_reason"
    ],
    "register_buffer_to_engine": [
      "self"
    ],
    "_add_remote_peer": [
      "self",
      "decode_kv_args"
    ],
    "send_kvcache": [
      "self",
      "peer_name",
      "prefill_kv_indices",
      "dst_kv_ptrs",
      "dst_kv_indices",
      "dst_gpu_id",
      "notif"
    ],
    "send_kvcache_slice": [
      "self",
      "peer_name",
      "prefill_kv_indices",
      "dst_kv_ptrs",
      "dst_kv_indices",
      "dst_gpu_id",
      "notif",
      "prefill_tp_size",
      "decode_tp_size",
      "decode_tp_rank",
      "dst_kv_item_len"
    ],
    "send_aux": [
      "self",
      "peer_name",
      "prefill_aux_index",
      "dst_aux_ptrs",
      "dst_aux_index",
      "notif"
    ],
    "add_transfer_request": [
      "self",
      "bootstrap_room",
      "kv_indices",
      "index_slice",
      "is_last",
      "chunk_id",
      "aux_index"
    ],
    "update_transfer_status": [
      "self"
    ],
    "check_transfer_done": [
      "self",
      "room"
    ],
    "_start_bootstrap_thread": [
      "self"
    ]
  },
  "NixlKVSender": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "dest_tp_ranks",
      "pp_rank"
    ],
    "send": [
      "self",
      "kv_indices",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "NixlKVReceiver": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "prefill_dp_rank"
    ],
    "init": [
      "self",
      "kv_indices",
      "aux_index",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "_register_kv_args": [
      "self"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "NixlKVBootstrapServer": {},
  "SUPPORTED_MOONCAKE_CUSTOM_MEM_POOL_TYPES": [],
  "init_mooncake_custom_mem_pool": [
    "device"
  ],
  "check_mooncake_custom_mem_pool_enabled": [],
  "KVTransferError": {
    "__init__": [
      "self",
      "bootstrap_room",
      "failure_reason"
    ],
    "__str__": [
      "self"
    ]
  },
  "TransferKVChunk": {},
  "AuxDataCodec": {
    "serialize_data_from_buffer": [
      "src_addr",
      "data_length"
    ],
    "deserialize_data_to_buffer": [
      "kv_args",
      "buffer_index",
      "aux_index",
      "data"
    ]
  },
  "MooncakeKVManager": {
    "AUX_DATA_HEADER": [],
    "__init__": [
      "self",
      "args",
      "disaggregation_mode",
      "server_args",
      "is_mla_backend"
    ],
    "init_engine": [
      "self"
    ],
    "register_buffer_to_engine": [
      "self"
    ],
    "_transfer_data": [
      "self",
      "mooncake_session_id",
      "transfer_blocks"
    ],
    "_send_kvcache_generic": [
      "self",
      "mooncake_session_id",
      "src_data_ptrs",
      "dst_data_ptrs",
      "item_lens",
      "prefill_data_indices",
      "dst_data_indices",
      "executor"
    ],
    "send_kvcache": [
      "self",
      "mooncake_session_id",
      "prefill_kv_indices",
      "dst_kv_ptrs",
      "dst_kv_indices",
      "executor"
    ],
    "send_kvcache_slice": [
      "self",
      "mooncake_session_id",
      "prefill_kv_indices",
      "dst_kv_ptrs",
      "dst_kv_indices",
      "dst_tp_rank",
      "dst_attn_tp_size",
      "dst_kv_item_len",
      "executor"
    ],
    "send_aux": [
      "self",
      "req",
      "prefill_aux_index",
      "dst_aux_ptrs"
    ],
    "send_aux_tcp": [
      "self",
      "req",
      "prefill_aux_index",
      "dst_aux_ptrs"
    ],
    "send_aux_data_to_endpoint": [
      "self",
      "remote",
      "dst_port",
      "room",
      "buffer_index",
      "aux_index",
      "data"
    ],
    "_handle_aux_data": [
      "self",
      "msg"
    ],
    "maybe_send_extra": [
      "self",
      "req",
      "prefill_state_indices",
      "dst_state_data_ptrs",
      "executor"
    ],
    "_send_mamba_state": [
      "self",
      "req",
      "prefill_mamba_index",
      "dst_state_data_ptrs"
    ],
    "sync_status_to_decode_endpoint": [
      "self",
      "remote",
      "dst_port",
      "room",
      "status",
      "prefill_rank"
    ],
    "transfer_worker": [
      "self",
      "queue",
      "executor"
    ],
    "start_prefill_thread": [
      "self"
    ],
    "start_decode_thread": [
      "self"
    ],
    "add_transfer_request": [
      "self",
      "bootstrap_room",
      "kv_indices",
      "index_slice",
      "is_last",
      "aux_index",
      "state_indices"
    ],
    "check_status": [
      "self",
      "bootstrap_room"
    ],
    "update_status": [
      "self",
      "bootstrap_room",
      "status"
    ],
    "record_failure": [
      "self",
      "bootstrap_room",
      "failure_reason"
    ],
    "get_session_id": [
      "self"
    ],
    "_handle_node_failure": [
      "self",
      "failed_bootstrap_addr"
    ]
  },
  "MooncakeKVSender": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "dest_tp_ranks",
      "pp_rank"
    ],
    "send": [
      "self",
      "kv_indices",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "failure_exception": [
      "self"
    ],
    "abort": [
      "self"
    ]
  },
  "MooncakeKVReceiver": {
    "_ctx": [],
    "_socket_cache": [],
    "_socket_locks": [],
    "_global_lock": [],
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "prefill_dp_rank"
    ],
    "_register_kv_args": [
      "self"
    ],
    "init": [
      "self",
      "kv_indices",
      "aux_index",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "failure_exception": [
      "self"
    ],
    "abort": [
      "self"
    ]
  },
  "MooncakeKVBootstrapServer": {},
  "get_ib_devices_for_gpu": [
    "ib_device_str",
    "gpu_id"
  ],
  "MooncakeTransferEngine": {
    "__init__": [
      "self",
      "hostname",
      "gpu_id",
      "ib_device"
    ],
    "register": [
      "self",
      "ptr",
      "length"
    ],
    "deregister": [
      "self",
      "ptr"
    ],
    "batch_register": [
      "self",
      "ptrs",
      "lengths"
    ],
    "batch_deregister": [
      "self",
      "ptrs"
    ],
    "initialize": [
      "self",
      "hostname",
      "device_name"
    ],
    "transfer_sync": [
      "self",
      "session_id",
      "buffer",
      "peer_buffer_address",
      "length"
    ],
    "batch_transfer_sync": [
      "self",
      "session_id",
      "buffers",
      "peer_buffer_addresses",
      "lengths"
    ],
    "get_session_id": [
      "self"
    ]
  },
  "AscendKVManager": {
    "init_engine": [
      "self"
    ],
    "register_buffer_to_engine": [
      "self"
    ],
    "send_kvcache": [
      "self",
      "mooncake_session_id",
      "prefill_kv_indices",
      "dst_kv_ptrs",
      "dst_kv_indices",
      "executor"
    ]
  },
  "AscendKVSender": {},
  "AscendKVReceiver": {},
  "AscendKVBootstrapServer": {},
  "AscendTransferEngine": {
    "__init__": [
      "self",
      "hostname",
      "npu_id",
      "disaggregation_mode"
    ],
    "initialize": [
      "self"
    ],
    "batch_register": [
      "self",
      "ptrs",
      "lengths"
    ],
    "_get_transfer_protocol": []
  },
  "KVArgs": {},
  "KVPoll": {
    "Failed": [],
    "Bootstrapping": [],
    "WaitingForInput": [],
    "Transferring": [],
    "Success": []
  },
  "BaseKVManager": {
    "__init__": [
      "self",
      "args",
      "disaggregation_mode",
      "server_args",
      "is_mla_backend"
    ]
  },
  "BaseKVSender": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room",
      "dest_tp_ranks",
      "pp_rank"
    ],
    "init": [
      "self",
      "num_kv_indices",
      "aux_index"
    ],
    "send": [
      "self",
      "kv_indices",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "failure_exception": [
      "self"
    ]
  },
  "BaseKVReceiver": {
    "__init__": [
      "self",
      "mgr",
      "bootstrap_addr",
      "bootstrap_room"
    ],
    "init": [
      "self",
      "kv_indices",
      "aux_index",
      "state_indices"
    ],
    "poll": [
      "self"
    ],
    "failure_exception": [
      "self"
    ],
    "clear": [
      "self"
    ],
    "abort": [
      "self"
    ]
  },
  "BaseKVBootstrapServer": {
    "__init__": [
      "self",
      "host",
      "port"
    ]
  },
  "_jit_stream_wait_value_module": [],
  "stream_wait_value": [
    "flag",
    "value"
  ],
  "test_wait_before_record": [
    "event"
  ],
  "_jit_qknorm_module": [
    "head_dim",
    "dtype"
  ],
  "_jit_rmsnorm_module": [
    "hidden_size",
    "dtype"
  ],
  "can_use_fused_inplace_qknorm": [
    "head_dim",
    "dtype"
  ],
  "rmsnorm": [
    "input",
    "weight",
    "output",
    "eps"
  ],
  "_jit_add_constant_module": [
    "constant"
  ],
  "add_constant": [
    "src",
    "constant"
  ],
  "_jit_per_tensor_quant_fp8_module": [
    "is_static",
    "dtype"
  ],
  "per_tensor_quant_fp8": [
    "input",
    "output_q",
    "output_s",
    "is_static"
  ],
  "_make_wrapper": [
    "tup"
  ],
  "_resolve_kernel_path": [],
  "KERNEL_PATH": [],
  "DEFAULT_INCLUDE": [],
  "DEFAULT_CFLAGS": [],
  "DEFAULT_CUDA_CFLAGS": [],
  "DEFAULT_LDFLAGS": [],
  "CPPArgList": {
    "__str__": [
      "self"
    ]
  },
  "CPP_DTYPE_MAP": [],
  "make_cpp_args": [],
  "load_jit": [],
  "cache_once": [
    "fn"
  ],
  "is_arch_support_pdl": [],
  "DEFAULT_BLOCK_QUOTA": [],
  "_jit_hicache_module": [],
  "can_use_hicache_jit_kernel": [],
  "_default_unroll": [
    "element_size"
  ],
  "transfer_hicache_one_layer": [
    "k_cache_dst",
    "v_cache_dst",
    "indices_dst",
    "k_cache_src",
    "v_cache_src",
    "indices_src"
  ],
  "transfer_hicache_all_layer": [
    "k_ptr_dst",
    "v_ptr_dst",
    "indices_dst",
    "k_ptr_src",
    "v_ptr_src",
    "indices_src"
  ],
  "_jit_kvcache_module": [
    "row_bytes"
  ],
  "can_use_store_cache": [
    "size"
  ],
  "TILE_K": [],
  "TILE_V": [],
  "TILE_V_PADDED": [],
  "TILE_V_SMALL": [],
  "TILE_V_SMALL_PADDED": [],
  "NUM_STAGES": [],
  "NUM_THREADS": [],
  "NUM_BLOCKS_PER_STATE_SMALL": [],
  "NUM_THREADS_LARGE": [],
  "NUM_WARPS_LARGE": [],
  "V_PER_WARP": [],
  "ROWS_PER_ITER": [],
  "NUM_K_ITERS": [],
  "SMALL_BATCH_THRESHOLD": [],
  "_define_kernels": [],
  "_create_jit_functions": [],
  "_jit_functions": [],
  "_get_jit_functions": [],
  "_get_compiled_kernel": [
    "N",
    "H",
    "HV",
    "K",
    "V",
    "pool_size",
    "use_small_batch",
    "is_varlen_decode"
  ],
  "cutedsl_fused_sigmoid_gating_delta_rule_update": [
    "A_log",
    "dt_bias",
    "q",
    "k",
    "v",
    "a",
    "b",
    "initial_state_source",
    "initial_state_indices",
    "cu_seqlens",
    "scale",
    "use_qk_l2norm_in_kernel",
    "softplus_beta",
    "softplus_threshold"
  ],
  "generate_clangd": [],
  "IS_CI": [],
  "alt_stream": [],
  "sglang_aot_qknorm": [
    "q",
    "k",
    "q_weight",
    "k_weight"
  ],
  "sglang_jit_qknorm": [
    "q",
    "k",
    "q_weight",
    "k_weight"
  ],
  "flashinfer_qknorm": [
    "q",
    "k",
    "q_weight",
    "k_weight"
  ],
  "torch_impl_qknorm": [
    "q",
    "k",
    "q_weight",
    "k_weight",
    "eps"
  ],
  "HEAD_DIM": [],
  "DTYPE": [],
  "DEVICE": [],
  "LINE_VALS": [],
  "LINE_NAMES": [],
  "STYLES": [],
  "configs": [],
  "fp8_type_": [],
  "vllm_scaled_fp8_quant": [
    "input",
    "scale"
  ],
  "sglang_scaled_fp8_quant": [
    "input",
    "scale"
  ],
  "calculate_diff": [
    "batch_size",
    "seq_len"
  ],
  "sglang_aot_rmsnorm": [
    "input",
    "weight"
  ],
  "sglang_jit_rmsnorm": [
    "input",
    "weight"
  ],
  "flashinfer_rmsnorm": [
    "input",
    "weight"
  ],
  "torch_impl_rmsnorm": [
    "input",
    "weight",
    "eps"
  ],
  "sglang_aot_store_cache": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "indices"
  ],
  "sglang_jit_store_cache": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "indices"
  ],
  "torch_compile_store_cache": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "indices"
  ],
  "torch_streams_store_cache": [
    "k",
    "v",
    "k_cache",
    "v_cache",
    "indices"
  ],
  "NUM_LAYERS": [],
  "CACHE_SIZE": [],
  "X_NAMES": [],
  "CONFIGS": [],
  "N_K_LIST": [],
  "N_Q_LIST": [],
  "HEAD_DIM_LIST": [],
  "test_qknorm": [
    "batch_size",
    "n_k",
    "n_q",
    "head_dim"
  ],
  "HIDDEN_DIMS": [],
  "test_store_cache": [
    "batch_size",
    "element_dim"
  ],
  "HIDDEN_SIZE_LIST": [],
  "test_rmsnorm": [
    "batch_size",
    "hidden_size"
  ],
  "torch_scaled_fp8_quant": [
    "tensor",
    "inv_scale"
  ],
  "test_jit_per_tensor_quant_compare_implementations": [
    "num_tokens",
    "hidden_dim"
  ],
  "test_jit_per_tensor_quant_supports_3d": [
    "shape"
  ],
  "run_triton_kernel": [
    "A_log",
    "dt_bias",
    "q",
    "k",
    "v",
    "a",
    "b",
    "initial_state",
    "indices",
    "scale"
  ],
  "test_cutedsl_gdn_precision": [
    "B"
  ],
  "test_cutedsl_gdn_performance": [
    "B"
  ],
  "get_client": [
    "api_url"
  ],
  "fetch_response": [
    "client",
    "context",
    "question",
    "semaphore",
    "index",
    "model",
    "output_dir"
  ],
  "analyse": [
    "args"
  ],
  "provider_to_models": [],
  "fetch_responses": [
    "client",
    "prompt",
    "semaphore",
    "index",
    "provider",
    "model_size",
    "output_dir",
    "max_tokens"
  ],
  "TASK_TO_MAX_TOKENS": [],
  "TASK_TO_EVAL_SET": [],
  "CustomAsyncHTTPXClient": {
    "send": [
      "self",
      "request"
    ]
  },
  "get_mmlu_answer": [
    "response"
  ],
  "get_mmlu_cot_answer": [
    "response"
  ],
  "get_answer_gsm8k": [
    "response"
  ],
  "TASK_TO_ANSWER_EXTRACTOR": [],
  "get_dataset_from_task": [
    "task",
    "response_path",
    "model_size"
  ],
  "analyze": [
    "task",
    "response_path",
    "model_size"
  ],
  "generate": [
    "args",
    "extra_argv"
  ],
  "_get_lock": [
    "model_name_or_path",
    "cache_dir"
  ],
  "_maybe_download_model": [
    "model_name_or_path",
    "local_dir",
    "download"
  ],
  "is_diffusers_model_path": [
    "model_path"
  ],
  "get_is_diffusion_model": [
    "model_path"
  ],
  "get_model_path": [
    "extra_argv"
  ],
  "get_git_commit_hash": [],
  "serve": [
    "args",
    "extra_argv"
  ],
  "get_default_cache_root": [],
  "get_default_config_root": [],
  "maybe_convert_int": [
    "value"
  ],
  "_lazy_str": [
    "key",
    "default"
  ],
  "_lazy_int": [
    "key",
    "default"
  ],
  "_lazy_float": [
    "key",
    "default"
  ],
  "_lazy_bool": [
    "key",
    "default"
  ],
  "_lazy_bool_any": [
    "keys",
    "default"
  ],
  "_lazy_path": [
    "key",
    "default_func"
  ],
  "_CACHE_DIT_SECONDARY_CONFIGS": [],
  "_create_secondary_getter": [
    "suffix",
    "type_func",
    "default_val"
  ],
  "_secondary_taylorseer_getter": [],
  "__getattr__": [
    "name"
  ],
  "__dir__": [],
  "PRECISION_TO_TYPE": [],
  "prev_set_stream": [],
  "_current_stream": [],
  "_patched_set_stream": [
    "stream"
  ],
  "current_stream": [],
  "StoreBoolean": {
    "__init__": [
      "self",
      "option_strings",
      "dest",
      "default",
      "required",
      "help"
    ],
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "FlexibleArgumentParser": {
    "__init__": [
      "self"
    ],
    "parse_args": [
      "self",
      "args",
      "namespace"
    ],
    "_pull_args_from_config": [
      "self",
      "args"
    ],
    "_load_config_file": [
      "self",
      "file_path"
    ]
  },
  "warn_for_unimplemented_methods": [
    "cls"
  ],
  "align_to": [
    "value",
    "alignment"
  ],
  "import_pynvml": [],
  "run_method": [
    "obj",
    "method",
    "args",
    "kwargs"
  ],
  "shallow_asdict": [
    "obj"
  ],
  "remote_breakpoint": [],
  "MixedPrecisionState": {},
  "_mixed_precision_state": [],
  "get_mixed_precision_state": [],
  "set_mixed_precision_policy": [
    "param_dtype",
    "reduce_dtype",
    "output_dtype",
    "mp_policy"
  ],
  "get_compute_dtype": [],
  "dict_to_3d_list": [
    "mask_strategy",
    "t_max",
    "l_max",
    "h_max"
  ],
  "is_vsa_available": [],
  "is_vmoba_available": [],
  "masks_like": [
    "tensors",
    "zero",
    "generator",
    "p"
  ],
  "best_output_size": [
    "w",
    "h",
    "dw",
    "dh",
    "expected_area"
  ],
  "calculate_dimensions": [
    "target_area",
    "ratio"
  ],
  "_discover_and_register_pipelines": [],
  "get_pipeline_config_classes": [
    "pipeline_class_name"
  ],
  "ConfigInfo": {},
  "register_configs": [
    "sampling_param_cls",
    "pipeline_config_cls",
    "hf_model_paths",
    "model_detectors"
  ],
  "get_model_short_name": [
    "model_id"
  ],
  "_get_config_info": [
    "model_path"
  ],
  "ModelInfo": {},
  "_get_diffusers_model_info": [
    "model_path"
  ],
  "_register_configs": [],
  "_nvmlEnableState_t": [],
  "NVML_FEATURE_DISABLED": [],
  "NVML_FEATURE_ENABLED": [],
  "_nvmlBrandType_t": [],
  "NVML_BRAND_UNKNOWN": [],
  "NVML_BRAND_QUADRO": [],
  "NVML_BRAND_TESLA": [],
  "NVML_BRAND_NVS": [],
  "NVML_BRAND_GRID": [],
  "NVML_BRAND_GEFORCE": [],
  "NVML_BRAND_TITAN": [],
  "NVML_BRAND_NVIDIA_VAPPS": [],
  "NVML_BRAND_NVIDIA_VPC": [],
  "NVML_BRAND_NVIDIA_VCS": [],
  "NVML_BRAND_NVIDIA_VWS": [],
  "NVML_BRAND_NVIDIA_CLOUD_GAMING": [],
  "NVML_BRAND_NVIDIA_VGAMING": [],
  "NVML_BRAND_QUADRO_RTX": [],
  "NVML_BRAND_NVIDIA_RTX": [],
  "NVML_BRAND_NVIDIA": [],
  "NVML_BRAND_GEFORCE_RTX": [],
  "NVML_BRAND_TITAN_RTX": [],
  "NVML_BRAND_COUNT": [],
  "_nvmlTemperatureThresholds_t": [],
  "NVML_TEMPERATURE_THRESHOLD_SHUTDOWN": [],
  "NVML_TEMPERATURE_THRESHOLD_SLOWDOWN": [],
  "NVML_TEMPERATURE_THRESHOLD_MEM_MAX": [],
  "NVML_TEMPERATURE_THRESHOLD_GPU_MAX": [],
  "NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MIN": [],
  "NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_CURR": [],
  "NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MAX": [],
  "NVML_TEMPERATURE_THRESHOLD_GPS_CURR": [],
  "NVML_TEMPERATURE_THRESHOLD_COUNT": [],
  "_nvmlTemperatureSensors_t": [],
  "NVML_TEMPERATURE_GPU": [],
  "NVML_TEMPERATURE_COUNT": [],
  "_nvmlComputeMode_t": [],
  "NVML_COMPUTEMODE_DEFAULT": [],
  "NVML_COMPUTEMODE_EXCLUSIVE_THREAD": [],
  "NVML_COMPUTEMODE_PROHIBITED": [],
  "NVML_COMPUTEMODE_EXCLUSIVE_PROCESS": [],
  "NVML_COMPUTEMODE_COUNT": [],
  "_nvmlMemoryLocation_t": [],
  "NVML_MEMORY_LOCATION_L1_CACHE": [],
  "NVML_MEMORY_LOCATION_L2_CACHE": [],
  "NVML_MEMORY_LOCATION_DEVICE_MEMORY": [],
  "NVML_MEMORY_LOCATION_DRAM": [],
  "NVML_MEMORY_LOCATION_REGISTER_FILE": [],
  "NVML_MEMORY_LOCATION_TEXTURE_MEMORY": [],
  "NVML_MEMORY_LOCATION_TEXTURE_SHM": [],
  "NVML_MEMORY_LOCATION_CBU": [],
  "NVML_MEMORY_LOCATION_SRAM": [],
  "NVML_MEMORY_LOCATION_COUNT": [],
  "NVML_NVLINK_MAX_LINKS": [],
  "NVML_NVLINK_MAX_LANES": [],
  "_nvmlNvLinkErrorCounter_t": [],
  "NVML_NVLINK_ERROR_DL_REPLAY": [],
  "NVML_NVLINK_ERROR_DL_RECOVERY": [],
  "NVML_NVLINK_ERROR_DL_CRC_FLIT": [],
  "NVML_NVLINK_ERROR_DL_CRC_DATA": [],
  "NVML_NVLINK_ERROR_DL_ECC_DATA": [],
  "NVML_NVLINK_ERROR_COUNT": [],
  "_nvmlNvLinkEccLaneErrorCounter_t": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE0": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE1": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE2": [],
  "NVML_NVLINK_ERROR_DL_ECC_LANE3": [],
  "NVML_NVLINK_ERROR_DL_ECC_COUNT": [],
  "_nvmlNvLinkCapability_t": [],
  "NVML_NVLINK_CAP_P2P_SUPPORTED": [],
  "NVML_NVLINK_CAP_SYSMEM_ACCESS": [],
  "NVML_NVLINK_CAP_P2P_ATOMICS": [],
  "NVML_NVLINK_CAP_SYSMEM_ATOMICS": [],
  "NVML_NVLINK_CAP_SLI_BRIDGE": [],
  "NVML_NVLINK_CAP_VALID": [],
  "NVML_NVLINK_CAP_COUNT": [],
  "_nvmlNvLinkUtilizationCountPktTypes_t": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_NOP": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_READ": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_WRITE": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_RATOM": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_NRATOM": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_FLUSH": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_RESPDATA": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_RESPNODATA": [],
  "NVML_NVLINK_COUNTER_PKTFILTER_ALL": [],
  "_nvmlNvLinkUtilizationCountUnits_t": [],
  "NVML_NVLINK_COUNTER_UNIT_CYCLES": [],
  "NVML_NVLINK_COUNTER_UNIT_PACKETS": [],
  "NVML_NVLINK_COUNTER_UNIT_BYTES": [],
  "NVML_NVLINK_COUNTER_UNIT_RESERVED": [],
  "NVML_NVLINK_COUNTER_UNIT_COUNT": [],
  "_nvmlNvLinkDeviceType_t": [],
  "NVML_NVLINK_DEVICE_TYPE_GPU": [],
  "NVML_NVLINK_DEVICE_TYPE_IBMNPU": [],
  "NVML_NVLINK_DEVICE_TYPE_SWITCH": [],
  "NVML_NVLINK_DEVICE_TYPE_UNKNOWN": [],
  "_nvmlEccBitType_t": [],
  "NVML_SINGLE_BIT_ECC": [],
  "NVML_DOUBLE_BIT_ECC": [],
  "NVML_ECC_ERROR_TYPE_COUNT": [],
  "_nvmlEccCounterType_t": [],
  "NVML_VOLATILE_ECC": [],
  "NVML_AGGREGATE_ECC": [],
  "NVML_ECC_COUNTER_TYPE_COUNT": [],
  "_nvmlMemoryErrorType_t": [],
  "NVML_MEMORY_ERROR_TYPE_CORRECTED": [],
  "NVML_MEMORY_ERROR_TYPE_UNCORRECTED": [],
  "NVML_MEMORY_ERROR_TYPE_COUNT": [],
  "_nvmlClockType_t": [],
  "NVML_CLOCK_GRAPHICS": [],
  "NVML_CLOCK_SM": [],
  "NVML_CLOCK_MEM": [],
  "NVML_CLOCK_VIDEO": [],
  "NVML_CLOCK_COUNT": [],
  "_nvmlClockId_t": [],
  "NVML_CLOCK_ID_CURRENT": [],
  "NVML_CLOCK_ID_APP_CLOCK_TARGET": [],
  "NVML_CLOCK_ID_APP_CLOCK_DEFAULT": [],
  "NVML_CLOCK_ID_CUSTOMER_BOOST_MAX": [],
  "NVML_CLOCK_ID_COUNT": [],
  "_nvmlDriverModel_t": [],
  "NVML_DRIVER_WDDM": [],
  "NVML_DRIVER_WDM": [],
  "NVML_DRIVER_MCDM": [],
  "NVML_MAX_GPU_PERF_PSTATES": [],
  "_nvmlPstates_t": [],
  "NVML_PSTATE_0": [],
  "NVML_PSTATE_1": [],
  "NVML_PSTATE_2": [],
  "NVML_PSTATE_3": [],
  "NVML_PSTATE_4": [],
  "NVML_PSTATE_5": [],
  "NVML_PSTATE_6": [],
  "NVML_PSTATE_7": [],
  "NVML_PSTATE_8": [],
  "NVML_PSTATE_9": [],
  "NVML_PSTATE_10": [],
  "NVML_PSTATE_11": [],
  "NVML_PSTATE_12": [],
  "NVML_PSTATE_13": [],
  "NVML_PSTATE_14": [],
  "NVML_PSTATE_15": [],
  "NVML_PSTATE_UNKNOWN": [],
  "_nvmlInforomObject_t": [],
  "NVML_INFOROM_OEM": [],
  "NVML_INFOROM_ECC": [],
  "NVML_INFOROM_POWER": [],
  "NVML_INFOROM_DEN": [],
  "NVML_INFOROM_COUNT": [],
  "_nvmlReturn_t": [],
  "NVML_SUCCESS": [],
  "NVML_ERROR_UNINITIALIZED": [],
  "NVML_ERROR_INVALID_ARGUMENT": [],
  "NVML_ERROR_NOT_SUPPORTED": [],
  "NVML_ERROR_NO_PERMISSION": [],
  "NVML_ERROR_ALREADY_INITIALIZED": [],
  "NVML_ERROR_NOT_FOUND": [],
  "NVML_ERROR_INSUFFICIENT_SIZE": [],
  "NVML_ERROR_INSUFFICIENT_POWER": [],
  "NVML_ERROR_DRIVER_NOT_LOADED": [],
  "NVML_ERROR_TIMEOUT": [],
  "NVML_ERROR_IRQ_ISSUE": [],
  "NVML_ERROR_LIBRARY_NOT_FOUND": [],
  "NVML_ERROR_FUNCTION_NOT_FOUND": [],
  "NVML_ERROR_CORRUPTED_INFOROM": [],
  "NVML_ERROR_GPU_IS_LOST": [],
  "NVML_ERROR_RESET_REQUIRED": [],
  "NVML_ERROR_OPERATING_SYSTEM": [],
  "NVML_ERROR_LIB_RM_VERSION_MISMATCH": [],
  "NVML_ERROR_IN_USE": [],
  "NVML_ERROR_MEMORY": [],
  "NVML_ERROR_NO_DATA": [],
  "NVML_ERROR_VGPU_ECC_NOT_SUPPORTED": [],
  "NVML_ERROR_INSUFFICIENT_RESOURCES": [],
  "NVML_ERROR_FREQ_NOT_SUPPORTED": [],
  "NVML_ERROR_ARGUMENT_VERSION_MISMATCH": [],
  "NVML_ERROR_DEPRECATED": [],
  "NVML_ERROR_NOT_READY": [],
  "NVML_ERROR_GPU_NOT_FOUND": [],
  "NVML_ERROR_INVALID_STATE": [],
  "NVML_ERROR_UNKNOWN": [],
  "_nvmlFanState_t": [],
  "NVML_FAN_NORMAL": [],
  "NVML_FAN_FAILED": [],
  "_nvmlFanControlPolicy_t": [],
  "NVML_FAN_POLICY_TEMPERATURE_CONTINOUS_SW": [],
  "NVML_FAN_POLICY_MANUAL": [],
  "_nvmlLedColor_t": [],
  "NVML_LED_COLOR_GREEN": [],
  "NVML_LED_COLOR_AMBER": [],
  "_nvmlGpuOperationMode_t": [],
  "NVML_GOM_ALL_ON": [],
  "NVML_GOM_COMPUTE": [],
  "NVML_GOM_LOW_DP": [],
  "_nvmlPageRetirementCause_t": [],
  "NVML_PAGE_RETIREMENT_CAUSE_MULTIPLE_SINGLE_BIT_ECC_ERRORS": [],
  "NVML_PAGE_RETIREMENT_CAUSE_DOUBLE_BIT_ECC_ERROR": [],
  "NVML_PAGE_RETIREMENT_CAUSE_COUNT": [],
  "_nvmlRestrictedAPI_t": [],
  "NVML_RESTRICTED_API_SET_APPLICATION_CLOCKS": [],
  "NVML_RESTRICTED_API_SET_AUTO_BOOSTED_CLOCKS": [],
  "NVML_RESTRICTED_API_COUNT": [],
  "_nvmlBridgeChipType_t": [],
  "NVML_BRIDGE_CHIP_PLX": [],
  "NVML_BRIDGE_CHIP_BRO4": [],
  "NVML_MAX_PHYSICAL_BRIDGE": [],
  "_nvmlValueType_t": [],
  "NVML_VALUE_TYPE_DOUBLE": [],
  "NVML_VALUE_TYPE_UNSIGNED_INT": [],
  "NVML_VALUE_TYPE_UNSIGNED_LONG": [],
  "NVML_VALUE_TYPE_UNSIGNED_LONG_LONG": [],
  "NVML_VALUE_TYPE_SIGNED_LONG_LONG": [],
  "NVML_VALUE_TYPE_SIGNED_INT": [],
  "NVML_VALUE_TYPE_UNSIGNED_SHORT": [],
  "NVML_VALUE_TYPE_COUNT": [],
  "_nvmlNvlinkVersion_t": [],
  "NVML_NVLINK_VERSION_INVALID": [],
  "NVML_NVLINK_VERSION_1_0": [],
  "NVML_NVLINK_VERSION_2_0": [],
  "NVML_NVLINK_VERSION_2_2": [],
  "NVML_NVLINK_VERSION_3_0": [],
  "NVML_NVLINK_VERSION_3_1": [],
  "NVML_NVLINK_VERSION_4_0": [],
  "NVML_NVLINK_VERSION_5_0": [],
  "_nvmlPerfPolicyType_t": [],
  "NVML_PERF_POLICY_POWER": [],
  "NVML_PERF_POLICY_THERMAL": [],
  "NVML_PERF_POLICY_SYNC_BOOST": [],
  "NVML_PERF_POLICY_BOARD_LIMIT": [],
  "NVML_PERF_POLICY_LOW_UTILIZATION": [],
  "NVML_PERF_POLICY_RELIABILITY": [],
  "NVML_PERF_POLICY_TOTAL_APP_CLOCKS": [],
  "NVML_PERF_POLICY_TOTAL_BASE_CLOCKS": [],
  "NVML_PERF_POLICY_COUNT": [],
  "_nvmlEncoderQueryType_t": [],
  "NVML_ENCODER_QUERY_H264": [],
  "NVML_ENCODER_QUERY_HEVC": [],
  "NVML_ENCODER_QUERY_AV1": [],
  "NVML_ENCODER_QUERY_UNKNOWN": [],
  "_nvmlFBCSessionType_t": [],
  "NVML_FBC_SESSION_TYPE_UNKNOWN": [],
  "NVML_FBC_SESSION_TYPE_TOSYS": [],
  "NVML_FBC_SESSION_TYPE_CUDA": [],
  "NVML_FBC_SESSION_TYPE_VID": [],
  "NVML_FBC_SESSION_TYPE_HWENC": [],
  "_nvmlDetachGpuState_t": [],
  "NVML_DETACH_GPU_KEEP": [],
  "NVML_DETACH_GPU_REMOVE": [],
  "_nvmlPcieLinkState_t": [],
  "NVML_PCIE_LINK_KEEP": [],
  "NVML_PCIE_LINK_SHUT_DOWN": [],
  "_nvmlSamplingType_t": [],
  "NVML_TOTAL_POWER_SAMPLES": [],
  "NVML_GPU_UTILIZATION_SAMPLES": [],
  "NVML_MEMORY_UTILIZATION_SAMPLES": [],
  "NVML_ENC_UTILIZATION_SAMPLES": [],
  "NVML_DEC_UTILIZATION_SAMPLES": [],
  "NVML_PROCESSOR_CLK_SAMPLES": [],
  "NVML_MEMORY_CLK_SAMPLES": [],
  "NVML_MODULE_POWER_SAMPLES": [],
  "NVML_JPG_UTILIZATION_SAMPLES": [],
  "NVML_OFA_UTILIZATION_SAMPLES": [],
  "NVML_SAMPLINGTYPE_COUNT": [],
  "_nvmlPcieUtilCounter_t": [],
  "NVML_PCIE_UTIL_TX_BYTES": [],
  "NVML_PCIE_UTIL_RX_BYTES": [],
  "NVML_PCIE_UTIL_COUNT": [],
  "_nvmlGpuTopologyLevel_t": [],
  "NVML_TOPOLOGY_INTERNAL": [],
  "NVML_TOPOLOGY_SINGLE": [],
  "NVML_TOPOLOGY_MULTIPLE": [],
  "NVML_TOPOLOGY_HOSTBRIDGE": [],
  "NVML_TOPOLOGY_NODE": [],
  "NVML_TOPOLOGY_CPU": [],
  "NVML_TOPOLOGY_SYSTEM": [],
  "_nvmlGpuP2PCapsIndex_t": [],
  "NVML_P2P_CAPS_INDEX_READ": [],
  "NVML_P2P_CAPS_INDEX_WRITE": [],
  "NVML_P2P_CAPS_INDEX_NVLINK": [],
  "NVML_P2P_CAPS_INDEX_ATOMICS": [],
  "NVML_P2P_CAPS_INDEX_PROP": [],
  "NVML_P2P_CAPS_INDEX_PCI": [],
  "NVML_P2P_CAPS_INDEX_UNKNOWN": [],
  "_nvmlGpuP2PStatus_t": [],
  "NVML_P2P_STATUS_OK": [],
  "NVML_P2P_STATUS_CHIPSET_NOT_SUPPORED": [],
  "NVML_P2P_STATUS_CHIPSET_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_GPU_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_IOH_TOPOLOGY_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_DISABLED_BY_REGKEY": [],
  "NVML_P2P_STATUS_NOT_SUPPORTED": [],
  "NVML_P2P_STATUS_UNKNOWN": [],
  "_nvmlDeviceArchitecture_t": [],
  "NVML_DEVICE_ARCH_KEPLER": [],
  "NVML_DEVICE_ARCH_MAXWELL": [],
  "NVML_DEVICE_ARCH_PASCAL": [],
  "NVML_DEVICE_ARCH_VOLTA": [],
  "NVML_DEVICE_ARCH_TURING": [],
  "NVML_DEVICE_ARCH_AMPERE": [],
  "NVML_DEVICE_ARCH_ADA": [],
  "NVML_DEVICE_ARCH_HOPPER": [],
  "NVML_DEVICE_ARCH_BLACKWELL": [],
  "NVML_DEVICE_ARCH_T23X": [],
  "NVML_DEVICE_ARCH_UNKNOWN": [],
  "_nvmlBusType_t": [],
  "NVML_BUS_TYPE_UNKNOWN": [],
  "NVML_BUS_TYPE_PCI": [],
  "NVML_BUS_TYPE_PCIE": [],
  "NVML_BUS_TYPE_FPCI": [],
  "NVML_BUS_TYPE_AGP": [],
  "_nvmlPowerSource_t": [],
  "NVML_POWER_SOURCE_AC": [],
  "NVML_POWER_SOURCE_BATTERY": [],
  "NVML_POWER_SOURCE_UNDERSIZED": [],
  "_nvmlAdaptiveClockInfoStatus_t": [],
  "NVML_ADAPTIVE_CLOCKING_INFO_STATUS_DISABLED": [],
  "NVML_ADAPTIVE_CLOCKING_INFO_STATUS_ENABLED": [],
  "_nvmlClockLimitId_t": [],
  "NVML_CLOCK_LIMIT_ID_RANGE_START": [],
  "NVML_CLOCK_LIMIT_ID_TDP": [],
  "NVML_CLOCK_LIMIT_ID_UNLIMITED": [],
  "_nvmlPcieLinkMaxSpeed_t": [],
  "NVML_PCIE_LINK_MAX_SPEED_INVALID": [],
  "NVML_PCIE_LINK_MAX_SPEED_2500MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_5000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_8000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_16000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_32000MBPS": [],
  "NVML_PCIE_LINK_MAX_SPEED_64000MBPS": [],
  "_nvmlPcieAtomicsCapability_t": [],
  "NVML_PCIE_ATOMICS_CAP_FETCHADD32": [],
  "NVML_PCIE_ATOMICS_CAP_FETCHADD64": [],
  "NVML_PCIE_ATOMICS_CAP_SWAP32": [],
  "NVML_PCIE_ATOMICS_CAP_SWAP64": [],
  "NVML_PCIE_ATOMICS_CAP_CAS32": [],
  "NVML_PCIE_ATOMICS_CAP_CAS64": [],
  "NVML_PCIE_ATOMICS_CAP_CAS128": [],
  "NVML_PCIE_ATOMICS_OPS_MAX": [],
  "_nvmlAffinityScope_t": [],
  "NVML_AFFINITY_SCOPE_NODE": [],
  "NVML_AFFINITY_SCOPE_SOCKET": [],
  "_nvmlDeviceGpuRecoveryAction_t": [],
  "NVML_GPU_RECOVERY_ACTION_NONE": [],
  "NVML_GPU_RECOVERY_ACTION_GPU_RESET": [],
  "NVML_GPU_RECOVERY_ACTION_NODE_REBOOT": [],
  "NVML_GPU_RECOVERY_ACTION_DRAIN_P2P": [],
  "NVML_GPU_RECOVERY_ACTION_DRAIN_AND_RESET": [],
  "nvmlFlagDefault": [],
  "nvmlFlagForce": [],
  "NVML_INIT_FLAG_NO_GPUS": [],
  "NVML_INIT_FLAG_NO_ATTACH": [],
  "NVML_MAX_GPC_COUNT": [],
  "NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE": [],
  "NVML_DEVICE_UUID_BUFFER_SIZE": [],
  "NVML_DEVICE_UUID_V2_BUFFER_SIZE": [],
  "NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE": [],
  "NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE": [],
  "NVML_DEVICE_NAME_BUFFER_SIZE": [],
  "NVML_DEVICE_NAME_V2_BUFFER_SIZE": [],
  "NVML_DEVICE_SERIAL_BUFFER_SIZE": [],
  "NVML_DEVICE_PART_NUMBER_BUFFER_SIZE": [],
  "NVML_DEVICE_GPU_PART_NUMBER_BUFFER_SIZE": [],
  "NVML_DEVICE_VBIOS_VERSION_BUFFER_SIZE": [],
  "NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE": [],
  "NVML_DEVICE_PCI_BUS_ID_BUFFER_V2_SIZE": [],
  "NVML_GRID_LICENSE_BUFFER_SIZE": [],
  "NVML_VGPU_NAME_BUFFER_SIZE": [],
  "NVML_GRID_LICENSE_FEATURE_MAX_COUNT": [],
  "NVML_VGPU_METADATA_OPAQUE_DATA_SIZE": [],
  "NVML_VGPU_PGPU_METADATA_OPAQUE_DATA_SIZE": [],
  "NVML_DEVICE_GPU_FRU_PART_NUMBER_BUFFER_SIZE": [],
  "NVML_PERF_MODES_BUFFER_SIZE": [],
  "NVML_DEVICE_PCI_BUS_ID_LEGACY_FMT": [],
  "NVML_DEVICE_PCI_BUS_ID_FMT": [],
  "NVML_VALUE_NOT_AVAILABLE_ulonglong": [],
  "NVML_VALUE_NOT_AVAILABLE_uint": [],
  "NVML_FI_DEV_ECC_CURRENT": [],
  "NVML_FI_DEV_ECC_PENDING": [],
  "NVML_FI_DEV_ECC_SBE_VOL_TOTAL": [],
  "NVML_FI_DEV_ECC_DBE_VOL_TOTAL": [],
  "NVML_FI_DEV_ECC_SBE_AGG_TOTAL": [],
  "NVML_FI_DEV_ECC_DBE_AGG_TOTAL": [],
  "NVML_FI_DEV_ECC_SBE_VOL_L1": [],
  "NVML_FI_DEV_ECC_DBE_VOL_L1": [],
  "NVML_FI_DEV_ECC_SBE_VOL_L2": [],
  "NVML_FI_DEV_ECC_DBE_VOL_L2": [],
  "NVML_FI_DEV_ECC_SBE_VOL_DEV": [],
  "NVML_FI_DEV_ECC_DBE_VOL_DEV": [],
  "NVML_FI_DEV_ECC_SBE_VOL_REG": [],
  "NVML_FI_DEV_ECC_DBE_VOL_REG": [],
  "NVML_FI_DEV_ECC_SBE_VOL_TEX": [],
  "NVML_FI_DEV_ECC_DBE_VOL_TEX": [],
  "NVML_FI_DEV_ECC_DBE_VOL_CBU": [],
  "NVML_FI_DEV_ECC_SBE_AGG_L1": [],
  "NVML_FI_DEV_ECC_DBE_AGG_L1": [],
  "NVML_FI_DEV_ECC_SBE_AGG_L2": [],
  "NVML_FI_DEV_ECC_DBE_AGG_L2": [],
  "NVML_FI_DEV_ECC_SBE_AGG_DEV": [],
  "NVML_FI_DEV_ECC_DBE_AGG_DEV": [],
  "NVML_FI_DEV_ECC_SBE_AGG_REG": [],
  "NVML_FI_DEV_ECC_DBE_AGG_REG": [],
  "NVML_FI_DEV_ECC_SBE_AGG_TEX": [],
  "NVML_FI_DEV_ECC_DBE_AGG_TEX": [],
  "NVML_FI_DEV_ECC_DBE_AGG_CBU": [],
  "NVML_FI_DEV_RETIRED_SBE": [],
  "NVML_FI_DEV_RETIRED_DBE": [],
  "NVML_FI_DEV_RETIRED_PENDING": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L0": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L1": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L2": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L3": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L4": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L5": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_TOTAL": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L0": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L1": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L2": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L3": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L4": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L5": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_TOTAL": [],
  "NVML_FI_DEV_PERF_POLICY_POWER": [],
  "NVML_FI_DEV_PERF_POLICY_THERMAL": [],
  "NVML_FI_DEV_PERF_POLICY_SYNC_BOOST": [],
  "NVML_FI_DEV_PERF_POLICY_BOARD_LIMIT": [],
  "NVML_FI_DEV_PERF_POLICY_LOW_UTILIZATION": [],
  "NVML_FI_DEV_PERF_POLICY_RELIABILITY": [],
  "NVML_FI_DEV_PERF_POLICY_TOTAL_APP_CLOCKS": [],
  "NVML_FI_DEV_PERF_POLICY_TOTAL_BASE_CLOCKS": [],
  "NVML_FI_DEV_MEMORY_TEMP": [],
  "NVML_FI_DEV_TOTAL_ENERGY_CONSUMPTION": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L0": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L1": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L2": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L3": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L4": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L5": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_COMMON": [],
  "NVML_FI_DEV_NVLINK_LINK_COUNT": [],
  "NVML_FI_DEV_RETIRED_PENDING_SBE": [],
  "NVML_FI_DEV_RETIRED_PENDING_DBE": [],
  "NVML_FI_DEV_PCIE_REPLAY_COUNTER": [],
  "NVML_FI_DEV_PCIE_REPLAY_ROLLOVER_COUNTER": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L6": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L7": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L8": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L9": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L10": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L11": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L6": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L7": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L8": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L9": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L10": [],
  "NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L11": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L6": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L7": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L8": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L9": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L10": [],
  "NVML_FI_DEV_NVLINK_SPEED_MBPS_L11": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_TX": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_RX": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_TX": [],
  "NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_RX": [],
  "NVML_FI_DEV_REMAPPED_COR": [],
  "NVML_FI_DEV_REMAPPED_UNC": [],
  "NVML_FI_DEV_REMAPPED_PENDING": [],
  "NVML_FI_DEV_REMAPPED_FAILURE": [],
  "NVML_FI_DEV_NVLINK_REMOTE_NVLINK_ID": [],
  "NVML_FI_DEV_NVSWITCH_CONNECTED_LINK_COUNT": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L0": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L1": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L2": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L3": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L4": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L5": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L6": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L7": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L8": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L9": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L10": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L11": [],
  "NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_TOTAL": [],
  "NVML_FI_DEV_NVLINK_ERROR_DL_REPLAY": [],
  "NVML_FI_DEV_NVLINK_ERROR_DL_RECOVERY": [],
  "NVML_FI_DEV_NVLINK_ERROR_DL_CRC": [],
  "NVML_FI_DEV_NVLINK_GET_SPEED": [],
  "NVML_FI_DEV_NVLINK_GET_STATE": [],
  "NVML_FI_DEV_NVLINK_GET_VERSION": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_STATE": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD": [],
  "NVML_FI_DEV_PCIE_L0_TO_RECOVERY_COUNTER": [],
  "NVML_FI_DEV_C2C_LINK_COUNT": [],
  "NVML_FI_DEV_C2C_LINK_GET_STATUS": [],
  "NVML_FI_DEV_C2C_LINK_GET_MAX_BW": [],
  "NVML_FI_DEV_PCIE_COUNT_CORRECTABLE_ERRORS": [],
  "NVML_FI_DEV_PCIE_COUNT_NAKS_RECEIVED": [],
  "NVML_FI_DEV_PCIE_COUNT_RECEIVER_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_BAD_TLP": [],
  "NVML_FI_DEV_PCIE_COUNT_NAKS_SENT": [],
  "NVML_FI_DEV_PCIE_COUNT_BAD_DLLP": [],
  "NVML_FI_DEV_PCIE_COUNT_NON_FATAL_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_FATAL_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_UNSUPPORTED_REQ": [],
  "NVML_FI_DEV_PCIE_COUNT_LCRC_ERROR": [],
  "NVML_FI_DEV_PCIE_COUNT_LANE_ERROR": [],
  "NVML_FI_DEV_IS_RESETLESS_MIG_SUPPORTED": [],
  "NVML_FI_DEV_POWER_AVERAGE": [],
  "NVML_FI_DEV_POWER_INSTANT": [],
  "NVML_FI_DEV_POWER_MIN_LIMIT": [],
  "NVML_FI_DEV_POWER_MAX_LIMIT": [],
  "NVML_FI_DEV_POWER_DEFAULT_LIMIT": [],
  "NVML_FI_DEV_POWER_CURRENT_LIMIT": [],
  "NVML_FI_DEV_ENERGY": [],
  "NVML_FI_DEV_POWER_REQUESTED_LIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_SHUTDOWN_TLIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_SLOWDOWN_TLIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_MEM_MAX_TLIMIT": [],
  "NVML_FI_DEV_TEMPERATURE_GPU_MAX_TLIMIT": [],
  "NVML_FI_DEV_PCIE_COUNT_TX_BYTES": [],
  "NVML_FI_DEV_PCIE_COUNT_RX_BYTES": [],
  "NVML_FI_DEV_IS_MIG_MODE_INDEPENDENT_MIG_QUERY_CAPABLE": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_MAX": [],
  "NVML_FI_DEV_NVLINK_COUNT_XMIT_PACKETS": [],
  "NVML_FI_DEV_NVLINK_COUNT_XMIT_BYTES": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_PACKETS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_BYTES": [],
  "NVML_FI_DEV_NVLINK_COUNT_VL15_DROPPED": [],
  "NVML_FI_DEV_NVLINK_COUNT_MALFORMED_PACKET_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_BUFFER_OVERRUN_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_REMOTE_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RCV_GENERAL_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LOCAL_LINK_INTEGRITY_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_XMIT_DISCARDS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LINK_RECOVERY_SUCCESSFUL_EVENTS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LINK_RECOVERY_FAILED_EVENTS": [],
  "NVML_FI_DEV_NVLINK_COUNT_LINK_RECOVERY_EVENTS": [],
  "NVML_FI_DEV_NVLINK_COUNT_RAW_BER_LANE0": [],
  "NVML_FI_DEV_NVLINK_COUNT_RAW_BER_LANE1": [],
  "NVML_FI_DEV_NVLINK_COUNT_RAW_BER": [],
  "NVML_FI_DEV_NVLINK_COUNT_EFFECTIVE_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_EFFECTIVE_BER": [],
  "NVML_FI_DEV_NVLINK_COUNT_SYMBOL_ERRORS": [],
  "NVML_FI_DEV_NVLINK_COUNT_SYMBOL_BER": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_MIN": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_UNITS": [],
  "NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD_SUPPORTED": [],
  "NVML_FI_DEV_RESET_STATUS": [],
  "NVML_FI_DEV_DRAIN_AND_RESET_STATUS": [],
  "NVML_FI_DEV_PCIE_OUTBOUND_ATOMICS_MASK": [],
  "NVML_FI_DEV_PCIE_INBOUND_ATOMICS_MASK": [],
  "NVML_FI_DEV_GET_GPU_RECOVERY_ACTION": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_0": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_1": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_2": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_3": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_4": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_5": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_6": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_7": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_8": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_9": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_10": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_11": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_12": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_13": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_14": [],
  "NVML_FI_DEV_NVLINK_COUNT_FEC_HISTORY_15": [],
  "NVML_FI_PWR_SMOOTHING_ENABLED": [],
  "NVML_FI_PWR_SMOOTHING_PRIV_LVL": [],
  "NVML_FI_PWR_SMOOTHING_IMM_RAMP_DOWN_ENABLED": [],
  "NVML_FI_PWR_SMOOTHING_APPLIED_TMP_CEIL": [],
  "NVML_FI_PWR_SMOOTHING_APPLIED_TMP_FLOOR": [],
  "NVML_FI_PWR_SMOOTHING_MAX_PERCENT_TMP_FLOOR_SETTING": [],
  "NVML_FI_PWR_SMOOTHING_MIN_PERCENT_TMP_FLOOR_SETTING": [],
  "NVML_FI_PWR_SMOOTHING_HW_CIRCUITRY_PERCENT_LIFETIME_REMAINING": [],
  "NVML_FI_PWR_SMOOTHING_MAX_NUM_PRESET_PROFILES": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_PERCENT_TMP_FLOOR": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_RAMP_UP_RATE": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_RAMP_DOWN_RATE": [],
  "NVML_FI_PWR_SMOOTHING_PROFILE_RAMP_DOWN_HYST_VAL": [],
  "NVML_FI_PWR_SMOOTHING_ACTIVE_PRESET_PROFILE": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_PERCENT_TMP_FLOOR": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_RAMP_UP_RATE": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_RAMP_DOWN_RATE": [],
  "NVML_FI_PWR_SMOOTHING_ADMIN_OVERRIDE_RAMP_DOWN_HYST_VAL": [],
  "NVML_FI_MAX": [],
  "NVML_NVLINK_STATE_INACTIVE": [],
  "NVML_NVLINK_STATE_ACTIVE": [],
  "NVML_NVLINK_STATE_SLEEP": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_UNIT_100US": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_UNIT_50US": [],
  "NVML_GPU_VIRTUALIZATION_MODE_NONE": [],
  "NVML_GPU_VIRTUALIZATION_MODE_PASSTHROUGH": [],
  "NVML_GPU_VIRTUALIZATION_MODE_VGPU": [],
  "NVML_GPU_VIRTUALIZATION_MODE_HOST_VGPU": [],
  "NVML_GPU_VIRTUALIZATION_MODE_HOST_VSGA": [],
  "nvmlLib": [],
  "libLoadLock": [],
  "_nvmlLib_refcount": [],
  "_nvmlVgpuTypeId_t": [],
  "_nvmlVgpuInstance_t": [],
  "_nvmlVgpuVmIdType_t": [],
  "NVML_VGPU_VM_ID_DOMAIN_ID": [],
  "NVML_VGPU_VM_ID_UUID": [],
  "_nvmlGridLicenseFeatureCode_t": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_UNKNOWN": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_VGPU": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_NVIDIA_RTX": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_VWORKSTATION": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_GAMING": [],
  "NVML_GRID_LICENSE_FEATURE_CODE_COMPUTE": [],
  "_nvmlGridLicenseExpiryStatus_t": [],
  "NVML_GRID_LICENSE_EXPIRY_NOT_AVAILABLE": [],
  "NVML_GRID_LICENSE_EXPIRY_INVALID": [],
  "NVML_GRID_LICENSE_EXPIRY_VALID": [],
  "NVML_GRID_LICENSE_EXPIRY_NOT_APPLICABLE": [],
  "NVML_GRID_LICENSE_EXPIRY_PERMANENT": [],
  "_nvmlVgpuCapability_t": [],
  "NVML_VGPU_CAP_NVLINK_P2P": [],
  "NVML_VGPU_CAP_GPUDIRECT": [],
  "NVML_VGPU_CAP_MULTI_VGPU_EXCLUSIVE": [],
  "NVML_VGPU_CAP_EXCLUSIVE_TYPE": [],
  "NVML_VGPU_CAP_EXCLUSIVE_SIZE": [],
  "NVML_VGPU_CAP_COUNT": [],
  "_nvmlVgpuDriverCapability_t": [],
  "NVML_VGPU_DRIVER_CAP_HETEROGENEOUS_MULTI_VGPU": [],
  "NVML_VGPU_DRIVER_CAP_WARM_UPDATE": [],
  "NVML_VGPU_DRIVER_CAP_COUNT": [],
  "_nvmlDeviceVgpuCapability_t": [],
  "NVML_DEVICE_VGPU_CAP_FRACTIONAL_MULTI_VGPU": [],
  "NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_PROFILES": [],
  "NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_SIZES": [],
  "NVML_DEVICE_VGPU_CAP_READ_DEVICE_BUFFER_BW": [],
  "NVML_DEVICE_VGPU_CAP_WRITE_DEVICE_BUFFER_BW": [],
  "NVML_DEVICE_VGPU_CAP_DEVICE_STREAMING": [],
  "NVML_DEVICE_VGPU_CAP_MINI_QUARTER_GPU": [],
  "NVML_DEVICE_VGPU_CAP_COMPUTE_MEDIA_ENGINE_GPU": [],
  "NVML_DEVICE_VGPU_CAP_WARM_UPDATE": [],
  "NVML_DEVICE_VGPU_CAP_HOMOGENEOUS_PLACEMENTS": [],
  "NVML_DEVICE_VGPU_CAP_COUNT": [],
  "_nvmlVgpuGuestInfoState_t": [],
  "NVML_VGPU_INSTANCE_GUEST_INFO_STATE_UNINITIALIZED": [],
  "NVML_VGPU_INSTANCE_GUEST_INFO_STATE_INITIALIZED": [],
  "_nvmlVgpuVmCompatibility_t": [],
  "NVML_VGPU_VM_COMPATIBILITY_NONE": [],
  "NVML_VGPU_VM_COMPATIBILITY_COLD": [],
  "NVML_VGPU_VM_COMPATIBILITY_HIBERNATE": [],
  "NVML_VGPU_VM_COMPATIBILITY_SLEEP": [],
  "NVML_VGPU_VM_COMPATIBILITY_LIVE": [],
  "_nvmlVgpuPgpuCompatibilityLimitCode_t": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_NONE": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_HOST_DRIVER": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_GUEST_DRIVER": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_GPU": [],
  "NVML_VGPU_COMPATIBILITY_LIMIT_OTHER": [],
  "_nvmlHostVgpuMode_t": [],
  "NVML_HOST_VGPU_MODE_NON_SRIOV": [],
  "NVML_HOST_VGPU_MODE_SRIOV": [],
  "_nvmlConfComputeGpusReadyState_t": [],
  "NVML_CC_ACCEPTING_CLIENT_REQUESTS_FALSE": [],
  "NVML_CC_ACCEPTING_CLIENT_REQUESTS_TRUE": [],
  "_nvmlConfComputeGpuCaps_t": [],
  "NVML_CC_SYSTEM_GPUS_CC_NOT_CAPABLE": [],
  "NVML_CC_SYSTEM_GPUS_CC_CAPABLE": [],
  "_nvmlConfComputeCpuCaps_t": [],
  "NVML_CC_SYSTEM_CPU_CAPS_NONE": [],
  "NVML_CC_SYSTEM_CPU_CAPS_AMD_SEV": [],
  "NVML_CC_SYSTEM_CPU_CAPS_INTEL_TDX": [],
  "NVML_CC_SYSTEM_CPU_CAPS_AMD_SEV_SNP": [],
  "NVML_CC_SYSTEM_CPU_CAPS_AMD_SNP_VTOM": [],
  "_nvmlConfComputeDevToolsMode_t": [],
  "NVML_CC_SYSTEM_DEVTOOLS_MODE_OFF": [],
  "NVML_CC_SYSTEM_DEVTOOLS_MODE_ON": [],
  "NVML_CC_SYSTEM_MULTIGPU_NONE": [],
  "NVML_CC_SYSTEM_MULTIGPU_PROTECTED_PCIE": [],
  "NVML_CC_SYSTEM_ENVIRONMENT_UNAVAILABLE": [],
  "NVML_CC_SYSTEM_ENVIRONMENT_SIM": [],
  "NVML_CC_SYSTEM_ENVIRONMENT_PROD": [],
  "_nvmlConfComputeCcFeature_t": [],
  "NVML_CC_SYSTEM_FEATURE_DISABLED": [],
  "NVML_CC_SYSTEM_FEATURE_ENABLED": [],
  "_nvmlConfComputeCcKeyRotationThreshAttackerAdv_t": [],
  "NVML_CC_KEY_ROTATION_THRESH_ATTACKER_ADVANTAGE_MIN": [],
  "NVML_CC_KEY_ROTATION_THRESH_ATTACKER_ADVANTAGE_MAX": [],
  "NVML_GSP_FIRMWARE_VERSION_BUF_SIZE": [],
  "NVMLLibraryMismatchError": {},
  "NVMLError": {
    "_valClassMapping": [],
    "_errcode_to_string": [],
    "__new__": [
      "typ",
      "value"
    ],
    "__str__": [
      "self"
    ],
    "__eq__": [
      "self",
      "other"
    ]
  },
  "nvmlExceptionClass": [
    "nvmlErrorCode"
  ],
  "_extractNVMLErrorsAsClasses": [],
  "_nvmlCheckReturn": [
    "ret"
  ],
  "_nvmlGetFunctionPointer_cache": [],
  "_nvmlGetFunctionPointer": [
    "name"
  ],
  "nvmlFriendlyObject": {
    "__init__": [
      "self",
      "dictionary"
    ],
    "__str__": [
      "self"
    ]
  },
  "nvmlStructToFriendlyObject": [
    "struct"
  ],
  "nvmlFriendlyObjectToStruct": [
    "obj",
    "model"
  ],
  "struct_c_nvmlUnit_t": {},
  "c_nvmlUnit_t": [],
  "_PrintableStructure": {
    "_fmt_": [],
    "__str__": [
      "self"
    ],
    "__getattribute__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ]
  },
  "c_nvmlUnitInfo_t": {
    "_fields_": []
  },
  "c_nvmlC2cModeInfo_v1_t": {
    "_fields_": []
  },
  "nvmlC2cModeInfo_v1": [],
  "c_nvmlLedState_t": {
    "_fields_": []
  },
  "c_nvmlPSUInfo_t": {
    "_fields_": []
  },
  "c_nvmlUnitFanInfo_t": {
    "_fields_": []
  },
  "c_nvmlUnitFanSpeeds_t": {
    "_fields_": []
  },
  "struct_c_nvmlDevice_t": {},
  "c_nvmlDevice_t": [],
  "nvmlPciInfoExt_v1_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlPciInfoExt_v1": [],
  "nvmlPciInfo_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlPciInfo_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlSystemDriverBranchInfo_v1_t": {
    "_fields_": []
  },
  "SystemDriverBranchInfo_v1": [],
  "c_nvmlExcludedDeviceInfo_t": {
    "_fields_": []
  },
  "nvmlNvLinkUtilizationControl_t": {
    "_fields_": []
  },
  "c_nvmlMemory_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlMemory_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlMemory_v2": [],
  "c_nvmlBAR1Memory_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlClkMonFaultInfo_t": {
    "_fields_": []
  },
  "MAX_CLK_DOMAINS": [],
  "nvmlClkMonStatus_t": {
    "_fields_": []
  },
  "c_nvmlProcessInfo_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlProcessInfo_v3_t": [],
  "c_nvmlProcessInfo_t": [],
  "_nvmlProcessMode_t": [],
  "NVML_PROCESS_MODE_COMPUTE": [],
  "NVML_PROCESS_MODE_GRAPHICS": [],
  "NVML_PROCESS_MODE_MPS": [],
  "c_nvmlProcessDetail_v1_t": {
    "_fields_": []
  },
  "c_nvmlProcessDetailList_v1_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlProcessDetailList_t": [],
  "nvmlProcessDetailList_v1": [],
  "c_nvmlBridgeChipInfo_t": {
    "_fields_": []
  },
  "c_nvmlBridgeChipHierarchy_t": {
    "_fields_": []
  },
  "c_nvmlEccErrorCounts_t": {
    "_fields_": []
  },
  "c_nvmlUtilization_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlHwbcEntry_t": {
    "_fields_": []
  },
  "c_nvmlValue_t": {
    "_fields_": []
  },
  "c_nvmlSample_t": {
    "_fields_": []
  },
  "c_nvmlViolationTime_t": {
    "_fields_": []
  },
  "c_nvmlFieldValue_t": {
    "_fields_": []
  },
  "NVML_NVLINK_TOTAL_SUPPORTED_BW_MODES": [],
  "nvmlNvlinkSupportedBwModes_v1": [],
  "c_nvmlNvlinkSupportedBwModes_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlNvlinkGetBwMode_v1": [],
  "c_nvmlNvlinkGetBwMode_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlNvlinkSetBwMode_v1": [],
  "c_nvmlNvlinkSetBwMode_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlVgpuHeterogeneousMode_v1_t": {
    "_fields_": []
  },
  "VgpuHeterogeneousMode_v1": [],
  "c_nvmlVgpuPlacementId_v1_t": {
    "_fields_": []
  },
  "VgpuPlacementId_v1": [],
  "c_nvmlVgpuPlacementList_v1_t": {
    "_fields_": []
  },
  "VgpuPlacementList_v1": [],
  "NVML_VGPU_PGPU_HETEROGENEOUS_MODE": [],
  "NVML_VGPU_PGPU_HOMOGENEOUS_MODE": [],
  "c_nvmlVgpuPlacementList_v2_t": {
    "_fields_": []
  },
  "VgpuPlacementList_v2": [],
  "c_nvmlVgpuTypeBar1Info_v1_t": {
    "_fields_": []
  },
  "VgpuTypeBar1Info_v1": [],
  "c_nvmlVgpuInstanceUtilizationSample_t": {
    "_fields_": []
  },
  "c_nvmlVgpuInstanceUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "c_nvmlVgpuInstancesUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "VgpuInstancesUtilizationInfo_v1": [],
  "c_nvmlVgpuProcessUtilizationSample_t": {
    "_fields_": []
  },
  "c_nvmlVgpuProcessUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "c_nvmlVgpuProcessesUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "VgpuProcessesUtilizationInfo_v1": [],
  "nvmlVgpuRuntimeState_v1_t": {
    "_fields_": []
  },
  "VgpuRuntimeState_v1": [],
  "c_nvmlVgpuLicenseExpiry_t": {
    "_fields_": []
  },
  "NVML_GRID_LICENSE_STATE_UNKNOWN": [],
  "NVML_GRID_LICENSE_STATE_UNINITIALIZED": [],
  "NVML_GRID_LICENSE_STATE_UNLICENSED_UNRESTRICTED": [],
  "NVML_GRID_LICENSE_STATE_UNLICENSED_RESTRICTED": [],
  "NVML_GRID_LICENSE_STATE_UNLICENSED": [],
  "NVML_GRID_LICENSE_STATE_LICENSED": [],
  "c_nvmlVgpuLicenseInfo_t": {
    "_fields_": []
  },
  "c_nvmlEncoderSession_t": {
    "_fields_": []
  },
  "c_nvmlProcessUtilizationSample_t": {
    "_fields_": []
  },
  "c_nvmlProcessUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "c_nvmlProcessesUtilizationInfo_v1_t": {
    "_fields_": []
  },
  "ProcessesUtilizationInfo_v1": [],
  "c_nvmlGridLicenseExpiry_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_v4_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_v4_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_v3_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_v3_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_v2_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_v2_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeature_t": {
    "_fields_": []
  },
  "c_nvmlGridLicensableFeatures_t": {
    "_fields_": []
  },
  "c_nvmlMarginTemperature_v1_t": {
    "_fields_": []
  },
  "nvmlMarginTemperature_v1": [],
  "struct_c_nvmlEventSet_t": {},
  "c_nvmlEventSet_t": [],
  "nvmlEventTypeSingleBitEccError": [],
  "nvmlEventTypeDoubleBitEccError": [],
  "nvmlEventTypePState": [],
  "nvmlEventTypeXidCriticalError": [],
  "nvmlEventTypeClock": [],
  "nvmlEventTypePowerSourceChange": [],
  "nvmlEventMigConfigChange": [],
  "nvmlEventTypeSingleBitEccErrorStorm": [],
  "nvmlEventTypeDramRetirementEvent": [],
  "nvmlEventTypeDramRetirementFailure": [],
  "nvmlEventTypeNonFatalPoisonError": [],
  "nvmlEventTypeFatalPoisonError": [],
  "nvmlEventTypeGpuUnavailableError": [],
  "nvmlEventTypeGpuRecoveryAction": [],
  "nvmlEventTypeNone": [],
  "nvmlEventTypeAll": [],
  "nvmlClocksEventReasonGpuIdle": [],
  "nvmlClocksEventReasonApplicationsClocksSetting": [],
  "nvmlClocksEventReasonUserDefinedClocks": [],
  "nvmlClocksEventReasonSwPowerCap": [],
  "nvmlClocksEventReasonHwSlowdown": [],
  "nvmlClocksEventReasonSyncBoost": [],
  "nvmlClocksEventReasonSwThermalSlowdown": [],
  "nvmlClocksEventReasonHwThermalSlowdown": [],
  "nvmlClocksEventReasonHwPowerBrakeSlowdown": [],
  "nvmlClocksEventReasonDisplayClockSetting": [],
  "nvmlClocksEventReasonNone": [],
  "nvmlClocksEventReasonAll": [],
  "nvmlClocksThrottleReasonGpuIdle": [],
  "nvmlClocksThrottleReasonApplicationsClocksSetting": [],
  "nvmlClocksThrottleReasonUserDefinedClocks": [],
  "nvmlClocksThrottleReasonSwPowerCap": [],
  "nvmlClocksThrottleReasonHwSlowdown": [],
  "nvmlClocksThrottleReasonSyncBoost": [],
  "nvmlClocksThrottleReasonSwThermalSlowdown": [],
  "nvmlClocksThrottleReasonHwThermalSlowdown": [],
  "nvmlClocksThrottleReasonHwPowerBrakeSlowdown": [],
  "nvmlClocksThrottleReasonDisplayClockSetting": [],
  "nvmlClocksThrottleReasonNone": [],
  "nvmlClocksThrottleReasonAll": [],
  "c_nvmlEventData_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "c_nvmlAccountingStats_t": {
    "_fields_": []
  },
  "c_nvmlVgpuVersion_t": {
    "_fields_": []
  },
  "c_nvmlVgpuMetadata_t": {
    "_fields_": []
  },
  "c_nvmlVgpuPgpuMetadata_t": {
    "_fields_": []
  },
  "c_nvmlVgpuPgpuCompatibility_t": {
    "_fields_": []
  },
  "NVML_VGPU_SCHEDULER_POLICY_UNKNOWN": [],
  "NVML_VGPU_SCHEDULER_POLICY_BEST_EFFORT": [],
  "NVML_VGPU_SCHEDULER_POLICY_EQUAL_SHARE": [],
  "NVML_VGPU_SCHEDULER_POLICY_FIXED_SHARE": [],
  "NVML_SUPPORTED_VGPU_SCHEDULER_POLICY_COUNT": [],
  "NVML_SCHEDULER_SW_MAX_LOG_ENTRIES": [],
  "NVML_VGPU_SCHEDULER_ARR_DEFAULT": [],
  "NVML_VGPU_SCHEDULER_ARR_DISABLE": [],
  "NVML_VGPU_SCHEDULER_ARR_ENABLE": [],
  "c_nvmlVgpuSchedDataWithARR_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedData_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerParams_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerLogEntry_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerLog_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerGetState_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedSetDataWithARR_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedSetData_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerSetParams_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerSetState_t": {
    "_fields_": []
  },
  "c_nvmlVgpuSchedulerCapabilities_t": {
    "_fields_": []
  },
  "c_nvmlFBCStats_t": {
    "_fields_": []
  },
  "c_nvmlFBCSession_t": {
    "_fields_": []
  },
  "NVML_DEVICE_MIG_DISABLE": [],
  "NVML_DEVICE_MIG_ENABLE": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_2_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_3_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_4_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_7_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_8_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_6_SLICE": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE_REV1": [],
  "NVML_GPU_INSTANCE_PROFILE_2_SLICE_REV1": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE_REV2": [],
  "NVML_GPU_INSTANCE_PROFILE_1_SLICE_GFX": [],
  "NVML_GPU_INSTANCE_PROFILE_2_SLICE_GFX": [],
  "NVML_GPU_INSTANCE_PROFILE_4_SLICE_GFX": [],
  "NVML_GPU_INSTANCE_PROFILE_COUNT": [],
  "c_nvmlGpuInstancePlacement_t": {
    "_fields_": []
  },
  "c_nvmlGpuInstanceProfileInfo_t": {
    "_fields_": []
  },
  "nvmlGpuInstanceProfileInfo_v2": [],
  "c_nvmlGpuInstanceProfileInfo_v2_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlGpuInstanceInfo_t": {
    "_fields_": []
  },
  "struct_c_nvmlGpuInstance_t": {},
  "c_nvmlGpuInstance_t": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_2_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_3_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_4_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_7_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_8_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_6_SLICE": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE_REV1": [],
  "NVML_COMPUTE_INSTANCE_PROFILE_COUNT": [],
  "NVML_COMPUTE_INSTANCE_ENGINE_PROFILE_SHARED": [],
  "NVML_COMPUTE_INSTANCE_ENGINE_PROFILE_COUNT": [],
  "c_nvmlComputeInstancePlacement_t": {
    "_fields_": []
  },
  "c_nvmlComputeInstanceProfileInfo_t": {
    "_fields_": []
  },
  "nvmlComputeInstanceProfileInfo_v2": [],
  "c_nvmlComputeInstanceProfileInfo_v2_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlComputeInstanceInfo_t": {
    "_fields_": []
  },
  "NVML_MAX_GPU_UTILIZATIONS": [],
  "NVML_GPU_UTILIZATION_DOMAIN_GPU": [],
  "NVML_GPU_UTILIZATION_DOMAIN_FB": [],
  "NVML_GPU_UTILIZATION_DOMAIN_VID": [],
  "NVML_GPU_UTILIZATION_DOMAIN_BUS": [],
  "c_nvmlGpuDynamicPstatesUtilization_t": {
    "_fields_": []
  },
  "c_nvmlGpuDynamicPstatesInfo_t": {
    "_fields_": []
  },
  "NVML_MAX_THERMAL_SENSORS_PER_GPU": [],
  "NVML_THERMAL_TARGET_NONE": [],
  "NVML_THERMAL_TARGET_GPU": [],
  "NVML_THERMAL_TARGET_MEMORY": [],
  "NVML_THERMAL_TARGET_POWER_SUPPLY": [],
  "NVML_THERMAL_TARGET_BOARD": [],
  "NVML_THERMAL_TARGET_VCD_BOARD": [],
  "NVML_THERMAL_TARGET_VCD_INLET": [],
  "NVML_THERMAL_TARGET_VCD_OUTLET": [],
  "NVML_THERMAL_TARGET_ALL": [],
  "NVML_THERMAL_TARGET_UNKNOWN": [],
  "NVML_THERMAL_CONTROLLER_NONE": [],
  "NVML_THERMAL_CONTROLLER_GPU_INTERNAL": [],
  "NVML_THERMAL_CONTROLLER_ADM1032": [],
  "NVML_THERMAL_CONTROLLER_ADT7461": [],
  "NVML_THERMAL_CONTROLLER_MAX6649": [],
  "NVML_THERMAL_CONTROLLER_MAX1617": [],
  "NVML_THERMAL_CONTROLLER_LM99": [],
  "NVML_THERMAL_CONTROLLER_LM89": [],
  "NVML_THERMAL_CONTROLLER_LM64": [],
  "NVML_THERMAL_CONTROLLER_G781": [],
  "NVML_THERMAL_CONTROLLER_ADT7473": [],
  "NVML_THERMAL_CONTROLLER_SBMAX6649": [],
  "NVML_THERMAL_CONTROLLER_VBIOSEVT": [],
  "NVML_THERMAL_CONTROLLER_OS": [],
  "NVML_THERMAL_CONTROLLER_NVSYSCON_CANOAS": [],
  "NVML_THERMAL_CONTROLLER_NVSYSCON_E551": [],
  "NVML_THERMAL_CONTROLLER_MAX6649R": [],
  "NVML_THERMAL_CONTROLLER_ADT7473S": [],
  "NVML_THERMAL_CONTROLLER_UNKNOWN": [],
  "c_nvmlGpuThermalSensor_t": {
    "_fields_": []
  },
  "c_nvmlGpuThermalSettings_t": {
    "_fields_": []
  },
  "_nvmlCoolerControl_t": [],
  "NVML_THERMAL_COOLER_SIGNAL_NONE": [],
  "NVML_THERMAL_COOLER_SIGNAL_TOGGLE": [],
  "NVML_THERMAL_COOLER_SIGNAL_VARIABLE": [],
  "NVML_THERMAL_COOLER_SIGNAL_COUNT": [],
  "_nvmlCoolerTarget_t": [],
  "NVML_THERMAL_COOLER_TARGET_NONE": [],
  "NVML_THERMAL_COOLER_TARGET_GPU": [],
  "NVML_THERMAL_COOLER_TARGET_MEMORY": [],
  "NVML_THERMAL_COOLER_TARGET_POWER_SUPPLY": [],
  "NVML_THERMAL_COOLER_TARGET_GPU_RELATED": [],
  "c_nvmlCoolerInfo_t": {
    "_fields_": []
  },
  "nvmlCoolerInfo_v1": [],
  "nvmlDeviceGetCoolerInfo": [
    "handle"
  ],
  "struct_c_nvmlComputeInstance_t": {},
  "c_nvmlComputeInstance_t": [],
  "c_nvmlDeviceAttributes": {
    "_fields_": []
  },
  "c_nvmlRowRemapperHistogramValues": {
    "_fields_": []
  },
  "NVML_GPU_CERT_CHAIN_SIZE": [],
  "NVML_GPU_ATTESTATION_CERT_CHAIN_SIZE": [],
  "NVML_CC_GPU_CEC_NONCE_SIZE": [],
  "NVML_CC_GPU_ATTESTATION_REPORT_SIZE": [],
  "NVML_CC_GPU_CEC_ATTESTATION_REPORT_SIZE": [],
  "NVML_CC_CEC_ATTESTATION_REPORT_NOT_PRESENT": [],
  "NVML_CC_CEC_ATTESTATION_REPORT_PRESENT": [],
  "c_nvmlConfComputeSystemState_t": {
    "_fields_": []
  },
  "nvmlSystemConfComputeSettings_v1": [],
  "c_nvmlSystemConfComputeSettings_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "c_nvmlConfComputeSystemCaps_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeMemSizeInfo_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeGpuCertificate_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeGpuAttestationReport_t": {
    "_fields_": []
  },
  "c_nvmlConfComputeSetKeyRotationThresholdInfo_t": {
    "_fields_": []
  },
  "ConfComputeSetKeyRotationThresholdInfo_v1": [],
  "c_nvmlConfComputeGetKeyRotationThresholdInfo_t": {
    "_fields_": []
  },
  "ConfComputeGetKeyRotationThresholdInfo_v1": [],
  "convertStrBytes": [
    "func"
  ],
  "throwOnVersionMismatch": [
    "func"
  ],
  "nvmlInitWithFlags": [
    "flags"
  ],
  "nvmlInit": [],
  "_LoadNvmlLibrary": [],
  "nvmlShutdown": [],
  "nvmlErrorString": [
    "result"
  ],
  "nvmlSystemGetNVMLVersion": [],
  "nvmlSystemGetCudaDriverVersion": [],
  "nvmlSystemGetCudaDriverVersion_v2": [],
  "nvmlSystemGetProcessName": [
    "pid"
  ],
  "nvmlSystemGetDriverVersion": [],
  "nvmlSystemGetHicVersion": [],
  "nvmlSystemGetDriverBranch": [],
  "nvmlUnitGetCount": [],
  "nvmlUnitGetHandleByIndex": [
    "index"
  ],
  "nvmlUnitGetUnitInfo": [
    "unit"
  ],
  "nvmlUnitGetLedState": [
    "unit"
  ],
  "nvmlUnitGetPsuInfo": [
    "unit"
  ],
  "nvmlUnitGetTemperature": [
    "unit",
    "type"
  ],
  "nvmlUnitGetFanSpeedInfo": [
    "unit"
  ],
  "nvmlUnitGetDeviceCount": [
    "unit"
  ],
  "nvmlUnitGetDevices": [
    "unit"
  ],
  "nvmlDeviceGetCount": [],
  "nvmlDeviceGetHandleByIndex": [
    "index"
  ],
  "nvmlDeviceGetHandleBySerial": [
    "serial"
  ],
  "nvmlDeviceGetHandleByUUID": [
    "uuid"
  ],
  "nvmlDeviceGetHandleByPciBusId": [
    "pciBusId"
  ],
  "nvmlDeviceGetName": [
    "handle"
  ],
  "c_nvmlDevicePerfModes_v1_t": {
    "_fields_": []
  },
  "nvmlDevicePerfModes_v1": [],
  "nvmlDeviceGetPerformanceModes": [
    "handle"
  ],
  "c_nvmlDeviceCurrentClockFreqs_v1_t": {
    "_fields_": []
  },
  "nvmlDeviceCurrentClockFreqs_v1": [],
  "nvmlDeviceGetCurrentClockFreqs": [
    "handle"
  ],
  "nvmlDeviceGetBoardId": [
    "handle"
  ],
  "nvmlDeviceGetMultiGpuBoard": [
    "handle"
  ],
  "nvmlDeviceGetBrand": [
    "handle"
  ],
  "nvmlDeviceGetC2cModeInfoV1": [
    "handle"
  ],
  "nvmlDeviceGetC2cModeInfoV": [
    "handle"
  ],
  "nvmlDeviceGetBoardPartNumber": [
    "handle"
  ],
  "nvmlDeviceGetSerial": [
    "handle"
  ],
  "nvmlDeviceGetModuleId": [
    "handle",
    "moduleId"
  ],
  "nvmlDeviceGetMemoryAffinity": [
    "handle",
    "nodeSetSize",
    "scope"
  ],
  "nvmlDeviceGetCpuAffinityWithinScope": [
    "handle",
    "cpuSetSize",
    "scope"
  ],
  "nvmlDeviceGetCpuAffinity": [
    "handle",
    "cpuSetSize"
  ],
  "nvmlDeviceSetCpuAffinity": [
    "handle"
  ],
  "nvmlDeviceClearCpuAffinity": [
    "handle"
  ],
  "nvmlDeviceGetNumaNodeId": [
    "handle"
  ],
  "nvmlDeviceGetMinorNumber": [
    "handle"
  ],
  "nvmlDeviceGetUUID": [
    "handle"
  ],
  "nvmlDeviceGetInforomVersion": [
    "handle",
    "infoRomObject"
  ],
  "nvmlDeviceGetInforomImageVersion": [
    "handle"
  ],
  "nvmlDeviceGetInforomConfigurationChecksum": [
    "handle"
  ],
  "nvmlDeviceValidateInforom": [
    "handle"
  ],
  "nvmlDeviceGetLastBBXFlushTime": [
    "handle"
  ],
  "nvmlDeviceGetDisplayMode": [
    "handle"
  ],
  "nvmlDeviceGetDisplayActive": [
    "handle"
  ],
  "nvmlDeviceGetPersistenceMode": [
    "handle"
  ],
  "nvmlDeviceGetPciInfoExt": [
    "handle",
    "c_info"
  ],
  "nvmlDeviceGetPciInfo_v3": [
    "handle"
  ],
  "nvmlDeviceGetPciInfo": [
    "handle"
  ],
  "nvmlDeviceGetClockInfo": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetMaxClockInfo": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetApplicationsClock": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetMaxCustomerBoostClock": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetClock": [
    "handle",
    "type",
    "id"
  ],
  "nvmlDeviceGetDefaultApplicationsClock": [
    "handle",
    "type"
  ],
  "nvmlDeviceGetSupportedMemoryClocks": [
    "handle"
  ],
  "nvmlDeviceGetSupportedGraphicsClocks": [
    "handle",
    "memoryClockMHz"
  ],
  "nvmlDeviceGetFanSpeed": [
    "handle"
  ],
  "nvmlDeviceGetFanSpeed_v2": [
    "handle",
    "fan"
  ],
  "c_nvmlFanSpeedInfo_t": {
    "_fields_": []
  },
  "nvmlFanSpeedInfo_v1": [],
  "nvmlDeviceGetFanSpeedRPM": [
    "handle"
  ],
  "nvmlDeviceGetTargetFanSpeed": [
    "handle",
    "fan"
  ],
  "nvmlDeviceGetNumFans": [
    "device"
  ],
  "nvmlDeviceSetDefaultFanSpeed_v2": [
    "handle",
    "index"
  ],
  "nvmlDeviceGetMinMaxFanSpeed": [
    "handle",
    "minSpeed",
    "maxSpeed"
  ],
  "nvmlDeviceGetFanControlPolicy_v2": [
    "handle",
    "fan",
    "fanControlPolicy"
  ],
  "nvmlDeviceSetFanControlPolicy": [
    "handle",
    "fan",
    "fanControlPolicy"
  ],
  "c_nvmlTemperature_v1_t": {
    "_fields_": []
  },
  "nvmlTemperature_v1": [],
  "nvmlDeviceGetTemperatureV1": [
    "handle",
    "sensor"
  ],
  "nvmlDeviceGetTemperatureV": [
    "handle",
    "sensor",
    "version"
  ],
  "nvmlDeviceGetTemperature": [
    "handle",
    "sensor"
  ],
  "nvmlDeviceGetTemperatureThreshold": [
    "handle",
    "threshold"
  ],
  "nvmlDeviceSetTemperatureThreshold": [
    "handle",
    "threshold",
    "temp"
  ],
  "nvmlDeviceGetMarginTemperature": [
    "handle"
  ],
  "nvmlDeviceGetPowerState": [
    "handle"
  ],
  "nvmlDeviceGetPerformanceState": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementMode": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementLimit": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementLimitConstraints": [
    "handle"
  ],
  "nvmlDeviceGetPowerManagementDefaultLimit": [
    "handle"
  ],
  "nvmlDeviceGetEnforcedPowerLimit": [
    "handle"
  ],
  "nvmlDeviceGetPowerUsage": [
    "handle"
  ],
  "nvmlDeviceGetTotalEnergyConsumption": [
    "handle"
  ],
  "nvmlDeviceGetGpuOperationMode": [
    "handle"
  ],
  "nvmlDeviceGetCurrentGpuOperationMode": [
    "handle"
  ],
  "nvmlDeviceGetPendingGpuOperationMode": [
    "handle"
  ],
  "nvmlDeviceGetMemoryInfo": [
    "handle",
    "version"
  ],
  "nvmlDeviceGetBAR1MemoryInfo": [
    "handle"
  ],
  "nvmlDeviceGetComputeMode": [
    "handle"
  ],
  "nvmlDeviceGetCudaComputeCapability": [
    "handle"
  ],
  "nvmlDeviceGetEccMode": [
    "handle"
  ],
  "nvmlDeviceGetCurrentEccMode": [
    "handle"
  ],
  "nvmlDeviceGetPendingEccMode": [
    "handle"
  ],
  "nvmlDeviceGetDefaultEccMode": [
    "handle"
  ],
  "nvmlDeviceGetTotalEccErrors": [
    "handle",
    "errorType",
    "counterType"
  ],
  "nvmlDeviceGetDetailedEccErrors": [
    "handle",
    "errorType",
    "counterType"
  ],
  "nvmlDeviceGetMemoryErrorCounter": [
    "handle",
    "errorType",
    "counterType",
    "locationType"
  ],
  "nvmlDeviceGetUtilizationRates": [
    "handle"
  ],
  "nvmlDeviceGetEncoderUtilization": [
    "handle"
  ],
  "nvmlDeviceGetDecoderUtilization": [
    "handle"
  ],
  "nvmlDeviceGetJpgUtilization": [
    "handle"
  ],
  "nvmlDeviceGetOfaUtilization": [
    "handle"
  ],
  "nvmlDeviceGetPcieReplayCounter": [
    "handle"
  ],
  "nvmlDeviceGetDriverModel": [
    "handle"
  ],
  "nvmlDeviceGetCurrentDriverModel": [
    "handle"
  ],
  "nvmlDeviceGetPendingDriverModel": [
    "handle"
  ],
  "nvmlDeviceGetVbiosVersion": [
    "handle"
  ],
  "nvmlDeviceGetComputeRunningProcesses_v2": [
    "handle"
  ],
  "nvmlDeviceGetComputeRunningProcesses_v3": [
    "handle"
  ],
  "nvmlDeviceGetComputeRunningProcesses": [
    "handle"
  ],
  "nvmlDeviceGetGraphicsRunningProcesses_v2": [
    "handle"
  ],
  "nvmlDeviceGetGraphicsRunningProcesses_v3": [
    "handle"
  ],
  "nvmlDeviceGetGraphicsRunningProcesses": [
    "handle"
  ],
  "nvmlDeviceGetMPSComputeRunningProcesses": [
    "handle"
  ],
  "nvmlDeviceGetMPSComputeRunningProcesses_v2": [
    "handle"
  ],
  "nvmlDeviceGetMPSComputeRunningProcesses_v3": [
    "handle"
  ],
  "nvmlDeviceGetRunningProcessDetailList": [
    "handle",
    "version",
    "mode"
  ],
  "nvmlDeviceGetAutoBoostedClocksEnabled": [
    "handle"
  ],
  "nvmlUnitSetLedState": [
    "unit",
    "color"
  ],
  "nvmlDeviceSetPersistenceMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceSetComputeMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceSetEccMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceClearEccErrorCounts": [
    "handle",
    "counterType"
  ],
  "nvmlDeviceSetDriverModel": [
    "handle",
    "model"
  ],
  "nvmlDeviceSetAutoBoostedClocksEnabled": [
    "handle",
    "enabled"
  ],
  "nvmlDeviceSetDefaultAutoBoostedClocksEnabled": [
    "handle",
    "enabled",
    "flags"
  ],
  "nvmlDeviceSetGpuLockedClocks": [
    "handle",
    "minGpuClockMHz",
    "maxGpuClockMHz"
  ],
  "nvmlDeviceResetGpuLockedClocks": [
    "handle"
  ],
  "nvmlDeviceSetMemoryLockedClocks": [
    "handle",
    "minMemClockMHz",
    "maxMemClockMHz"
  ],
  "nvmlDeviceResetMemoryLockedClocks": [
    "handle"
  ],
  "nvmlDeviceGetClkMonStatus": [
    "handle",
    "c_clkMonInfo"
  ],
  "nvmlDeviceSetApplicationsClocks": [
    "handle",
    "maxMemClockMHz",
    "maxGraphicsClockMHz"
  ],
  "nvmlDeviceResetApplicationsClocks": [
    "handle"
  ],
  "nvmlDeviceSetPowerManagementLimit": [
    "handle",
    "limit"
  ],
  "nvmlDeviceSetGpuOperationMode": [
    "handle",
    "mode"
  ],
  "nvmlEventSetCreate": [],
  "nvmlDeviceRegisterEvents": [
    "handle",
    "eventTypes",
    "eventSet"
  ],
  "nvmlDeviceGetSupportedEventTypes": [
    "handle"
  ],
  "nvmlEventSetWait_v2": [
    "eventSet",
    "timeoutms"
  ],
  "nvmlEventSetWait": [
    "eventSet",
    "timeoutms"
  ],
  "nvmlEventSetFree": [
    "eventSet"
  ],
  "nvmlDeviceOnSameBoard": [
    "handle1",
    "handle2"
  ],
  "nvmlDeviceGetCurrPcieLinkGeneration": [
    "handle"
  ],
  "nvmlDeviceGetMaxPcieLinkGeneration": [
    "handle"
  ],
  "nvmlDeviceGetCurrPcieLinkWidth": [
    "handle"
  ],
  "nvmlDeviceGetMaxPcieLinkWidth": [
    "handle"
  ],
  "nvmlDeviceGetGpuMaxPcieLinkGeneration": [
    "handle"
  ],
  "nvmlDeviceGetSupportedClocksThrottleReasons": [
    "handle"
  ],
  "nvmlDeviceGetSupportedClocksEventReasons": [
    "handle"
  ],
  "nvmlDeviceGetCurrentClocksThrottleReasons": [
    "handle"
  ],
  "nvmlDeviceGetCurrentClocksEventReasons": [
    "handle"
  ],
  "nvmlDeviceGetIndex": [
    "handle"
  ],
  "nvmlDeviceGetAccountingMode": [
    "handle"
  ],
  "nvmlDeviceSetAccountingMode": [
    "handle",
    "mode"
  ],
  "nvmlDeviceClearAccountingPids": [
    "handle"
  ],
  "nvmlDeviceGetAccountingStats": [
    "handle",
    "pid"
  ],
  "nvmlDeviceGetAccountingPids": [
    "handle"
  ],
  "nvmlDeviceGetAccountingBufferSize": [
    "handle"
  ],
  "nvmlDeviceGetRetiredPages": [
    "device",
    "sourceFilter"
  ],
  "nvmlDeviceGetRetiredPages_v2": [
    "device",
    "sourceFilter"
  ],
  "nvmlDeviceGetRetiredPagesPendingStatus": [
    "device"
  ],
  "nvmlDeviceGetAPIRestriction": [
    "device",
    "apiType"
  ],
  "nvmlDeviceSetAPIRestriction": [
    "handle",
    "apiType",
    "isRestricted"
  ],
  "nvmlDeviceGetBridgeChipInfo": [
    "handle"
  ],
  "nvmlDeviceGetSamples": [
    "device",
    "sampling_type",
    "timeStamp"
  ],
  "nvmlDeviceGetViolationStatus": [
    "device",
    "perfPolicyType"
  ],
  "nvmlDeviceGetPcieThroughput": [
    "device",
    "counter"
  ],
  "nvmlSystemGetTopologyGpuSet": [
    "cpuNumber"
  ],
  "nvmlDeviceGetTopologyNearestGpus": [
    "device",
    "level"
  ],
  "nvmlDeviceGetTopologyCommonAncestor": [
    "device1",
    "device2"
  ],
  "nvmlDeviceGetNvLinkUtilizationCounter": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceFreezeNvLinkUtilizationCounter": [
    "device",
    "link",
    "counter",
    "freeze"
  ],
  "nvmlDeviceResetNvLinkUtilizationCounter": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceSetNvLinkUtilizationControl": [
    "device",
    "link",
    "counter",
    "control",
    "reset"
  ],
  "nvmlDeviceGetNvLinkUtilizationControl": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceGetNvLinkCapability": [
    "device",
    "link",
    "capability"
  ],
  "nvmlDeviceGetNvLinkErrorCounter": [
    "device",
    "link",
    "counter"
  ],
  "nvmlDeviceResetNvLinkErrorCounters": [
    "device",
    "link"
  ],
  "nvmlDeviceGetNvLinkRemotePciInfo": [
    "device",
    "link"
  ],
  "nvmlDeviceGetNvLinkRemoteDeviceType": [
    "handle",
    "link"
  ],
  "nvmlDeviceGetNvLinkState": [
    "device",
    "link"
  ],
  "nvmlDeviceGetNvLinkVersion": [
    "device",
    "link"
  ],
  "nvmlDeviceModifyDrainState": [
    "pciInfo",
    "newState"
  ],
  "nvmlDeviceQueryDrainState": [
    "pciInfo"
  ],
  "nvmlDeviceRemoveGpu": [
    "pciInfo"
  ],
  "nvmlDeviceDiscoverGpus": [
    "pciInfo"
  ],
  "nvmlDeviceGetFieldValues": [
    "handle",
    "fieldIds"
  ],
  "nvmlDeviceClearFieldValues": [
    "handle",
    "fieldIds"
  ],
  "nvmlDeviceGetVirtualizationMode": [
    "handle"
  ],
  "nvmlDeviceSetVirtualizationMode": [
    "handle",
    "virtualization_mode"
  ],
  "nvmlDeviceGetVgpuHeterogeneousMode": [
    "handle"
  ],
  "nvmlDeviceSetVgpuHeterogeneousMode": [
    "handle",
    "heterogeneous_mode"
  ],
  "nvmlVgpuInstanceGetPlacementId": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetVgpuTypeSupportedPlacements": [
    "handle",
    "vgpuTypeId",
    "mode",
    "version"
  ],
  "nvmlDeviceGetVgpuTypeCreatablePlacements": [
    "handle",
    "vgpuTypeId",
    "version"
  ],
  "nvmlGetVgpuDriverCapabilities": [
    "capability"
  ],
  "nvmlDeviceGetVgpuCapabilities": [
    "handle",
    "capability"
  ],
  "nvmlDeviceSetVgpuCapabilities": [
    "handle",
    "capability",
    "state"
  ],
  "nvmlDeviceGetSupportedVgpus": [
    "handle"
  ],
  "nvmlDeviceGetCreatableVgpus": [
    "handle"
  ],
  "nvmlVgpuTypeGetGpuInstanceProfileId": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetClass": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetName": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetDeviceID": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetFramebufferSize": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetNumDisplayHeads": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetResolution": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetLicense": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetFrameRateLimit": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetGspHeapSize": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetFbReservation": [
    "vgpuTypeId"
  ],
  "nvmlVgpuInstanceGetRuntimeStateSize": [
    "vgpuInstance"
  ],
  "nvmlVgpuTypeGetMaxInstances": [
    "handle",
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetMaxInstancesPerVm": [
    "vgpuTypeId"
  ],
  "nvmlVgpuTypeGetBAR1Info": [
    "vgpuTypeId"
  ],
  "nvmlDeviceGetActiveVgpus": [
    "handle"
  ],
  "nvmlVgpuInstanceGetVmID": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetUUID": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetMdevUUID": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetVmDriverVersion": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetLicenseStatus": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetLicenseInfo_v2": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetLicenseInfo": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetFrameRateLimit": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetEccMode": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetType": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetEncoderCapacity": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceSetEncoderCapacity": [
    "vgpuInstance",
    "encoder_capacity"
  ],
  "nvmlVgpuInstanceGetFbUsage": [
    "vgpuInstance"
  ],
  "nvmlVgpuTypeGetCapabilities": [
    "vgpuTypeId",
    "capability"
  ],
  "nvmlVgpuInstanceGetGpuInstanceId": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetGpuPciId": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetVgpuUtilization": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetVgpuInstancesUtilizationInfo": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetP2PStatus": [
    "device1",
    "device2",
    "p2pIndex"
  ],
  "nvmlDeviceGetGridLicensableFeatures_v4": [
    "handle"
  ],
  "nvmlDeviceGetGridLicensableFeatures": [
    "handle"
  ],
  "nvmlDeviceGetGspFirmwareVersion": [
    "handle",
    "version"
  ],
  "nvmlDeviceGetGspFirmwareMode": [
    "handle",
    "isEnabled",
    "defaultMode"
  ],
  "nvmlDeviceGetEncoderCapacity": [
    "handle",
    "encoderQueryType"
  ],
  "nvmlDeviceGetVgpuProcessUtilization": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetVgpuProcessesUtilizationInfo": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetEncoderStats": [
    "handle"
  ],
  "nvmlDeviceGetEncoderSessions": [
    "handle"
  ],
  "nvmlDeviceGetFBCStats": [
    "handle"
  ],
  "nvmlDeviceGetFBCSessions": [
    "handle"
  ],
  "nvmlVgpuInstanceGetEncoderStats": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetEncoderSessions": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetFBCStats": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetFBCSessions": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetProcessUtilization": [
    "handle",
    "timeStamp"
  ],
  "nvmlDeviceGetProcessesUtilizationInfo": [
    "handle",
    "timeStamp"
  ],
  "nvmlVgpuInstanceGetMetadata": [
    "vgpuInstance"
  ],
  "nvmlDeviceGetVgpuMetadata": [
    "handle"
  ],
  "nvmlGetVgpuCompatibility": [
    "vgpuMetadata",
    "pgpuMetadata"
  ],
  "nvmlDeviceGetPgpuMetadataString": [
    "handle"
  ],
  "nvmlDeviceGetVgpuSchedulerLog": [
    "handle"
  ],
  "nvmlDeviceGetVgpuSchedulerState": [
    "handle"
  ],
  "nvmlDeviceGetVgpuSchedulerCapabilities": [
    "handle"
  ],
  "nvmlDeviceSetVgpuSchedulerState": [
    "handle",
    "sched_state"
  ],
  "nvmlSetVgpuVersion": [
    "vgpuVersion"
  ],
  "nvmlGetVgpuVersion": [
    "supported",
    "current"
  ],
  "nvmlVgpuInstanceGetAccountingMode": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetAccountingPids": [
    "vgpuInstance"
  ],
  "nvmlVgpuInstanceGetAccountingStats": [
    "vgpuInstance",
    "pid"
  ],
  "nvmlVgpuInstanceClearAccountingPids": [
    "vgpuInstance"
  ],
  "nvmlGetExcludedDeviceCount": [],
  "nvmlGetExcludedDeviceInfoByIndex": [
    "index"
  ],
  "nvmlDeviceGetHostVgpuMode": [
    "handle"
  ],
  "nvmlDeviceSetMigMode": [
    "device",
    "mode"
  ],
  "nvmlDeviceGetMigMode": [
    "device"
  ],
  "nvmlDeviceGetGpuInstanceProfileInfo": [
    "device",
    "profile",
    "version"
  ],
  "nvmlDeviceGetGpuInstanceProfileInfoV": [],
  "nvmlDeviceGetGpuInstanceRemainingCapacity": [
    "device",
    "profileId"
  ],
  "nvmlDeviceGetGpuInstancePossiblePlacements": [
    "device",
    "profileId",
    "placementsRef",
    "countRef"
  ],
  "nvmlDeviceCreateGpuInstance": [
    "device",
    "profileId"
  ],
  "nvmlDeviceCreateGpuInstanceWithPlacement": [
    "device",
    "profileId",
    "placement"
  ],
  "nvmlGpuInstanceDestroy": [
    "gpuInstance"
  ],
  "nvmlDeviceGetGpuInstances": [
    "device",
    "profileId",
    "gpuInstancesRef",
    "countRef"
  ],
  "nvmlDeviceGetGpuInstanceById": [
    "device",
    "gpuInstanceId"
  ],
  "nvmlGpuInstanceGetInfo": [
    "gpuInstance"
  ],
  "nvmlGpuInstanceGetComputeInstanceProfileInfo": [
    "device",
    "profile",
    "engProfile",
    "version"
  ],
  "nvmlGpuInstanceGetComputeInstanceProfileInfoV": [],
  "nvmlGpuInstanceGetComputeInstanceRemainingCapacity": [
    "gpuInstance",
    "profileId"
  ],
  "nvmlGpuInstanceGetComputeInstancePossiblePlacements": [
    "gpuInstance",
    "profileId",
    "placementsRef",
    "countRef"
  ],
  "nvmlGpuInstanceCreateComputeInstance": [
    "gpuInstance",
    "profileId"
  ],
  "nvmlGpuInstanceCreateComputeInstanceWithPlacement": [
    "gpuInstance",
    "profileId",
    "placement"
  ],
  "nvmlComputeInstanceDestroy": [
    "computeInstance"
  ],
  "nvmlGpuInstanceGetComputeInstances": [
    "gpuInstance",
    "profileId",
    "computeInstancesRef",
    "countRef"
  ],
  "nvmlGpuInstanceGetComputeInstanceById": [
    "gpuInstance",
    "computeInstanceId"
  ],
  "nvmlComputeInstanceGetInfo_v2": [
    "computeInstance"
  ],
  "nvmlComputeInstanceGetInfo": [
    "computeInstance"
  ],
  "nvmlDeviceIsMigDeviceHandle": [
    "device"
  ],
  "nvmlDeviceGetGpuInstanceId": [
    "device"
  ],
  "nvmlDeviceGetComputeInstanceId": [
    "device"
  ],
  "nvmlDeviceGetMaxMigDeviceCount": [
    "device"
  ],
  "nvmlDeviceGetMigDeviceHandleByIndex": [
    "device",
    "index"
  ],
  "nvmlDeviceGetDeviceHandleFromMigDeviceHandle": [
    "migDevice"
  ],
  "nvmlDeviceGetAttributes_v2": [
    "device"
  ],
  "nvmlDeviceGetAttributes": [
    "device"
  ],
  "nvmlDeviceGetRemappedRows": [
    "device"
  ],
  "nvmlDeviceGetRowRemapperHistogram": [
    "device"
  ],
  "nvmlDeviceGetArchitecture": [
    "device"
  ],
  "nvmlDeviceGetBusType": [
    "device"
  ],
  "nvmlDeviceGetIrqNum": [
    "device"
  ],
  "nvmlDeviceGetNumGpuCores": [
    "device"
  ],
  "nvmlDeviceGetPowerSource": [
    "device"
  ],
  "nvmlDeviceGetMemoryBusWidth": [
    "device"
  ],
  "nvmlDeviceGetPcieLinkMaxSpeed": [
    "device"
  ],
  "nvmlDeviceGetAdaptiveClockInfoStatus": [
    "device"
  ],
  "nvmlDeviceGetPcieSpeed": [
    "device"
  ],
  "nvmlDeviceGetDynamicPstatesInfo": [
    "device",
    "c_dynamicpstatesinfo"
  ],
  "nvmlDeviceSetFanSpeed_v2": [
    "handle",
    "index",
    "speed"
  ],
  "nvmlDeviceGetThermalSettings": [
    "device",
    "sensorindex",
    "c_thermalsettings"
  ],
  "nvmlDeviceGetMinMaxClockOfPState": [
    "device",
    "clockType",
    "pstate",
    "minClockMHz",
    "maxClockMHz"
  ],
  "c_nvmlClockOffset_t": {
    "_fields_": []
  },
  "nvmlClockOffset_v1": [],
  "nvmlDeviceGetClockOffsets": [
    "device",
    "info"
  ],
  "nvmlDeviceSetClockOffsets": [
    "device",
    "info"
  ],
  "nvmlDeviceGetSupportedPerformanceStates": [
    "device"
  ],
  "nvmlDeviceGetGpcClkVfOffset": [
    "device"
  ],
  "nvmlDeviceSetGpcClkVfOffset": [
    "device",
    "offset"
  ],
  "nvmlDeviceGetGpcClkMinMaxVfOffset": [
    "device",
    "minOffset",
    "maxOffset"
  ],
  "nvmlDeviceGetMemClkVfOffset": [
    "device"
  ],
  "nvmlDeviceSetMemClkVfOffset": [
    "device",
    "offset"
  ],
  "nvmlDeviceGetMemClkMinMaxVfOffset": [
    "device",
    "minOffset",
    "maxOffset"
  ],
  "nvmlSystemSetConfComputeGpusReadyState": [
    "state"
  ],
  "nvmlSystemGetConfComputeGpusReadyState": [],
  "nvmlSystemGetConfComputeCapabilities": [],
  "nvmlSystemGetConfComputeState": [],
  "nvmlSystemGetConfComputeSettings": [
    "settings"
  ],
  "nvmlDeviceSetConfComputeUnprotectedMemSize": [
    "device",
    "c_ccMemSize"
  ],
  "nvmlDeviceGetConfComputeMemSizeInfo": [
    "device"
  ],
  "nvmlDeviceGetConfComputeProtectedMemoryUsage": [
    "device"
  ],
  "nvmlDeviceGetConfComputeGpuCertificate": [
    "device"
  ],
  "nvmlDeviceGetConfComputeGpuAttestationReport": [
    "device",
    "c_nonce"
  ],
  "nvmlSystemSetConfComputeKeyRotationThresholdInfo": [
    "max_atk_adv"
  ],
  "nvmlSystemGetConfComputeKeyRotationThresholdInfo": [],
  "NVML_GPM_METRIC_GRAPHICS_UTIL": [],
  "NVML_GPM_METRIC_SM_UTIL": [],
  "NVML_GPM_METRIC_SM_OCCUPANCY": [],
  "NVML_GPM_METRIC_INTEGER_UTIL": [],
  "NVML_GPM_METRIC_ANY_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_DFMA_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_HMMA_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_IMMA_TENSOR_UTIL": [],
  "NVML_GPM_METRIC_DRAM_BW_UTIL": [],
  "NVML_GPM_METRIC_FP64_UTIL": [],
  "NVML_GPM_METRIC_FP32_UTIL": [],
  "NVML_GPM_METRIC_FP16_UTIL": [],
  "NVML_GPM_METRIC_PCIE_TX_PER_SEC": [],
  "NVML_GPM_METRIC_PCIE_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVDEC_0_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_1_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_2_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_3_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_4_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_5_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_6_UTIL": [],
  "NVML_GPM_METRIC_NVDEC_7_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_0_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_1_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_2_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_3_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_4_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_5_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_6_UTIL": [],
  "NVML_GPM_METRIC_NVJPG_7_UTIL": [],
  "NVML_GPM_METRIC_NVOFA_0_UTIL": [],
  "NVML_GPM_METRIC_NVOFA_1_UTIL": [],
  "NVML_GPM_METRIC_NVLINK_TOTAL_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_TOTAL_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L0_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L0_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L1_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L1_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L2_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L2_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L3_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L3_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L4_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L4_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L5_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L5_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L6_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L6_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L7_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L7_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L8_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L8_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L9_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L9_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L10_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L10_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L11_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L11_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L12_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L12_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L13_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L13_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L14_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L14_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L15_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L15_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L16_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L16_TX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L17_RX_PER_SEC": [],
  "NVML_GPM_METRIC_NVLINK_L17_TX_PER_SEC": [],
  "NVML_GPM_METRIC_MAX": [],
  "struct_c_nvmlGpmSample_t": {},
  "c_nvmlGpmSample_t": [],
  "c_metricInfo_t": {
    "_fields_": []
  },
  "c_nvmlGpmMetric_t": {
    "_fields_": []
  },
  "c_nvmlGpmMetricsGet_t": {
    "_fields_": []
  },
  "NVML_GPM_METRICS_GET_VERSION": [],
  "c_nvmlGpmSupport_t": {
    "_fields_": []
  },
  "NVML_GPM_SUPPORT_VERSION": [],
  "nvmlGpmMetricsGet": [
    "metricsGet"
  ],
  "nvmlGpmSampleFree": [
    "gpmSample"
  ],
  "nvmlGpmSampleAlloc": [],
  "nvmlGpmSampleGet": [
    "device",
    "gpmSample"
  ],
  "nvmlGpmMigSampleGet": [
    "device",
    "gpuInstanceId",
    "gpmSample"
  ],
  "nvmlGpmQueryDeviceSupport": [
    "device"
  ],
  "nvmlGpmSetStreamingEnabled": [
    "device",
    "state"
  ],
  "nvmlGpmQueryIfStreamingEnabled": [
    "device"
  ],
  "NVML_NVLINK_POWER_STATE_HIGH_SPEED": [],
  "NVML_NVLINK_POWER_STATE_LOW": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_MIN": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_MAX": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_RESET": [],
  "NVML_NVLINK_LOW_POWER_THRESHOLD_DEFAULT": [],
  "c_nvmlNvLinkPowerThres_t": {
    "_fields_": []
  },
  "nvmlDeviceSetNvLinkDeviceLowPowerThreshold": [
    "device",
    "l1threshold"
  ],
  "NVML_GPU_FABRIC_UUID_LEN": [],
  "_nvmlGpuFabricState_t": [],
  "NVML_GPU_FABRIC_STATE_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_STATE_NOT_STARTED": [],
  "NVML_GPU_FABRIC_STATE_IN_PROGRESS": [],
  "NVML_GPU_FABRIC_STATE_COMPLETED": [],
  "c_nvmlGpuFabricInfo_t": {
    "_fields_": []
  },
  "NVML_GPU_FABRIC_HEALTH_MASK_DEGRADED_BW_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_DEGRADED_BW_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_DEGRADED_BW_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_DEGRADED_BW": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_DEGRADED_BW": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_RECOVERY_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_RECOVERY_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_RECOVERY_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_ROUTE_RECOVERY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_ROUTE_RECOVERY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_UNHEALTHY_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_UNHEALTHY_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ROUTE_UNHEALTHY_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_ROUTE_UNHEALTHY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_ROUTE_UNHEALTHY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ACCESS_TIMEOUT_RECOVERY_NOT_SUPPORTED": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ACCESS_TIMEOUT_RECOVERY_TRUE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_ACCESS_TIMEOUT_RECOVERY_FALSE": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_SHIFT_ACCESS_TIMEOUT_RECOVERY": [],
  "NVML_GPU_FABRIC_HEALTH_MASK_WIDTH_ACCESS_TIMEOUT_RECOVERY": [],
  "nvmlGpuFabricInfo_v2": [],
  "c_nvmlGpuFabricInfoV_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceGetGpuFabricInfo": [
    "device",
    "gpuFabricInfo"
  ],
  "nvmlDeviceGetGpuFabricInfoV": [
    "device",
    "gpuFabricInfo"
  ],
  "NVML_GPU_NVLINK_BW_MODE_FULL": [],
  "NVML_GPU_NVLINK_BW_MODE_OFF": [],
  "NVML_GPU_NVLINK_BW_MODE_MIN": [],
  "NVML_GPU_NVLINK_BW_MODE_HALF": [],
  "NVML_GPU_NVLINK_BW_MODE_3QUARTER": [],
  "NVML_GPU_NVLINK_BW_MODE_COUNT": [],
  "nvmlSystemSetNvlinkBwMode": [
    "mode"
  ],
  "nvmlSystemGetNvlinkBwMode": [],
  "_nvmlPowerScopeType_t": [],
  "NVML_POWER_SCOPE_GPU": [],
  "NVML_POWER_SCOPE_MODULE": [],
  "NVML_POWER_SCOPE_MEMORY": [],
  "c_nvmlPowerValue_v2_t": {
    "_fields_": [],
    "_fmt_": []
  },
  "nvmlPowerValue_v2": [],
  "nvmlDeviceSetPowerManagementLimit_v2": [
    "device",
    "powerScope",
    "powerLimit",
    "version"
  ],
  "c_nvmlEccSramErrorStatus_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlEccSramErrorStatus_v1": [],
  "nvmlDeviceGetSramEccErrorStatus": [
    "device",
    "status"
  ],
  "NVML_DEV_CAP_EGM": [],
  "nvmlDeviceCapabilities_v1": [],
  "c_nvmlDeviceCapabilities_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceGetCapabilities": [
    "device",
    "caps"
  ],
  "c_nvmlPlatformInfo_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlPlatformInfo_v1": [],
  "nvmlDeviceGetPlatformInfo": [
    "device",
    "platformInfo"
  ],
  "c_nvmlMask255_t": {
    "_fields_": []
  },
  "NVML_WORKLOAD_POWER_MAX_PROFILES": [],
  "NVML_POWER_PROFILE_MAX_P": [],
  "NVML_POWER_PROFILE_MAX_Q": [],
  "NVML_POWER_PROFILE_COMPUTE": [],
  "NVML_POWER_PROFILE_MEMORY_BOUND": [],
  "NVML_POWER_PROFILE_NETWORK": [],
  "NVML_POWER_PROFILE_BALANCED": [],
  "NVML_POWER_PROFILE_LLM_INFERENCE": [],
  "NVML_POWER_PROFILE_LLM_TRAINING": [],
  "NVML_POWER_PROFILE_RBM": [],
  "NVML_POWER_PROFILE_DCPCIE": [],
  "NVML_POWER_PROFILE_HMMA_SPARSE": [],
  "NVML_POWER_PROFILE_HMMA_DENSE": [],
  "NVML_POWER_PROFILE_SYNC_BALANCED": [],
  "NVML_POWER_PROFILE_HPC": [],
  "NVML_POWER_PROFILE_MIG": [],
  "NVML_POWER_PROFILE_MAX": [],
  "nvmlWorkloadPowerProfileInfo_v1": [],
  "c_nvmlWorkloadPowerProfileInfo_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlWorkloadPowerProfileProfilesInfo_v1": [],
  "c_nvmlWorkloadPowerProfileProfilesInfo_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlWorkloadPowerProfileCurrentProfiles_v1": [],
  "c_nvmlWorkloadPowerProfileCurrentProfiles_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlWorkloadPowerProfileRequestedProfiles_v1": [],
  "c_nvmlWorkloadPowerProfileRequestedProfiles_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceWorkloadPowerProfileGetProfilesInfo": [
    "device",
    "profilesInfo"
  ],
  "nvmlDeviceWorkloadPowerProfileGetCurrentProfiles": [
    "device",
    "currentProfiles"
  ],
  "nvmlDeviceWorkloadPowerProfileSetRequestedProfiles": [
    "device",
    "requestedProfiles"
  ],
  "nvmlDeviceWorkloadPowerProfileClearRequestedProfiles": [
    "device",
    "requestedProfiles"
  ],
  "nvmlDeviceGetNvlinkSupportedBwModes": [
    "device",
    "supportedBwModes"
  ],
  "nvmlDeviceGetNvlinkBwMode": [
    "device",
    "getBwMode"
  ],
  "nvmlDeviceSetNvlinkBwMode": [
    "device",
    "setBwMode"
  ],
  "nvmlDramEncryptionInfo_v1": [],
  "c_nvmlDramEncryptionInfo_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDeviceGetDramEncryptionMode": [
    "handle"
  ],
  "nvmlDeviceGetCurrentDramEncryptionMode": [
    "handle"
  ],
  "nvmlDeviceGetPendingDramEncryptionMode": [
    "handle"
  ],
  "nvmlDeviceSetDramEncryptionMode": [
    "handle",
    "mode"
  ],
  "NVML_POWER_SMOOTHING_MAX_NUM_PROFILES": [],
  "NVML_POWER_SMOOTHING_ADMIN_OVERRIDE_NOT_SET": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_PERCENT_TMP_FLOOR": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_RAMP_UP_RATE": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_RAMP_DOWN_RATE": [],
  "NVML_POWER_SMOOTHING_PROFILE_PARAM_RAMP_DOWN_HYSTERESIS": [],
  "nvmlPowerSmoothingState_v1": [],
  "c_nvmlPowerSmoothingState_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlPowerSmoothingProfile_v1": [],
  "c_nvmlPowerSmoothingProfile_v1_t": {
    "_fields_": [],
    "__init__": [
      "self"
    ]
  },
  "nvmlDevicePowerSmoothingActivatePresetProfile": [
    "device",
    "profile"
  ],
  "nvmlDevicePowerSmoothingUpdatePresetProfileParam": [
    "device",
    "profile"
  ],
  "nvmlDevicePowerSmoothingSetState": [
    "device",
    "state"
  ],
  "is_dir_not_empty": [
    "path"
  ],
  "BaseDataset": {
    "__init__": [
      "self",
      "args",
      "api_url",
      "model"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get_requests": [
      "self"
    ]
  },
  "VBenchDataset": {
    "T2V_PROMPT_URL": [],
    "I2V_DOWNLOAD_SCRIPT_URL": [],
    "__init__": [
      "self",
      "args",
      "api_url",
      "model"
    ],
    "_load_data": [
      "self"
    ],
    "_download_file": [
      "self",
      "url",
      "dest_path"
    ],
    "_load_t2v_prompts": [
      "self"
    ],
    "_auto_download_i2v_dataset": [
      "self"
    ],
    "_load_from_i2v_json": [
      "self",
      "json_path"
    ],
    "_scan_directory_for_images": [
      "self",
      "path"
    ],
    "_create_dummy_data": [
      "self"
    ],
    "_load_i2v_data": [
      "self"
    ],
    "_resize_data": [
      "self",
      "data"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get_requests": [
      "self"
    ]
  },
  "RandomDataset": {
    "__init__": [
      "self",
      "args",
      "api_url",
      "model"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "idx"
    ],
    "get_requests": [
      "self"
    ]
  },
  "async_request_image_sglang": [
    "input",
    "session",
    "pbar"
  ],
  "async_request_video_sglang": [
    "input",
    "session",
    "pbar"
  ],
  "wait_for_service": [
    "base_url",
    "timeout"
  ],
  "calculate_upper_bound": [
    "baseline",
    "rel_tol",
    "min_abs_tol"
  ],
  "calculate_lower_bound": [
    "baseline",
    "rel_tol",
    "min_abs_tol"
  ],
  "get_perf_status_emoji": [
    "baseline",
    "new",
    "rel_tol",
    "min_abs_tol"
  ],
  "consolidate_steps": [
    "steps_list"
  ],
  "_load_benchmark_file": [
    "file_path"
  ],
  "_get_status_emoji_from_diff_percent": [
    "diff_pct"
  ],
  "_print_single_comparison_report": [
    "others_data",
    "base_e2e",
    "combined_order",
    "base_durations",
    "others_processed",
    "base_counts"
  ],
  "_print_multi_comparison_report": [
    "base_e2e",
    "others_data",
    "other_labels",
    "combined_order",
    "base_durations",
    "others_processed"
  ],
  "compare_benchmarks": [
    "file_paths",
    "output_format"
  ],
  "TestSamplingParamsValidate": {
    "test_prompt_path_suffix": [
      "self"
    ],
    "test_num_outputs_per_prompt_must_be_positive": [
      "self"
    ],
    "test_fps_must_be_positive_int": [
      "self"
    ],
    "test_num_inference_steps_optional_but_if_set_must_be_positive": [
      "self"
    ],
    "test_guidance_scale_must_be_finite_non_negative_if_set": [
      "self"
    ],
    "test_guidance_rescale_must_be_finite_non_negative": [
      "self"
    ],
    "test_boundary_ratio_range": [
      "self"
    ]
  },
  "_create_temp_file": [
    "tmp_path",
    "name",
    "content"
  ],
  "test_upload_file_success": [
    "tmp_path"
  ],
  "test_upload_and_cleanup": [
    "tmp_path"
  ],
  "test_upload_failure_preserves_file": [
    "tmp_path"
  ],
  "test_disabled_storage_returns_none": [
    "tmp_path"
  ],
  "test_aws_url_with_region": [
    "tmp_path"
  ],
  "test_aws_url_default_region": [
    "tmp_path"
  ],
  "test_custom_endpoint_url": [
    "tmp_path"
  ],
  "test_content_type_detection": [
    "tmp_path"
  ],
  "has_moto": [],
  "test_integration_with_moto": [
    "tmp_path"
  ],
  "is_image_url": [
    "image_path"
  ],
  "probe_port": [
    "host",
    "port",
    "timeout"
  ],
  "get_dynamic_server_port": [],
  "is_mp4": [
    "data"
  ],
  "is_jpeg": [
    "data"
  ],
  "is_png": [
    "data"
  ],
  "is_webp": [
    "data"
  ],
  "get_expected_image_format": [
    "output_format",
    "background"
  ],
  "wait_for_port": [
    "host",
    "port",
    "deadline",
    "interval"
  ],
  "check_image_size": [
    "ut",
    "image",
    "width",
    "height"
  ],
  "get_perf_log_dir": [],
  "_ensure_log_path": [
    "log_dir"
  ],
  "clear_perf_log": [
    "log_dir"
  ],
  "prepare_perf_log": [],
  "read_perf_logs": [
    "log_path"
  ],
  "wait_for_req_perf_record": [
    "request_id",
    "log_path",
    "timeout"
  ],
  "validate_image": [
    "b64_json"
  ],
  "validate_video": [
    "b64_json"
  ],
  "validate_openai_video": [
    "video_bytes"
  ],
  "validate_image_file": [
    "file_path",
    "expected_filename",
    "expected_width",
    "expected_height",
    "output_format",
    "background"
  ],
  "_get_video_dimensions_from_metadata": [
    "cap"
  ],
  "_get_video_dimensions_from_frame": [
    "cap"
  ],
  "get_video_dimensions": [
    "file_path"
  ],
  "validate_video_file": [
    "file_path",
    "expected_filename",
    "expected_width",
    "expected_height"
  ],
  "_get_status_message": [
    "run_id",
    "current_case_id",
    "thread_messages"
  ],
  "upload_file_to_slack": [
    "case_id",
    "model",
    "prompt",
    "file_path",
    "origin_file_path"
  ],
  "SUITES": [],
  "parse_args": [],
  "collect_test_items": [
    "files",
    "filter_expr"
  ],
  "run_pytest": [
    "files",
    "filter_expr"
  ],
  "TestFlux_T2V": {
    "model_path": [],
    "extra_args": []
  },
  "TestResult": {},
  "run_command": [
    "command"
  ],
  "CLIBase": {
    "extra_args": [],
    "get_base_command": [
      "self"
    ],
    "_run_command": [
      "self",
      "name",
      "model_path",
      "args"
    ],
    "_run_test": [
      "self",
      "name",
      "args",
      "model_path",
      "test_key"
    ],
    "verify": [
      "self",
      "status",
      "name"
    ],
    "model_name": [
      "self"
    ],
    "test_single_gpu": [
      "self"
    ]
  },
  "TestDiffusionServerOneGpu": {
    "case": [
      "self",
      "request"
    ]
  },
  "download_image_from_url": [
    "url"
  ],
  "parse_dimensions": [
    "size_string"
  ],
  "ServerContext": {
    "cleanup": [
      "self"
    ],
    "_cleanup_hf_cache_if_not_persistent": [
      "self"
    ],
    "_cleanup_rocm_gpu_memory": [
      "self"
    ]
  },
  "ServerManager": {
    "__init__": [
      "self",
      "model",
      "port",
      "wait_deadline",
      "extra_args",
      "env_vars"
    ],
    "_wait_for_rocm_gpu_memory_clear": [
      "self",
      "max_wait"
    ],
    "start": [
      "self"
    ],
    "_wait_for_ready": [
      "self",
      "process",
      "stdout_path"
    ],
    "_get_log_tail": [
      "path",
      "lines"
    ]
  },
  "WarmupRunner": {
    "__init__": [
      "self",
      "port",
      "model",
      "prompt",
      "output_size",
      "output_format"
    ],
    "run_text_warmups": [
      "self",
      "count"
    ],
    "run_edit_warmups": [
      "self",
      "count",
      "edit_prompt",
      "image_path"
    ]
  },
  "PerformanceValidator": {
    "__init__": [
      "self",
      "scenario",
      "tolerances",
      "step_fractions"
    ],
    "_assert_le": [
      "self",
      "name",
      "actual",
      "expected",
      "tolerance",
      "min_abs_tolerance_ms"
    ],
    "validate": [
      "self",
      "perf_record"
    ],
    "collect_metrics": [
      "self",
      "perf_record"
    ],
    "_validate_e2e": [
      "self",
      "summary"
    ],
    "_validate_denoise_agg": [
      "self",
      "summary"
    ],
    "_validate_denoise_steps": [
      "self",
      "summary"
    ],
    "_validate_stages": [
      "self",
      "summary"
    ]
  },
  "VideoPerformanceValidator": {
    "is_video_gen": [],
    "validate": [
      "self",
      "perf_record",
      "num_frames"
    ],
    "_validate_frame_rate": [
      "self",
      "summary"
    ]
  },
  "VALIDATOR_REGISTRY": [],
  "get_generate_fn": [
    "model_path",
    "modality",
    "sampling_params"
  ],
  "_GLOBAL_PERF_RESULTS": [],
  "pytest_sessionfinish": [
    "session"
  ],
  "ToleranceConfig": {
    "load_profile": [
      "cls",
      "all_tolerances",
      "profile_name"
    ]
  },
  "ScenarioConfig": {},
  "BaselineConfig": {
    "load": [
      "cls",
      "path"
    ]
  },
  "DiffusionServerArgs": {},
  "DiffusionSamplingParams": {},
  "DiffusionTestCase": {},
  "sample_step_indices": [
    "step_map",
    "fractions"
  ],
  "PerformanceSummary": {
    "from_req_perf_record": [
      "record",
      "step_fractions"
    ]
  },
  "T2I_sampling_params": [],
  "TI2I_sampling_params": [],
  "MULTI_IMAGE_TI2I_sampling_params": [],
  "MULTI_FRAME_I2I_sampling_params": [],
  "T2V_PROMPT": [],
  "TI2V_sampling_params": [],
  "TURBOWAN_I2V_sampling_params": [],
  "TWO_GPU_CASES_A": [],
  "TWO_GPU_CASES_B": [],
  "BASELINE_CONFIG": [],
  "diffusion_server": [
    "case"
  ],
  "DiffusionServerBase": {
    "setup_class": [
      "cls"
    ],
    "teardown_class": [
      "cls"
    ],
    "_client": [
      "self",
      "ctx"
    ],
    "run_and_collect": [
      "self",
      "ctx",
      "case_id",
      "generate_fn"
    ],
    "_validate_and_record": [
      "self",
      "case",
      "perf_record"
    ],
    "_check_for_improvement": [
      "self",
      "case",
      "summary",
      "scenario"
    ],
    "_dump_baseline_for_testcase": [
      "self",
      "case",
      "summary",
      "missing_scenario"
    ],
    "_test_lora_api_functionality": [
      "self",
      "ctx",
      "case",
      "generate_fn"
    ],
    "_test_lora_dynamic_switch_e2e": [
      "self",
      "ctx",
      "case",
      "generate_fn",
      "second_lora_path"
    ],
    "_test_dynamic_lora_loading": [
      "self",
      "ctx",
      "case"
    ],
    "_test_multi_lora_e2e": [
      "self",
      "ctx",
      "case",
      "generate_fn",
      "first_lora_path",
      "second_lora_path"
    ],
    "_test_v1_models_endpoint": [
      "self",
      "ctx",
      "case"
    ],
    "test_diffusion_perf": [
      "self",
      "case",
      "diffusion_server"
    ]
  },
  "ROOT_DIR": [],
  "download_lora": [
    "repo_id",
    "filename",
    "local_name"
  ],
  "is_diffusers_style_keys": [
    "sd",
    "debug_name"
  ],
  "run_single_test": [
    "name",
    "repo_id",
    "filename",
    "local_name",
    "expected_before",
    "expected_after"
  ],
  "_run_all_tests": [],
  "_print_summary": [
    "results"
  ],
  "TestLoRAFormatAdapter": {
    "test_lora_format_adapter_all_formats": [
      "self"
    ]
  },
  "TestDiffusionServerTwoGpu": {
    "case": [
      "self",
      "request"
    ]
  },
  "_all_cases": [],
  "_baseline_path": [],
  "_openai_client": [
    "port"
  ],
  "_build_server_extra_args": [
    "case"
  ],
  "_build_env_vars": [
    "case"
  ],
  "_torch_cleanup": [],
  "_run_case": [
    "case"
  ],
  "PACKAGE_NAME": [],
  "VERSION": [],
  "AUTHOR": [],
  "DESCRIPTION": [],
  "URL": [],
  "generate_test_data": [
    "batch_size",
    "total_seqlen",
    "num_heads",
    "head_dim",
    "dtype",
    "device"
  ],
  "test_moba_attn_varlen_forward": [
    "batch_size",
    "total_seqlen",
    "num_heads",
    "head_dim",
    "moba_chunk_size",
    "moba_topk",
    "select_mode",
    "threshold_type",
    "dtype"
  ],
  "calc_chunks": [
    "cu_seqlen",
    "moba_chunk_size"
  ],
  "_select_threshold_query_head": [
    "gate",
    "valid_gate_mask",
    "gate_self_chunk_mask",
    "simsum_threshold"
  ],
  "_select_threshold_block": [
    "gate",
    "valid_gate_mask",
    "gate_self_chunk_mask",
    "simsum_threshold"
  ],
  "_select_threshold_overall": [
    "gate",
    "valid_gate_mask",
    "gate_self_chunk_mask",
    "simsum_threshold"
  ],
  "_select_threshold_head_global": [
    "gate",
    "valid_gate_mask",
    "gate_self_chunk_mask",
    "simsum_threshold"
  ],
  "MixedAttention": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "self_attn_cu_seqlen",
      "moba_q",
      "moba_kv",
      "moba_cu_seqlen_q",
      "moba_cu_seqlen_kv",
      "max_seqlen",
      "moba_chunk_size",
      "moba_q_sh_indices"
    ],
    "backward": [
      "ctx",
      "d_output"
    ]
  },
  "moba_attn_varlen": [
    "q",
    "k",
    "v",
    "cu_seqlens",
    "max_seqlen",
    "moba_chunk_size",
    "moba_topk",
    "select_mode",
    "simsum_threshold",
    "threshold_type"
  ],
  "process_moba_input": [
    "x",
    "patch_resolution",
    "chunk_size"
  ],
  "process_moba_output": [
    "x",
    "patch_resolution",
    "chunk_size"
  ],
  "generate_data": [
    "batch_size",
    "seqlen",
    "num_head",
    "head_dim",
    "dtype"
  ],
  "test_attn_varlen_moba_speed": [
    "batch",
    "head",
    "seqlen",
    "head_dim",
    "moba_chunk_size",
    "moba_topk",
    "dtype",
    "select_mode",
    "simsum_threshold",
    "threshold_type"
  ],
  "update_config_from_args": [
    "config",
    "args_dict",
    "prefix",
    "pop_args"
  ],
  "clean_cli_args": [
    "args"
  ],
  "t5_postprocess_text": [
    "outputs",
    "_text_inputs"
  ],
  "FluxPipelineConfig": {
    "prepare_sigmas": [
      "self",
      "sigmas",
      "num_inference_steps"
    ],
    "prepare_latent_shape": [
      "self",
      "batch",
      "batch_size",
      "num_frames"
    ],
    "maybe_pack_latents": [
      "self",
      "latents",
      "batch_size",
      "batch"
    ],
    "get_pos_prompt_embeds": [
      "self",
      "batch"
    ],
    "get_neg_prompt_embeds": [
      "self",
      "batch"
    ],
    "_prepare_latent_image_ids": [
      "self",
      "original_height",
      "original_width",
      "device"
    ],
    "get_freqs_cis": [
      "self",
      "prompt_embeds",
      "width",
      "height",
      "device",
      "rotary_emb",
      "batch"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_neg_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ]
  },
  "_prepare_latent_ids": [
    "latents"
  ],
  "_unpack_latents_with_ids": [
    "x",
    "x_ids"
  ],
  "_patchify_latents": [
    "latents"
  ],
  "_unpatchify_latents": [
    "latents"
  ],
  "_prepare_text_ids": [
    "x",
    "t_coord"
  ],
  "_prepare_image_ids": [
    "image_latents",
    "scale"
  ],
  "flux2_postprocess_text": [
    "outputs",
    "_text_inputs"
  ],
  "flux2_klein_postprocess_text": [
    "outputs",
    "_text_inputs"
  ],
  "Flux2MistralTextArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "Flux2MistralTextConfig": {},
  "format_text_input": [
    "prompts",
    "system_message"
  ],
  "flux_2_preprocess_text": [
    "prompt"
  ],
  "flux2_pack_latents": [
    "latents"
  ],
  "Flux2PipelineConfig": {
    "tokenize_prompt": [
      "self",
      "prompts",
      "tokenizer",
      "tok_kwargs"
    ],
    "prepare_latent_shape": [
      "self",
      "batch",
      "batch_size",
      "num_frames"
    ],
    "get_pos_prompt_embeds": [
      "self",
      "batch"
    ],
    "get_neg_prompt_embeds": [
      "self",
      "batch"
    ],
    "calculate_condition_image_size": [
      "self",
      "image",
      "width",
      "height"
    ],
    "preprocess_condition_image": [
      "self",
      "image",
      "target_width",
      "target_height",
      "vae_image_processor"
    ],
    "postprocess_image_latent": [
      "self",
      "latent_condition",
      "batch"
    ],
    "get_freqs_cis": [
      "self",
      "prompt_embeds",
      "width",
      "height",
      "device",
      "rotary_emb",
      "batch"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_neg_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "maybe_pack_latents": [
      "self",
      "latents",
      "batch_size",
      "batch"
    ],
    "maybe_prepare_latent_ids": [
      "self",
      "latents"
    ],
    "postprocess_vae_encode": [
      "self",
      "image_latents",
      "vae"
    ],
    "_check_vae_has_bn": [
      "self",
      "vae"
    ],
    "preprocess_decoding": [
      "self",
      "latents",
      "server_args",
      "vae"
    ],
    "get_decode_scale_and_shift": [
      "self",
      "device",
      "dtype",
      "vae"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ],
    "slice_noise_pred": [
      "self",
      "noise",
      "latents"
    ]
  },
  "Flux2KleinPipelineConfig": {
    "tokenize_prompt": [
      "self",
      "prompts",
      "tokenizer",
      "tok_kwargs"
    ]
  },
  "_extract_masked_hidden": [
    "hidden_states",
    "mask"
  ],
  "qwen_image_preprocess_text": [
    "prompt"
  ],
  "qwen_image_postprocess_text": [
    "outputs",
    "_text_inputs",
    "drop_idx"
  ],
  "_pack_latents": [
    "latents",
    "batch_size",
    "num_channels_latents",
    "height",
    "width"
  ],
  "QwenImagePipelineConfig": {
    "prepare_sigmas": [
      "self",
      "sigmas",
      "num_inference_steps"
    ],
    "prepare_image_processor_kwargs": [
      "self",
      "batch",
      "neg"
    ],
    "get_vae_scale_factor": [
      "self"
    ],
    "prepare_latent_shape": [
      "self",
      "batch",
      "batch_size",
      "num_frames"
    ],
    "maybe_pack_latents": [
      "self",
      "latents",
      "batch_size",
      "batch"
    ],
    "get_decode_scale_and_shift": [
      "self",
      "device",
      "dtype",
      "vae"
    ],
    "get_freqs_cis": [
      "img_shapes",
      "txt_seq_lens",
      "rotary_emb",
      "device",
      "dtype"
    ],
    "_prepare_cond_kwargs": [
      "self",
      "batch",
      "prompt_embeds",
      "rotary_emb",
      "device",
      "dtype"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_neg_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ]
  },
  "QwenImageEditPipelineConfig": {
    "_prepare_edit_cond_kwargs": [
      "self",
      "batch",
      "prompt_embeds",
      "rotary_emb",
      "device",
      "dtype"
    ],
    "preprocess_condition_image": [
      "self",
      "image",
      "target_width",
      "target_height",
      "_vae_image_processor"
    ],
    "postprocess_image_latent": [
      "self",
      "latent_condition",
      "batch"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_neg_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "calculate_condition_image_size": [
      "self",
      "image",
      "width",
      "height"
    ],
    "slice_noise_pred": [
      "self",
      "noise",
      "latents"
    ]
  },
  "CONDITION_IMAGE_SIZE": [],
  "VAE_IMAGE_SIZE": [],
  "QwenImageEditPlusPipelineConfig": {
    "_get_condition_image_sizes": [
      "self",
      "batch"
    ],
    "prepare_image_processor_kwargs": [
      "self",
      "batch",
      "neg"
    ],
    "prepare_calculated_size": [
      "self",
      "image"
    ],
    "resize_condition_image": [
      "self",
      "images",
      "target_width",
      "target_height"
    ],
    "calculate_condition_image_size": [
      "self",
      "image",
      "width",
      "height"
    ],
    "calculate_vae_image_size": [
      "self",
      "image",
      "width",
      "height"
    ],
    "preprocess_vae_image": [
      "self",
      "batch",
      "vae_image_processor"
    ],
    "_prepare_edit_cond_kwargs": [
      "self",
      "batch",
      "prompt_embeds",
      "rotary_emb",
      "device",
      "dtype"
    ]
  },
  "QwenImageEditPlus_2511_PipelineConfig": {},
  "QwenImageLayeredPipelineConfig": {
    "_prepare_edit_cond_kwargs": [
      "self",
      "batch",
      "prompt_embeds",
      "rotary_emb",
      "device",
      "dtype"
    ],
    "_unpad_and_unpack_latents": [
      "self",
      "latents",
      "batch"
    ],
    "allow_set_num_frames": [
      "self"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ]
  },
  "WanI2VCommonConfig": {
    "adjust_num_frames": [
      "self",
      "num_frames"
    ]
  },
  "WanT2V480PConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "TurboWanT2V480PConfig": {},
  "WanT2V720PConfig": {},
  "WanI2V480PConfig": {
    "postprocess_image": [
      "self",
      "image"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "WanI2V720PConfig": {},
  "TurboWanI2V720Config": {
    "__post_init__": [
      "self"
    ]
  },
  "FastWan2_1_T2V_480P_Config": {},
  "Wan2_2_TI2V_5B_Config": {
    "vae_stride": [],
    "prepare_latent_shape": [
      "self",
      "batch",
      "batch_size",
      "num_frames"
    ],
    "__post_init__": [
      "self"
    ]
  },
  "FastWan2_2_TI2V_5B_Config": {},
  "Wan2_2_T2V_A14B_Config": {
    "__post_init__": [
      "self"
    ]
  },
  "Wan2_2_I2V_A14B_Config": {
    "__post_init__": [
      "self"
    ]
  },
  "SelfForcingWanT2V480PConfig": {},
  "Flux2FinetunedPipelineConfig": {
    "preprocess_decoding": [
      "self",
      "latents",
      "server_args",
      "vae"
    ],
    "get_decode_scale_and_shift": [
      "self",
      "device",
      "dtype",
      "vae"
    ]
  },
  "ModelTaskType": {
    "I2V": [],
    "T2V": [],
    "TI2V": [],
    "T2I": [],
    "I2I": [],
    "TI2I": [],
    "is_image_gen": [
      "self"
    ],
    "requires_image_input": [
      "self"
    ],
    "accepts_image_input": [
      "self"
    ],
    "data_type": [
      "self"
    ]
  },
  "STA_Mode": {
    "STA_INFERENCE": [],
    "STA_SEARCHING": [],
    "STA_TUNING": [],
    "STA_TUNING_CFG": [],
    "NONE": []
  },
  "preprocess_text": [
    "prompt"
  ],
  "postprocess_text": [
    "output",
    "_text_inputs"
  ],
  "shard_rotary_emb_for_sp": [
    "emb"
  ],
  "maybe_unpad_latents": [
    "latents",
    "batch"
  ],
  "PipelineConfig": {
    "DEFAULT_TEXT_ENCODER_PRECISIONS": [],
    "postprocess_image": [
      "self",
      "image"
    ],
    "calculate_condition_image_size": [
      "self",
      "image",
      "width",
      "height"
    ],
    "prepare_sigmas": [
      "self",
      "sigmas",
      "num_inference_steps"
    ],
    "preprocess_condition_image": [
      "self",
      "image",
      "target_width",
      "target_height",
      "_vae_image_processor"
    ],
    "prepare_calculated_size": [
      "self",
      "image"
    ],
    "prepare_image_processor_kwargs": [
      "self",
      "batch",
      "neg"
    ],
    "postprocess_image_latent": [
      "self",
      "latent_condition",
      "batch"
    ],
    "slice_noise_pred": [
      "self",
      "noise",
      "latents"
    ],
    "adjust_num_frames": [
      "self",
      "num_frames"
    ],
    "tokenize_prompt": [
      "self",
      "prompt",
      "tokenizer",
      "tok_kwargs"
    ],
    "prepare_latent_shape": [
      "self",
      "batch",
      "batch_size",
      "num_frames"
    ],
    "allow_set_num_frames": [
      "self"
    ],
    "get_decode_scale_and_shift": [
      "self",
      "device",
      "dtype",
      "vae"
    ],
    "maybe_pack_latents": [
      "self",
      "latents",
      "batch_size",
      "batch"
    ],
    "maybe_prepare_latent_ids": [
      "self",
      "latents"
    ],
    "postprocess_vae_encode": [
      "self",
      "image_latents",
      "vae"
    ],
    "preprocess_decoding": [
      "self",
      "latents",
      "server_args",
      "vae"
    ],
    "gather_latents_for_sp": [
      "self",
      "latents"
    ],
    "preprocess_vae_image": [
      "self",
      "batch",
      "vae_image_processor"
    ],
    "shard_latents_for_sp": [
      "self",
      "batch",
      "latents"
    ],
    "get_pos_prompt_embeds": [
      "self",
      "batch"
    ],
    "get_neg_prompt_embeds": [
      "self",
      "batch"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ],
    "post_decoding": [
      "self",
      "frames",
      "server_args"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_neg_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "add_cli_args": [
      "parser",
      "prefix"
    ],
    "update_config_from_dict": [
      "self",
      "args",
      "prefix"
    ],
    "from_kwargs": [
      "cls",
      "kwargs",
      "config_cli_prefix"
    ],
    "check_pipeline_config": [
      "self"
    ],
    "dump_to_json": [
      "self",
      "file_path"
    ],
    "load_from_json": [
      "self",
      "file_path"
    ],
    "update_pipeline_config": [
      "self",
      "source_pipeline_dict"
    ]
  },
  "ImagePipelineConfig": {
    "_prepare_sigmas": [
      "self",
      "sigmas",
      "num_inference_steps"
    ],
    "shard_latents_for_sp": [
      "self",
      "batch",
      "latents"
    ],
    "gather_latents_for_sp": [
      "self",
      "latents"
    ],
    "_unpad_and_unpack_latents": [
      "self",
      "latents",
      "batch"
    ]
  },
  "SlidingTileAttnConfig": {},
  "parse_int_list": [
    "value"
  ],
  "PROMPT_TEMPLATE_ENCODE_VIDEO": [],
  "PromptTemplate": {},
  "llama_preprocess_text": [
    "prompt"
  ],
  "llama_postprocess_text": [
    "outputs",
    "_text_inputs"
  ],
  "clip_preprocess_text": [
    "prompt"
  ],
  "clip_postprocess_text": [
    "outputs",
    "_text_inputs"
  ],
  "HunyuanConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "FastHunyuanConfig": {},
  "GlmImagePipelineConfig": {
    "__post_init__": [
      "self"
    ],
    "get_freqs_cis": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "prepare_neg_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ],
    "get_decode_scale_and_shift": [
      "self",
      "device",
      "dtype",
      "vae"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ],
    "post_decoding": [
      "self",
      "frames",
      "server_args"
    ]
  },
  "zimage_preprocess_text": [
    "prompt"
  ],
  "zimage_postprocess_text": [
    "outputs",
    "_text_inputs"
  ],
  "TransformersModelConfig": {},
  "ZImagePipelineConfig": {
    "tokenize_prompt": [
      "self",
      "prompts",
      "tokenizer",
      "tok_kwargs"
    ],
    "shard_latents_for_sp": [
      "self",
      "batch",
      "latents"
    ],
    "gather_latents_for_sp": [
      "self",
      "latents"
    ],
    "post_denoising_loop": [
      "self",
      "latents",
      "batch"
    ],
    "get_freqs_cis": [
      "self",
      "prompt_embeds",
      "width",
      "height",
      "device",
      "rotary_emb",
      "batch"
    ],
    "prepare_pos_cond_kwargs": [
      "self",
      "batch",
      "device",
      "rotary_emb",
      "dtype"
    ]
  },
  "DiffusersGenericPipelineConfig": {
    "check_pipeline_config": [
      "self"
    ],
    "adjust_size": [
      "self",
      "width",
      "height",
      "image"
    ],
    "adjust_num_frames": [
      "self",
      "num_frames"
    ]
  },
  "FluxSamplingParams": {
    "__post_init__": [
      "self"
    ]
  },
  "Flux2KleinSamplingParams": {},
  "WanT2V_1_3B_SamplingParams": {},
  "WanT2V_14B_SamplingParams": {},
  "WanI2V_14B_480P_SamplingParam": {},
  "WanI2V_14B_720P_SamplingParam": {},
  "FastWanT2V480PConfig": {},
  "Wan2_1_Fun_1_3B_InP_SamplingParams": {},
  "Wan2_2_Base_SamplingParams": {},
  "Wan2_2_TI2V_5B_SamplingParam": {},
  "Wan2_2_T2V_A14B_SamplingParam": {},
  "Wan2_2_I2V_A14B_SamplingParam": {},
  "Turbo_Wan2_2_I2V_A14B_SamplingParam": {},
  "TeaCacheParams": {},
  "WanTeaCacheParams": {
    "coefficients": [
      "self"
    ],
    "ret_steps": [
      "self"
    ],
    "get_cutoff_steps": [
      "self",
      "num_inference_steps"
    ]
  },
  "HunyuanSamplingParams": {},
  "FastHunyuanSamplingParam": {},
  "GlmImageSamplingParams": {
    "negative_prompt": []
  },
  "ZImageSamplingParams": {},
  "_json_safe": [
    "obj"
  ],
  "generate_request_id": [],
  "_sanitize_filename": [
    "name",
    "replacement",
    "max_length"
  ],
  "DataType": {
    "IMAGE": [],
    "VIDEO": [],
    "get_default_extension": [
      "self"
    ]
  },
  "CacheParams": {},
  "QwenImageSamplingParams": {},
  "QwenImage2512SamplingParams": {},
  "QwenImageEditPlusSamplingParams": {},
  "QwenImageLayeredSamplingParams": {},
  "DiffusersGenericSamplingParams": {
    "__post_init__": [
      "self"
    ]
  },
  "ArchConfig": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "key",
      "value"
    ]
  },
  "_is_transformer_layer": [
    "n",
    "m"
  ],
  "_is_embeddings": [
    "n",
    "m"
  ],
  "_is_final_norm": [
    "n",
    "m"
  ],
  "QwenImageArchConfig": {},
  "Qwen2_5VLConfig": {},
  "EncoderArchConfig": {},
  "TextEncoderArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "ImageEncoderArchConfig": {},
  "BaseEncoderOutput": {},
  "EncoderConfig": {},
  "TextEncoderConfig": {},
  "ImageEncoderConfig": {},
  "CLIPTextArchConfig": {},
  "CLIPVisionArchConfig": {},
  "CLIPTextConfig": {},
  "CLIPVisionConfig": {},
  "LlamaArchConfig": {},
  "LlamaConfig": {},
  "Qwen3TextArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "Qwen3TextConfig": {},
  "_is_final_layernorm": [
    "n",
    "m"
  ],
  "T5ArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "T5Config": {},
  "FluxArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "FluxConfig": {},
  "DiTArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "DiTConfig": {
    "add_cli_args": [
      "parser",
      "prefix"
    ]
  },
  "GlmImageArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "GlmImageDitConfig": {},
  "is_blocks": [
    "n",
    "m"
  ],
  "WanVideoArchConfig": {
    "text_len": [],
    "__post_init__": [
      "self"
    ]
  },
  "WanVideoConfig": {},
  "ZImageArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "ZImageDitConfig": {},
  "QwenImageEditPlus_2511_ArchConfig": {},
  "QwenImageDitConfig": {},
  "QwenImageEditPlus_2511_DitConfig": {},
  "is_double_block": [
    "n",
    "m"
  ],
  "is_single_block": [
    "n",
    "m"
  ],
  "is_refiner_block": [
    "n",
    "m"
  ],
  "is_txt_in": [
    "n",
    "m"
  ],
  "HunyuanVideoArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "HunyuanVideoConfig": {},
  "FluxVAEArchConfig": {},
  "Flux2VAEArchConfig": {},
  "FluxVAEConfig": {
    "__post_init__": [
      "self"
    ],
    "post_init": [
      "self"
    ]
  },
  "Flux2VAEConfig": {},
  "WanVAEArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "WanVAEConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "VAEArchConfig": {},
  "VAEConfig": {
    "__post_init__": [
      "self"
    ],
    "post_init": [
      "self"
    ],
    "add_cli_args": [
      "parser",
      "prefix"
    ],
    "get_vae_scale_factor": [
      "self"
    ],
    "encode_sample_mode": [
      "self"
    ],
    "from_cli_args": [
      "cls",
      "args"
    ]
  },
  "GlmImageVAEArchConfig": {},
  "GlmImageVAEConfig": {
    "get_vae_scale_factor": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "post_init": [
      "self"
    ]
  },
  "HunyuanVAEArchConfig": {
    "__post_init__": [
      "self"
    ]
  },
  "HunyuanVAEConfig": {},
  "QwenImageVAEArchConfig": {},
  "QwenImageVAEConfig": {
    "get_vae_scale_factor": [
      "self"
    ],
    "__post_init__": [
      "self"
    ],
    "post_init": [
      "self"
    ]
  },
  "_ensure_dir": [
    "path"
  ],
  "_to_numpy_image": [
    "image"
  ],
  "_to_hwc_tensor": [
    "image"
  ],
  "is_empty_image": [
    "image",
    "tolerance"
  ],
  "get_image_path": [
    "image"
  ],
  "convert_b64_to_tensor_image": [
    "b64_image"
  ],
  "SGLDVideoInput": {
    "__init__": [
      "self",
      "video_path",
      "height",
      "width"
    ],
    "get_dimensions": [
      "self"
    ],
    "get_components": [
      "self"
    ],
    "save_to": [
      "self",
      "path",
      "format",
      "codec",
      "metadata"
    ]
  },
  "convert_video_to_comfy_video": [
    "video_path",
    "height",
    "width"
  ],
  "SGLDOptions": {
    "INPUT_TYPES": [
      "cls"
    ],
    "RETURN_TYPES": [],
    "RETURN_NAMES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "create_options": [
      "self",
      "enable_torch_compile",
      "num_gpus",
      "tp_size",
      "sp_degree",
      "ulysses_degree",
      "ring_degree",
      "dp_size",
      "dp_degree",
      "enable_cfg_parallel",
      "attention_backend",
      "cache_strategy"
    ]
  },
  "SGLDUNETLoader": {
    "__init__": [
      "self"
    ],
    "INPUT_TYPES": [
      "s"
    ],
    "RETURN_TYPES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "load_unet": [
      "self",
      "unet_name",
      "weight_dtype",
      "sgld_options"
    ]
  },
  "SGLDiffusionServerModel": {
    "INPUT_TYPES": [
      "cls"
    ],
    "RETURN_TYPES": [],
    "RETURN_NAMES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "load_server": [
      "self",
      "base_url",
      "api_key"
    ]
  },
  "SGLDiffusionGenerateImage": {
    "INPUT_TYPES": [
      "cls"
    ],
    "RETURN_TYPES": [],
    "RETURN_NAMES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "OUTPUT_NODE": [],
    "generate_image": [
      "self",
      "sgld_client",
      "positive_prompt",
      "negative_prompt",
      "image",
      "seed",
      "steps",
      "cfg",
      "width",
      "height",
      "enable_teacache"
    ]
  },
  "SGLDiffusionGenerateVideo": {
    "INPUT_TYPES": [
      "cls"
    ],
    "RETURN_TYPES": [],
    "RETURN_NAMES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "OUTPUT_NODE": [],
    "generate_video": [
      "self",
      "sgld_client",
      "positive_prompt",
      "negative_prompt",
      "image",
      "seed",
      "steps",
      "cfg",
      "width",
      "height",
      "num_frames",
      "fps",
      "seconds",
      "enable_teacache"
    ]
  },
  "SGLDiffusionServerSetLora": {
    "INPUT_TYPES": [
      "cls"
    ],
    "RETURN_TYPES": [],
    "RETURN_NAMES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "OUTPUT_NODE": [],
    "set_lora": [
      "self",
      "sgld_client",
      "lora_name",
      "lora_nickname",
      "target"
    ]
  },
  "SGLDiffusionServerUnsetLora": {
    "INPUT_TYPES": [
      "cls"
    ],
    "RETURN_TYPES": [],
    "RETURN_NAMES": [],
    "FUNCTION": [],
    "CATEGORY": [],
    "OUTPUT_NODE": [],
    "unset_lora": [
      "self",
      "sgld_client",
      "target"
    ]
  },
  "NODE_CLASS_MAPPINGS": [],
  "NODE_DISPLAY_NAME_MAPPINGS": [],
  "SGLDiffusionServerAPI": {
    "__init__": [
      "self",
      "base_url",
      "api_key"
    ],
    "get_model_info": [
      "self"
    ],
    "generate_image": [
      "self",
      "prompt",
      "image_path",
      "mask_path",
      "size",
      "width",
      "height",
      "n",
      "negative_prompt",
      "guidance_scale",
      "num_inference_steps",
      "seed",
      "enable_teacache",
      "response_format",
      "quality",
      "style",
      "background",
      "output_format",
      "generator_device"
    ],
    "generate_video": [
      "self",
      "prompt",
      "size",
      "width",
      "height",
      "seconds",
      "fps",
      "num_frames",
      "negative_prompt",
      "guidance_scale",
      "num_inference_steps",
      "seed",
      "enable_teacache",
      "generator_device",
      "input_reference",
      "output_path"
    ],
    "_build_image_common_params": [
      "self",
      "prompt",
      "size",
      "n",
      "response_format",
      "negative_prompt",
      "guidance_scale",
      "num_inference_steps",
      "seed",
      "enable_teacache",
      "background",
      "output_format",
      "generator_device"
    ],
    "_get_content_type": [
      "self",
      "file_path"
    ],
    "decode_image_from_response": [
      "self",
      "response_data",
      "index"
    ],
    "set_lora": [
      "self",
      "lora_nickname",
      "lora_path",
      "target"
    ],
    "unset_lora": [
      "self",
      "target"
    ]
  },
  "SGLDiffusionGenerator": {
    "__init__": [
      "self"
    ],
    "__del__": [
      "self"
    ],
    "init_generator": [
      "self",
      "model_path",
      "pipeline_class_name",
      "kwargs"
    ],
    "kill_generator": [
      "self"
    ],
    "close_generator": [
      "self"
    ],
    "get_comfyui_model": [
      "self",
      "model_path",
      "model_options"
    ],
    "load_model": [
      "self",
      "model_path",
      "model_options",
      "sgld_options"
    ]
  },
  "SGLDModelPatcher": {
    "__init__": [
      "self",
      "model",
      "load_device",
      "offload_device",
      "size",
      "weight_inplace_update",
      "model_type"
    ],
    "clone": [
      "self"
    ],
    "model_size": [
      "self"
    ],
    "load": [
      "self",
      "device_to",
      "lowvram_model_memory",
      "force_patch_weights",
      "full_load"
    ],
    "patch_model": [
      "self",
      "device_to",
      "lowvram_model_memory",
      "load_weights",
      "force_patch_weights"
    ],
    "unpatch_model": [
      "self",
      "device_to",
      "unpatch_weights"
    ]
  },
  "FluxExecutor": {
    "__init__": [
      "self",
      "generator",
      "model_path",
      "model",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "timestep",
      "context",
      "y",
      "guidance"
    ]
  },
  "SGLDiffusionExecutor": {
    "__init__": [
      "self",
      "generator",
      "model_path",
      "model",
      "config"
    ],
    "_unpack_latents": [
      "self",
      "latents",
      "height",
      "width",
      "channels"
    ],
    "_pack_latents": [
      "self",
      "latents"
    ]
  },
  "ZImageExecutor": {
    "__init__": [
      "self",
      "generator",
      "model_path",
      "model",
      "config"
    ],
    "forward": [
      "self",
      "x",
      "timesteps",
      "context"
    ]
  },
  "add_webui_args": [
    "parser"
  ],
  "run_sgl_diffusion_webui": [
    "server_args"
  ],
  "launch_http_server_only": [
    "server_args"
  ],
  "_is_torch_tensor": [
    "obj"
  ],
  "_sanitize_for_logging": [
    "obj",
    "key_hint"
  ],
  "ExecutionMode": {
    "INFERENCE": [],
    "from_string": [
      "cls",
      "value"
    ],
    "choices": [
      "cls"
    ]
  },
  "WorkloadType": {
    "I2V": [],
    "T2V": [],
    "T2I": [],
    "I2I": [],
    "from_string": [
      "cls",
      "value"
    ],
    "choices": [
      "cls"
    ]
  },
  "_current_server_args": [],
  "_global_server_args": [],
  "set_current_server_args": [
    "server_args"
  ],
  "set_global_server_args": [
    "server_args"
  ],
  "get_current_server_args": [],
  "run_zeromq_broker": [
    "server_args"
  ],
  "SchedulerClient": {
    "__init__": [
      "self"
    ],
    "initialize": [
      "self",
      "server_args"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "ping": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "AsyncSchedulerClient": {
    "__init__": [
      "self"
    ],
    "initialize": [
      "self",
      "server_args"
    ],
    "forward": [
      "self",
      "batch"
    ],
    "ping": [
      "self"
    ],
    "close": [
      "self"
    ]
  },
  "async_scheduler_client": [],
  "sync_scheduler_client": [],
  "LoRAPipeline": {
    "__init__": [
      "self"
    ],
    "is_target_layer": [
      "self",
      "module_name"
    ],
    "_get_target_lora_layers": [
      "self",
      "target"
    ],
    "_temporarily_disable_offload": [
      "self",
      "target_modules",
      "target",
      "use_module_names_only"
    ],
    "convert_module_lora_layers": [
      "self",
      "module",
      "module_name",
      "target_lora_layers",
      "check_exclude"
    ],
    "convert_to_lora_layers": [
      "self"
    ],
    "_normalize_lora_params": [
      "self",
      "lora_nickname",
      "lora_path",
      "strength",
      "target"
    ],
    "_check_lora_config_matches": [
      "self",
      "module_name",
      "target_nicknames",
      "target_strengths",
      "adapter_updated"
    ],
    "_apply_lora_to_layers": [
      "self",
      "lora_layers",
      "lora_nicknames",
      "lora_paths",
      "rank",
      "strengths",
      "clear_existing"
    ],
    "is_lora_effective": [
      "self",
      "target"
    ],
    "is_lora_set": [
      "self",
      "target"
    ],
    "load_lora_adapter": [
      "self",
      "lora_path",
      "lora_nickname",
      "rank"
    ],
    "set_lora": [
      "self",
      "lora_nickname",
      "lora_path",
      "target",
      "strength"
    ],
    "merge_lora_weights": [
      "self",
      "target",
      "strength"
    ],
    "unmerge_lora_weights": [
      "self",
      "target"
    ],
    "get_lora_status": [
      "self"
    ]
  },
  "SAMPLING_PARAMS_FIELDS": [],
  "OutputBatch": {},
  "LoRAFormat": {
    "STANDARD": [],
    "NON_DIFFUSERS_SD": [],
    "QWEN_IMAGE_STANDARD": [],
    "XLABS_FLUX": [],
    "KOHYA_FLUX": [],
    "WAN": []
  },
  "_sample_keys": [
    "keys",
    "k"
  ],
  "_has_substring_key": [
    "keys",
    "substr"
  ],
  "_has_prefix_key": [
    "keys",
    "prefix"
  ],
  "_looks_like_xlabs_flux_key": [
    "k"
  ],
  "_looks_like_kohya_flux": [
    "state_dict"
  ],
  "_looks_like_non_diffusers_sd": [
    "state_dict"
  ],
  "_looks_like_wan_lora": [
    "state_dict"
  ],
  "_looks_like_qwen_image": [
    "state_dict"
  ],
  "detect_lora_format_from_state_dict": [
    "state_dict"
  ],
  "_convert_qwen_image_standard": [
    "state_dict",
    "log"
  ],
  "_convert_non_diffusers_sd_simple": [
    "state_dict",
    "log"
  ],
  "_convert_with_diffusers_utils_if_available": [
    "state_dict",
    "log"
  ],
  "_convert_via_diffusers_candidates": [
    "state_dict",
    "candidate_names",
    "log",
    "unavailable_warning",
    "no_converter_warning",
    "success_info",
    "all_failed_warning"
  ],
  "_convert_xlabs_ai_via_diffusers": [
    "state_dict",
    "log"
  ],
  "_convert_kohya_flux_via_diffusers": [
    "state_dict",
    "log"
  ],
  "convert_lora_state_dict_by_format": [
    "state_dict",
    "fmt",
    "log"
  ],
  "normalize_lora_state_dict": [
    "state_dict",
    "logger"
  ],
  "ComposedPipelineBase": {
    "is_lora_effective": [
      "self"
    ],
    "is_lora_set": [
      "self"
    ],
    "__init__": [
      "self",
      "model_path",
      "server_args",
      "required_config_modules",
      "loaded_modules",
      "executor"
    ],
    "build_executor": [
      "self",
      "server_args"
    ],
    "__post_init__": [
      "self"
    ],
    "get_module": [
      "self",
      "module_name",
      "default_value"
    ],
    "add_module": [
      "self",
      "module_name",
      "module"
    ],
    "_load_config": [
      "self"
    ],
    "required_config_modules": [
      "self"
    ],
    "stages": [
      "self"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "load_modules": [
      "self",
      "server_args",
      "loaded_modules"
    ],
    "add_stage": [
      "self",
      "stage_name",
      "stage"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "PipelineWithLoRA": {},
  "build_pipeline": [
    "server_args"
  ],
  "V": [],
  "InputValidationStage": {
    "__init__": [
      "self",
      "vae_image_processor"
    ],
    "_generate_seeds": [
      "self",
      "batch",
      "server_args"
    ],
    "preprocess_condition_image": [
      "self",
      "batch",
      "server_args",
      "condition_image_width",
      "condition_image_height"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "StageParallelismType": {
    "REPLICATED": [],
    "MAIN_RANK_ONLY": [],
    "CFG_PARALLEL": []
  },
  "StageVerificationError": {},
  "PipelineStage": {
    "__init__": [
      "self"
    ],
    "log_info": [
      "self",
      "msg"
    ],
    "log_warning": [
      "self",
      "msg"
    ],
    "log_error": [
      "self",
      "msg"
    ],
    "log_debug": [
      "self",
      "msg"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "maybe_free_model_hooks": [
      "self"
    ],
    "load_model": [
      "self"
    ],
    "offload_model": [
      "self"
    ],
    "parallelism_type": [
      "self"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ],
    "_run_verification": [
      "self",
      "verification_result",
      "stage_name",
      "verification_type"
    ],
    "device": [
      "self"
    ],
    "set_logging": [
      "self",
      "enable"
    ],
    "__call__": [
      "self",
      "batch",
      "server_args"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "backward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "DenoisingStage": {
    "__init__": [
      "self",
      "transformer",
      "scheduler",
      "pipeline",
      "transformer_2",
      "vae"
    ],
    "compile_module_with_torch_compile": [
      "self",
      "module"
    ],
    "_maybe_enable_cache_dit": [
      "self",
      "num_inference_steps",
      "batch"
    ],
    "_build_guidance": [
      "self",
      "batch_size",
      "target_dtype",
      "device",
      "guidance_val"
    ],
    "get_or_build_guidance": [
      "self",
      "bsz",
      "dtype",
      "device"
    ],
    "parallelism_type": [
      "self"
    ],
    "_preprocess_latents_for_ti2v": [
      "self",
      "latents",
      "target_dtype",
      "batch",
      "server_args"
    ],
    "_postprocess_latents_for_ti2v": [
      "self",
      "z",
      "reserved_frames_masks",
      "batch"
    ],
    "_handle_boundary_ratio": [
      "self",
      "server_args",
      "batch"
    ],
    "_prepare_denoising_loop": [
      "self",
      "batch",
      "server_args"
    ],
    "_post_denoising_loop": [
      "self",
      "batch",
      "latents",
      "trajectory_latents",
      "trajectory_timesteps",
      "server_args",
      "is_warmup"
    ],
    "_preprocess_sp_latents": [
      "self",
      "batch",
      "server_args"
    ],
    "_postprocess_sp_latents": [
      "self",
      "batch",
      "latents",
      "trajectory_tensor"
    ],
    "step_profile": [
      "self"
    ],
    "_manage_device_placement": [
      "self",
      "model_to_use",
      "model_to_offload",
      "server_args"
    ],
    "_select_and_manage_model": [
      "self",
      "t_int",
      "boundary_timestep",
      "server_args",
      "batch"
    ],
    "expand_timestep_before_forward": [
      "self",
      "batch",
      "server_args",
      "t_device",
      "target_dtype",
      "seq_len",
      "reserved_frames_mask"
    ],
    "post_forward_for_ti2v_task": [
      "self",
      "batch",
      "server_args",
      "reserved_frames_mask",
      "latents",
      "z"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "prepare_extra_func_kwargs": [
      "self",
      "func",
      "kwargs"
    ],
    "progress_bar": [
      "self",
      "iterable",
      "total"
    ],
    "rescale_noise_cfg": [
      "self",
      "noise_cfg",
      "noise_pred_text",
      "guidance_rescale"
    ],
    "_build_attn_metadata": [
      "self",
      "i",
      "batch",
      "server_args"
    ],
    "_predict_noise": [
      "self",
      "current_model",
      "latent_model_input",
      "timestep",
      "target_dtype",
      "guidance"
    ],
    "_predict_noise_with_cfg": [
      "self",
      "current_model",
      "latent_model_input",
      "timestep",
      "batch",
      "timestep_index",
      "attn_metadata",
      "target_dtype",
      "current_guidance_scale",
      "image_kwargs",
      "pos_cond_kwargs",
      "neg_cond_kwargs",
      "server_args",
      "guidance",
      "latents"
    ],
    "prepare_sta_param": [
      "self",
      "batch",
      "server_args"
    ],
    "save_sta_search_results": [
      "self",
      "batch"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "CausalDMDDenoisingStage": {
    "__init__": [
      "self",
      "transformer",
      "scheduler"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "_initialize_kv_cache": [
      "self",
      "batch_size",
      "dtype",
      "device"
    ],
    "_initialize_crossattn_cache": [
      "self",
      "batch_size",
      "max_text_len",
      "dtype",
      "device"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "TextEncodingStage": {
    "__init__": [
      "self",
      "text_encoders",
      "tokenizers"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "prepare_tokenizer_kwargs": [
      "self",
      "tokenizer_kwargs"
    ],
    "encode_text": [
      "self",
      "text",
      "server_args",
      "encoder_index",
      "return_attention_mask",
      "return_type",
      "device",
      "dtype",
      "max_length",
      "truncation",
      "padding",
      "return_overflowing_tokens",
      "return_length"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "LatentPreparationStage": {
    "__init__": [
      "self",
      "scheduler",
      "transformer"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "adjust_video_length": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "ConditioningStage": {
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "TimestepPreparationStage": {
    "__init__": [
      "self",
      "scheduler",
      "prepare_extra_set_timesteps_kwargs"
    ],
    "parallelism_type": [
      "self"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "_ensure_tensor_decode_output": [
    "decode_output"
  ],
  "DecodingStage": {
    "__init__": [
      "self",
      "vae",
      "pipeline"
    ],
    "parallelism_type": [
      "self"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ],
    "scale_and_shift": [
      "self",
      "latents",
      "server_args"
    ],
    "decode": [
      "self",
      "latents",
      "server_args"
    ],
    "load_model": [
      "self"
    ],
    "offload_model": [
      "self"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "DmdDenoisingStage": {
    "__init__": [
      "self",
      "transformer",
      "scheduler",
      "transformer_2"
    ],
    "_preprocess_sp_latents": [
      "self",
      "batch",
      "server_args"
    ],
    "_postprocess_sp_latents": [
      "self",
      "batch",
      "latents",
      "trajectory_tensor"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "_select_and_manage_model": [
      "self",
      "t_int",
      "boundary_timestep",
      "server_args",
      "batch"
    ],
    "_manage_device_placement": [
      "self",
      "model_to_use",
      "model_to_offload",
      "server_args"
    ],
    "_handle_boundary_ratio": [
      "self",
      "server_args",
      "batch"
    ]
  },
  "ComfyUILatentPreparationStage": {
    "_fix_tensor_device": [
      "value",
      "target_device"
    ],
    "_has_tensor": [
      "value"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "StageValidators": {
    "not_none": [
      "value"
    ],
    "positive_int": [
      "value"
    ],
    "non_negative_int": [
      "value"
    ],
    "positive_float": [
      "value"
    ],
    "non_negative_float": [
      "value"
    ],
    "divisible_by": [
      "value",
      "divisor"
    ],
    "is_tensor": [
      "value"
    ],
    "tensor_with_dims": [
      "value",
      "dims"
    ],
    "tensor_min_dims": [
      "value",
      "min_dims"
    ],
    "tensor_shape_matches": [
      "value",
      "expected_shape"
    ],
    "list_not_empty": [
      "value"
    ],
    "list_length": [
      "value",
      "length"
    ],
    "list_min_length": [
      "value",
      "min_length"
    ],
    "string_not_empty": [
      "value"
    ],
    "string_not_none": [
      "value"
    ],
    "string_or_list_strings": [
      "value"
    ],
    "bool_value": [
      "value"
    ],
    "generator_or_list_generators": [
      "value"
    ],
    "is_list": [
      "value"
    ],
    "is_tuple": [
      "value"
    ],
    "none_or_tensor": [
      "value"
    ],
    "list_of_tensors_with_dims": [
      "value",
      "dims"
    ],
    "list_of_tensors": [
      "value"
    ],
    "list_of_tensors_with_min_dims": [
      "value",
      "min_dims"
    ],
    "none_or_tensor_with_dims": [
      "dims"
    ],
    "none_or_list": [
      "value"
    ],
    "none_or_positive_int": [
      "value"
    ],
    "with_dims": [
      "dims"
    ],
    "min_dims": [
      "min_dims"
    ],
    "divisible": [
      "divisor"
    ],
    "positive_int_divisible": [
      "divisor"
    ],
    "list_of_tensors_dims": [
      "dims"
    ],
    "list_of_tensors_min_dims": [
      "min_dims"
    ]
  },
  "ValidationFailure": {
    "__init__": [
      "self",
      "validator_name",
      "actual_value",
      "expected",
      "error_msg"
    ],
    "__str__": [
      "self"
    ],
    "_format_value": [
      "self",
      "value"
    ]
  },
  "VerificationResult": {
    "__init__": [
      "self"
    ],
    "add_check": [
      "self",
      "field_name",
      "value",
      "validators"
    ],
    "_create_validation_failure": [
      "self",
      "validator",
      "value"
    ],
    "is_valid": [
      "self"
    ],
    "get_failed_fields": [
      "self"
    ],
    "get_detailed_failures": [
      "self"
    ],
    "get_failure_summary": [
      "self"
    ],
    "to_dict": [
      "self"
    ]
  },
  "ImageEncodingStage": {
    "__init__": [
      "self",
      "image_processor",
      "image_encoder",
      "text_encoder"
    ],
    "load_model": [
      "self"
    ],
    "offload_model": [
      "self"
    ],
    "move_to_device": [
      "self",
      "device"
    ],
    "encoding_qwen_image_edit": [
      "self",
      "outputs",
      "image_inputs"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "ImageVAEEncodingStage": {
    "__init__": [
      "self",
      "vae"
    ],
    "load_model": [
      "self"
    ],
    "offload_model": [
      "self"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "retrieve_latents": [
      "self",
      "encoder_output",
      "generator",
      "sample_mode"
    ],
    "preprocess": [
      "self",
      "image"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "EncodingStage": {
    "__init__": [
      "self",
      "vae"
    ],
    "verify_input": [
      "self",
      "batch",
      "server_args"
    ],
    "verify_output": [
      "self",
      "batch",
      "server_args"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "Timer": {
    "__init__": [
      "self",
      "name"
    ]
  },
  "PipelineExecutor": {
    "__init__": [
      "self",
      "server_args"
    ],
    "execute_with_profiling": [
      "self",
      "stages",
      "batch",
      "server_args"
    ],
    "execute": [
      "self",
      "stages",
      "batch",
      "server_args"
    ],
    "profile_execution": [
      "self",
      "batch",
      "dump_rank"
    ]
  },
  "ParallelExecutor": {
    "collect_from_main": [
      "self",
      "batches"
    ],
    "_execute": [
      "self",
      "stages",
      "batch",
      "server_args"
    ],
    "execute": [
      "self",
      "stages",
      "batch",
      "server_args"
    ]
  },
  "SyncExecutor": {
    "run_profile_all_stages": [
      "self",
      "stages",
      "batch",
      "server_args"
    ],
    "execute": [
      "self",
      "stages",
      "batch",
      "server_args"
    ]
  },
  "DEFAULT_SEED": [],
  "VERTEX_ROUTE": [],
  "health_router": [],
  "health": [],
  "get_models": [
    "request"
  ],
  "make_serializable": [
    "obj"
  ],
  "encode_video_to_base64": [
    "file_path"
  ],
  "forward_to_scheduler": [
    "req_obj",
    "sp"
  ],
  "vertex_router": [],
  "create_app": [
    "server_args"
  ],
  "DiffGenerator": {
    "__init__": [
      "self",
      "server_args"
    ],
    "from_pretrained": [
      "cls",
      "local_mode"
    ],
    "from_server_args": [
      "cls",
      "server_args",
      "local_mode"
    ],
    "_start_local_server_if_needed": [
      "self"
    ],
    "_check_remote_scheduler": [
      "self"
    ],
    "generate": [
      "self",
      "sampling_params_kwargs"
    ],
    "_send_to_scheduler_and_wait_for_response": [
      "self",
      "batch"
    ],
    "_send_lora_request": [
      "self",
      "req",
      "success_msg",
      "failure_msg"
    ],
    "set_lora": [
      "self",
      "lora_nickname",
      "lora_path",
      "target",
      "strength"
    ],
    "unmerge_lora_weights": [
      "self",
      "target"
    ],
    "merge_lora_weights": [
      "self",
      "target",
      "strength"
    ],
    "list_loras": [
      "self"
    ],
    "_ensure_lora_state": [
      "self",
      "lora_path",
      "lora_nickname",
      "merge_lora"
    ],
    "generate_with_lora": [
      "self",
      "prompt",
      "sampling_params"
    ],
    "shutdown": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "__del__": [
      "self"
    ]
  },
  "prepare_request": [
    "server_args",
    "sampling_params"
  ],
  "post_process_sample": [
    "sample",
    "data_type",
    "fps",
    "save_output",
    "save_file_path"
  ],
  "add_multimodal_gen_generate_args": [
    "parser"
  ],
  "maybe_dump_performance": [
    "args",
    "server_args",
    "prompt",
    "results"
  ],
  "generate_cmd": [
    "args"
  ],
  "GenerateSubcommand": {
    "__init__": [
      "self"
    ],
    "_get_init_arg_names": [
      "self"
    ],
    "_get_generation_arg_names": [
      "self"
    ],
    "cmd": [
      "self",
      "args"
    ],
    "validate": [
      "self",
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "CLISubcommand": {
    "cmd": [
      "self",
      "args"
    ],
    "validate": [
      "self",
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "generate_cmd_init": [],
  "cmd_init": [],
  "RaiseNotImplementedAction": {
    "__call__": [
      "self",
      "parser",
      "namespace",
      "values",
      "option_string"
    ]
  },
  "launch_distributed": [
    "num_gpus",
    "args",
    "master_port"
  ],
  "add_multimodal_gen_serve_args": [
    "parser"
  ],
  "execute_serve_cmd": [
    "args",
    "unknown_args"
  ],
  "ServeSubcommand": {
    "__init__": [
      "self"
    ],
    "cmd": [
      "self",
      "args",
      "unknown_args"
    ],
    "validate": [
      "self",
      "args"
    ],
    "subparser_init": [
      "self",
      "subparsers"
    ]
  },
  "SetLoraReq": {},
  "MergeLoraWeightsReq": {},
  "UnmergeLoraWeightsReq": {},
  "ListLorasReq": {},
  "format_lora_message": [
    "lora_nickname",
    "target",
    "strength"
  ],
  "_parse_size": [
    "size"
  ],
  "save_image_to_path": [
    "image",
    "target_path"
  ],
  "_save_upload_to_path": [
    "upload",
    "target_path"
  ],
  "_maybe_url_image": [
    "img_url",
    "target_path"
  ],
  "_save_url_image_to_path": [
    "image_url",
    "target_path"
  ],
  "_save_base64_image_to_path": [
    "base64_data",
    "target_path"
  ],
  "process_generation_batch": [
    "scheduler_client",
    "batch"
  ],
  "merge_image_input_list": [],
  "add_common_data_to_response": [
    "response",
    "request_id",
    "result"
  ],
  "_choose_ext": [
    "output_format",
    "background"
  ],
  "_build_sampling_params_from_request": [
    "request_id",
    "prompt",
    "n",
    "size",
    "output_format",
    "background",
    "image_path",
    "seed",
    "generator_device",
    "num_inference_steps",
    "guidance_scale",
    "true_cfg_scale",
    "negative_prompt",
    "enable_teacache",
    "num_frames"
  ],
  "generations": [
    "request"
  ],
  "edits": [
    "image",
    "image_array",
    "url",
    "url_array",
    "prompt",
    "mask",
    "model",
    "n",
    "response_format",
    "size",
    "output_format",
    "background",
    "seed",
    "generator_device",
    "user",
    "negative_prompt",
    "guidance_scale",
    "true_cfg_scale",
    "num_inference_steps",
    "enable_teacache",
    "num_frames"
  ],
  "download_image_content": [
    "image_id",
    "variant"
  ],
  "AsyncDictStore": {
    "__init__": [
      "self"
    ],
    "upsert": [
      "self",
      "key",
      "value"
    ],
    "update_fields": [
      "self",
      "key",
      "updates"
    ],
    "get": [
      "self",
      "key"
    ],
    "pop": [
      "self",
      "key"
    ],
    "list_values": [
      "self"
    ]
  },
  "VIDEO_STORE": [],
  "IMAGE_STORE": [],
  "ImageResponseData": {},
  "ImageResponse": {},
  "ImageGenerationsRequest": {},
  "VideoResponse": {},
  "VideoGenerationsRequest": {},
  "VideoListResponse": {},
  "VideoRemixRequest": {},
  "CloudStorage": {
    "__init__": [
      "self"
    ],
    "is_enabled": [
      "self"
    ],
    "upload_file": [
      "self",
      "local_path",
      "destination_key"
    ],
    "upload_and_cleanup": [
      "self",
      "file_path"
    ]
  },
  "cloud_storage": [],
  "DiffusionModelCard": {},
  "_handle_lora_request": [
    "req",
    "success_msg",
    "failure_msg"
  ],
  "set_lora": [
    "lora_nickname",
    "lora_path",
    "target",
    "strength"
  ],
  "merge_lora_weights": [
    "target",
    "strength"
  ],
  "unmerge_lora_weights": [
    "target"
  ],
  "list_loras": [],
  "_video_job_from_sampling": [
    "request_id",
    "req",
    "sampling"
  ],
  "_dispatch_job_async": [
    "job_id",
    "batch"
  ],
  "create_video": [
    "request",
    "prompt",
    "input_reference",
    "reference_url",
    "model",
    "seconds",
    "size",
    "fps",
    "num_frames",
    "seed",
    "generator_device",
    "negative_prompt",
    "guidance_scale",
    "num_inference_steps",
    "enable_teacache",
    "extra_body"
  ],
  "list_videos": [
    "after",
    "limit",
    "order"
  ],
  "retrieve_video": [
    "video_id"
  ],
  "delete_video": [
    "video_id"
  ],
  "download_video_content": [
    "video_id",
    "variant"
  ],
  "get_param_names_mapping": [
    "mapping_dict"
  ],
  "hf_to_custom_state_dict": [
    "hf_param_sd",
    "param_names_mapping"
  ],
  "_BAR_FORMAT": [],
  "_make_param_like": [
    "actual_param",
    "tensor"
  ],
  "set_default_dtype": [
    "dtype"
  ],
  "maybe_load_fsdp_model": [
    "model_cls",
    "init_params",
    "weight_dir_list",
    "device",
    "hsdp_replicate_dim",
    "hsdp_shard_dim",
    "default_dtype",
    "param_dtype",
    "reduce_dtype",
    "cpu_offload",
    "fsdp_inference",
    "output_dtype",
    "pin_cpu_memory",
    "strict"
  ],
  "shard_model": [
    "model"
  ],
  "load_model_from_full_model_state_dict": [
    "model",
    "full_sd_iterator",
    "device",
    "param_dtype",
    "strict",
    "cpu_offload",
    "param_names_mapping"
  ],
  "skip_init_modules": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ]
  },
  "_normalize_module_type": [
    "module_type"
  ],
  "_clean_hf_config_inplace": [
    "model_config"
  ],
  "_list_safetensors_files": [
    "model_path"
  ],
  "get_memory_usage_of_component": [
    "module"
  ],
  "ComponentLoader": {
    "__init__": [
      "self",
      "device"
    ],
    "should_offload": [
      "self",
      "server_args",
      "model_config"
    ],
    "target_device": [
      "self",
      "should_offload"
    ],
    "load": [
      "self",
      "component_model_path",
      "server_args",
      "module_name",
      "transformers_or_diffusers"
    ],
    "load_native": [
      "self",
      "component_model_path",
      "server_args",
      "transformers_or_diffusers"
    ],
    "load_customized": [
      "self",
      "component_model_path",
      "server_args",
      "module_name"
    ],
    "for_module_type": [
      "cls",
      "module_type",
      "transformers_or_diffusers"
    ]
  },
  "TextEncoderLoader": {
    "should_offload": [
      "self",
      "server_args",
      "model_config"
    ],
    "_prepare_weights": [
      "self",
      "model_name_or_path",
      "fall_back_to_pt",
      "allow_patterns_overrides"
    ],
    "_get_weights_iterator": [
      "self",
      "source",
      "to_cpu"
    ],
    "_get_all_weights": [
      "self",
      "model",
      "model_path",
      "to_cpu"
    ],
    "load_customized": [
      "self",
      "component_model_path",
      "server_args",
      "module_name"
    ],
    "load_model": [
      "self",
      "model_path",
      "model_config",
      "server_args",
      "dtype",
      "cpu_offload_flag"
    ]
  },
  "ImageEncoderLoader": {
    "should_offload": [
      "self",
      "server_args",
      "model_config"
    ],
    "load_customized": [
      "self",
      "component_model_path",
      "server_args"
    ]
  },
  "ImageProcessorLoader": {
    "load_customized": [
      "self",
      "component_model_path",
      "server_args",
      "module_name"
    ]
  },
  "AutoProcessorLoader": {
    "load_customized": [
      "self",
      "component_model_path",
      "server_args",
      "module_name"
    ]
  },
  "TokenizerLoader": {
    "load_customized": [
      "self",
      "component_model_path",
      "server_args",
      "module_name"
    ]
  },
  "VAELoader": {
    "should_offload": [
      "self",
      "server_args",
      "model_config"
    ],
    "load_customized": [
      "self",
      "component_model_path",
      "server_args"
    ]
  },
  "TransformerLoader": {
    "load_customized": [
      "self",
      "component_model_path",
      "server_args"
    ]
  },
  "SchedulerLoader": {
    "load_customized": [
      "self",
      "component_model_path",
      "server_args"
    ]
  },
  "GenericComponentLoader": {
    "__init__": [
      "self",
      "library"
    ]
  },
  "VisionLanguageEncoderLoader": {
    "load_customized": [
      "self",
      "component_model_path",
      "server_args",
      "transformers_or_diffusers"
    ]
  },
  "PipelineComponentLoader": {
    "load_module": [
      "module_name",
      "component_model_path",
      "transformers_or_diffusers",
      "server_args"
    ]
  },
  "all_reduce": [
    "tensor",
    "group_name"
  ],
  "all_reduce_fake": [
    "tensor",
    "group_name"
  ],
  "init_parallel_group_coordinator": [
    "group_ranks",
    "local_rank",
    "backend",
    "parallel_mode"
  ],
  "get_sp_group": [],
  "get_dp_group": [],
  "get_sp_world_size": [],
  "get_sp_parallel_rank": [],
  "get_dp_world_size": [],
  "get_dp_rank": [],
  "maybe_init_distributed_environment_and_model_parallel": [
    "tp_size",
    "sp_size",
    "enable_cfg_parallel",
    "ulysses_degree",
    "ring_degree",
    "dp_size",
    "distributed_init_method"
  ],
  "get_tp_world_size": [],
  "get_tp_rank": [],
  "is_the_same_node_as": [
    "pg",
    "source_rank"
  ],
  "initialize_tensor_parallel_group": [
    "tensor_model_parallel_size",
    "backend",
    "group_name_suffix"
  ],
  "initialize_sequence_parallel_group": [
    "sequence_model_parallel_size",
    "backend",
    "group_name_suffix"
  ],
  "get_sequence_parallel_world_size": [],
  "get_sequence_parallel_rank": [],
  "get_ulysses_parallel_world_size": [],
  "get_ulysses_parallel_rank": [],
  "get_ring_parallel_world_size": [],
  "get_ring_parallel_rank": [],
  "get_pipeline_parallel_world_size": [],
  "get_pipeline_parallel_rank": [],
  "is_pipeline_first_stage": [],
  "is_pipeline_last_stage": [],
  "get_cfg_group": [],
  "get_classifier_free_guidance_world_size": [],
  "get_classifier_free_guidance_rank": [],
  "get_data_parallel_world_size": [],
  "get_data_parallel_rank": [],
  "is_dp_last_group": [],
  "get_dit_world_size": [],
  "get_vae_parallel_group": [],
  "get_vae_parallel_world_size": [],
  "get_vae_parallel_rank": [],
  "init_dit_group": [
    "dit_parallel_size",
    "backend"
  ],
  "get_dit_group": [],
  "init_vae_group": [
    "dit_parallel_size",
    "vae_parallel_size",
    "backend"
  ],
  "sequence_model_parallel_all_to_all_4D": [
    "input_",
    "scatter_dim",
    "gather_dim"
  ],
  "sequence_model_parallel_all_gather": [
    "input_",
    "dim"
  ],
  "cfg_model_parallel_all_gather": [
    "input_",
    "dim",
    "separate_tensors"
  ],
  "cfg_model_parallel_all_reduce": [
    "input_",
    "op"
  ],
  "Singleton": {
    "_instance": [],
    "__new__": [
      "cls"
    ]
  },
  "ProcessGroupSingleton": {
    "__init__": [
      "self"
    ]
  },
  "PROCESS_GROUP": [],
  "set_seq_parallel_pg_by_sp_groups": [
    "sp_ulysses_degree",
    "sp_ring_degree",
    "rank",
    "sp_groups",
    "use_ulysses_low"
  ],
  "get_local_torch_device": [],
  "_update_nested_dict": [
    "nested_dict",
    "flattened_key",
    "value"
  ],
  "PipelineGroupCoordinator": {
    "__init__": [
      "self",
      "group_ranks",
      "local_rank",
      "torch_distributed_backend",
      "group_name"
    ],
    "reset_buffer": [
      "self"
    ],
    "set_config": [
      "self",
      "dtype"
    ],
    "set_recv_buffer": [
      "self",
      "num_pipefusion_patches",
      "patches_shape_list",
      "feature_map_shape",
      "dtype"
    ],
    "set_extra_tensors_recv_buffer": [
      "self",
      "name",
      "shape",
      "num_buffers",
      "dtype"
    ],
    "_check_shape_and_buffer": [
      "self",
      "tensor_send_to_next",
      "recv_prev",
      "name",
      "segment_idx"
    ],
    "_communicate_shapes": [
      "self",
      "tensor_send_to_next",
      "recv_prev"
    ],
    "pipeline_send": [
      "self",
      "tensor",
      "name",
      "segment_idx"
    ],
    "pipeline_isend": [
      "self",
      "tensor",
      "name",
      "segment_idx"
    ],
    "pipeline_recv": [
      "self",
      "idx",
      "name"
    ],
    "add_pipeline_recv_task": [
      "self",
      "idx",
      "name"
    ],
    "recv_next": [
      "self"
    ],
    "get_pipeline_recv_data": [
      "self",
      "idx",
      "name"
    ],
    "_pipeline_irecv": [
      "self",
      "tensor"
    ],
    "_pipeline_isend": [
      "self",
      "tensor"
    ],
    "set_skip_tensor_recv_buffer": [
      "self",
      "patches_shape_list",
      "feature_map_shape"
    ],
    "pipeline_send_skip": [
      "self",
      "tensor"
    ],
    "pipeline_isend_skip": [
      "self",
      "tensor"
    ],
    "pipeline_recv_skip": [
      "self",
      "idx"
    ],
    "add_pipeline_recv_skip_task": [
      "self",
      "idx"
    ],
    "get_pipeline_recv_skip_data": [
      "self",
      "idx"
    ],
    "recv_skip_next": [
      "self"
    ],
    "_pipeline_irecv_skip": [
      "self",
      "tensor"
    ],
    "_pipeline_isend_skip": [
      "self",
      "tensor"
    ]
  },
  "SequenceParallelGroupCoordinator": {
    "__init__": [
      "self",
      "group_ranks",
      "local_rank",
      "torch_distributed_backend",
      "group_name"
    ]
  },
  "CudaCommunicator": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_",
      "op"
    ],
    "send": [
      "self",
      "tensor",
      "dst"
    ],
    "recv": [
      "self",
      "size",
      "dtype",
      "src"
    ],
    "destroy": [
      "self"
    ]
  },
  "DistributedAutograd": {},
  "DeviceCommunicatorBase": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_",
      "op"
    ],
    "all_gather": [
      "self",
      "input_",
      "dim"
    ],
    "all_to_all_4D": [
      "self",
      "input_",
      "scatter_dim",
      "gather_dim"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "send": [
      "self",
      "tensor",
      "dst"
    ],
    "recv": [
      "self",
      "size",
      "dtype",
      "src"
    ],
    "destroy": [
      "self"
    ]
  },
  "CpuCommunicator": {
    "__init__": [
      "self",
      "cpu_group",
      "device",
      "device_group",
      "unique_name"
    ],
    "all_reduce": [
      "self",
      "input_",
      "op"
    ],
    "gather": [
      "self",
      "input_",
      "dst",
      "dim"
    ],
    "all_gather": [
      "self",
      "input_",
      "dim"
    ]
  },
  "_CPUSHMDistributed": {
    "__init__": [
      "self",
      "communicator"
    ],
    "_init_cpu_shm": [
      "self"
    ],
    "all_reduce": [
      "self",
      "input",
      "group"
    ],
    "gather": [
      "self",
      "input",
      "gather_list",
      "dst",
      "group"
    ],
    "all_gather_into_tensor": [
      "self",
      "output",
      "input",
      "group"
    ]
  },
  "generate_masked_orthogonal_rank_groups": [
    "world_size",
    "parallel_size",
    "mask"
  ],
  "RankGenerator": {
    "__init__": [
      "self",
      "tp",
      "sp",
      "pp",
      "cfg",
      "dp",
      "order",
      "rank_offset"
    ],
    "get_mask": [
      "self",
      "order",
      "token"
    ],
    "get_ranks": [
      "self",
      "token"
    ]
  },
  "LayerwiseOffloadManager": {
    "__init__": [
      "self",
      "model"
    ],
    "_match_layer_idx": [
      "self",
      "name"
    ],
    "_initialize": [
      "self"
    ],
    "prepare_for_next_denoise": [
      "self",
      "non_blocking"
    ],
    "get_target_with_name": [
      "self",
      "name"
    ],
    "prefetch_layer": [
      "self",
      "layer_idx",
      "non_blocking"
    ],
    "release_layer": [
      "self",
      "layer_idx"
    ],
    "release_all": [
      "self"
    ],
    "load_all_layers": [
      "self"
    ],
    "sync_layer_to_cpu": [
      "self",
      "layer_idx"
    ],
    "sync_all_layers_to_cpu": [
      "self"
    ],
    "register_forward_hooks": [
      "self"
    ],
    "remove_forward_hooks": [
      "self"
    ]
  },
  "OffloadableDiTMixin": {
    "configure_layerwise_offload": [
      "self",
      "server_args"
    ],
    "prepare_for_next_denoise": [
      "self"
    ],
    "disable_offload": [
      "self"
    ],
    "enable_offload": [
      "self"
    ]
  },
  "SGLANG_DIFFUSION_LOGGING_LEVEL": [],
  "SGLANG_DIFFUSION_LOGGING_PREFIX": [],
  "CYAN": [],
  "RED": [],
  "GREEN": [],
  "YELLOW": [],
  "RESET": [],
  "_FORMAT": [],
  "_DATE_FORMAT": [],
  "DEFAULT_LOGGING_CONFIG": [],
  "NewLineFormatter": {
    "__init__": [
      "self",
      "fmt",
      "datefmt",
      "style"
    ],
    "format": [
      "self",
      "record"
    ]
  },
  "ColoredFormatter": {
    "LEVEL_COLORS": [],
    "format": [
      "self",
      "record"
    ]
  },
  "SortedHelpFormatter": {
    "add_arguments": [
      "self",
      "actions"
    ]
  },
  "_print_info_once": [
    "logger",
    "msg"
  ],
  "_print_warning_once": [
    "logger",
    "msg"
  ],
  "get_is_main_process": [],
  "get_is_local_main_process": [],
  "_log_process_aware": [
    "level",
    "logger_self",
    "msg"
  ],
  "_SGLDiffusionLogger": {
    "info_once": [
      "self",
      "msg"
    ],
    "warning_once": [
      "self",
      "msg"
    ],
    "info": [
      "self",
      "msg"
    ],
    "debug": [
      "self",
      "msg"
    ],
    "warning": [
      "self",
      "msg"
    ],
    "error": [
      "self",
      "msg"
    ]
  },
  "init_logger": [
    "name"
  ],
  "_trace_calls": [
    "log_path",
    "root_dir",
    "frame",
    "event",
    "arg"
  ],
  "enable_trace_function_call": [
    "log_file_path",
    "root_dir"
  ],
  "suppress_loggers": [
    "loggers_to_suppress",
    "level"
  ],
  "globally_suppress_loggers": [],
  "suppress_stdout": [],
  "GenerationTimer": {
    "__init__": [
      "self"
    ]
  },
  "log_generation_timer": [
    "logger",
    "prompt",
    "request_idx",
    "total_requests"
  ],
  "log_batch_completion": [
    "logger",
    "num_outputs",
    "total_time"
  ],
  "_check_index_files_for_missing_shards": [
    "model_path"
  ],
  "_cleanup_model_cache": [
    "model_path",
    "reason"
  ],
  "_ci_validate_diffusers_model": [
    "model_path"
  ],
  "get_hf_config": [
    "component_model_path",
    "trust_remote_code",
    "revision",
    "model_override_args"
  ],
  "load_dict": [
    "file_path"
  ],
  "get_diffusers_component_config": [
    "model_path"
  ],
  "maybe_download_lora": [
    "model_name_or_path",
    "local_dir",
    "download"
  ],
  "verify_model_config_and_directory": [
    "model_path"
  ],
  "maybe_download_model_index": [
    "model_name_or_path"
  ],
  "maybe_download_model": [
    "model_name_or_path",
    "local_dir",
    "download",
    "is_lora",
    "allow_patterns"
  ],
  "RequestTimings": {
    "__init__": [
      "self",
      "request_id"
    ],
    "total_duration_s": [
      "self"
    ],
    "record_stage": [
      "self",
      "stage_name",
      "duration_s"
    ],
    "record_steps": [
      "self",
      "index",
      "duration_s"
    ],
    "to_dict": [
      "self"
    ]
  },
  "get_diffusion_perf_log_dir": [],
  "RequestPerfRecord": {
    "__init__": [
      "self",
      "request_id",
      "commit_hash",
      "tag",
      "stages",
      "steps",
      "total_duration_ms",
      "timestamp"
    ]
  },
  "StageProfiler": {
    "__init__": [
      "self",
      "stage_name",
      "logger",
      "timings",
      "log_stage_start_end",
      "perf_dump_path_provided"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ]
  },
  "PerformanceLogger": {
    "dump_benchmark_report": [
      "cls",
      "file_path",
      "timings",
      "meta",
      "tag"
    ],
    "log_request_summary": [
      "cls",
      "timings",
      "tag"
    ]
  },
  "SGLDiffusionProfiler": {
    "_instance": [],
    "__init__": [
      "self",
      "request_id",
      "rank",
      "full_profile",
      "num_steps",
      "num_inference_steps",
      "log_dir"
    ],
    "start": [
      "self"
    ],
    "_step": [
      "self"
    ],
    "step_stage": [
      "self"
    ],
    "step_denoising_step": [
      "self"
    ],
    "get_instance": [
      "cls"
    ],
    "stop": [
      "self",
      "export_trace",
      "dump_rank"
    ],
    "_export_trace": [
      "self"
    ],
    "_check_trace_integrity": [
      "self",
      "trace_path"
    ]
  },
  "TeaCacheContext": {},
  "TeaCacheMixin": {
    "_init_teacache_state": [
      "self"
    ],
    "reset_teacache_state": [
      "self"
    ],
    "_compute_l1_and_decide": [
      "self",
      "modulated_inp",
      "coefficients",
      "teacache_thresh"
    ],
    "_compute_teacache_decision": [
      "self",
      "modulated_inp",
      "is_boundary_step",
      "coefficients",
      "teacache_thresh"
    ],
    "_get_teacache_context": [
      "self"
    ],
    "maybe_cache_states": [
      "self",
      "hidden_states",
      "original_hidden_states"
    ],
    "should_skip_forward_for_cached_states": [
      "self"
    ],
    "retrieve_cached_states": [
      "self",
      "hidden_states"
    ]
  },
  "_original_similarity": [],
  "_patch_cache_dit_similarity": [],
  "_build_parallelism_config": [
    "sp_group",
    "tp_group"
  ],
  "_mark_transformer_parallelized": [
    "transformer",
    "config",
    "sp_group",
    "tp_group"
  ],
  "get_scm_mask": [
    "preset",
    "num_inference_steps",
    "compute_bins",
    "cache_bins"
  ],
  "CacheDitConfig": {},
  "enable_cache_on_transformer": [
    "transformer",
    "config",
    "model_name",
    "sp_group",
    "tp_group"
  ],
  "enable_cache_on_dual_transformer": [
    "transformer",
    "transformer_2",
    "primary_config",
    "secondary_config",
    "model_name",
    "sp_group",
    "tp_group"
  ],
  "MINIMUM_PICTURE_BASE64_FOR_WARMUP": [],
  "GPUWorker": {
    "__init__": [
      "self",
      "local_rank",
      "rank",
      "master_port",
      "server_args"
    ],
    "init_device_and_model": [
      "self"
    ],
    "execute_forward": [
      "self",
      "batch"
    ],
    "get_can_stay_resident_components": [
      "self",
      "remaining_gpu_mem_gb"
    ],
    "set_lora": [
      "self",
      "lora_nickname",
      "lora_path",
      "target",
      "strength"
    ],
    "merge_lora_weights": [
      "self",
      "target",
      "strength"
    ],
    "unmerge_lora_weights": [
      "self",
      "target"
    ],
    "list_loras": [
      "self"
    ]
  },
  "OOM_MSG": [],
  "Timesteps": {
    "forward": [
      "self",
      "timesteps"
    ]
  },
  "CombinedTimestepGuidanceTextProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim"
    ]
  },
  "CombinedTimestepTextProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "pooled_projection_dim"
    ]
  },
  "TimestepEmbedder": {
    "__init__": [
      "self",
      "hidden_size",
      "act_layer",
      "frequency_embedding_size",
      "max_period",
      "dtype",
      "freq_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "t",
      "timestep_seq_len"
    ]
  },
  "timestep_embedding": [
    "t",
    "dim",
    "max_period",
    "dtype"
  ],
  "ModulateProjection": {
    "__init__": [
      "self",
      "hidden_size",
      "factor",
      "act_layer",
      "dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "unpatchify": [
    "x",
    "t",
    "h",
    "w",
    "patch_size",
    "channels"
  ],
  "_maybe_wait": [
    "tensor"
  ],
  "_usp_all_to_all_single": [
    "x"
  ],
  "_usp_input_all_to_all": [
    "x",
    "head_dim"
  ],
  "_usp_output_all_to_all": [
    "x",
    "head_dim"
  ],
  "ring_attn": [
    "query",
    "key",
    "value",
    "attn_impl",
    "is_causal",
    "dropout_p"
  ],
  "get_token_bin_counts_and_mask": [
    "tokens",
    "vocab_size",
    "num_seqs"
  ],
  "_ACTIVATION_AND_MUL_REGISTRY": [],
  "get_act_and_mul_fn": [
    "act_fn_name"
  ],
  "apply_flashinfer_rope_qk_inplace": [
    "q",
    "k",
    "cos_sin_cache"
  ],
  "OneDRotaryEmbedding": {
    "__init__": [
      "self",
      "dim",
      "theta",
      "theta_rescale_factor",
      "interpolation_factor",
      "dtype",
      "use_real",
      "repeat_interleave_real"
    ],
    "build_freqs": [
      "self",
      "device"
    ],
    "build_freqs_outer": [
      "self",
      "pos",
      "device"
    ],
    "forward_from_grid": [
      "self",
      "seq_len",
      "start_pos",
      "device_str"
    ],
    "forward": [
      "self",
      "pos"
    ],
    "_forward_cached": [
      "self",
      "pos_tuple",
      "device_str"
    ]
  },
  "NDRotaryEmbedding": {
    "__init__": [
      "self",
      "rope_dim_list",
      "rope_theta",
      "theta_rescale_factor",
      "interpolation_factor",
      "use_real",
      "repeat_interleave_real",
      "dtype"
    ],
    "forward": [
      "self",
      "positions"
    ],
    "_forward_cached": [
      "self",
      "pos_tuple",
      "device_str"
    ],
    "forward_uncached": [
      "self",
      "pos"
    ],
    "forward_from_grid": [
      "self",
      "grid_size",
      "shard_dim",
      "start_frame",
      "device"
    ],
    "_forward_cached_from_grid": [
      "self",
      "grid_size",
      "shard_dim",
      "start_frame",
      "device_str"
    ]
  },
  "_to_tuple": [
    "x",
    "dim"
  ],
  "get_meshgrid_nd": [
    "start"
  ],
  "get_1d_rotary_pos_embed": [
    "dim",
    "pos",
    "theta",
    "theta_rescale_factor",
    "interpolation_factor",
    "dtype",
    "device"
  ],
  "get_nd_rotary_pos_embed": [
    "rope_dim_list",
    "start"
  ],
  "get_rotary_pos_embed": [
    "rope_sizes",
    "hidden_size",
    "heads_num",
    "rope_dim_list",
    "rope_theta",
    "theta_rescale_factor",
    "interpolation_factor",
    "shard_dim",
    "dtype",
    "start_frame",
    "device"
  ],
  "_fused_scale_shift_4d_kernel": [
    "output_ptr",
    "normalized_ptr",
    "scale_ptr",
    "shift_ptr",
    "rows",
    "inner_dim",
    "seq_len",
    "num_frames",
    "frame_seqlen",
    "BLOCK_N"
  ],
  "fuse_scale_shift_kernel_blc_opt": [
    "x_ptr",
    "shift_ptr",
    "scale_ptr",
    "y_ptr",
    "B",
    "L",
    "C",
    "stride_x_b",
    "stride_x_l",
    "stride_x_c",
    "stride_s_b",
    "stride_s_l",
    "stride_s_c",
    "stride_sc_b",
    "stride_sc_l",
    "stride_sc_c",
    "SCALE_IS_SCALAR",
    "SHIFT_IS_SCALAR",
    "BLOCK_L",
    "BLOCK_C"
  ],
  "fuse_scale_shift_gate_select01_kernel_blc_opt": [
    "x_ptr",
    "shift0_ptr",
    "scale0_ptr",
    "gate0_ptr",
    "shift1_ptr",
    "scale1_ptr",
    "gate1_ptr",
    "index_ptr",
    "y_ptr",
    "gate_out_ptr",
    "B",
    "L",
    "C",
    "stride_x_b",
    "stride_x_l",
    "stride_x_c",
    "stride_s0_b",
    "stride_s0_c",
    "stride_sc0_b",
    "stride_sc0_c",
    "stride_g0_b",
    "stride_g0_c",
    "stride_s1_b",
    "stride_s1_c",
    "stride_sc1_b",
    "stride_sc1_c",
    "stride_g1_b",
    "stride_g1_c",
    "stride_i_b",
    "stride_i_l",
    "stride_go_b",
    "stride_go_l",
    "stride_go_c",
    "BLOCK_L",
    "BLOCK_C"
  ],
  "fuse_scale_shift_kernel": [
    "x",
    "scale",
    "shift",
    "block_l",
    "block_c"
  ],
  "fuse_scale_shift_gate_select01_kernel": [
    "x",
    "scale0",
    "shift0",
    "gate0",
    "scale1",
    "shift1",
    "gate1",
    "index",
    "block_l",
    "block_c"
  ],
  "_rotary_embedding_kernel": [
    "output_ptr",
    "x_ptr",
    "cos_ptr",
    "sin_ptr",
    "num_heads",
    "head_size",
    "num_tokens",
    "stride_x_row",
    "stride_cos_row",
    "stride_sin_row",
    "interleaved",
    "BLOCK_HS_HALF"
  ],
  "apply_rotary_embedding": [
    "x",
    "cos",
    "sin",
    "interleaved"
  ],
  "maybe_contiguous_lastdim": [
    "x"
  ],
  "maybe_contiguous": [
    "x"
  ],
  "triton_autotune_configs": [],
  "_layer_norm_fwd_impl": [
    "x",
    "weight",
    "bias",
    "eps",
    "out",
    "residual",
    "x1",
    "weight1",
    "bias1",
    "dropout_p",
    "rowscale",
    "zero_centered_weight",
    "is_rms_norm",
    "return_dropout_mask",
    "residual_out"
  ],
  "layer_norm_fn": [
    "x",
    "weight",
    "bias",
    "residual",
    "x1",
    "weight1",
    "bias1",
    "eps",
    "dropout_p",
    "rowscale",
    "prenorm",
    "residual_in_fp32",
    "zero_centered_weight",
    "is_rms_norm",
    "return_dropout_mask",
    "out_dtype",
    "out",
    "residual_out"
  ],
  "_norm_infer_kernel": [
    "X",
    "Y",
    "W",
    "B",
    "stride_x_row",
    "stride_y_row",
    "M",
    "N",
    "eps",
    "IS_RMS_NORM",
    "HAS_WEIGHT",
    "HAS_BIAS",
    "BLOCK_N"
  ],
  "norm_infer": [
    "x",
    "weight",
    "bias",
    "eps",
    "is_rms_norm",
    "out"
  ],
  "rms_norm_fn": [
    "x",
    "weight",
    "bias",
    "residual",
    "x1",
    "weight1",
    "bias1",
    "eps",
    "dropout_p",
    "rowscale",
    "prenorm",
    "residual_in_fp32",
    "zero_centered_weight",
    "return_dropout_mask",
    "out_dtype",
    "out",
    "residual_out"
  ],
  "_rms_norm_tiled_onepass": [
    "y_ptr",
    "x_ptr",
    "w_ptr",
    "SEQ",
    "DIM",
    "EPS",
    "BLOCK_SIZE_SEQ",
    "BLOCK_SIZE_DIM"
  ],
  "triton_one_pass_rms_norm": [
    "x",
    "w",
    "eps"
  ],
  "ScaleResidual": {
    "__init__": [
      "self",
      "prefix"
    ],
    "forward": [
      "self",
      "residual",
      "x",
      "gate"
    ]
  },
  "FP32LayerNorm": {
    "forward": [
      "self",
      "inputs"
    ]
  },
  "ScaleResidualLayerNormScaleShift": {
    "__init__": [
      "self",
      "hidden_size",
      "norm_type",
      "eps",
      "elementwise_affine",
      "dtype",
      "compute_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "residual",
      "x",
      "gate",
      "shift",
      "scale"
    ]
  },
  "LayerNormScaleShift": {
    "__init__": [
      "self",
      "hidden_size",
      "norm_type",
      "eps",
      "elementwise_affine",
      "dtype",
      "compute_dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "shift",
      "scale"
    ]
  },
  "tensor_parallel_rms_norm": [
    "x",
    "norm"
  ],
  "CustomOp": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self"
    ],
    "forward_native": [
      "self"
    ],
    "forward_cuda": [
      "self"
    ],
    "forward_hip": [
      "self"
    ],
    "forward_cpu": [
      "self"
    ],
    "forward_tpu": [
      "self"
    ],
    "forward_oot": [
      "self"
    ],
    "dispatch_forward": [
      "self"
    ],
    "enabled": [
      "cls"
    ],
    "default_on": [],
    "register": [
      "cls",
      "name"
    ]
  },
  "LinearWithLoRA": {
    "__init__": [
      "self",
      "base_layer",
      "lora_rank",
      "lora_alpha"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "wrap_with_lora_layer": [
    "layer",
    "lora_rank",
    "lora_alpha"
  ],
  "backend_name_to_enum": [
    "backend_name"
  ],
  "get_env_variable_attn_backend": [],
  "global_force_attn_backend": [
    "attn_backend"
  ],
  "get_global_forced_attn_backend": [],
  "get_attn_backend": [
    "head_size",
    "dtype",
    "supported_attention_backends"
  ],
  "_cached_get_attn_backend": [
    "head_size",
    "dtype",
    "supported_attention_backends"
  ],
  "global_force_attn_backend_context_manager": [
    "attn_backend"
  ],
  "post_all2all": [
    "local_seq_2_local_head",
    "seq_world_size"
  ],
  "single_all_to_all": [
    "input",
    "local_seq_2_local_head",
    "group",
    "async_op"
  ],
  "async_a2a_communicate": [
    "a2a_inputs",
    "cp_size",
    "cp_group",
    "cp_stream",
    "local_seq_2_local_head"
  ],
  "_SeqAllToAll": {
    "forward": [
      "ctx",
      "group",
      "input",
      "local_seq_2_local_head"
    ],
    "backward": [
      "ctx"
    ]
  },
  "_SeqAllToAllQKV": {
    "forward": [
      "ctx",
      "group",
      "q",
      "k",
      "v",
      "cp_size",
      "cp_stream",
      "local_seq_2_local_head"
    ],
    "backward": [
      "ctx"
    ]
  },
  "DistributedAttention": {
    "__init__": [
      "self",
      "local_attention"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "ctx_attn_metadata"
    ],
    "set_context_parallel_group": [
      "self",
      "group",
      "stream"
    ]
  },
  "MinimalA2AAttnOp": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "attention_type",
      "topk",
      "supported_attention_backends"
    ],
    "set_context_parallel_group": [
      "self",
      "process_group",
      "ranks",
      "stream"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value"
    ]
  },
  "configure_sta": [
    "mode",
    "layer_num",
    "time_step_num",
    "head_num"
  ],
  "read_specific_json_files": [
    "folder_path"
  ],
  "average_head_losses": [
    "results",
    "selected_masks"
  ],
  "select_best_mask_strategy": [
    "averaged_results",
    "selected_masks",
    "skip_time_steps",
    "timesteps",
    "head_num"
  ],
  "save_mask_search_results": [
    "mask_search_final_result",
    "prompt",
    "mask_strategies",
    "output_dir"
  ],
  "UlyssesAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "num_kv_heads",
      "softmax_scale",
      "causal",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "replicated_q",
      "replicated_k",
      "replicated_v"
    ]
  },
  "UlyssesAttention_VSA": {
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "replicated_q",
      "replicated_k",
      "replicated_v",
      "gate_compress"
    ]
  },
  "LocalAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "num_kv_heads",
      "softmax_scale",
      "causal",
      "supported_attention_backends"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v"
    ]
  },
  "USPAttention": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "num_kv_heads",
      "softmax_scale",
      "causal",
      "supported_attention_backends",
      "prefix",
      "dropout_rate"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "replicated_q",
      "replicated_k",
      "replicated_v"
    ]
  },
  "RangeDict": {
    "__getitem__": [
      "self",
      "item"
    ]
  },
  "SlidingTileAttentionBackend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "SlidingTileAttentionMetadata": {},
  "SlidingTileAttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self",
      "STA_param",
      "current_timestep"
    ]
  },
  "SlidingTileAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "tile": [
      "self",
      "x"
    ],
    "untile": [
      "self",
      "x"
    ],
    "preprocess_qkv": [
      "self",
      "qkv",
      "attn_metadata"
    ],
    "postprocess_output": [
      "self",
      "output",
      "attn_metadata"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_metadata"
    ]
  },
  "SDPABackend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": []
  },
  "SDPAImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "VMOBAAttentionBackend": {
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "VideoMobaAttentionMetadata": {},
  "pad_input": [
    "hidden_states",
    "indices",
    "batch",
    "seqlen"
  ],
  "VideoMobaAttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self",
      "current_timestep",
      "raw_latent_shape",
      "patch_size",
      "temporal_chunk_size",
      "temporal_topk",
      "spatial_chunk_size",
      "spatial_topk",
      "st_chunk_size",
      "st_topk",
      "moba_select_mode",
      "moba_threshold",
      "moba_threshold_type",
      "device",
      "first_full_layer",
      "first_full_step",
      "temporal_layer",
      "spatial_layer",
      "st_layer"
    ]
  },
  "VMOBAAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "softmax_scale",
      "causal",
      "num_kv_heads",
      "prefix"
    ],
    "_get_layer_idx": [
      "self",
      "prefix"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "flash_attn_varlen_func_fake_out": [
    "q",
    "k",
    "v",
    "cu_seqlens_q",
    "cu_seqlens_k",
    "max_seqlen_q",
    "max_seqlen_k",
    "seqused_q",
    "seqused_k",
    "page_table",
    "softmax_scale",
    "causal",
    "qv",
    "q_descale",
    "k_descale",
    "v_descale",
    "window_size",
    "attention_chunk",
    "softcap",
    "num_splits",
    "pack_gqa",
    "sm_margin",
    "return_softmax_lse",
    "sinks",
    "ver"
  ],
  "flash_attn_varlen_func_fake_out_lse": [
    "q",
    "k",
    "v",
    "cu_seqlens_q",
    "cu_seqlens_k",
    "max_seqlen_q",
    "max_seqlen_k",
    "seqused_q",
    "seqused_k",
    "page_table",
    "softmax_scale",
    "causal",
    "qv",
    "q_descale",
    "k_descale",
    "v_descale",
    "window_size",
    "attention_chunk",
    "softcap",
    "num_splits",
    "pack_gqa",
    "sm_margin",
    "return_softmax_lse",
    "sinks",
    "ver"
  ],
  "flash_attn_varlen_func_op": [
    "q",
    "k",
    "v",
    "cu_seqlens_q",
    "cu_seqlens_k",
    "max_seqlen_q",
    "max_seqlen_k",
    "seqused_q",
    "seqused_k",
    "page_table",
    "softmax_scale",
    "causal",
    "qv",
    "q_descale",
    "k_descale",
    "v_descale",
    "window_size",
    "attention_chunk",
    "softcap",
    "num_splits",
    "pack_gqa",
    "sm_margin",
    "return_softmax_lse",
    "sinks",
    "ver"
  ],
  "flash_attn_varlen_func_op_lse": [
    "q",
    "k",
    "v",
    "cu_seqlens_q",
    "cu_seqlens_k",
    "max_seqlen_q",
    "max_seqlen_k",
    "seqused_q",
    "seqused_k",
    "page_table",
    "softmax_scale",
    "causal",
    "qv",
    "q_descale",
    "k_descale",
    "v_descale",
    "window_size",
    "attention_chunk",
    "softcap",
    "num_splits",
    "pack_gqa",
    "sm_margin",
    "return_softmax_lse",
    "sinks",
    "ver"
  ],
  "fa_ver": [],
  "_get_cu_seqlens": [
    "device_index",
    "bsz",
    "seqlen"
  ],
  "_should_use_upstream_flash_attention": [
    "upstream_available",
    "upstream_heads_ok",
    "q_shape",
    "k_shape",
    "v_shape"
  ],
  "set_fa_ver": [
    "ver"
  ],
  "FlashAttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self",
      "raw_latent_shape"
    ]
  },
  "FlashAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "SageAttention3Backend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": []
  },
  "SageAttention3Impl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "AITerBackend": {
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "AITerImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "softmax_scale",
      "causal",
      "num_kv_heads",
      "prefix",
      "dropout_p"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "get_block_map": [
    "q",
    "k",
    "topk_ratio",
    "BLKQ",
    "BLKK"
  ],
  "mean_pool": [
    "x",
    "BLK"
  ],
  "compress_kernel": [
    "X",
    "XM",
    "L",
    "D",
    "BLOCK_L"
  ],
  "_attn_fwd": [
    "Q",
    "K",
    "V",
    "qk_scale",
    "topk",
    "LUT",
    "LSE",
    "OS",
    "L",
    "M_BLOCKS",
    "D",
    "BLOCK_M",
    "BLOCK_N"
  ],
  "_get_cuda_arch": [
    "device_index"
  ],
  "SparseLinearAttentionBackend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "SparseLinearAttentionMetadata": {},
  "SparseLinearAttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self",
      "current_timestep",
      "topk_ratio"
    ]
  },
  "SparseLinearAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix",
      "topk_ratio",
      "feature_map",
      "BLKQ",
      "BLKK",
      "use_bf16"
    ],
    "_init_weights": [
      "self"
    ],
    "_calc_linear_attention_with_torch": [
      "self",
      "q",
      "k",
      "v"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "_attention": {
    "forward": [
      "ctx",
      "q",
      "k",
      "v",
      "k_block_id",
      "lut",
      "topk",
      "BLOCK_M",
      "BLOCK_N",
      "qk_scale"
    ]
  },
  "SAGESLA_ENABLED": [],
  "SAGE2PP_ENABLED": [],
  "SageSparseLinearAttentionBackend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "SageSparseLinearAttentionMetadata": {},
  "SageSparseLinearAttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self",
      "current_timestep",
      "topk_ratio"
    ]
  },
  "SageSparseLinearAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix",
      "topk_ratio",
      "feature_map",
      "use_bf16"
    ],
    "_init_weights": [
      "self"
    ],
    "_calc_linear_attention_with_torch": [
      "self",
      "q",
      "k",
      "v"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "VSA_TILE_SIZE": [],
  "get_tile_partition_indices": [
    "dit_seq_shape",
    "tile_size",
    "device"
  ],
  "get_reverse_tile_partition_indices": [
    "dit_seq_shape",
    "tile_size",
    "device"
  ],
  "construct_variable_block_sizes": [
    "dit_seq_shape",
    "num_tiles",
    "device"
  ],
  "get_non_pad_index": [
    "variable_block_sizes",
    "max_block_size"
  ],
  "VideoSparseAttentionBackend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "VideoSparseAttentionMetadata": {},
  "VideoSparseAttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self",
      "current_timestep",
      "raw_latent_shape",
      "patch_size",
      "VSA_sparsity",
      "device"
    ]
  },
  "VideoSparseAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "tile": [
      "self",
      "x",
      "num_tiles",
      "tile_partition_indices",
      "non_pad_index"
    ],
    "untile": [
      "self",
      "x",
      "reverse_tile_partition_indices",
      "non_pad_index"
    ],
    "preprocess_qkv": [
      "self",
      "qkv",
      "attn_metadata"
    ],
    "postprocess_output": [
      "self",
      "output",
      "attn_metadata"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "gate_compress",
      "attn_metadata"
    ]
  },
  "AttentionMetadata": {
    "asdict_zerocopy": [
      "self",
      "skip_fields"
    ]
  },
  "AttentionMetadataBuilder": {
    "__init__": [
      "self"
    ],
    "prepare": [
      "self"
    ],
    "build": [
      "self"
    ]
  },
  "AttentionLayer": {
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "kv_cache",
      "attn_metadata"
    ]
  },
  "AttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "softmax_scale",
      "causal",
      "num_kv_heads",
      "prefix"
    ],
    "preprocess_qkv": [
      "self",
      "qkv",
      "attn_metadata"
    ],
    "postprocess_output": [
      "self",
      "output",
      "attn_metadata"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "SageAttentionBackend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": []
  },
  "SageAttentionImpl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "FlashAttention2Backend": {
    "get_supported_head_sizes": [],
    "get_enum": [],
    "get_impl_cls": [],
    "get_metadata_cls": [],
    "get_builder_cls": []
  },
  "FlashAttention2Impl": {
    "__init__": [
      "self",
      "num_heads",
      "head_size",
      "causal",
      "softmax_scale",
      "num_kv_heads",
      "prefix"
    ],
    "forward": [
      "self",
      "query",
      "key",
      "value",
      "attn_metadata"
    ]
  },
  "QuantizationMethods": [],
  "_CUSTOMIZED_METHOD_TO_QUANT_CONFIG": [],
  "register_quantization_config": [
    "quantization"
  ],
  "all": [],
  "AttentionBackendEnum": {
    "FA2": [],
    "FA": [],
    "SLIDING_TILE_ATTN": [],
    "TORCH_SDPA": [],
    "SAGE_ATTN": [],
    "SAGE_ATTN_3": [],
    "VIDEO_SPARSE_ATTN": [],
    "VMOBA_ATTN": [],
    "AITER": [],
    "SLA_ATTN": [],
    "SAGE_SLA_ATTN": [],
    "NO_ATTENTION": [],
    "__str__": [
      "self"
    ]
  },
  "PlatformEnum": {
    "CUDA": [],
    "ROCM": [],
    "TPU": [],
    "CPU": [],
    "MPS": [],
    "MUSA": [],
    "OOT": [],
    "UNSPECIFIED": []
  },
  "CpuArchEnum": {
    "X86": [],
    "ARM": [],
    "UNSPECIFIED": []
  },
  "Platform": {
    "is_cuda": [
      "self"
    ],
    "is_rocm": [
      "self"
    ],
    "is_tpu": [
      "self"
    ],
    "is_cpu": [
      "self"
    ],
    "is_blackwell": [
      "cls"
    ],
    "is_hopper": [
      "cls"
    ],
    "is_sm120": [
      "cls"
    ],
    "is_cuda_static": [
      "cls"
    ],
    "is_rocm_static": [
      "cls"
    ],
    "is_hpu": [
      "self"
    ],
    "is_xpu": [
      "self"
    ],
    "is_npu": [
      "self"
    ],
    "is_out_of_tree": [
      "self"
    ],
    "is_cuda_alike": [
      "self"
    ],
    "is_mps": [
      "self"
    ],
    "is_musa": [
      "self"
    ],
    "is_hip": [
      "self"
    ],
    "get_attn_backend_cls_str": [
      "cls",
      "selected_backend",
      "head_size",
      "dtype"
    ],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "has_device_capability": [
      "cls",
      "capability",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "get_device": [
      "self",
      "local_rank"
    ],
    "get_torch_distributed_backend_str": [
      "self"
    ],
    "is_async_output_supported": [
      "cls",
      "enforce_eager"
    ],
    "inference_mode": [
      "cls"
    ],
    "seed_everything": [
      "cls",
      "seed"
    ],
    "verify_model_arch": [
      "cls",
      "model_arch"
    ],
    "verify_quantization": [
      "cls",
      "quant"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_available_gpu_memory": [
      "cls",
      "device_id",
      "distributed",
      "empty_cache",
      "cpu_group"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "get_cpu_architecture": [
      "cls"
    ],
    "enable_dit_layerwise_offload_for_wan_by_default": [
      "cls"
    ],
    "get_attn_backend": [
      "self"
    ]
  },
  "UnspecifiedPlatform": {
    "_enum": [],
    "device_type": []
  },
  "device_id_to_physical_device_id": [
    "device_id"
  ],
  "with_mtml_context": [
    "fn"
  ],
  "MusaPlatformBase": {
    "_enum": [],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_async_output_supported": [
      "cls",
      "enforce_eager"
    ],
    "is_full_mtlink": [
      "cls",
      "device_ids"
    ],
    "log_warnings": [
      "cls"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_available_gpu_memory": [
      "cls",
      "device_id",
      "distributed",
      "empty_cache",
      "cpu_group"
    ],
    "get_attn_backend_cls_str": [
      "cls",
      "selected_backend",
      "head_size",
      "dtype"
    ],
    "get_device_communicator_cls": [
      "cls"
    ]
  },
  "MtmlMusaPlatform": {
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "has_device_capability": [
      "cls",
      "capability",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_full_mtlink": [
      "cls",
      "physical_device_ids"
    ],
    "_get_physical_device_name": [
      "cls",
      "device_id"
    ],
    "log_warnings": [
      "cls"
    ]
  },
  "NonMtmlMusaPlatform": {
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_full_mtlink": [
      "cls",
      "physical_device_ids"
    ]
  },
  "mtml_available": [],
  "MusaPlatform": [],
  "RocmPlatform": {
    "_enum": [],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_async_output_supported": [
      "cls",
      "enforce_eager"
    ],
    "log_warnings": [
      "cls"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_available_gpu_memory": [
      "cls",
      "device_id",
      "distributed",
      "empty_cache",
      "cpu_group"
    ],
    "get_attn_backend_cls_str": [
      "cls",
      "selected_backend",
      "head_size",
      "dtype"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "enable_dit_layerwise_offload_for_wan_by_default": [
      "cls"
    ]
  },
  "cuda_platform_plugin": [],
  "mps_platform_plugin": [],
  "cpu_platform_plugin": [],
  "rocm_platform_plugin": [],
  "musa_platform_plugin": [],
  "builtin_platform_plugins": [],
  "resolve_current_platform_cls_qualname": [],
  "MpsPlatform": {
    "_enum": [],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_async_output_supported": [
      "cls",
      "enforce_eager"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_available_gpu_memory": [
      "cls",
      "device_id",
      "distributed",
      "empty_cache",
      "cpu_group"
    ],
    "get_attn_backend_cls_str": [
      "cls",
      "selected_backend",
      "head_size",
      "dtype"
    ],
    "get_device_communicator_cls": [
      "cls"
    ],
    "seed_everything": [
      "cls",
      "seed"
    ]
  },
  "CpuPlatform": {
    "_enum": [],
    "device_name": [],
    "device_type": [],
    "dispatch_key": [],
    "get_cpu_architecture": [
      "cls"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_async_output_supported": [
      "cls",
      "enforce_eager"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_available_gpu_memory": [
      "cls",
      "device_id",
      "distributed",
      "empty_cache",
      "cpu_group"
    ],
    "get_device_communicator_cls": [
      "cls"
    ]
  },
  "pynvml": [],
  "CudaPlatformBase": {
    "_enum": [],
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_async_output_supported": [
      "cls",
      "enforce_eager"
    ],
    "is_full_nvlink": [
      "cls",
      "device_ids"
    ],
    "log_warnings": [
      "cls"
    ],
    "get_current_memory_usage": [
      "cls",
      "device"
    ],
    "get_available_gpu_memory": [
      "cls",
      "device_id",
      "distributed",
      "empty_cache",
      "cpu_group"
    ],
    "get_attn_backend_cls_str": [
      "cls",
      "selected_backend",
      "head_size",
      "dtype"
    ],
    "get_device_communicator_cls": [
      "cls"
    ]
  },
  "NvmlCudaPlatform": {
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "has_device_capability": [
      "cls",
      "capability",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_uuid": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_full_nvlink": [
      "cls",
      "physical_device_ids"
    ],
    "_get_physical_device_name": [
      "cls",
      "device_id"
    ],
    "log_warnings": [
      "cls"
    ]
  },
  "NonNvmlCudaPlatform": {
    "get_device_capability": [
      "cls",
      "device_id"
    ],
    "get_device_name": [
      "cls",
      "device_id"
    ],
    "get_device_total_memory": [
      "cls",
      "device_id"
    ],
    "is_full_nvlink": [
      "cls",
      "physical_device_ids"
    ]
  },
  "nvml_available": [],
  "CudaPlatform": [],
  "calculate_shift": [
    "image_seq_len",
    "base_seq_len",
    "max_seq_len",
    "base_shift",
    "max_shift"
  ],
  "prepare_mu": [
    "batch",
    "server_args"
  ],
  "FluxPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "QwenImagePipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "QwenImageEditPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "QwenImageEditPlusPipeline": {
    "pipeline_name": []
  },
  "prepare_mu_layered": [
    "batch",
    "server_args"
  ],
  "QwenImageLayeredPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "WanCausalDMDPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "WanImageToVideoPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "WanImageToVideoDmdPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "GlmImagePipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "compute_empirical_mu": [
    "batch",
    "server_args"
  ],
  "Flux2Pipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "HunyuanVideoPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "Flux2KleinPipeline": {
    "pipeline_name": []
  },
  "ComfyUIZImagePipeline": {
    "pipeline_name": [],
    "pipeline_config_cls": [],
    "sampling_params_cls": [],
    "_required_config_modules": [],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "load_modules": [
      "self",
      "server_args",
      "loaded_modules"
    ],
    "_convert_comfyui_qkv_weights": [
      "self",
      "weight_iterator",
      "dim",
      "num_heads",
      "num_kv_heads"
    ],
    "_load_transformer_from_safetensors": [
      "self",
      "server_args",
      "loaded_modules"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "DiffusersExecutionStage": {
    "__init__": [
      "self",
      "diffusers_pipe"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "_filter_pipeline_kwargs": [
      "self",
      "kwargs"
    ],
    "_extract_output": [
      "self",
      "output"
    ],
    "_convert_to_tensor": [
      "self",
      "data"
    ],
    "_convert_list_to_tensor": [
      "self",
      "data"
    ],
    "_postprocess_output": [
      "self",
      "output"
    ],
    "_fix_output_shape": [
      "self",
      "output"
    ],
    "_build_pipeline_kwargs": [
      "self",
      "batch",
      "server_args"
    ],
    "_get_pipeline_device": [
      "self"
    ],
    "_load_input_image": [
      "self",
      "batch"
    ]
  },
  "DiffusersPipeline": {
    "pipeline_name": [],
    "is_video_pipeline": [],
    "__init__": [
      "self",
      "model_path",
      "server_args",
      "required_config_modules",
      "loaded_modules",
      "executor"
    ],
    "_load_diffusers_pipeline": [
      "self",
      "model_path",
      "server_args"
    ],
    "_apply_vae_optimizations": [
      "self",
      "pipe",
      "server_args"
    ],
    "_apply_attention_backend": [
      "self",
      "pipe",
      "server_args"
    ],
    "_get_device_map": [
      "self",
      "server_args"
    ],
    "_get_dtype": [
      "self",
      "server_args"
    ],
    "_detect_pipeline_type": [
      "self"
    ],
    "load_modules": [
      "self",
      "server_args",
      "loaded_modules"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "post_init": [
      "self"
    ],
    "add_stage": [
      "self",
      "stage_name",
      "stage"
    ],
    "stages": [
      "self"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ],
    "from_pretrained": [
      "cls",
      "model_path",
      "device",
      "torch_dtype",
      "pipeline_config",
      "args",
      "required_config_modules",
      "loaded_modules"
    ],
    "get_module": [
      "self",
      "module_name",
      "default_value"
    ]
  },
  "ComfyUIFluxPipeline": {
    "pipeline_name": [],
    "pipeline_config_cls": [],
    "sampling_params_cls": [],
    "_required_config_modules": [],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "load_modules": [
      "self",
      "server_args",
      "loaded_modules"
    ],
    "_load_and_convert_weights_from_safetensors": [
      "self",
      "model_cls",
      "dit_config",
      "hf_config",
      "safetensors_list",
      "updated_mapping",
      "qkv_size",
      "mlp_hidden_dim",
      "has_guidance_embeds",
      "default_dtype"
    ],
    "_convert_comfyui_weights": [
      "self",
      "weight_iterator",
      "qkv_size",
      "mlp_hidden_dim",
      "has_guidance_embeds"
    ],
    "_load_transformer_from_safetensors": [
      "self",
      "server_args",
      "loaded_modules"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "ZImagePipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "WanDMDPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "WanPipeline": {
    "pipeline_name": [],
    "_required_config_modules": [],
    "initialize_pipeline": [
      "self",
      "server_args"
    ],
    "create_pipeline_stages": [
      "self",
      "server_args"
    ]
  },
  "_make_synced_weight_loader": [
    "original_weight_loader"
  ],
  "modulate": [
    "x",
    "shift",
    "scale"
  ],
  "pred_noise_to_pred_video": [
    "pred_noise",
    "noise_input_latent",
    "timestep",
    "scheduler"
  ],
  "MODELS_PATH": [],
  "COMPONENT_DIRS": [],
  "_discover_and_register_models": [],
  "_SGLANG_DIFFUSION_MODELS": [],
  "_SUBPROCESS_COMMAND": [],
  "_T": [],
  "_ModelInfo": {
    "from_model_cls": [
      "model"
    ]
  },
  "_BaseRegisteredModel": {
    "inspect_model_cls": [
      "self"
    ],
    "load_model_cls": [
      "self"
    ]
  },
  "_RegisteredModel": {
    "from_model_cls": [
      "model_cls"
    ],
    "inspect_model_cls": [
      "self"
    ],
    "load_model_cls": [
      "self"
    ]
  },
  "_run_in_subprocess": [
    "fn"
  ],
  "_LazyRegisteredModel": {
    "inspect_model_cls": [
      "self"
    ],
    "load_model_cls": [
      "self"
    ]
  },
  "_try_load_model_cls": [
    "model_arch",
    "model"
  ],
  "_try_inspect_model_cls": [
    "model_arch",
    "model"
  ],
  "pil_to_numpy": [
    "images"
  ],
  "numpy_to_pt": [
    "images"
  ],
  "normalize": [
    "images"
  ],
  "get_default_height_width": [
    "image",
    "vae_scale_factor",
    "height",
    "width"
  ],
  "resize": [
    "image",
    "height",
    "width",
    "resize_mode",
    "resample"
  ],
  "retrieve_timesteps": [
    "scheduler",
    "num_inference_steps",
    "device",
    "timesteps",
    "sigmas"
  ],
  "retrieve_latents": [
    "encoder_output",
    "generator",
    "sample_mode"
  ],
  "GlmImageBeforeDenoisingStage": {
    "__init__": [
      "self",
      "tokenizer",
      "processor",
      "text_encoder",
      "vision_language_encoder",
      "vae",
      "transformer",
      "scheduler"
    ],
    "_parse_and_expand_shape_info": [
      "self",
      "prompt"
    ],
    "_build_image_grid_thw": [
      "self",
      "token_h",
      "token_w",
      "prev_token_h",
      "prev_token_w",
      "existing_grid",
      "device"
    ],
    "_calculate_ar_generation_params": [
      "self",
      "token_h",
      "token_w",
      "prev_token_h",
      "prev_token_w",
      "is_text_to_image"
    ],
    "_extract_large_image_tokens": [
      "self",
      "outputs",
      "input_length",
      "large_image_start_offset",
      "large_image_tokens"
    ],
    "_upsample_d32_to_d16": [
      "self",
      "token_ids",
      "token_h",
      "token_w"
    ],
    "_compute_generation_params": [
      "image_grid_thw",
      "is_text_to_image"
    ],
    "_upsample_token_ids": [
      "token_ids",
      "token_h",
      "token_w"
    ],
    "generate_prior_tokens": [
      "self",
      "prompt",
      "height",
      "width",
      "image",
      "factor"
    ],
    "get_glyph_texts": [
      "self",
      "prompt"
    ],
    "_get_glyph_embeds": [
      "self",
      "prompt",
      "max_sequence_length",
      "device",
      "dtype"
    ],
    "encode_prompt": [
      "self",
      "prompt",
      "do_classifier_free_guidance",
      "prompt_embeds",
      "device",
      "dtype",
      "max_sequence_length"
    ],
    "prepare_latents": [
      "self",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "dtype",
      "device",
      "generator"
    ],
    "check_inputs": [
      "self",
      "prompt",
      "height",
      "width",
      "callback_on_step_end_tensor_inputs",
      "prompt_embeds"
    ],
    "guidance_scale": [
      "self"
    ],
    "do_classifier_free_guidance": [
      "self"
    ],
    "num_timesteps": [
      "self"
    ],
    "attention_kwargs": [
      "self"
    ],
    "current_timestep": [
      "self"
    ],
    "interrupt": [
      "self"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "QwenImageLayeredBeforeDenoisingStage": {
    "__init__": [
      "self",
      "vae",
      "tokenizer",
      "processor",
      "transformer",
      "scheduler",
      "model_path"
    ],
    "_extract_masked_hidden": [
      "self",
      "hidden_states",
      "mask"
    ],
    "get_image_caption": [
      "self",
      "prompt_image",
      "use_en_prompt",
      "device"
    ],
    "_get_qwen_prompt_embeds": [
      "self",
      "prompt",
      "device",
      "dtype"
    ],
    "_pack_latents": [
      "latents",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "layers"
    ],
    "encode_prompt": [
      "self",
      "prompt",
      "device",
      "num_images_per_prompt",
      "prompt_embeds",
      "prompt_embeds_mask",
      "max_sequence_length"
    ],
    "_encode_vae_image": [
      "self",
      "image",
      "generator"
    ],
    "prepare_latents": [
      "self",
      "image",
      "batch_size",
      "num_channels_latents",
      "height",
      "width",
      "layers",
      "dtype",
      "device",
      "generator",
      "latents"
    ],
    "forward": [
      "self",
      "batch",
      "server_args"
    ]
  },
  "repeat_kv": [
    "hidden_states",
    "n_rep"
  ],
  "MistralAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "position_embeddings",
      "attention_mask",
      "past_key_values",
      "cache_position"
    ]
  },
  "MistralDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "use_cache",
      "cache_position",
      "position_embeddings"
    ]
  },
  "Mistral3Model": {
    "_checkpoint_conversion_mapping": [],
    "__init__": [
      "self",
      "config"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "output_hidden_states",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidoutput_hidden_statesden_states",
      "return_dict",
      "cache_position",
      "image_sizes"
    ]
  },
  "TextEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "output_hidden_states"
    ],
    "supported_attention_backends": [
      "self"
    ]
  },
  "ImageEncoder": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "pixel_values"
    ],
    "supported_attention_backends": [
      "self"
    ]
  },
  "HunyuanClip": {
    "__init__": [
      "self",
      "model_dir",
      "max_length"
    ],
    "forward": [
      "self",
      "prompts",
      "with_mask"
    ]
  },
  "Qwen2_5_VLAttention": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "output_attentions",
      "use_cache",
      "cache_position",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLDecoderLayer": {
    "__init__": [
      "self",
      "config",
      "layer_idx"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "output_attentions",
      "use_cache",
      "cache_position",
      "position_embeddings"
    ]
  },
  "Qwen2_5_VLTextModel": {
    "__init__": [
      "self",
      "config"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "cache_position"
    ]
  },
  "Qwen2_5_VLModel": {
    "base_model_prefix": [],
    "_checkpoint_conversion_mapping": [],
    "accepts_loss_kwargs": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config",
      "enable_image_understanding"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "set_input_embeddings": [
      "self",
      "value"
    ],
    "set_decoder": [
      "self",
      "decoder"
    ],
    "get_decoder": [
      "self"
    ],
    "get_rope_index": [
      "self",
      "input_ids",
      "image_grid_thw",
      "video_grid_thw",
      "second_per_grid_ts",
      "attention_mask"
    ],
    "get_video_features": [
      "self",
      "pixel_values_videos",
      "video_grid_thw"
    ],
    "get_image_features": [
      "self",
      "pixel_values",
      "image_grid_thw"
    ],
    "get_placeholder_mask": [
      "self",
      "input_ids",
      "inputs_embeds",
      "image_features",
      "video_features"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "use_cache",
      "output_attentions",
      "output_hidden_states",
      "return_dict",
      "pixel_values",
      "pixel_values_videos",
      "image_grid_thw",
      "video_grid_thw",
      "rope_deltas",
      "cache_position",
      "second_per_grid_ts"
    ]
  },
  "CLIPAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "_shape": [
      "self",
      "tensor",
      "seq_len",
      "bsz"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "_C": [],
  "VisionEncoderInfo": {
    "__init__": [
      "self",
      "vision_config"
    ],
    "get_num_image_tokens": [
      "self"
    ],
    "get_max_image_tokens": [
      "self"
    ],
    "get_image_size": [
      "self"
    ],
    "get_patch_size": [
      "self"
    ],
    "get_patch_grid_length": [
      "self"
    ]
  },
  "Qwen3MLP": {
    "__init__": [
      "self",
      "hidden_size",
      "intermediate_size",
      "hidden_act",
      "quant_config",
      "bias",
      "prefix"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_seen_keys": [],
  "T5DenseActDense": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5DenseGatedActDense": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5LayerFF": {
    "__init__": [
      "self",
      "config",
      "quant_config"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "T5MultiHeadAttention": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "attn_bias"
    ]
  },
  "T5Attention": {
    "__init__": [
      "self",
      "config",
      "attn_type",
      "has_relative_attention_bias",
      "quant_config",
      "prefix"
    ],
    "_relative_position_bucket": [
      "relative_position",
      "bidirectional",
      "num_buckets",
      "max_distance"
    ],
    "compute_bias": [
      "self",
      "query_length",
      "key_length",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "attn_metadata"
    ]
  },
  "T5LayerSelfAttention": {
    "__init__": [
      "self",
      "config",
      "has_relative_attention_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "attn_metadata"
    ]
  },
  "T5LayerCrossAttention": {
    "__init__": [
      "self",
      "config",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attn_metadata"
    ]
  },
  "T5Block": {
    "__init__": [
      "self",
      "config",
      "is_decoder",
      "has_relative_attention_bias",
      "quant_config",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "attn_metadata"
    ]
  },
  "T5Stack": {
    "__init__": [
      "self",
      "config",
      "is_decoder",
      "n_layers",
      "embed_tokens",
      "quant_config",
      "prefix",
      "is_umt5"
    ],
    "forward": [
      "self",
      "input_ids",
      "attention_mask",
      "attn_metadata"
    ]
  },
  "T5EncoderModel": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "output_hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "UMT5EncoderModel": {
    "__init__": [
      "self",
      "config",
      "prefix"
    ],
    "get_input_embeddings": [
      "self"
    ],
    "forward": [
      "self",
      "input_ids",
      "position_ids",
      "attention_mask",
      "inputs_embeds",
      "output_hidden_states"
    ],
    "load_weights": [
      "self",
      "weights"
    ]
  },
  "_get_qkv_projections": [
    "attn",
    "hidden_states",
    "encoder_hidden_states"
  ],
  "FluxAttention": {
    "__init__": [
      "self",
      "query_dim",
      "num_heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "context_pre_only",
      "pre_only"
    ],
    "forward": [
      "self",
      "x",
      "encoder_hidden_states",
      "freqs_cis"
    ]
  },
  "FluxSingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "freqs_cis",
      "joint_attention_kwargs"
    ]
  },
  "FluxTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "freqs_cis",
      "joint_attention_kwargs"
    ]
  },
  "FluxPosEmbed": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "FluxTransformer2DModel": {
    "param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "pooled_projections",
      "timestep",
      "guidance",
      "freqs_cis",
      "joint_attention_kwargs"
    ]
  },
  "QwenTimestepProjEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "use_additional_t_cond"
    ],
    "forward": [
      "self",
      "timestep",
      "hidden_states",
      "addition_t_cond"
    ]
  },
  "QwenEmbedRope": {
    "__init__": [
      "self",
      "theta",
      "axes_dim",
      "scale_rope"
    ],
    "rope_params": [
      "self",
      "index",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "video_fhw",
      "txt_seq_lens",
      "device"
    ],
    "_compute_video_freqs": [
      "self",
      "frame",
      "height",
      "width",
      "idx"
    ]
  },
  "QwenEmbedLayer3DRope": {
    "__init__": [
      "self",
      "theta",
      "axes_dim",
      "scale_rope"
    ],
    "rope_params": [
      "self",
      "index",
      "dim",
      "theta"
    ],
    "forward": [
      "self",
      "video_fhw",
      "txt_seq_lens",
      "device"
    ],
    "_compute_video_freqs": [
      "self",
      "frame",
      "height",
      "width",
      "idx"
    ],
    "_compute_condition_freqs": [
      "self",
      "frame",
      "height",
      "width"
    ]
  },
  "QwenImageCrossAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "head_dim",
      "window_size",
      "added_kv_proj_dim",
      "out_bias",
      "qk_norm",
      "eps",
      "pre_only",
      "context_pre_only",
      "parallel_attention",
      "out_dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "image_rotary_emb"
    ]
  },
  "QwenImageTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "qk_norm",
      "eps",
      "zero_cond_t"
    ],
    "_modulate": [
      "self",
      "x",
      "mod_params",
      "index"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "encoder_hidden_states_mask",
      "temb_img_silu",
      "temb_txt_silu",
      "image_rotary_emb",
      "joint_attention_kwargs",
      "modulate_index"
    ]
  },
  "to_hashable": [
    "obj"
  ],
  "QwenImageTransformer2DModel": {
    "_supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "_skip_layerwise_casting_patterns": [],
    "_repeated_blocks": [],
    "param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "build_modulate_index": [
      "self",
      "img_shapes",
      "device"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "encoder_hidden_states_mask",
      "timestep",
      "img_shapes",
      "txt_seq_lens",
      "freqs_cis",
      "additional_t_cond",
      "guidance",
      "attention_kwargs",
      "controlnet_block_samples",
      "return_dict"
    ]
  },
  "BaseDiT": {
    "__init_subclass__": [
      "cls"
    ],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "encoder_hidden_states_image",
      "guidance"
    ],
    "__post_init__": [
      "self"
    ],
    "supported_attention_backends": [
      "self"
    ],
    "device": [
      "self"
    ]
  },
  "CachableDiT": {
    "_fsdp_shard_conditions": [],
    "param_names_mapping": [],
    "reverse_param_names_mapping": [],
    "__init__": [
      "self",
      "config"
    ]
  },
  "WanImageEmbedding": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "encoder_hidden_states_image"
    ]
  },
  "WanTimeTextImageEmbedding": {
    "__init__": [
      "self",
      "dim",
      "time_freq_dim",
      "text_embed_dim",
      "image_embed_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "encoder_hidden_states",
      "encoder_hidden_states_image",
      "timestep_seq_len"
    ]
  },
  "WanSelfAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "window_size",
      "qk_norm",
      "eps",
      "parallel_attention",
      "supported_attention_backends"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "context_lens"
    ]
  },
  "WanT2VCrossAttention": {
    "forward": [
      "self",
      "x",
      "context",
      "context_lens"
    ]
  },
  "WanI2VCrossAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "window_size",
      "qk_norm",
      "eps",
      "supported_attention_backends"
    ],
    "forward": [
      "self",
      "x",
      "context",
      "context_lens"
    ]
  },
  "WanTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "ffn_dim",
      "num_heads",
      "qk_norm",
      "cross_attn_norm",
      "eps",
      "added_kv_proj_dim",
      "supported_attention_backends",
      "prefix",
      "attention_type",
      "sla_topk"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "freqs_cis"
    ]
  },
  "WanTransformerBlock_VSA": {
    "__init__": [
      "self",
      "dim",
      "ffn_dim",
      "num_heads",
      "qk_norm",
      "cross_attn_norm",
      "eps",
      "added_kv_proj_dim",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "freqs_cis"
    ]
  },
  "WanTransformer3DModel": {
    "_fsdp_shard_conditions": [],
    "_compile_conditions": [],
    "_supported_attention_backends": [],
    "param_names_mapping": [],
    "reverse_param_names_mapping": [],
    "lora_param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "encoder_hidden_states_image",
      "guidance"
    ],
    "maybe_cache_states": [
      "self",
      "hidden_states",
      "original_hidden_states"
    ],
    "should_skip_forward_for_cached_states": [
      "self"
    ],
    "retrieve_cached_states": [
      "self",
      "hidden_states"
    ]
  },
  "GlmImageLayerKVCache": {
    "__init__": [
      "self"
    ],
    "store": [
      "self",
      "k",
      "v"
    ],
    "get": [
      "self"
    ],
    "clear": [
      "self"
    ]
  },
  "GlmImageKVCache": {
    "__init__": [
      "self",
      "num_layers"
    ],
    "__getitem__": [
      "self",
      "layer_idx"
    ],
    "set_mode": [
      "self",
      "mode"
    ],
    "clear": [
      "self"
    ]
  },
  "GlmImageTimestepEmbedding": {
    "__init__": [
      "self",
      "in_channels",
      "time_embed_dim",
      "act_fn",
      "out_dim"
    ],
    "forward": [
      "self",
      "sample"
    ]
  },
  "GlmImageTextProjection": {
    "__init__": [
      "self",
      "in_features",
      "hidden_size",
      "out_features",
      "act_fn"
    ],
    "forward": [
      "self",
      "caption"
    ]
  },
  "GlmImageCombinedTimestepSizeEmbeddings": {
    "__init__": [
      "self",
      "embedding_dim",
      "condition_dim",
      "pooled_projection_dim",
      "timesteps_dim"
    ],
    "forward": [
      "self",
      "timestep",
      "target_size",
      "crop_coords",
      "hidden_dtype"
    ]
  },
  "GlmImageImageProjector": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_size",
      "patch_size"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GlmImageAdaLayerNormZero": {
    "__init__": [
      "self",
      "embedding_dim",
      "dim"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb"
    ]
  },
  "GlmImageAttention": {
    "__init__": [
      "self",
      "query_dim",
      "heads",
      "dim_head",
      "out_dim",
      "bias",
      "qk_norm",
      "elementwise_affine",
      "eps",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "attention_mask",
      "image_rotary_emb",
      "kv_cache"
    ]
  },
  "GlmImageTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "time_embed_dim",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "image_rotary_emb",
      "attention_mask",
      "attention_kwargs",
      "kv_cache"
    ]
  },
  "GlmImageRotaryPosEmbed": {
    "__init__": [
      "self",
      "dim",
      "patch_size",
      "theta"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "GlmImageAdaLayerNormContinuous": {
    "__init__": [
      "self",
      "embedding_dim",
      "conditioning_embedding_dim",
      "elementwise_affine",
      "eps",
      "bias",
      "norm_type"
    ],
    "forward": [
      "self",
      "x",
      "conditioning_embedding"
    ]
  },
  "GlmImageTransformer2DModel": {
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "prior_token_id",
      "prior_token_drop",
      "timestep",
      "target_size",
      "crop_coords",
      "attention_kwargs",
      "attention_mask",
      "kv_caches",
      "kv_caches_mode",
      "freqs_cis",
      "guidance"
    ]
  },
  "Flux2SwiGLU": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Flux2FeedForward": {
    "__init__": [
      "self",
      "dim",
      "dim_out",
      "mult",
      "inner_dim",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Flux2Attention": {
    "__init__": [
      "self",
      "query_dim",
      "num_heads",
      "dim_head",
      "dropout",
      "bias",
      "added_kv_proj_dim",
      "added_proj_bias",
      "out_bias",
      "eps",
      "out_dim",
      "elementwise_affine"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "freqs_cis"
    ]
  },
  "Flux2ParallelSelfAttention": {
    "_supports_qkv_fusion": [],
    "__init__": [
      "self",
      "query_dim",
      "num_heads",
      "dim_head",
      "dropout",
      "bias",
      "out_bias",
      "eps",
      "out_dim",
      "elementwise_affine",
      "mlp_ratio",
      "mlp_mult_factor"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask",
      "freqs_cis"
    ]
  },
  "Flux2SingleTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb_mod_params",
      "freqs_cis",
      "joint_attention_kwargs",
      "split_hidden_states",
      "text_seq_len"
    ]
  },
  "Flux2TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_attention_heads",
      "attention_head_dim",
      "mlp_ratio",
      "eps",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb_mod_params_img",
      "temb_mod_params_txt",
      "freqs_cis",
      "joint_attention_kwargs"
    ]
  },
  "Flux2TimestepGuidanceEmbeddings": {
    "__init__": [
      "self",
      "in_channels",
      "embedding_dim",
      "bias",
      "guidance_embeds"
    ],
    "forward": [
      "self",
      "timestep",
      "guidance"
    ]
  },
  "Flux2Modulation": {
    "__init__": [
      "self",
      "dim",
      "mod_param_sets",
      "bias"
    ],
    "forward": [
      "self",
      "temb"
    ]
  },
  "Flux2PosEmbed": {
    "__init__": [
      "self",
      "theta",
      "axes_dim"
    ],
    "forward": [
      "self",
      "ids"
    ]
  },
  "Flux2Transformer2DModel": {
    "param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "guidance",
      "freqs_cis",
      "joint_attention_kwargs"
    ]
  },
  "ADALN_EMBED_DIM": [],
  "SEQ_MULTI_OF": [],
  "SelectFirstElement": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ZImageAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "num_kv_heads",
      "qk_norm",
      "eps"
    ],
    "forward": [
      "self",
      "hidden_states",
      "freqs_cis"
    ]
  },
  "ZImageTransformerBlock": {
    "__init__": [
      "self",
      "layer_id",
      "dim",
      "n_heads",
      "n_kv_heads",
      "norm_eps",
      "qk_norm",
      "modulation"
    ],
    "forward": [
      "self",
      "x",
      "freqs_cis",
      "adaln_input"
    ]
  },
  "FinalLayer": {
    "__init__": [
      "self",
      "hidden_size",
      "out_channels"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "RopeEmbedder": {
    "__init__": [
      "self",
      "theta",
      "axes_dims",
      "axes_lens"
    ],
    "precompute_freqs": [
      "dim",
      "end",
      "theta"
    ],
    "__call__": [
      "self",
      "ids"
    ]
  },
  "ZImageTransformer2DModel": {
    "_supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "param_names_mapping": [],
    "reverse_param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "unpatchify": [
      "self",
      "x",
      "size",
      "patch_size",
      "f_patch_size"
    ],
    "create_coordinate_grid": [
      "size",
      "start",
      "device"
    ],
    "patchify_and_embed": [
      "self",
      "all_image",
      "all_cap_feats",
      "patch_size",
      "f_patch_size"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "guidance",
      "patch_size",
      "f_patch_size",
      "freqs_cis"
    ]
  },
  "flex_attention": [],
  "CausalWanSelfAttention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "local_attn_size",
      "sink_size",
      "qk_norm",
      "eps",
      "parallel_attention"
    ],
    "forward": [
      "self",
      "q",
      "k",
      "v",
      "freqs_cis",
      "block_mask",
      "kv_cache",
      "current_start",
      "cache_start"
    ]
  },
  "CausalWanTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "ffn_dim",
      "num_heads",
      "local_attn_size",
      "sink_size",
      "qk_norm",
      "cross_attn_norm",
      "eps",
      "added_kv_proj_dim",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "temb",
      "freqs_cis",
      "block_mask",
      "kv_cache",
      "crossattn_cache",
      "current_start",
      "cache_start"
    ]
  },
  "CausalWanTransformer3DModel": {
    "_fsdp_shard_conditions": [],
    "_compile_conditions": [],
    "_supported_attention_backends": [],
    "param_names_mapping": [],
    "reverse_param_names_mapping": [],
    "lora_param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "_prepare_blockwise_causal_attn_mask": [
      "device",
      "num_frames",
      "frame_seqlen",
      "num_frame_per_block",
      "local_attn_size"
    ],
    "_forward_inference": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "encoder_hidden_states_image",
      "kv_cache",
      "crossattn_cache",
      "current_start",
      "cache_start",
      "start_frame"
    ],
    "_forward_train": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "encoder_hidden_states_image",
      "start_frame"
    ],
    "forward": [
      "self"
    ]
  },
  "MMDoubleStreamBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "mlp_ratio",
      "dtype",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "img",
      "txt",
      "vec",
      "freqs_cis"
    ]
  },
  "MMSingleStreamBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "mlp_ratio",
      "dtype",
      "supported_attention_backends",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "vec",
      "txt_len",
      "freqs_cis"
    ]
  },
  "HunyuanVideoTransformer3DModel": {
    "_fsdp_shard_conditions": [],
    "_compile_conditions": [],
    "_supported_attention_backends": [],
    "param_names_mapping": [],
    "reverse_param_names_mapping": [],
    "lora_param_names_mapping": [],
    "__init__": [
      "self",
      "config",
      "hf_config"
    ],
    "forward": [
      "self",
      "hidden_states",
      "encoder_hidden_states",
      "timestep",
      "encoder_hidden_states_image",
      "guidance"
    ],
    "maybe_cache_states": [
      "self",
      "hidden_states",
      "original_hidden_states"
    ],
    "should_skip_forward_for_cached_states": [
      "self"
    ],
    "retrieve_cached_states": [
      "self",
      "hidden_states"
    ]
  },
  "SingleTokenRefiner": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_size",
      "num_attention_heads",
      "depth",
      "qkv_bias",
      "dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "t"
    ]
  },
  "IndividualTokenRefinerBlock": {
    "__init__": [
      "self",
      "hidden_size",
      "num_attention_heads",
      "mlp_ratio",
      "qkv_bias",
      "dtype",
      "prefix"
    ],
    "forward": [
      "self",
      "x",
      "c"
    ]
  },
  "CACHE_T": [],
  "is_first_frame": [],
  "feat_cache": [],
  "feat_idx": [],
  "first_chunk": [],
  "forward_context": [
    "first_frame_arg",
    "feat_cache_arg",
    "feat_idx_arg",
    "first_chunk_arg"
  ],
  "AvgDown3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "factor_t",
      "factor_s"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DupUp3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "factor_t",
      "factor_s"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x",
      "cache_x"
    ]
  },
  "WanRMS_norm": {
    "__init__": [
      "self",
      "dim",
      "channel_first",
      "images",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanUpsample": {
    "forward": [
      "self",
      "x"
    ]
  },
  "WanResample": {
    "__init__": [
      "self",
      "dim",
      "mode",
      "upsample_out_dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanResidualBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanAttentionBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanMidBlock": {
    "__init__": [
      "self",
      "dim",
      "dropout",
      "non_linearity",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanResidualDownBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "num_res_blocks",
      "temperal_downsample",
      "down_flag"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanEncoder3d": {
    "__init__": [
      "self",
      "in_channels",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_downsample",
      "dropout",
      "non_linearity",
      "is_residual"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanResidualUpBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "num_res_blocks",
      "dropout",
      "temperal_upsample",
      "up_flag",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanUpBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "num_res_blocks",
      "dropout",
      "upsample_mode",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WanDecoder3d": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_upsample",
      "dropout",
      "non_linearity",
      "out_channels",
      "is_residual"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "patchify": [
    "x",
    "patch_size"
  ],
  "AutoencoderKLWan": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "config"
    ],
    "clear_cache": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "_encode": [
      "self",
      "x",
      "first_frame"
    ],
    "tiled_encode": [
      "self",
      "x"
    ],
    "spatial_tiled_encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "_decode": [
      "self",
      "z",
      "first_frame"
    ],
    "tiled_decode": [
      "self",
      "z"
    ],
    "spatial_tiled_decode": [
      "self",
      "z"
    ],
    "parallel_tiled_decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "sample",
      "sample_posterior",
      "generator"
    ]
  },
  "AutoencoderKLFlux2": {
    "_supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "attn_processors": [
      "self"
    ],
    "set_attn_processor": [
      "self",
      "processor"
    ],
    "set_default_attn_processor": [
      "self"
    ],
    "_encode": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "_decode": [
      "self",
      "z",
      "return_dict"
    ],
    "decode": [
      "self",
      "z",
      "return_dict",
      "generator"
    ],
    "blend_v": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_h": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "_tiled_encode": [
      "self",
      "x"
    ],
    "tiled_encode": [
      "self",
      "x",
      "return_dict"
    ],
    "tiled_decode": [
      "self",
      "z",
      "return_dict"
    ],
    "forward": [
      "self",
      "sample",
      "sample_posterior",
      "return_dict",
      "generator"
    ]
  },
  "ParallelTiledVAE": {
    "__init__": [
      "self",
      "config"
    ],
    "device": [
      "self"
    ],
    "temporal_compression_ratio": [
      "self"
    ],
    "spatial_compression_ratio": [
      "self"
    ],
    "scaling_factor": [
      "self"
    ],
    "_encode": [
      "self"
    ],
    "_decode": [
      "self"
    ],
    "encode": [
      "self",
      "x"
    ],
    "decode": [
      "self",
      "z"
    ],
    "blend_v": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_h": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_t": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "spatial_tiled_encode": [
      "self",
      "x"
    ],
    "_parallel_data_generator": [
      "self",
      "gathered_results",
      "gathered_dim_metadata"
    ],
    "parallel_tiled_decode": [
      "self",
      "z"
    ],
    "_merge_spatial_tiles": [
      "self",
      "tiles",
      "blend_height",
      "blend_width",
      "stride_height",
      "stride_width"
    ],
    "spatial_tiled_decode": [
      "self",
      "z"
    ],
    "tiled_encode": [
      "self",
      "x"
    ],
    "tiled_decode": [
      "self",
      "z"
    ],
    "enable_tiling": [
      "self",
      "tile_sample_min_height",
      "tile_sample_min_width",
      "tile_sample_min_num_frames",
      "tile_sample_stride_height",
      "tile_sample_stride_width",
      "tile_sample_stride_num_frames",
      "blend_num_frames",
      "use_tiling",
      "use_temporal_tiling",
      "use_parallel_tiling"
    ],
    "disable_tiling": [
      "self"
    ]
  },
  "DiagonalGaussianDistribution": {
    "__init__": [
      "self",
      "parameters",
      "deterministic"
    ],
    "sample": [
      "self",
      "generator"
    ],
    "kl": [
      "self",
      "other"
    ],
    "nll": [
      "self",
      "sample",
      "dims"
    ],
    "mode": [
      "self"
    ]
  },
  "QwenImageCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding"
    ],
    "forward": [
      "self",
      "x",
      "cache_x"
    ]
  },
  "QwenImageRMS_norm": {
    "__init__": [
      "self",
      "dim",
      "channel_first",
      "images",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenImageUpsample": {
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenImageResample": {
    "__init__": [
      "self",
      "dim",
      "mode"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageResidualBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "dropout",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageAttentionBlock": {
    "__init__": [
      "self",
      "dim"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "QwenImageMidBlock": {
    "__init__": [
      "self",
      "dim",
      "dropout",
      "non_linearity",
      "num_layers"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageEncoder3d": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_downsample",
      "dropout",
      "non_linearity",
      "input_channels"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageUpBlock": {
    "__init__": [
      "self",
      "in_dim",
      "out_dim",
      "num_res_blocks",
      "dropout",
      "upsample_mode",
      "non_linearity"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "QwenImageDecoder3d": {
    "__init__": [
      "self",
      "dim",
      "z_dim",
      "dim_mult",
      "num_res_blocks",
      "attn_scales",
      "temperal_upsample",
      "dropout",
      "non_linearity",
      "input_channels"
    ],
    "forward": [
      "self",
      "x",
      "feat_cache",
      "feat_idx"
    ]
  },
  "AutoencoderKLQwenImage": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "config"
    ],
    "enable_tiling": [
      "self",
      "tile_sample_min_height",
      "tile_sample_min_width",
      "tile_sample_stride_height",
      "tile_sample_stride_width"
    ],
    "disable_tiling": [
      "self"
    ],
    "enable_slicing": [
      "self"
    ],
    "disable_slicing": [
      "self"
    ],
    "clear_cache": [
      "self"
    ],
    "_encode": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "_decode": [
      "self",
      "z",
      "return_dict"
    ],
    "decode": [
      "self",
      "z",
      "return_dict"
    ],
    "blend_v": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_h": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "tiled_encode": [
      "self",
      "x"
    ],
    "tiled_decode": [
      "self",
      "z",
      "return_dict"
    ],
    "forward": [
      "self",
      "sample",
      "sample_posterior",
      "return_dict",
      "generator"
    ]
  },
  "prepare_causal_attention_mask": [
    "num_frames",
    "height_width",
    "dtype",
    "device",
    "batch_size"
  ],
  "HunyuanVAEAttention": {
    "__init__": [
      "self",
      "in_channels",
      "heads",
      "dim_head",
      "eps",
      "norm_num_groups",
      "bias"
    ],
    "forward": [
      "self",
      "hidden_states",
      "attention_mask"
    ]
  },
  "HunyuanVideoCausalConv3d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "padding",
      "dilation",
      "bias",
      "pad_mode"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoUpsampleCausal3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "stride",
      "bias",
      "upsample_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoDownsampleCausal3D": {
    "__init__": [
      "self",
      "channels",
      "out_channels",
      "padding",
      "kernel_size",
      "bias",
      "stride"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoResnetBlockCausal3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "groups",
      "eps",
      "non_linearity"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoMidBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_attention",
      "attention_head_dim"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoDownBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_downsample",
      "downsample_stride",
      "downsample_padding"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoUpBlock3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "dropout",
      "num_layers",
      "resnet_eps",
      "resnet_act_fn",
      "resnet_groups",
      "add_upsample",
      "upsample_scale_factor"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoEncoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "double_z",
      "mid_block_add_attention",
      "temporal_compression_ratio",
      "spatial_compression_ratio"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "HunyuanVideoDecoder3D": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up_block_types",
      "block_out_channels",
      "layers_per_block",
      "norm_num_groups",
      "act_fn",
      "mid_block_add_attention",
      "time_compression_ratio",
      "spatial_compression_ratio"
    ],
    "forward": [
      "self",
      "hidden_states"
    ]
  },
  "AutoencoderKLHunyuanVideo": {
    "_supports_gradient_checkpointing": [],
    "__init__": [
      "self",
      "config"
    ],
    "_encode": [
      "self",
      "x"
    ],
    "_decode": [
      "self",
      "z"
    ],
    "forward": [
      "self",
      "sample",
      "sample_posterior",
      "generator"
    ]
  },
  "AutoencoderKL": {
    "_supports_gradient_checkpointing": [],
    "_no_split_modules": [],
    "__init__": [
      "self",
      "config"
    ],
    "enable_tiling": [
      "self",
      "use_tiling"
    ],
    "disable_tiling": [
      "self"
    ],
    "enable_slicing": [
      "self"
    ],
    "disable_slicing": [
      "self"
    ],
    "attn_processors": [
      "self"
    ],
    "set_attn_processor": [
      "self",
      "processor"
    ],
    "set_default_attn_processor": [
      "self"
    ],
    "_encode": [
      "self",
      "x"
    ],
    "encode": [
      "self",
      "x",
      "return_dict"
    ],
    "_decode": [
      "self",
      "z",
      "return_dict"
    ],
    "decode": [
      "self",
      "z"
    ],
    "blend_v": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "blend_h": [
      "self",
      "a",
      "b",
      "blend_extent"
    ],
    "_tiled_encode": [
      "self",
      "x"
    ],
    "tiled_encode": [
      "self",
      "x",
      "return_dict"
    ],
    "tiled_decode": [
      "self",
      "z",
      "return_dict"
    ],
    "forward": [
      "self",
      "sample",
      "sample_posterior",
      "generator"
    ],
    "fuse_qkv_projections": [
      "self"
    ]
  },
  "FlowMatchEulerDiscreteSchedulerOutput": {},
  "FlowMatchEulerDiscreteScheduler": {
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "shift",
      "use_dynamic_shifting",
      "base_shift",
      "max_shift",
      "base_image_seq_len",
      "max_image_seq_len",
      "invert_sigmas",
      "shift_terminal",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "time_shift_type",
      "stochastic_sampling"
    ],
    "shift": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "scale_noise": [
      "self",
      "sample",
      "timestep",
      "noise"
    ],
    "_sigma_to_t": [
      "self",
      "sigma"
    ],
    "time_shift": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "stretch_shift_to_terminal": [
      "self",
      "t"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "sigmas",
      "mu",
      "timesteps"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "s_churn",
      "s_tmin",
      "s_tmax",
      "s_noise",
      "generator",
      "per_token_timesteps",
      "return_dict"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "_time_shift_exponential": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "_time_shift_linear": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "add_noise": [
      "self",
      "clean_latent",
      "noise",
      "timestep"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "__len__": [
      "self"
    ]
  },
  "BaseScheduler": {
    "__init__": [
      "self"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "set_timesteps": [
      "self"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ]
  },
  "SelfForcingFlowMatchSchedulerOutput": {},
  "SelfForcingFlowMatchScheduler": {
    "config_name": [],
    "order": [],
    "__init__": [
      "self",
      "num_inference_steps",
      "num_train_timesteps",
      "shift",
      "sigma_max",
      "sigma_min",
      "inverse_timesteps",
      "extra_one_step",
      "reverse_sigmas"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "denoising_strength",
      "return_dict"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "to_final",
      "return_dict"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timestep"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_shift": [
      "self",
      "shift"
    ]
  },
  "ComfyUIPassThroughSchedulerOutput": {},
  "ComfyUIPassThroughScheduler": {
    "config_name": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "timesteps",
      "device"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample",
      "timestep"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "begin_index": [
      "self"
    ],
    "step_index": [
      "self"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timestep"
    ]
  },
  "FlowUniPCMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "solver_order",
      "prediction_type",
      "shift",
      "use_dynamic_shifting",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "predict_x0",
      "solver_type",
      "lower_order_final",
      "disable_corrector",
      "solver_p",
      "timestep_spacing",
      "steps_offset",
      "final_sigmas_type"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "sigmas",
      "mu",
      "shift"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "time_shift": [
      "self",
      "mu",
      "sigma",
      "t"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "multistep_uni_p_bh_update": [
      "self",
      "model_output"
    ],
    "multistep_uni_c_bh_update": [
      "self",
      "this_model_output"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict",
      "generator"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ]
  },
  "betas_for_alpha_bar": [
    "num_diffusion_timesteps",
    "max_beta",
    "alpha_transform_type"
  ],
  "rescale_zero_terminal_snr": [
    "betas"
  ],
  "UniPCMultistepScheduler": {
    "_compatibles": [],
    "order": [],
    "__init__": [
      "self",
      "num_train_timesteps",
      "beta_start",
      "beta_end",
      "beta_schedule",
      "trained_betas",
      "solver_order",
      "prediction_type",
      "thresholding",
      "dynamic_thresholding_ratio",
      "sample_max_value",
      "predict_x0",
      "solver_type",
      "lower_order_final",
      "disable_corrector",
      "solver_p",
      "use_karras_sigmas",
      "use_exponential_sigmas",
      "use_beta_sigmas",
      "use_flow_sigmas",
      "flow_shift",
      "timestep_spacing",
      "steps_offset",
      "final_sigmas_type",
      "rescale_betas_zero_snr",
      "use_dynamic_shifting",
      "time_shift_type"
    ],
    "step_index": [
      "self"
    ],
    "begin_index": [
      "self"
    ],
    "set_shift": [
      "self",
      "shift"
    ],
    "set_begin_index": [
      "self",
      "begin_index"
    ],
    "set_timesteps": [
      "self",
      "num_inference_steps",
      "device",
      "mu"
    ],
    "_threshold_sample": [
      "self",
      "sample"
    ],
    "_sigma_to_t": [
      "self",
      "sigma",
      "log_sigmas"
    ],
    "_sigma_to_alpha_sigma_t": [
      "self",
      "sigma"
    ],
    "_convert_to_karras": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_exponential": [
      "self",
      "in_sigmas",
      "num_inference_steps"
    ],
    "_convert_to_beta": [
      "self",
      "in_sigmas",
      "num_inference_steps",
      "alpha",
      "beta"
    ],
    "convert_model_output": [
      "self",
      "model_output"
    ],
    "multistep_uni_p_bh_update": [
      "self",
      "model_output"
    ],
    "multistep_uni_c_bh_update": [
      "self",
      "this_model_output"
    ],
    "index_for_timestep": [
      "self",
      "timestep",
      "schedule_timesteps"
    ],
    "_init_step_index": [
      "self",
      "timestep"
    ],
    "step": [
      "self",
      "model_output",
      "timestep",
      "sample",
      "return_dict"
    ],
    "scale_model_input": [
      "self",
      "sample"
    ],
    "add_noise": [
      "self",
      "original_samples",
      "noise",
      "timesteps"
    ],
    "__len__": [
      "self"
    ]
  },
  "align": [
    "x",
    "y"
  ],
  "per_block_quant_fp8": [
    "x"
  ],
  "per_token_group_quant_mxfp8": [
    "x"
  ],
  "per_block_quant_mxfp8": [
    "x"
  ],
  "native_w8a8_block_fp8_matmul": [
    "A",
    "B",
    "As",
    "Bs",
    "block_size",
    "output_dtype"
  ],
  "TestDeepGemmBlackwell": {
    "setUpClass": [
      "cls"
    ],
    "_test_deep_gemm_blackwell": [
      "self",
      "M",
      "NK",
      "block_size",
      "out_dtype",
      "seed"
    ],
    "test_deep_gemm_blackwell": [
      "self"
    ]
  },
  "subject2category": [],
  "MMLUEval": {
    "__init__": [
      "self",
      "filename",
      "num_examples",
      "num_threads"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "GSM8K_URL": [],
  "INVALID": [],
  "get_one_example": [
    "lines",
    "i",
    "include_answer"
  ],
  "get_few_shot_examples": [
    "lines",
    "k"
  ],
  "get_answer_value": [
    "answer_str"
  ],
  "GSM8KEval": {
    "__init__": [
      "self",
      "num_examples",
      "num_threads",
      "num_shots",
      "data_path"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "_load_auth_module": [],
  "_auth": [],
  "TestHttpServerAdminAuth": {
    "_decide": [
      "self"
    ],
    "test_no_keys_configured": [
      "self"
    ],
    "test_api_key_only": [
      "self"
    ],
    "test_admin_api_key_only": [
      "self"
    ],
    "test_with_both_api_keys": [
      "self"
    ],
    "test_options_is_always_allowed": [
      "self"
    ],
    "test_health_and_metrics_are_always_allowed": [
      "self"
    ]
  },
  "test_few_shot_qa": [],
  "test_mt_bench": [],
  "test_select": [
    "check_answer"
  ],
  "test_decode_int": [],
  "test_decode_json_regex": [],
  "test_decode_json": [],
  "test_expert_answer": [
    "check_answer"
  ],
  "test_tool_use": [],
  "test_react": [],
  "test_parallel_decoding": [],
  "test_parallel_encoding": [
    "check_answer"
  ],
  "test_image_qa": [],
  "test_stream": [],
  "test_regex": [],
  "test_dtype_gen": [],
  "test_completion_speculative": [],
  "test_chat_completion_speculative": [],
  "test_hellaswag_select": [],
  "test_gen_min_new_tokens": [],
  "evaluate_functional_correctness": [
    "sample",
    "completions",
    "n_workers",
    "timeout"
  ],
  "HumanEval": {
    "__init__": [
      "self",
      "num_examples",
      "num_threads",
      "num_samples_per_task",
      "ks_passes",
      "timeout"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "IMAGE_MAN_IRONING_URL": [],
  "IMAGE_SGL_LOGO_URL": [],
  "VIDEO_JOBS_URL": [],
  "AUDIO_TRUMP_SPEECH_URL": [],
  "AUDIO_BIRD_SONG_URL": [],
  "TestOpenAIMLLMServerBase": {
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ],
    "get_vision_request_kwargs": [
      "self"
    ],
    "get_request_kwargs": [
      "self"
    ],
    "get_or_download_file": [
      "self",
      "url"
    ]
  },
  "AudioOpenAITestMixin": {
    "verify_speech_recognition_response": [
      "self",
      "text"
    ],
    "prepare_audio_messages": [
      "self",
      "prompt",
      "audio_file_name"
    ],
    "get_audio_request_kwargs": [
      "self"
    ],
    "get_audio_response": [
      "self",
      "url",
      "prompt",
      "category"
    ],
    "test_audio_speech_completion": [
      "self"
    ],
    "test_audio_ambient_completion": [
      "self"
    ]
  },
  "ImageOpenAITestMixin": {
    "run_decode_with_image": [
      "self",
      "image_id"
    ],
    "test_mixed_batch": [
      "self"
    ],
    "verify_single_image_response": [
      "self",
      "response"
    ],
    "test_single_image_chat_completion": [
      "self"
    ],
    "test_multi_turn_chat_completion": [
      "self"
    ],
    "test_multi_images_chat_completion": [
      "self"
    ],
    "prepare_video_images_messages": [
      "self",
      "video_path"
    ],
    "test_video_images_chat_completion": [
      "self"
    ]
  },
  "VideoOpenAITestMixin": {
    "prepare_video_messages": [
      "self",
      "video_path"
    ],
    "test_video_chat_completion": [
      "self"
    ]
  },
  "OmniOpenAITestMixin": {
    "test_mixed_modality_chat_completion": [
      "self"
    ]
  },
  "OPENAI_SYSTEM_MESSAGE_API": [],
  "OPENAI_SYSTEM_MESSAGE_CHATGPT": [],
  "Message": [],
  "MessageList": [],
  "SamplerBase": {
    "__call__": [
      "self",
      "message_list"
    ]
  },
  "EvalResult": {},
  "SingleEvalResult": {},
  "Eval": {
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "LargerHttpxClient": {
    "__init__": [
      "self"
    ]
  },
  "ChatCompletionSampler": {
    "__init__": [
      "self",
      "base_url",
      "model",
      "system_message",
      "temperature",
      "top_p",
      "reasoning_effort",
      "max_tokens",
      "extra_body"
    ],
    "_handle_image": [
      "self",
      "image",
      "encoding",
      "format",
      "fovea"
    ],
    "_handle_text": [
      "self",
      "text"
    ],
    "_pack_message": [
      "self",
      "role",
      "content"
    ],
    "__call__": [
      "self",
      "message_list"
    ]
  },
  "QUERY_TEMPLATE_MULTICHOICE": [],
  "ANSWER_PATTERN_MULTICHOICE": [],
  "ANSWER_PATTERN": [],
  "EQUALITY_TEMPLATE": [],
  "HTML_JINJA": [],
  "format_multichoice_question": [
    "row"
  ],
  "check_equality": [
    "sampler",
    "expr1",
    "expr2"
  ],
  "_compute_stat": [
    "values",
    "stat"
  ],
  "aggregate_results": [
    "single_eval_results",
    "default_stats",
    "name2stats"
  ],
  "map_with_progress": [
    "f",
    "xs",
    "num_threads"
  ],
  "jinja_env": [],
  "_message_template": [],
  "message_to_html": [
    "message"
  ],
  "_report_template": [],
  "make_report": [
    "eval_result"
  ],
  "make_report_from_example_htmls": [
    "htmls"
  ],
  "download_dataset": [
    "path",
    "url"
  ],
  "MNK_FACTORS": [],
  "torch_moe_reference": [
    "a",
    "w13",
    "w2",
    "score",
    "topk"
  ],
  "test_flashinfer_bf16_cutlass_moe": [
    "m",
    "n",
    "k",
    "e",
    "topk"
  ],
  "get_thinking_kwargs": [
    "args"
  ],
  "run_eval_once": [
    "args",
    "base_url",
    "eval_obj"
  ],
  "run_eval": [
    "args"
  ],
  "THINKING_MODE_CHOICES": [],
  "BenchmarkResult": {
    "help_str": [],
    "to_markdown_row": [
      "self",
      "trace_dir",
      "base_url",
      "relay_base"
    ]
  },
  "generate_markdown_report": [
    "trace_dir",
    "results",
    "variant"
  ],
  "save_results_as_pydantic_models": [
    "results",
    "pydantic_result_filename",
    "model_path"
  ],
  "DEFAULT_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_SMALL_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_SMALL_MODEL_NAME_FOR_TEST_BASE": [],
  "DEFAULT_SMALL_MODEL_NAME_FOR_TEST_SCORE": [],
  "DEFAULT_MOE_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_SMALL_MOE_MODEL_NAME_FOR_TEST_BASE": [],
  "DEFAULT_SMALL_MOE_MODEL_NAME_FOR_TEST_CHAT": [],
  "DEFAULT_SMALL_EMBEDDING_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_SMALL_CROSS_ENCODER_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_MLA_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_MLA_FP8_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_MLA": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_MLA_NEXTN": [],
  "DEFAULT_HYBRID_MAMBA_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_VL_PP": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_GLM_41V_PP": [],
  "DEFAULT_DEEPSEEK_NVFP4_MODEL_FOR_TEST": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_MOE_NVFP4": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_FP8": [],
  "DEFAULT_MODEL_NAME_FOR_ACCURACY_TEST_FP8": [],
  "DEFAULT_MODEL_NAME_FOR_DYNAMIC_QUANT_ACCURACY_TEST_FP8": [],
  "DEFAULT_MODEL_NAME_FOR_MODELOPT_QUANT_ACCURACY_TEST_FP8": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_QWEN_FP8": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_FP8_WITH_MOE": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_MXFP4_WITH_MOE": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_W8A8": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_W8A8_WITH_MOE": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_AWQ_INT4": [],
  "DEFAULT_TARGET_MODEL_EAGLE": [],
  "DEFAULT_DRAFT_MODEL_EAGLE": [],
  "DEFAULT_TARGET_MODEL_EAGLE3": [],
  "DEFAULT_DRAFT_MODEL_EAGLE3": [],
  "DEFAULT_TARGET_MODEL_EAGLE_DP_ATTN": [],
  "DEFAULT_DRAFT_MODEL_EAGLE_DP_ATTN": [],
  "DEFAULT_TARGET_MODEL_STANDALONE": [],
  "DEFAULT_DRAFT_MODEL_STANDALONE": [],
  "DEFAULT_TARGET_MODEL_NGRAM": [],
  "DEFAULT_AUTOROUND_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_MODEL_NAME_FOR_TEST_LOCAL_ATTENTION": [],
  "DEFAULT_REASONING_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_DEEPEP_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_AWQ_MOE_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_ENABLE_THINKING_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_DEEPSEEK_W4AFP8_MODEL_FOR_TEST": [],
  "DEFAULT_ENABLE_ROUTED_EXPERTS_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_MODEL_NAME_FOR_NIGHTLY_EVAL_TP1": [],
  "DEFAULT_MODEL_NAME_FOR_NIGHTLY_EVAL_TP2": [],
  "DEFAULT_MODEL_NAME_FOR_NIGHTLY_EVAL_FP8_TP1": [],
  "DEFAULT_MODEL_NAME_FOR_NIGHTLY_EVAL_FP8_TP2": [],
  "DEFAULT_MODEL_NAME_FOR_NIGHTLY_EVAL_QUANT_TP1": [],
  "DEFAULT_SMALL_MODEL_NAME_FOR_TEST_QWEN": [],
  "DEFAULT_SMALL_VLM_MODEL_NAME_FOR_TEST": [],
  "DEFAULT_IMAGE_URL": [],
  "DEFAULT_VIDEO_URL": [],
  "DEFAULT_TIMEOUT_FOR_SERVER_LAUNCH": [],
  "download_image_with_retry": [
    "image_url",
    "max_retries"
  ],
  "is_in_amd_ci": [],
  "is_blackwell_system": [],
  "is_h200_system": [],
  "_use_cached_default_models": [
    "model_repo"
  ],
  "DEFAULT_URL_FOR_TEST": [],
  "call_generate_lightllm": [
    "prompt",
    "temperature",
    "max_tokens",
    "stop",
    "url"
  ],
  "find_available_port": [
    "base_port"
  ],
  "call_generate_vllm": [
    "prompt",
    "temperature",
    "max_tokens",
    "stop",
    "n",
    "url"
  ],
  "call_generate_outlines": [
    "prompt",
    "temperature",
    "max_tokens",
    "stop",
    "regex",
    "n",
    "url"
  ],
  "call_generate_srt_raw": [
    "prompt",
    "temperature",
    "max_tokens",
    "stop",
    "url"
  ],
  "call_generate_guidance": [
    "prompt",
    "temperature",
    "max_tokens",
    "stop",
    "n",
    "regex",
    "model"
  ],
  "call_select_lightllm": [
    "context",
    "choices",
    "url"
  ],
  "call_select_vllm": [
    "context",
    "choices",
    "url"
  ],
  "call_select_guidance": [
    "context",
    "choices",
    "model"
  ],
  "add_common_other_args_and_parse": [
    "parser"
  ],
  "auto_config_device": [],
  "add_common_sglang_args_and_parse": [
    "parser"
  ],
  "select_sglang_backend": [
    "args"
  ],
  "_get_call_generate": [
    "args"
  ],
  "_get_call_select": [
    "args"
  ],
  "get_call_generate": [
    "args"
  ],
  "get_call_select": [
    "args"
  ],
  "_get_default_models": [],
  "try_cached_model": [
    "model_repo"
  ],
  "popen_with_error_check": [
    "command",
    "allow_exit"
  ],
  "_try_enable_offline_mode_if_cache_complete": [
    "model_name_or_path",
    "env",
    "other_args"
  ],
  "_create_clean_subprocess_env": [
    "env"
  ],
  "_launch_server_process": [
    "command",
    "env",
    "return_stdout_stderr",
    "model"
  ],
  "_wait_for_server_health": [
    "proc",
    "base_url",
    "api_key",
    "timeout_duration"
  ],
  "popen_launch_server": [
    "model",
    "base_url",
    "timeout",
    "api_key",
    "other_args",
    "env",
    "return_stdout_stderr",
    "device",
    "pd_separated",
    "num_replicas"
  ],
  "popen_launch_pd_server": [
    "model",
    "base_url",
    "timeout",
    "api_key",
    "other_args",
    "env"
  ],
  "get_similarities": [
    "vec1",
    "vec2"
  ],
  "get_benchmark_args": [
    "base_url",
    "backend",
    "dataset_name",
    "dataset_path",
    "tokenizer",
    "num_prompts",
    "sharegpt_output_len",
    "random_input_len",
    "random_output_len",
    "sharegpt_context_len",
    "request_rate",
    "disable_stream",
    "disable_ignore_eos",
    "seed",
    "device",
    "pd_separated",
    "lora_name",
    "lora_request_distribution",
    "lora_zipf_alpha",
    "gsp_num_groups",
    "gsp_prompts_per_group",
    "gsp_system_prompt_len",
    "gsp_question_len",
    "gsp_output_len",
    "gsp_num_turns",
    "header"
  ],
  "run_bench_serving": [
    "model",
    "num_prompts",
    "request_rate",
    "other_server_args",
    "dataset_name",
    "dataset_path",
    "tokenizer",
    "random_input_len",
    "random_output_len",
    "sharegpt_context_len",
    "disable_stream",
    "disable_ignore_eos",
    "need_warmup",
    "seed",
    "device",
    "background_task",
    "lora_name"
  ],
  "_run_api_benchmark_requests": [
    "base_url",
    "endpoint",
    "test_requests",
    "num_requests",
    "response_validator"
  ],
  "run_score_benchmark": [
    "model",
    "num_requests",
    "batch_size",
    "other_server_args",
    "need_warmup",
    "device"
  ],
  "run_embeddings_benchmark": [
    "model",
    "num_requests",
    "batch_size",
    "input_tokens",
    "other_server_args",
    "need_warmup",
    "device"
  ],
  "run_bench_serving_multi": [
    "model",
    "base_url",
    "other_server_args",
    "benchmark_args",
    "need_warmup",
    "pd_separated"
  ],
  "run_bench_one_batch": [
    "model",
    "other_args"
  ],
  "run_bench_offline_throughput": [
    "model",
    "other_args"
  ],
  "run_bench_one_batch_server": [
    "model",
    "base_url",
    "server_args",
    "bench_args",
    "other_server_args",
    "simulate_spec_acc_lens"
  ],
  "lcs": [
    "X",
    "Y"
  ],
  "calculate_rouge_l": [
    "output_strs_list1",
    "output_strs_list2"
  ],
  "STDERR_FILENAME": [],
  "STDOUT_FILENAME": [],
  "read_output": [
    "output_lines",
    "filename"
  ],
  "run_and_check_memory_leak": [
    "workload_func",
    "disable_radix_cache",
    "enable_mixed_chunk",
    "disable_overlap",
    "chunked_prefill_size",
    "assert_has_abort"
  ],
  "run_command_and_capture_output": [
    "command",
    "env"
  ],
  "run_mmlu_test": [
    "disable_radix_cache",
    "enable_mixed_chunk",
    "disable_overlap",
    "chunked_prefill_size"
  ],
  "run_mulit_request_test": [
    "disable_radix_cache",
    "enable_mixed_chunk",
    "enable_overlap",
    "chunked_prefill_size"
  ],
  "write_github_step_summary": [
    "content"
  ],
  "run_logprob_check": [
    "self",
    "arg"
  ],
  "send_generate_requests": [
    "base_url",
    "num_requests"
  ],
  "send_concurrent_generate_requests": [
    "base_url",
    "num_requests"
  ],
  "send_concurrent_generate_requests_with_custom_params": [
    "base_url",
    "custom_params"
  ],
  "CustomTestCase": {
    "_callTestMethod": [
      "self",
      "method"
    ],
    "setUp": [
      "self"
    ]
  },
  "dump_bench_raw_result": [
    "path",
    "states",
    "preds",
    "labels"
  ],
  "_ensure_remove_suffix": [
    "text",
    "suffix"
  ],
  "ModelLaunchSettings": {
    "__init__": [
      "self",
      "model_path",
      "tp_size",
      "extra_args",
      "env",
      "variant"
    ]
  },
  "ModelEvalMetrics": {
    "__init__": [
      "self",
      "accuracy",
      "eval_time"
    ]
  },
  "extract_trace_link_from_bench_one_batch_server_output": [
    "output"
  ],
  "parse_models": [
    "model_string"
  ],
  "check_evaluation_test_results": [
    "results",
    "test_name",
    "model_accuracy_thresholds",
    "model_latency_thresholds",
    "model_count"
  ],
  "_parse_int_list_env": [
    "name",
    "default_val"
  ],
  "find_traces_under_path": [
    "path"
  ],
  "write_results_to_json": [
    "model",
    "metrics",
    "mode"
  ],
  "intel_amx_benchmark": [
    "extra_args",
    "min_throughput"
  ],
  "run_doctests": [
    "obj"
  ],
  "dump_metric": [
    "metric_name",
    "value",
    "labels"
  ],
  "_get_test_context": [],
  "_repo_relative_path": [
    "filepath"
  ],
  "PROMPT_1": [],
  "PROMPT_2": [],
  "dirpath": [],
  "send_single": [
    "args",
    "profile",
    "profile_steps",
    "profile_by_stage",
    "return_full_response",
    "input_ids",
    "prompt",
    "max_new_tokens",
    "extra_params",
    "pick_first_result"
  ],
  "send_prefix": [
    "args",
    "batch_size",
    "prompts",
    "return_full_response"
  ],
  "compare_logprobs": [
    "logprobs1",
    "logprobs2",
    "tolerance"
  ],
  "_test_mode_p_vs_d": [
    "args",
    "batch_size"
  ],
  "TokenIdsAndLogprobs": {
    "__add__": [
      "self",
      "other"
    ],
    "compare": [
      "cls",
      "a",
      "b"
    ]
  },
  "_extract_ids_and_logprobs": [
    "responses"
  ],
  "test_deterministic": [
    "args"
  ],
  "DummyModel": {
    "__init__": [
      "self",
      "d_in",
      "n_heads",
      "softmax_scale"
    ],
    "_get_logits_head_gate_orig": [
      "self",
      "x",
      "q_scale"
    ],
    "_get_logits_head_gate_opt": [
      "self",
      "x",
      "q_scale"
    ]
  },
  "DEFAULT_MAX_RUNNING_REQUESTS": [],
  "DEFAULT_MAX_TOTAL_TOKENS": [],
  "_original_post_init": [],
  "patched_post_init": [
    "self"
  ],
  "MarlinWorkspace": {
    "__init__": [
      "self",
      "out_features",
      "min_thread_n",
      "max_parallel"
    ]
  },
  "marlin_permute_weights": [
    "q_w",
    "size_k",
    "size_n",
    "perm",
    "tile"
  ],
  "marlin_weights": [
    "q_w",
    "size_k",
    "size_n",
    "num_bits",
    "perm"
  ],
  "marlin_quantize": [
    "w",
    "quant_type",
    "group_size",
    "act_order",
    "test_perm"
  ],
  "awq_marlin_quantize": [
    "w",
    "quant_type",
    "group_size"
  ],
  "send_one_prompt": [
    "args"
  ],
  "QUERY_TEMPLATE": [],
  "normalize_aime_answer": [
    "answer"
  ],
  "AIME25Eval": {
    "__init__": [
      "self",
      "num_examples",
      "num_threads"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "LoRAAdaptor": {},
  "LoRAModelCase": {
    "__post_init__": [
      "self"
    ]
  },
  "TORCH_DTYPES": [],
  "BACKENDS": [],
  "DEFAULT_PROMPTS": [],
  "CI_LORA_MODELS": [],
  "ALL_OTHER_LORA_MODELS": [],
  "CI_MULTI_LORA_MODELS": [],
  "ALL_OTHER_MULTI_LORA_MODELS": [],
  "LORA_MODELS_QWEN3": [],
  "safe_matmul": [
    "a",
    "b"
  ],
  "reference_sgmv_shrink": [
    "x",
    "weights",
    "weight_indices",
    "seq_lengths",
    "lora_ranks",
    "lora_scalings",
    "num_slices"
  ],
  "reference_sgmv_expand": [
    "x",
    "weights",
    "weight_indices",
    "seq_lengths",
    "lora_ranks",
    "slice_offsets",
    "base_output"
  ],
  "run_lora_test_one_by_one": [
    "prompts",
    "model_case",
    "torch_dtype",
    "max_new_tokens",
    "backend",
    "enable_lora_overlap_loading",
    "disable_cuda_graph",
    "disable_radix_cache",
    "mem_fraction_static",
    "test_tag"
  ],
  "run_lora_test_by_batch": [
    "prompts",
    "model_case",
    "torch_dtype",
    "max_new_tokens",
    "backend",
    "disable_cuda_graph",
    "disable_radix_cache",
    "mem_fraction_static",
    "test_tag"
  ],
  "ensure_reproducibility": [],
  "TEST_MULTIPLE_BATCH_PROMPTS": [],
  "create_multiple_batch_test_samples": [
    "prompts",
    "lora_adapter_paths"
  ],
  "run_lora_multiple_batch_on_model_cases": [
    "model_cases",
    "use_spec_decoding",
    "attention_backend",
    "disable_cuda_graph",
    "enable_deterministic_inference",
    "disable_radix_cache"
  ],
  "run_lora_batch_splitting_equivalence_test": [
    "model_cases",
    "attention_backend",
    "disable_cuda_graph",
    "disable_radix_cache"
  ],
  "init_dist": [
    "local_rank",
    "num_local_ranks"
  ],
  "per_token_cast_to_fp8": [
    "x"
  ],
  "per_token_cast_back": [
    "x_fp8",
    "x_scales"
  ],
  "inplace_unique": [
    "x",
    "num_slots"
  ],
  "create_grouped_scores": [
    "scores",
    "group_idx",
    "num_groups"
  ],
  "bench": [
    "fn",
    "num_warmups",
    "num_tests",
    "post_fn"
  ],
  "empty_suppress": {
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self"
    ]
  },
  "hash_tensor": [
    "t"
  ],
  "TestDynamicGradMode": {
    "test_inference": [
      "self"
    ],
    "test_no_grad": [
      "self"
    ],
    "test_nested_inference": [
      "self"
    ],
    "test_nested_no_grad": [
      "self"
    ]
  },
  "ALL_LANGUAGES": [],
  "LATIN_LANGUAGES": [],
  "NON_LATIN_LANGUAGES": [],
  "LANG_TO_FPATH": [],
  "LANG_TO_INSTRUCTIONS": [],
  "LANG_TO_ANSWER_PREFIX": [],
  "parse_answer": [
    "answer",
    "answer_prefix"
  ],
  "score_mgsm": [
    "target",
    "prediction"
  ],
  "get_lang_examples": [
    "lang"
  ],
  "get_all_examples": [],
  "MGSMEval": {
    "__init__": [
      "self",
      "num_examples_per_lang",
      "num_threads",
      "languages"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "DEFAULT_TIMEOUT": [],
  "get_cache_tokens_from_metrics": [
    "url"
  ],
  "calculate_cache_hit_rate": [
    "before",
    "after"
  ],
  "BenchOneCaseResult": {
    "dump_to_jsonl": [
      "self",
      "result_filename"
    ]
  },
  "_warmup_cache": [
    "url",
    "input_ids",
    "input_len",
    "cache_hit_rate",
    "dataset_name",
    "image_data"
  ],
  "run_one_case": [
    "url",
    "batch_size",
    "input_len",
    "output_len",
    "temperature",
    "return_logprob",
    "stream_interval",
    "input_len_step_percentage",
    "run_name",
    "result_filename",
    "tokenizer",
    "profile",
    "profile_steps",
    "profile_by_stage",
    "profile_prefix",
    "profile_output_dir",
    "dataset_name",
    "dataset_path",
    "parallel_batch",
    "cache_hit_rate"
  ],
  "should_skip_due_to_token_capacity": [
    "batch_size",
    "input_len",
    "output_len",
    "skip_token_capacity_threshold"
  ],
  "should_skip_due_to_max_running_requests": [
    "batch_size",
    "skip_max_running_requests_threshold"
  ],
  "get_report_summary": [
    "results",
    "bench_args",
    "server_args"
  ],
  "run_benchmark_internal": [
    "server_args",
    "bench_args",
    "launch_server_func"
  ],
  "TestRMSNorm": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "HIDDEN_SIZES": [],
    "ADD_RESIDUAL": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_run_rms_norm_test": [
      "self",
      "num_tokens",
      "hidden_size",
      "add_residual",
      "dtype",
      "seed"
    ],
    "test_rms_norm": [
      "self"
    ]
  },
  "TestGemmaRMSNorm": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "HIDDEN_SIZES": [],
    "ADD_RESIDUAL": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_run_gemma_rms_norm_test": [
      "self",
      "num_tokens",
      "hidden_size",
      "add_residual",
      "dtype",
      "seed"
    ],
    "test_gemma_rms_norm": [
      "self"
    ]
  },
  "TestLayerNorm": {
    "DTYPES": [],
    "PARAM_DTYPES": [],
    "NUM_TOKENS": [],
    "HIDDEN_SIZES": [],
    "USE_AFFINE": [],
    "USE_BIAS": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_run_layer_norm_test": [
      "self",
      "num_tokens",
      "hidden_size",
      "use_affine",
      "use_bias",
      "dtype",
      "seed",
      "param_dtype"
    ],
    "test_layer_norm": [
      "self"
    ]
  },
  "PerformanceTestParams": {},
  "PerformanceTestResult": {},
  "run_performance_test": [
    "model",
    "perf_runner",
    "batch_sizes",
    "input_lens",
    "output_lens",
    "is_vlm",
    "dataset_name",
    "spec_accept_length_threshold"
  ],
  "run_performance_for_models": [
    "models",
    "profile_dir",
    "test_name",
    "base_url",
    "batch_sizes",
    "input_lens",
    "output_lens",
    "is_vlm",
    "dataset_name"
  ],
  "GPQAEval": {
    "__init__": [
      "self",
      "filename",
      "num_examples",
      "num_threads",
      "n_repeats"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "TestDumpMetric": {
    "_ENV_KEYS_TO_CLEAN": [],
    "setUp": [
      "self"
    ],
    "tearDown": [
      "self"
    ],
    "test_writes_valid_jsonl": [
      "self"
    ],
    "test_no_env_no_file": [
      "self"
    ],
    "test_labels_not_serializable_stringified": [
      "self"
    ],
    "test_bool_to_int": [
      "self"
    ],
    "test_pytest_current_test_parsing": [
      "self"
    ]
  },
  "run_combined_tests": [
    "models",
    "test_name",
    "base_url",
    "is_vlm",
    "accuracy_params",
    "performance_params"
  ],
  "MathEval": {
    "__init__": [
      "self",
      "filename",
      "equality_checker",
      "num_examples",
      "num_threads"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "native_per_token_group_quant_fp8": [
    "x",
    "group_size",
    "eps",
    "dtype"
  ],
  "TestPerTokenGroupQuantFP8": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "D": [],
    "GROUP_SIZE": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_per_token_group_quant_fp8": [
      "self",
      "num_tokens",
      "d",
      "dtype",
      "group_size",
      "seed"
    ],
    "test_per_token_group_quant_fp8": [
      "self"
    ]
  },
  "native_static_quant_fp8": [
    "x",
    "x_s",
    "dtype"
  ],
  "TestStaticQuantFP8": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "D": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_static_quant_fp8": [
      "self",
      "num_tokens",
      "d",
      "dtype",
      "seed"
    ],
    "test_static_quant_fp8": [
      "self"
    ]
  },
  "TestPerTensorQuantMlaFP8": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "D": [],
    "LAST_D_EXT": [],
    "LAST_D": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_per_tensor_quant_mla_fp8": [
      "self",
      "num_tokens",
      "d",
      "last_d_ext",
      "last_d",
      "dtype",
      "seed"
    ],
    "test_per_tensor_quant_mla_fp8": [
      "self"
    ]
  },
  "TestPerTokenGroupQuantMlaDeepGemmMaskedFP8": {
    "DTYPES": [],
    "B": [],
    "NUM_TOKENS": [],
    "D": [],
    "GROUP_SIZE": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_per_token_group_quant_mla_deep_gemm_masked_fp8": [
      "self",
      "b",
      "num_tokens",
      "d",
      "dtype",
      "group_size",
      "seed"
    ],
    "test_per_token_group_quant_mla_deep_gemm_masked_fp8": [
      "self"
    ]
  },
  "TestW8A8BlockFP8Matmul": {
    "setUpClass": [
      "cls"
    ],
    "_w8a8_block_fp8_matmul": [
      "self",
      "M",
      "NK",
      "block_size",
      "out_dtype",
      "seed"
    ],
    "test_w8a8_block_fp8_matmul": [
      "self"
    ]
  },
  "torch_w8a8_block_fp8_moe": [
    "a",
    "w1",
    "w2",
    "w1_s",
    "w2_s",
    "score",
    "topk",
    "block_shape"
  ],
  "TestW8A8BlockFP8FusedMoE": {
    "DTYPES": [],
    "M": [],
    "N": [],
    "K": [],
    "E": [],
    "TOP_KS": [],
    "BLOCK_SIZE": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_w8a8_block_fp8_fused_moe": [
      "self",
      "M",
      "N",
      "K",
      "E",
      "topk",
      "block_size",
      "dtype",
      "seed"
    ],
    "test_w8a8_block_fp8_fused_moe": [
      "self"
    ]
  },
  "torch_w8a8_block_fp8_bmm": [
    "a",
    "a_s",
    "w",
    "w_s",
    "block_shape",
    "out_dtype"
  ],
  "TestW8A8BlockFP8BatchedDeepGemm": {
    "DTYPES": [],
    "M": [],
    "N": [],
    "K": [],
    "BATCH": [],
    "BLOCK_SIZE": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_w8a8_block_fp8_batched_deep_gemm": [
      "self",
      "M",
      "N",
      "K",
      "B",
      "block_size",
      "dtype",
      "seed"
    ],
    "test_w8a8_block_fp8_batched_deep_gemm": [
      "self"
    ]
  },
  "calculate_accuracy_metrics": [
    "original",
    "reconstructed"
  ],
  "test_kvfp4_quant_dequant": [
    "m",
    "n",
    "k"
  ],
  "DEFAULT_MODEL": [],
  "COMMON_SERVER_ARGS": [],
  "TestDeterministicBase": {
    "get_server_args": [
      "cls"
    ],
    "get_model": [
      "cls"
    ],
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ],
    "_extract_host_and_port": [
      "self",
      "url"
    ],
    "test_single": [
      "self"
    ],
    "test_prefix_with_logprobs": [
      "self"
    ]
  },
  "concurrent_generate": [
    "engine",
    "prompts",
    "sampling_param"
  ],
  "get_model_config": [
    "tp_size"
  ],
  "to_fp8": [
    "tensor"
  ],
  "run_test": [
    "tp_size",
    "batch_size",
    "model_config",
    "check"
  ],
  "MMMUVLMEval": {
    "DOMAIN_CAT2SUB_CAT": [],
    "__init__": [
      "self",
      "num_examples",
      "num_threads",
      "seed",
      "response_answer_regex"
    ],
    "_to_data_uri": [
      "image"
    ],
    "_build_mc_mapping": [
      "options"
    ],
    "_prepare_mmmu_samples": [
      "self",
      "k"
    ],
    "_split_prompt_for_image": [
      "prompt"
    ],
    "build_chat_messages_from_prompt": [
      "prompt",
      "image_data"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "_parse_multi_choice_response": [
    "response",
    "all_choices",
    "index2ans"
  ],
  "_check_is_number": [
    "s"
  ],
  "_normalize_str": [
    "s"
  ],
  "_extract_numbers": [
    "s"
  ],
  "_parse_open_response": [
    "response"
  ],
  "_eval_open": [
    "gold",
    "preds"
  ],
  "NightlyBenchmarkRunner": {
    "__init__": [
      "self",
      "profile_dir",
      "test_name",
      "base_url",
      "gpu_config"
    ],
    "setup_profile_directory": [
      "self"
    ],
    "generate_profile_filename": [
      "self",
      "model_path",
      "variant"
    ],
    "build_benchmark_command": [
      "self",
      "model_path",
      "batch_sizes",
      "input_lens",
      "output_lens",
      "profile_path_prefix",
      "json_output_file",
      "extra_args"
    ],
    "run_benchmark_command": [
      "self",
      "command",
      "model_description"
    ],
    "load_benchmark_results": [
      "self",
      "json_output_file",
      "model_description"
    ],
    "run_benchmark_for_model": [
      "self",
      "model_path",
      "batch_sizes",
      "input_lens",
      "output_lens",
      "other_args",
      "variant",
      "extra_bench_args"
    ],
    "_get_spec_accept_length": [
      "self"
    ],
    "add_report": [
      "self",
      "results",
      "variant"
    ],
    "write_final_report": [
      "self"
    ],
    "get_full_report": [
      "self"
    ]
  },
  "pack_int4_values_to_int8": [
    "int4_values_interleaved"
  ],
  "pack_interleave": [
    "num_experts",
    "ref_weight",
    "ref_scale",
    "alignment"
  ],
  "test_cutlass_w4a8_moe": [
    "M",
    "N",
    "K",
    "E",
    "tp_size",
    "use_ep_moe",
    "topk",
    "group_size",
    "dtype"
  ],
  "cutlass_moe": [
    "a",
    "w1_q",
    "w2_q",
    "w1_scale",
    "w2_scale",
    "topk_weights",
    "topk_ids",
    "a_strides1",
    "b_strides1",
    "c_strides1",
    "a_strides2",
    "b_strides2",
    "c_strides2",
    "s_strides13",
    "s_strides2",
    "num_local_experts",
    "a1_scale",
    "a2_scale",
    "expert_map",
    "apply_router_weight_on_input"
  ],
  "ref": [
    "x",
    "num_experts",
    "topk_weights",
    "topk_ids",
    "ref_weight_1",
    "ref_weight_2",
    "ref_weight_scale_1",
    "ref_weight_scale_2",
    "has_pre_quant",
    "has_alpha",
    "pre_quant_scale_1",
    "pre_quant_scale_2",
    "alpha_1",
    "alpha_2"
  ],
  "LONGBENCH_V2_DATASET": [],
  "LONGBENCH_V2_SPLIT": [],
  "DEFAULT_NUM_SAMPLES": [],
  "DEFAULT_PROMPT_TOKENS": [],
  "CACHE_DIR": [],
  "_cached_input_ids": [],
  "format_longbench_v2_example": [
    "example"
  ],
  "get_input_ids": [
    "tokenizer_path",
    "max_prompt_tokens",
    "num_samples"
  ],
  "compare_kl_divergence": [
    "input_logprobs",
    "output_logprobs",
    "ACC_THRESHOLDS",
    "model_name",
    "test_name"
  ],
  "_flush_cache": [
    "base_url"
  ],
  "_generate": [
    "base_url",
    "input_ids",
    "max_new_tokens",
    "return_logprob",
    "logprob_start_len"
  ],
  "_get_input_logprobs": [
    "base_url",
    "new_input_ids",
    "output_logprobs"
  ],
  "_extract_output_logprobs": [
    "result"
  ],
  "test_input_output_logprobs_match_helper": [
    "base_url",
    "ACC_THRESHOLDS",
    "model_name",
    "max_samples",
    "max_new_tokens"
  ],
  "test_input_output_logprobs_match_prefill_cache_hit_helper": [
    "base_url",
    "ACC_THRESHOLDS",
    "model_name",
    "max_samples",
    "max_new_tokens"
  ],
  "test_input_output_logprobs_match_decode_cache_hit_helper": [
    "base_url",
    "ACC_THRESHOLDS",
    "model_name",
    "max_samples",
    "max_new_tokens"
  ],
  "TEST_RERANK_QUERY_DOCS": [],
  "NUM_TOP_LOGPROBS": [],
  "get_dtype_str": [
    "torch_dtype"
  ],
  "_get_sentence_transformer_embedding_model": [
    "model_path",
    "torch_dtype",
    "matryoshka_dim"
  ],
  "ModelOutput": {},
  "HFRunner": {
    "__init__": [
      "self",
      "model_path",
      "torch_dtype",
      "model_type",
      "output_str_only",
      "trust_remote_code",
      "patch_model_do_sample_false",
      "matryoshka_dim"
    ],
    "needs_trust_remote_code": [
      "self",
      "model_path"
    ],
    "_get_gme_qwen2_vl_embeddings": [
      "self",
      "prompts",
      "image_data"
    ],
    "_forward_gme_qwen2_vl": [
      "self",
      "input_ids",
      "attention_mask",
      "position_ids",
      "past_key_values",
      "inputs_embeds",
      "pixel_values",
      "image_grid_thw",
      "pooling_mask"
    ],
    "start_model_process": [
      "self",
      "in_queue",
      "out_queue",
      "model_path",
      "torch_dtype",
      "matryoshka_dim"
    ],
    "forward": [
      "self",
      "prompts",
      "image_data",
      "max_new_tokens",
      "lora_paths",
      "token_ids_logprob"
    ],
    "terminate": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "forward_generation_raw": [
      "base_model",
      "prompts",
      "max_new_tokens",
      "tokenizer",
      "torch_dtype",
      "lora_paths",
      "output_str_only",
      "token_ids_logprob",
      "patch_model_do_sample_false"
    ]
  },
  "SRTRunner": {
    "__init__": [
      "self",
      "model_path",
      "torch_dtype",
      "model_type",
      "tp_size",
      "model_impl",
      "port",
      "lora_paths",
      "max_loras_per_batch",
      "attention_backend",
      "prefill_attention_backend",
      "decode_attention_backend",
      "lora_backend",
      "disable_cuda_graph",
      "disable_radix_cache",
      "chunked_prefill_size",
      "context_length",
      "max_total_tokens",
      "page_size",
      "dp_size",
      "tokenizer_path",
      "mem_fraction_static",
      "trust_remote_code",
      "speculative_draft_model_path",
      "speculative_draft_model_revision",
      "speculative_algorithm",
      "speculative_num_steps",
      "speculative_eagle_topk",
      "speculative_num_draft_tokens",
      "speculative_ngram_min_match_window_size",
      "speculative_ngram_max_match_window_size",
      "disable_overlap_schedule",
      "disable_custom_all_reduce",
      "torchao_config",
      "cuda_graph_max_bs",
      "sleep_on_idle",
      "max_lora_rank",
      "lora_target_modules",
      "enable_lora",
      "enable_lora_overlap_loading",
      "max_loaded_loras",
      "json_model_override_args",
      "lora_eviction_policy",
      "enable_deterministic_inference"
    ],
    "load_lora_adapter": [
      "self",
      "lora_name",
      "lora_path",
      "pinned"
    ],
    "unload_lora_adapter": [
      "self",
      "lora_name"
    ],
    "forward": [
      "self",
      "prompts",
      "image_data",
      "max_new_tokens",
      "lora_paths",
      "logprob_start_len",
      "top_k",
      "token_ids_logprob",
      "dimensions"
    ],
    "batch_forward": [
      "self",
      "prompts",
      "image_data",
      "max_new_tokens",
      "lora_paths"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "forward_generation_raw": [
      "engine",
      "prompts",
      "max_new_tokens",
      "lora_paths",
      "logprob_start_len",
      "top_k",
      "token_ids_logprob"
    ],
    "batch_forward_generation_raw": [
      "prompts",
      "max_new_tokens",
      "lora_paths",
      "engine"
    ]
  },
  "monkey_patch_gemma2_sdpa": [],
  "check_close_model_outputs": [
    "hf_outputs",
    "srt_outputs",
    "prefill_tolerance",
    "decode_tolerance",
    "rouge_l_tolerance",
    "debug_text",
    "check_logprobs"
  ],
  "_base_url": [],
  "BaseTestGptOss": {
    "run_test": [
      "self",
      "model_variant",
      "quantization",
      "expected_score_of_reasoning_effort",
      "other_args"
    ],
    "_run_test_raw": [
      "self",
      "model",
      "expected_score_of_reasoning_effort",
      "other_args"
    ],
    "_check_streaming_responses_api_request": [
      "self",
      "model"
    ],
    "_run_one_eval": [
      "self",
      "model",
      "reasoning_effort",
      "expected_score"
    ]
  },
  "fp8_dtype": [],
  "test_scaled_fp8_quant_per_tensor": [
    "dtype"
  ],
  "TestGeluAndMul": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "D": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_run_gelu_and_mul_test": [
      "self",
      "num_tokens",
      "d",
      "dtype",
      "seed"
    ],
    "test_gelu_and_mul": [
      "self"
    ]
  },
  "TestQuickGELU": {
    "DTYPES": [],
    "NUM_TOKENS": [],
    "DIMS": [],
    "SEEDS": [],
    "setUpClass": [
      "cls"
    ],
    "_run_gelu_quick_test": [
      "self",
      "n_tok",
      "dim",
      "dtype",
      "seed"
    ],
    "test_quick_gelu": [
      "self"
    ]
  },
  "AccuracyTestParams": {},
  "AccuracyTestResult": {},
  "write_accuracy_github_summary": [
    "test_name",
    "dataset",
    "results"
  ],
  "_run_simple_eval": [
    "model",
    "base_url",
    "dataset",
    "num_examples",
    "num_threads",
    "max_tokens",
    "return_latency",
    "thinking_mode",
    "temperature",
    "repeat"
  ],
  "_run_few_shot_eval": [
    "model",
    "base_url",
    "num_questions",
    "num_shots",
    "max_tokens"
  ],
  "run_accuracy_test": [
    "model",
    "params",
    "base_url"
  ],
  "TASK_CATEGORIES": [],
  "DEFAULT_DATASET": [],
  "DEFAULT_DATASET_SPLIT": [],
  "format_longbench_v2_question": [
    "row"
  ],
  "extract_longbench_v2_answer": [
    "response"
  ],
  "LongBenchV2Eval": {
    "__init__": [
      "self",
      "model",
      "data_source",
      "num_examples",
      "num_threads",
      "n_repeats",
      "categories",
      "max_context_length",
      "min_context_length"
    ],
    "_load_dataset": [
      "self",
      "data_source"
    ],
    "_load_local_file": [
      "self",
      "path"
    ],
    "_load_hf_dataset": [
      "self",
      "identifier"
    ],
    "_normalize_example": [
      "self",
      "example"
    ],
    "_check_context_length": [
      "self",
      "formatted_question",
      "tokenizer",
      "min_length",
      "max_length"
    ],
    "__call__": [
      "self",
      "sampler"
    ]
  },
  "BYTES_PER_TILE": [],
  "TestSpecUtils": {
    "setUp": [
      "self"
    ],
    "test_assign_draft_cache_locs_single_seq": [
      "self"
    ],
    "test_assign_draft_cache_locs_multi_seq": [
      "self"
    ],
    "test_assign_draft_cache_locs_page_size_1": [
      "self"
    ],
    "test_assign_draft_cache_locs_page_size_gt_spec_steps": [
      "self"
    ]
  },
  "TestRegexConstrainedMixin": {
    "_run_decode_regex": [
      "self",
      "regex",
      "prompt",
      "return_logprob",
      "top_logprobs_num",
      "n"
    ],
    "regex_match": [
      "self",
      "text",
      "pattern"
    ],
    "test_regex_generate_email": [
      "self"
    ],
    "test_regex_generate_greeting": [
      "self"
    ],
    "test_regex_generate_number": [
      "self"
    ],
    "test_regex_generate_phone": [
      "self"
    ],
    "test_regex_generate_date": [
      "self"
    ],
    "test_regex_generate_hex_color": [
      "self"
    ],
    "test_regex_generate_complex_json": [
      "self"
    ],
    "test_regex_generate_custom_log_format": [
      "self"
    ]
  },
  "MANY_NEW_TOKENS_PROMPT": [],
  "MatchedStopMixin": {
    "_run_completions_generation": [
      "self",
      "prompt",
      "max_tokens",
      "stop",
      "stop_regex",
      "finish_reason",
      "matched_stop"
    ],
    "_run_chat_completions_generation": [
      "self",
      "prompt",
      "max_tokens",
      "stop",
      "stop_regex",
      "finish_reason",
      "matched_stop"
    ],
    "test_finish_stop_str": [
      "self"
    ],
    "test_finish_stop_regex_str": [
      "self"
    ],
    "test_finish_stop_eos": [
      "self"
    ],
    "test_finish_length": [
      "self"
    ]
  },
  "gen_radix_tree": [
    "num_nodes",
    "chunk_len"
  ],
  "run_radix_attention_test": [
    "base_url"
  ],
  "SpecDecodingMixin": {
    "test_bs_1_speed": [
      "self"
    ]
  },
  "GSM8KMixin": {
    "test_gsm8k": [
      "self"
    ]
  },
  "TestEBNFConstrainedMixin": {
    "ebnf_grammar": [],
    "_run_decode_ebnf": [
      "self",
      "ebnf",
      "expected_patterns",
      "prompt",
      "return_logprob",
      "top_logprobs_num",
      "n"
    ],
    "regex_match": [
      "self",
      "text",
      "pattern"
    ],
    "test_ebnf_generate_email": [
      "self"
    ],
    "test_ebnf_generate_greeting": [
      "self"
    ],
    "test_ebnf_generate_number": [
      "self"
    ],
    "test_ebnf_generate_phone": [
      "self"
    ],
    "test_ebnf_generate_date": [
      "self"
    ],
    "test_ebnf_generate_hex_color": [
      "self"
    ],
    "test_ebnf_generate_complex_json": [
      "self"
    ],
    "test_ebnf_generate_custom_log_format": [
      "self"
    ],
    "test_ebnf_generate_all_optional_function_params": [
      "self"
    ]
  },
  "DEFAULT_MEM_FRACTION_STATIC": [],
  "_is_mmmu_parquet_corruption": [
    "error_output"
  ],
  "_cleanup_mmmu_dataset_cache": [],
  "_run_lmms_eval_with_retry": [
    "cmd",
    "timeout"
  ],
  "MMMUMixin": {
    "api_key": [],
    "run_mmmu_eval": [
      "self",
      "model_version",
      "output_path"
    ],
    "test_mmmu": [
      "self"
    ]
  },
  "MMMUMultiModelTestBase": {
    "parsed_args": [],
    "other_args": [],
    "mmmu_args": [],
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ],
    "run_mmmu_eval": [
      "self",
      "model_version",
      "output_path"
    ],
    "_run_vlm_mmmu_test": [
      "self",
      "model",
      "output_path",
      "test_name",
      "custom_env",
      "log_level",
      "capture_output"
    ],
    "_read_output_from_files": [
      "self"
    ]
  },
  "MMMUVLMTestBase": [],
  "TestJSONConstrainedMixin": {
    "json_schema": [],
    "_run_decode_json": [
      "self",
      "json_schema",
      "return_logprob",
      "top_logprobs_num",
      "n"
    ],
    "test_json_generate": [
      "self"
    ],
    "test_json_invalid": [
      "self"
    ],
    "test_json_openai": [
      "self"
    ],
    "test_mix_json_and_other": [
      "self"
    ]
  },
  "create_sample_official_data": [],
  "create_alternative_format_data": [],
  "MockSampler": {
    "__init__": [
      "self",
      "responses"
    ],
    "_pack_message": [
      "self",
      "content",
      "role"
    ],
    "__call__": [
      "self",
      "messages"
    ]
  },
  "test_format_compatibility": [],
  "test_answer_extraction": [],
  "test_evaluation_pipeline": [],
  "test_category_filtering": [],
  "run_accuracy_benchmark": [],
  "generate_comparison_report": [],
  "create_official_format_samples": [],
  "create_alternative_format_samples": [],
  "test_data_loading_simulation": [],
  "run_accuracy_simulation": [],
  "generate_validation_report": [],
  "test_format_longbench_v2_question": [],
  "test_extract_longbench_v2_answer": [],
  "test_longbench_v2_eval_initialization": [],
  "test_difficulty_metrics": [],
  "CustomProcessor": {
    "models": [],
    "__init__": [
      "self",
      "hf_config",
      "server_args",
      "_processor"
    ]
  },
  "TestFile": {},
  "RETRIABLE_PATTERNS": [],
  "NON_RETRIABLE_PATTERNS": [],
  "is_retriable_failure": [
    "output"
  ],
  "run_with_timeout": [
    "func",
    "args",
    "kwargs",
    "timeout"
  ],
  "run_unittest_files": [
    "files",
    "timeout_per_file",
    "continue_on_error",
    "enable_retry",
    "max_attempts",
    "retry_wait_seconds"
  ],
  "StressTestRunner": {
    "__init__": [
      "self",
      "test_name",
      "base_url",
      "num_prompts",
      "duration_minutes"
    ],
    "build_stress_test_command": [
      "self",
      "model_path",
      "random_input_len",
      "random_output_len",
      "output_file",
      "random_range_ratio",
      "extra_args"
    ],
    "run_stress_test_command": [
      "self",
      "command",
      "timeout_minutes"
    ],
    "run_stress_test_for_model": [
      "self",
      "model_path",
      "random_input_len",
      "random_output_len",
      "output_file",
      "server_args",
      "extra_bench_args",
      "timeout_minutes"
    ],
    "_add_success_to_report": [
      "self",
      "model_path",
      "input_len",
      "output_len"
    ],
    "_add_failure_to_report": [
      "self",
      "model_path",
      "error"
    ],
    "write_final_report": [
      "self"
    ],
    "get_full_report": [
      "self"
    ]
  },
  "_PARAM_ORDER": [],
  "_UNSET": [],
  "HWBackend": {
    "CPU": [],
    "CUDA": [],
    "AMD": [],
    "NPU": []
  },
  "CIRegistry": {},
  "register_cpu_ci": [
    "est_time",
    "suite",
    "nightly",
    "disabled"
  ],
  "register_cuda_ci": [
    "est_time",
    "suite",
    "nightly",
    "disabled"
  ],
  "register_amd_ci": [
    "est_time",
    "suite",
    "nightly",
    "disabled"
  ],
  "register_npu_ci": [
    "est_time",
    "suite",
    "nightly",
    "disabled"
  ],
  "REGISTER_MAPPING": [],
  "RegistryVisitor": {
    "__init__": [
      "self",
      "filename"
    ],
    "_constant_value": [
      "self",
      "node"
    ],
    "_parse_call_args": [
      "self",
      "func_call"
    ],
    "_collect_ci_registry": [
      "self",
      "func_call"
    ],
    "visit_Module": [
      "self",
      "node"
    ]
  },
  "ut_parse_one_file": [
    "filename"
  ],
  "collect_tests": [
    "files",
    "sanity_check"
  ],
  "DEFAULT_CONFIG": [],
  "ROPE_BASE": [],
  "ROPE_SCALING_CONFIG": [],
  "build_rotary_emb": [
    "config",
    "device"
  ],
  "TEST_CASES": [],
  "MockModelRunner": {
    "__init__": [
      "self",
      "config"
    ]
  },
  "compare_outputs": [
    "trtllm_out",
    "reference_out",
    "tolerance"
  ],
  "TestTRTLLMMLA": {
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ],
    "_merge_config": [
      "self",
      "test_case"
    ],
    "_create_model_components": [
      "self",
      "config",
      "is_prefill"
    ],
    "_create_qkv_tensors": [
      "self",
      "batch_size",
      "config",
      "dtype_override"
    ],
    "_create_forward_batch": [
      "self",
      "batch_size",
      "seq_lens",
      "backend",
      "model_runner",
      "config"
    ],
    "_populate_kv_cache": [
      "self",
      "batch_size",
      "seq_lens",
      "model_runners",
      "layer",
      "config"
    ],
    "test_basic_functionality": [
      "self"
    ],
    "test_decode_output_match": [
      "self"
    ],
    "test_page_size_consistency": [
      "self"
    ],
    "test_shape_sanity": [
      "self"
    ],
    "test_metadata_initialization": [
      "self"
    ],
    "test_metadata_block_calculation": [
      "self"
    ],
    "test_metadata_kv_indices_correctness": [
      "self"
    ],
    "test_metadata_cuda_graph_compatibility": [
      "self"
    ],
    "test_metadata_consistency_across_calls": [
      "self"
    ],
    "test_prefill_output_match_self_attention": [
      "self"
    ],
    "test_draft_extend_padding_unpadding_kernels": [
      "self"
    ]
  },
  "MockForwardBatch": {
    "__init__": [
      "self",
      "max_chunk_capacity"
    ],
    "get_max_chunk_capacity": [
      "self"
    ]
  },
  "MockReqToTokenPool": {
    "__init__": [
      "self",
      "batch_size",
      "seq_len",
      "device"
    ]
  },
  "check_kv_indices": [
    "forward_batch"
  ],
  "TestPrefixChunkInfo": {
    "setUp": [
      "self"
    ],
    "test_prefix_chunk_info": [
      "self"
    ]
  },
  "TestFlashAttentionMLABackend": {
    "setUp": [
      "self"
    ],
    "_init_model_runner": [
      "self"
    ],
    "_create_attention_layer": [
      "self"
    ],
    "_run_reference_forward": [
      "self",
      "mode",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "expected_shape"
    ],
    "_verify_output": [
      "self",
      "output",
      "expected_shape"
    ],
    "_create_forward_batch": [
      "self",
      "mode",
      "q_len",
      "prefix_len"
    ],
    "_setup_kv_cache": [
      "self",
      "forward_batch",
      "layer",
      "cache_len"
    ],
    "_run_attention_test": [
      "self",
      "mode",
      "q_len",
      "prefix_len"
    ],
    "test_forward_extend": [
      "self"
    ],
    "test_forward_decode": [
      "self"
    ],
    "test_forward_extend_with_prefix": [
      "self"
    ]
  },
  "TestFlashAttentionBackend": {
    "setUp": [
      "self"
    ],
    "_init_model_runner": [
      "self",
      "page_size"
    ],
    "_mock_write_to_req_to_token_pool": [
      "self",
      "batch_size",
      "seq_len",
      "page_size"
    ],
    "_create_attention_layer": [
      "self"
    ],
    "_create_qkv_tensors": [
      "self",
      "tokens_len"
    ],
    "_run_reference_forward": [
      "self",
      "mode",
      "q",
      "k",
      "v",
      "layer",
      "forward_batch",
      "expected_shape"
    ],
    "_verify_output": [
      "self",
      "output",
      "expected_shape",
      "output_ref"
    ],
    "_create_forward_batch": [
      "self",
      "mode",
      "q_len",
      "prefix_len",
      "page_size"
    ],
    "_setup_kv_cache": [
      "self",
      "forward_batch",
      "layer",
      "cache_len"
    ],
    "_run_attention_test": [
      "self",
      "mode",
      "q_len",
      "prefix_len",
      "page_size"
    ],
    "test_forward_extend": [
      "self"
    ],
    "test_forward_decode": [
      "self"
    ],
    "test_forward_extend_with_prefix": [
      "self"
    ],
    "test_forward_extend_with_page_size_greater_than_1": [
      "self"
    ],
    "test_forward_decode_with_page_size_greater_than_1": [
      "self"
    ]
  },
  "TestUpdateDraftDecodeSetExpandMetadata": {
    "test_draft_decode_set_expand_metadata": [
      "self"
    ],
    "test_update_draft_decode_set_expand_metadata_multi_batch": [
      "self"
    ]
  },
  "TestVLMModels": {
    "model": [],
    "mmmu_accuracy": [],
    "other_args": [],
    "setUpClass": [
      "cls"
    ],
    "run_mmmu_eval": [
      "self",
      "model_version",
      "output_path",
      "limit"
    ],
    "_run_vlm_mmmu_test": [
      "self",
      "output_path",
      "test_name",
      "custom_env",
      "capture_output",
      "limit"
    ],
    "_read_output_from_files": [
      "self"
    ]
  },
  "GSM8KAscendMixin": {
    "model": [],
    "accuracy": [],
    "other_args": [],
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ],
    "test_gsm8k": [
      "self"
    ]
  },
  "PROMPTS": [],
  "EagleServerBase": {
    "target_model": [],
    "draft_model": [],
    "spec_algo": [],
    "spec_steps": [],
    "spec_topk": [],
    "spec_tokens": [],
    "mem_fraction_static": [],
    "extra_args": [],
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ],
    "send_request": [
      "self"
    ],
    "send_requests_abort": [
      "self"
    ],
    "run_decode": [
      "self",
      "sampling_params"
    ]
  },
  "openai_api_env": [
    "api_key"
  ],
  "DefaultServerBase": {
    "model": [],
    "base_url": [],
    "timeout": [],
    "api_key": [],
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ]
  },
  "PDDisaggregationServerBase": {
    "setUpClass": [
      "cls"
    ],
    "launch_lb": [
      "cls"
    ],
    "wait_server_ready": [
      "cls",
      "url",
      "timeout"
    ],
    "tearDownClass": [
      "cls"
    ]
  },
  "get_rdma_devices_args": [],
  "MMMUServerBase": {
    "model": [],
    "base_url": [],
    "timeout": [],
    "setUpClass": [
      "cls"
    ],
    "tearDownClass": [
      "cls"
    ]
  },
  "REGEX_INT": [],
  "REGEX_FLOAT": [],
  "REGEX_BOOL": [],
  "REGEX_STR": [],
  "SglSamplingParams": {
    "clone": [
      "self"
    ],
    "to_openai_kwargs": [
      "self"
    ],
    "to_vertexai_kwargs": [
      "self"
    ],
    "to_anthropic_kwargs": [
      "self"
    ],
    "to_litellm_kwargs": [
      "self"
    ],
    "to_srt_kwargs": [
      "self"
    ]
  },
  "SglFunction": {
    "__init__": [
      "self",
      "func",
      "num_api_spec_tokens",
      "bind_arguments"
    ],
    "bind": [
      "self"
    ],
    "run": [
      "self"
    ],
    "run_batch": [
      "self",
      "batch_kwargs"
    ],
    "trace": [
      "self"
    ],
    "cache": [
      "self",
      "backend"
    ],
    "__call__": [
      "self"
    ]
  },
  "SglExpr": {
    "node_ct": [],
    "__init__": [
      "self"
    ],
    "__add__": [
      "self",
      "other"
    ],
    "__radd__": [
      "self",
      "other"
    ],
    "concatenate_ir": [
      "self",
      "a",
      "b"
    ],
    "print_graph_dfs": [
      "self"
    ]
  },
  "SglExprList": {
    "__init__": [
      "self",
      "expr_list"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglArgument": {
    "__init__": [
      "self",
      "name",
      "value"
    ],
    "__repr__": [
      "self"
    ],
    "__len__": [
      "self"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__int__": [
      "self"
    ],
    "__bool__": [
      "self"
    ],
    "__format__": [
      "self"
    ]
  },
  "SglImage": {
    "__init__": [
      "self",
      "path"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglVideo": {
    "__init__": [
      "self",
      "path",
      "num_frames"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglGen": {
    "__init__": [
      "self",
      "name",
      "max_new_tokens",
      "min_new_tokens",
      "n",
      "stop",
      "stop_token_ids",
      "stop_regex",
      "temperature",
      "top_p",
      "top_k",
      "min_p",
      "frequency_penalty",
      "presence_penalty",
      "ignore_eos",
      "return_logprob",
      "logprob_start_len",
      "top_logprobs_num",
      "return_text_in_logprobs",
      "dtype",
      "regex",
      "json_schema"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglConstantText": {
    "__init__": [
      "self",
      "value"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglRoleBegin": {
    "__init__": [
      "self",
      "role"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglRoleEnd": {
    "__init__": [
      "self",
      "role"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglSelect": {
    "__init__": [
      "self",
      "name",
      "choices",
      "temperature",
      "choices_method"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglFork": {
    "__init__": [
      "self",
      "number",
      "position_ids_offset"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglGetForkItem": {
    "__init__": [
      "self",
      "index"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglVariable": {
    "__init__": [
      "self",
      "name",
      "source"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglVarScopeBegin": {
    "__init__": [
      "self",
      "name"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglVarScopeEnd": {
    "__init__": [
      "self",
      "name"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglConcateAndAppend": {
    "__init__": [
      "self",
      "states"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglCommitLazy": {
    "__init__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "SglSeparateReasoning": {
    "__init__": [
      "self",
      "model_type",
      "expr"
    ],
    "process_name_for_reasoning": [
      "self",
      "name"
    ],
    "_process_expr": [
      "self",
      "expr"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ChoicesDecision": {},
  "ChoicesSamplingMethod": {
    "requires_unconditional_logprobs": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "TokenLengthNormalized": {
    "__call__": [
      "self"
    ]
  },
  "token_length_normalized": [],
  "GreedyTokenSelection": {
    "__call__": [
      "self"
    ],
    "_build_logprob_matrix": [
      "self",
      "input_token_logprobs",
      "max_tokens",
      "num_options"
    ],
    "_greedy_selection": [
      "self",
      "logprob_matrix",
      "num_options",
      "max_tokens"
    ]
  },
  "greedy_token_selection": [],
  "UnconditionalLikelihoodNormalized": {
    "requires_unconditional_logprobs": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "_normalize_logprobs": [
      "self",
      "input_token_logprobs",
      "unconditional_token_logprobs"
    ]
  },
  "unconditional_likelihood_normalized": [],
  "function": [
    "func",
    "num_api_spec_tokens"
  ],
  "Runtime": [],
  "set_default_backend": [
    "backend"
  ],
  "gen": [
    "name",
    "max_tokens",
    "min_tokens",
    "n",
    "stop",
    "stop_token_ids",
    "stop_regex",
    "temperature",
    "top_p",
    "top_k",
    "min_p",
    "frequency_penalty",
    "presence_penalty",
    "ignore_eos",
    "return_logprob",
    "logprob_start_len",
    "top_logprobs_num",
    "return_text_in_logprobs",
    "dtype",
    "choices",
    "choices_method",
    "regex",
    "json_schema"
  ],
  "gen_int": [
    "name",
    "max_tokens",
    "n",
    "stop",
    "stop_token_ids",
    "stop_regex",
    "temperature",
    "top_p",
    "top_k",
    "min_p",
    "frequency_penalty",
    "presence_penalty",
    "ignore_eos",
    "return_logprob",
    "logprob_start_len",
    "top_logprobs_num",
    "return_text_in_logprobs"
  ],
  "gen_string": [
    "name",
    "max_tokens",
    "n",
    "stop",
    "stop_token_ids",
    "stop_regex",
    "temperature",
    "top_p",
    "top_k",
    "min_p",
    "frequency_penalty",
    "presence_penalty",
    "ignore_eos",
    "return_logprob",
    "logprob_start_len",
    "top_logprobs_num",
    "return_text_in_logprobs"
  ],
  "image": [
    "expr"
  ],
  "video": [
    "path",
    "num_frames"
  ],
  "select": [
    "name",
    "choices",
    "temperature",
    "choices_method"
  ],
  "_role_common": [
    "name",
    "expr"
  ],
  "system": [
    "expr"
  ],
  "user": [
    "expr"
  ],
  "assistant": [
    "expr"
  ],
  "system_begin": [],
  "system_end": [],
  "user_begin": [],
  "user_end": [],
  "assistant_begin": [],
  "assistant_end": [],
  "separate_reasoning": [
    "expr",
    "model_type"
  ],
  "ChatTemplateStyle": {
    "PLAIN": [],
    "LLAMA2": []
  },
  "ChatTemplate": {
    "get_prefix_and_suffix": [
      "self",
      "role",
      "hist_messages"
    ],
    "get_prompt": [
      "self",
      "messages"
    ]
  },
  "register_chat_template": [
    "template"
  ],
  "register_chat_template_matching_function": [
    "func"
  ],
  "get_chat_template": [
    "name"
  ],
  "get_chat_template_by_model_path": [
    "model_path"
  ],
  "match_deepseek": [
    "model_path"
  ],
  "match_orion": [
    "model_path"
  ],
  "match_dbrx": [
    "model_path"
  ],
  "match_llama2_chat": [
    "model_path"
  ],
  "match_mistral": [
    "model_path"
  ],
  "match_llama3_instruct": [
    "model_path"
  ],
  "match_chat_ml": [
    "model_path"
  ],
  "match_chat_yi": [
    "model_path"
  ],
  "match_gemma_it": [
    "model_path"
  ],
  "match_openbmb_minicpm": [
    "model_path"
  ],
  "match_c4ai_command_r": [
    "model_path"
  ],
  "match_granite_instruct": [
    "model_path"
  ],
  "match_gemma3_instruct": [
    "model_path"
  ],
  "match_internvl_chat": [
    "model_path"
  ],
  "match_interns1_chat": [
    "model_path"
  ],
  "run_internal": [
    "state",
    "program",
    "func_args",
    "func_kwargs",
    "sync"
  ],
  "run_program": [
    "program",
    "backend",
    "func_args",
    "func_kwargs",
    "default_sampling_para",
    "stream",
    "sync",
    "use_thread"
  ],
  "run_program_batch": [
    "program",
    "backend",
    "batch_arguments",
    "default_sampling_para",
    "num_threads",
    "progress_bar",
    "generator_style"
  ],
  "_run_program_batch_generator": [
    "program",
    "backend",
    "batch_arguments",
    "default_sampling_para",
    "num_threads",
    "progress_bar"
  ],
  "cache_program": [
    "program",
    "backend"
  ],
  "StreamExecutor": {
    "__init__": [
      "self",
      "backend",
      "arguments",
      "default_sampling_para",
      "chat_template",
      "stream",
      "num_api_spec_tokens",
      "use_thread"
    ],
    "submit": [
      "self",
      "expr"
    ],
    "sync": [
      "self"
    ],
    "get_var": [
      "self",
      "name"
    ],
    "set_var": [
      "self",
      "name",
      "value"
    ],
    "get_meta_info": [
      "self",
      "name",
      "timeout"
    ],
    "fork": [
      "self",
      "size",
      "position_ids_offset"
    ],
    "text": [
      "self"
    ],
    "messages": [
      "self"
    ],
    "error": [
      "self"
    ],
    "end": [
      "self"
    ],
    "_thread_worker_func": [
      "self"
    ],
    "_execute": [
      "self",
      "other"
    ],
    "_execute_fill": [
      "self",
      "value",
      "prefix"
    ],
    "_execute_image": [
      "self",
      "expr"
    ],
    "_execute_video": [
      "self",
      "expr"
    ],
    "_spec_gen": [
      "self",
      "sampling_params"
    ],
    "_execute_gen": [
      "self",
      "expr"
    ],
    "_execute_select": [
      "self",
      "expr"
    ],
    "_execute_variable": [
      "self",
      "expr"
    ],
    "_execute_role_begin": [
      "self",
      "expr"
    ],
    "_execute_role_end": [
      "self",
      "expr"
    ],
    "_execute_var_scope_begin": [
      "self",
      "expr"
    ],
    "_execute_var_scope_end": [
      "self",
      "expr"
    ],
    "_execute_commit_lazy_operations": [
      "self",
      "expr"
    ],
    "_execute_concatenate_and_append_text": [
      "self",
      "expr"
    ],
    "_execute_concatenate_and_append_kv_cache": [
      "self",
      "expr"
    ],
    "_execute_separate_reasoning": [
      "self",
      "expr"
    ],
    "_init_var_event": [
      "self",
      "expr"
    ],
    "_resolve_sampling_params": [
      "self",
      "sampling_params"
    ],
    "__del__": [
      "self"
    ]
  },
  "ProgramState": {
    "__init__": [
      "self",
      "stream_executor"
    ],
    "_role_common": [
      "self",
      "name",
      "expr"
    ],
    "system": [
      "self",
      "expr"
    ],
    "user": [
      "self",
      "expr"
    ],
    "assistant": [
      "self",
      "expr"
    ],
    "var_scope": [
      "self",
      "name"
    ],
    "fork": [
      "self",
      "size",
      "position_ids_offset"
    ],
    "copy": [
      "self",
      "position_ids_offset"
    ],
    "text": [
      "self"
    ],
    "messages": [
      "self"
    ],
    "sync": [
      "self"
    ],
    "error": [
      "self"
    ],
    "text_iter": [
      "self",
      "var_name"
    ],
    "text_async_iter": [
      "self",
      "var_name",
      "return_meta_data"
    ],
    "get_var": [
      "self",
      "name"
    ],
    "set_var": [
      "self",
      "name",
      "value"
    ],
    "get_meta_info": [
      "self",
      "name"
    ],
    "__iadd__": [
      "self",
      "other"
    ],
    "__getitem__": [
      "self",
      "name"
    ],
    "__setitem__": [
      "self",
      "name",
      "value"
    ],
    "__contains__": [
      "self",
      "name"
    ],
    "__del__": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "ProgramStateGroup": {
    "__init__": [
      "self",
      "states",
      "src_state"
    ],
    "join": [
      "self",
      "mode"
    ],
    "__getitem__": [
      "self",
      "i"
    ],
    "__setitem__": [
      "self",
      "i",
      "value"
    ],
    "__iadd__": [
      "self",
      "other"
    ]
  },
  "StopTracing": {},
  "extract_prefix_by_tracing": [
    "program",
    "backend"
  ],
  "trace_program": [
    "program",
    "arguments",
    "backend"
  ],
  "TracerProgramState": {
    "__init__": [
      "self",
      "backend",
      "arguments",
      "only_trace_prefix"
    ],
    "fork": [
      "self",
      "size",
      "position_ids_offset"
    ],
    "_append_node": [
      "self",
      "other"
    ],
    "_execute": [
      "self",
      "other"
    ],
    "__iadd__": [
      "self",
      "other"
    ],
    "_execute_fill": [
      "self",
      "expr"
    ],
    "_execute_gen": [
      "self",
      "expr"
    ],
    "_execute_select": [
      "self",
      "expr"
    ],
    "_execute_role_begin": [
      "self",
      "expr"
    ],
    "_execute_role_end": [
      "self",
      "expr"
    ],
    "_execute_var_scope_end": [
      "self",
      "expr"
    ],
    "get_var": [
      "self",
      "name"
    ],
    "flatten_nodes": [
      "self"
    ],
    "__del__": [
      "self"
    ]
  },
  "TracingScope": {
    "cur_scope": [],
    "__init__": [
      "self",
      "tracer_state"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_value",
      "traceback"
    ],
    "get_current_scope": [],
    "add_child_state": [
      "self",
      "state"
    ]
  },
  "RuntimeEndpoint": {
    "__init__": [
      "self",
      "base_url",
      "api_key",
      "verify",
      "chat_template_name"
    ],
    "get_model_name": [
      "self"
    ],
    "flush_cache": [
      "self"
    ],
    "get_server_info": [
      "self"
    ],
    "get_chat_template": [
      "self"
    ],
    "cache_prefix": [
      "self",
      "prefix_str"
    ],
    "start_profile": [
      "self"
    ],
    "stop_profile": [
      "self"
    ],
    "commit_lazy_operations": [
      "self",
      "s"
    ],
    "fill_image": [
      "self",
      "s"
    ],
    "_handle_dtype_to_regex": [
      "self",
      "sampling_params"
    ],
    "generate": [
      "self",
      "s",
      "sampling_params"
    ],
    "generate_stream": [
      "self",
      "s",
      "sampling_params"
    ],
    "select": [
      "self",
      "s",
      "choices",
      "temperature",
      "choices_method"
    ],
    "concatenate_and_append": [
      "self",
      "src_rids",
      "dst_rid"
    ],
    "_generate_http_request": [
      "self",
      "s",
      "data"
    ],
    "_add_images": [
      "self",
      "s",
      "data"
    ],
    "_assert_success": [
      "self",
      "res"
    ]
  },
  "compute_normalized_prompt_logprobs": [
    "input_logprobs"
  ],
  "create_logit_bias_int": [
    "tokenizer"
  ],
  "INSTRUCT_MODEL_NAMES": [],
  "TokenUsage": {
    "reset": [
      "self"
    ]
  },
  "openai_completion": [
    "client",
    "token_usage",
    "is_chat",
    "retries",
    "prompt"
  ],
  "openai_completion_stream": [
    "client",
    "token_usage",
    "is_chat",
    "retries",
    "prompt"
  ],
  "BaseBackend": {
    "__init__": [
      "self"
    ],
    "get_model_name": [
      "self"
    ],
    "get_chat_template": [
      "self"
    ],
    "cache_prefix": [
      "self",
      "prefix_str"
    ],
    "uncache_prefix": [
      "self",
      "rid"
    ],
    "end_request": [
      "self",
      "rid"
    ],
    "begin_program": [
      "self",
      "s"
    ],
    "end_program": [
      "self",
      "s"
    ],
    "commit_lazy_operations": [
      "self",
      "s"
    ],
    "fork_program": [
      "self",
      "src",
      "dst",
      "position_ids_offset"
    ],
    "fill_image": [
      "self",
      "s"
    ],
    "generate": [
      "self",
      "s",
      "sampling_params"
    ],
    "generate_stream": [
      "self",
      "s",
      "sampling_params"
    ],
    "select": [
      "self",
      "s",
      "choices",
      "temperature",
      "choices_method"
    ],
    "concatenate_and_append": [
      "self",
      "src_rids",
      "dst_rid"
    ],
    "shutdown": [
      "self"
    ],
    "flush_cache": [
      "self"
    ],
    "get_server_info": [
      "self"
    ]
  }
}