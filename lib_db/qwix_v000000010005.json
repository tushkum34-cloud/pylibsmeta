{
  "__all__": [],
  "QArray": [],
  "quantize": [],
  "dequantize": [],
  "get_current_rule": [],
  "pallas_call": [],
  "dot_general": [],
  "dot": [],
  "einsum": [],
  "wrap_func_intercepted": [
    "func",
    "get_intercept_map"
  ],
  "_wrap_to_call_original_if_needed": [
    "interceptor_id",
    "original_fn",
    "intercept_fn"
  ],
  "_install": [
    "func_map"
  ],
  "_fn_to_code": [
    "fn"
  ],
  "_copy_fn": [
    "fn"
  ],
  "disable_interceptions": [
    "fn"
  ],
  "has_attribute": [
    "name"
  ],
  "ModelType": [],
  "quantize_model": [
    "model",
    "provider"
  ],
  "quantize_linen_model": [
    "model",
    "provider",
    "methods"
  ],
  "quantize_nnx_model": [
    "model",
    "provider"
  ],
  "_input_transform": [
    "provider",
    "args",
    "kwargs"
  ],
  "_output_transform_nnx": [
    "provider",
    "method_name",
    "output"
  ],
  "QuantStat": {},
  "should_update_quant_stats": [],
  "get_current_module": [],
  "get_current_module_path": [],
  "get_or_create_variable": [
    "collection",
    "name",
    "init_fn"
  ],
  "get_and_delete_variable": [
    "collection",
    "name"
  ],
  "get_or_create_param": [
    "name",
    "init_fn"
  ],
  "find_param": [
    "x",
    "ptq_array_type"
  ],
  "unbox": [
    "maybe_boxed"
  ],
  "update_sharding": [
    "spec"
  ],
  "update_boxed": [
    "boxed"
  ],
  "_check_shape": [
    "value",
    "init_fn"
  ],
  "make_rng": [
    "rng_stream"
  ],
  "QuantizationRule": {},
  "QuantizationProvider": {
    "__init__": [
      "self",
      "rules"
    ],
    "_init_rule": [
      "self",
      "rule"
    ],
    "get_intercept_map": [
      "self"
    ],
    "process_model_inputs": [
      "self",
      "model",
      "model_args",
      "model_kwargs"
    ],
    "process_model_output": [
      "self",
      "method_name",
      "model_output"
    ],
    "_get_current_rule_and_op_id": [
      "self",
      "op_name"
    ]
  },
  "SimpleMovingAverage": {
    "__init__": [
      "self",
      "bootstrap_steps"
    ],
    "init": [
      "self",
      "calibration"
    ],
    "update": [
      "self",
      "quant_stat",
      "calibration"
    ],
    "get_calibration": [
      "self",
      "quant_stat",
      "default_calibration"
    ]
  },
  "_MISSING": [],
  "set": [
    "obj",
    "key",
    "value"
  ],
  "get": [
    "obj",
    "key",
    "default"
  ],
  "clear": [
    "obj"
  ],
  "apply_lora_to_model": [
    "model",
    "provider"
  ],
  "LoraRule": {},
  "_find_lora_dim_char": [
    "all_dims"
  ],
  "_parse_einsum_str_for_lora": [
    "lhs_shape",
    "rhs_shape",
    "einsum_str",
    "lora_rank"
  ],
  "LoraProvider": {
    "__init__": [
      "self",
      "rules"
    ],
    "dot_general": [
      "self",
      "lhs",
      "rhs",
      "dimension_numbers",
      "precision",
      "preferred_element_type",
      "out_sharding"
    ],
    "einsum": [
      "self",
      "einsum_str"
    ],
    "conv_general_dilated": [
      "self",
      "lhs",
      "rhs",
      "window_strides",
      "padding",
      "lhs_dilation",
      "rhs_dilation",
      "dimension_numbers",
      "feature_group_count",
      "batch_group_count",
      "precision",
      "preferred_element_type"
    ]
  },
  "_get_or_create_lora_params": [],
  "get_all_ops": [],
  "NotAnActivationError": [],
  "_FQ_RULE": [],
  "_FQ_ARRAY": [],
  "_ALLOW_FUSION": [],
  "_IS_ACTIVATION": [],
  "_WEIGHT_NAME": [],
  "_FIXED_RANGE": [],
  "GetRuleAndOpIdFn": [],
  "FakeQuantFn": [],
  "QuantizedOp": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self"
    ],
    "_inputs_have_activations": [
      "self",
      "args"
    ],
    "_call_original_op": [
      "self"
    ],
    "_fake_quant_inputs": [
      "self",
      "args",
      "rule",
      "op_id"
    ],
    "_maybe_fake_quant": [
      "self",
      "array",
      "rule",
      "quant_stat_name"
    ],
    "_fake_quant_output": [
      "self",
      "array",
      "rule"
    ]
  },
  "OnlyInputOp": {
    "input_idx": [],
    "__call__": [
      "self"
    ]
  },
  "OnlyOutputOp": {
    "input_idx": [],
    "__call__": [
      "self"
    ]
  },
  "TransparentOp": {
    "input_idx": [],
    "forwarded_aux_data": [],
    "__call__": [
      "self"
    ]
  },
  "NoQuantOp": {
    "input_idx": [],
    "__call__": [
      "self"
    ]
  },
  "ModelInput": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "FinalOutput": {
    "__init__": [
      "self"
    ],
    "__call__": [
      "self",
      "x"
    ]
  },
  "BatchNorm": {
    "__call__": [
      "self",
      "norm",
      "x"
    ]
  },
  "Softmax": {
    "input_idx": [],
    "fixed_range_for_output": []
  },
  "Tanh": {
    "input_idx": [],
    "fixed_range_for_output": []
  },
  "UfuncCall": {
    "__call__": [
      "self"
    ],
    "_fake_quant_inputs": [
      "self",
      "args",
      "rule",
      "op_id"
    ],
    "_fake_quant_output": [
      "self",
      "array",
      "rule"
    ]
  },
  "Concatenate": {
    "__call__": [
      "self",
      "arrays"
    ]
  },
  "Take": {
    "input_idx": [],
    "__call__": [
      "self"
    ]
  },
  "Split": {
    "__call__": [
      "self",
      "x",
      "sizes",
      "axis"
    ]
  },
  "Silu": {
    "__call__": [
      "self",
      "x"
    ]
  },
  "DotEinsumConv": {
    "__init__": [
      "self"
    ],
    "_get_how_to_quantize": [
      "self",
      "for_lhs",
      "qtype",
      "calibration_method",
      "args",
      "kwargs"
    ],
    "__call__": [
      "self"
    ]
  },
  "CustomJvpCall": {
    "input_idx": [],
    "__call__": [
      "self"
    ]
  },
  "ArrayTypeVar": [],
  "WithAux": {
    "value": [],
    "shape": [],
    "ndim": [],
    "__getitem__": [],
    "reshape": [
      "self"
    ]
  },
  "PtqProvider": {
    "__init__": [
      "self",
      "rules"
    ],
    "dot_general": [
      "self",
      "lhs",
      "rhs",
      "dimension_numbers",
      "precision",
      "preferred_element_type"
    ],
    "einsum": [
      "self",
      "einsum_str"
    ],
    "conv_general_dilated": [
      "self",
      "lhs",
      "rhs",
      "window_strides",
      "padding",
      "lhs_dilation",
      "rhs_dilation",
      "dimension_numbers",
      "feature_group_count",
      "batch_group_count",
      "precision",
      "preferred_element_type"
    ],
    "nn_param": [
      "self",
      "module",
      "name"
    ],
    "promote_dtype": [
      "self"
    ],
    "dot": [
      "self",
      "a",
      "b",
      "precision",
      "preferred_element_type",
      "out_sharding"
    ],
    "get_intercept_map": [
      "self"
    ]
  },
  "quantize_act": [
    "array",
    "how",
    "rule",
    "act_name"
  ],
  "create_quantized_param": [
    "name",
    "value",
    "how"
  ],
  "quantize_params": [
    "params",
    "abstract_quantized_params",
    "quant_stats"
  ],
  "get_value_from_path": [
    "obj",
    "path"
  ],
  "OdmlQatProvider": {
    "__init__": [
      "self",
      "rules"
    ],
    "_init_rule": [
      "self",
      "rule"
    ],
    "nn_param": [
      "self",
      "module",
      "name",
      "init_fn"
    ],
    "get_intercept_map": [
      "self"
    ],
    "process_model_inputs": [
      "self",
      "model",
      "model_args",
      "model_kwargs"
    ],
    "process_model_output": [
      "self",
      "method_name",
      "model_output"
    ],
    "_fake_quant": [
      "self",
      "array",
      "how",
      "quant_stat_name"
    ],
    "_collect_quant_stat": [
      "self",
      "name",
      "calibration",
      "calibration_is_fixed_range"
    ]
  },
  "OdmlConversionProvider": {
    "__init__": [
      "self",
      "rules",
      "params",
      "quant_stats"
    ],
    "get_intercept_map": [
      "self"
    ],
    "_flatten_dot_general": [
      "self"
    ],
    "_fake_quant": [
      "self",
      "array",
      "how",
      "quant_stat_name"
    ],
    "_compute_static_scale_zero_point": [
      "self",
      "how",
      "quant_stat_name"
    ],
    "_get_attributes": [
      "self"
    ]
  },
  "QtRule": {},
  "QtProvider": {
    "_init_rule": [
      "self",
      "rule"
    ],
    "dot_general": [
      "self",
      "lhs",
      "rhs",
      "dimension_numbers",
      "precision",
      "preferred_element_type"
    ],
    "einsum": [
      "self",
      "einsum_str"
    ],
    "conv_general_dilated": [
      "self",
      "lhs",
      "rhs",
      "window_strides",
      "padding",
      "lhs_dilation",
      "rhs_dilation",
      "dimension_numbers",
      "feature_group_count",
      "batch_group_count",
      "precision",
      "preferred_element_type"
    ],
    "ragged_dot": [
      "self",
      "lhs",
      "rhs",
      "group_sizes",
      "precision",
      "preferred_element_type",
      "group_offset"
    ],
    "get_intercept_map": [
      "self"
    ],
    "_collect_quant_stat": [
      "self",
      "name",
      "batch_axes",
      "calibration"
    ],
    "_create_conv_general_qt_config": [
      "self",
      "rule",
      "op_id",
      "lhs",
      "rhs"
    ],
    "_create_dot_general_qt_config": [
      "self",
      "rule",
      "op_id",
      "lhs",
      "rhs"
    ],
    "_create_ragged_dot_qt_config": [
      "self",
      "rule"
    ]
  },
  "_BASIC_RAGGED_DOT_DIMENSION_NUMBERS": [],
  "_apply_group_channelwise_scale": [
    "rhs_scale",
    "lhs_shape",
    "group_sizes",
    "dimension_numbers",
    "precision",
    "group_offset"
  ],
  "_apply_tiling": [
    "contracting_axes",
    "batch_axes",
    "tiled_axes"
  ],
  "_ragged_get_scale_transpose": [
    "dimension_numbers",
    "ndims"
  ],
  "_fast_ragged_dot_general": [
    "lhs",
    "rhs",
    "group_sizes",
    "dimension_numbers",
    "precision",
    "preferred_element_type",
    "group_offset"
  ],
  "_slow_ragged_dot_general": [
    "lhs",
    "rhs",
    "group_sizes",
    "dimension_numbers"
  ],
  "ragged_dot_general": [
    "lhs",
    "rhs",
    "group_sizes",
    "dimension_numbers",
    "precision",
    "preferred_element_type",
    "group_offset"
  ],
  "ragged_dot": [
    "lhs",
    "rhs",
    "group_sizes",
    "precision",
    "preferred_element_type",
    "group_offset"
  ],
  "low_bit_uniform_noise": [
    "key",
    "shape"
  ],
  "uniform_noise": [
    "key",
    "shape"
  ],
  "get_noise_fn": [
    "method",
    "key",
    "channelwise_noise_axes"
  ],
  "get_how_to_quantize": [],
  "get_transpose": [
    "dimension_numbers",
    "for_lhs"
  ],
  "_slow_conv_general_dilated": [
    "lhs",
    "rhs",
    "window_strides",
    "padding",
    "lhs_dilation",
    "rhs_dilation",
    "dimension_numbers",
    "feature_group_count",
    "batch_group_count",
    "precision",
    "preferred_element_type",
    "out_sharding"
  ],
  "_fast_conv_general_dilated": [
    "lhs",
    "rhs",
    "window_strides",
    "padding",
    "lhs_dilation",
    "rhs_dilation",
    "dimension_numbers",
    "feature_group_count",
    "batch_group_count",
    "preferred_element_type",
    "out_sharding"
  ],
  "conv_general_dilated": [
    "lhs",
    "rhs",
    "window_strides",
    "padding",
    "lhs_dilation",
    "rhs_dilation",
    "dimension_numbers",
    "feature_group_count",
    "batch_group_count",
    "precision",
    "preferred_element_type",
    "out_sharding"
  ],
  "EinsumInfo": {},
  "get_einsum_info": [
    "einsum_str",
    "ndims"
  ],
  "reshape": [
    "array"
  ],
  "rewriting_take": [
    "array",
    "idx"
  ],
  "validate_qarray": [
    "array"
  ],
  "HowToQuantize": {},
  "get_scale_shape": [
    "array_shape",
    "how"
  ],
  "transpose_array": [
    "array",
    "transpose"
  ],
  "split_axis": [
    "array",
    "tiled_axes"
  ],
  "get_tiled_axes": [
    "array"
  ],
  "call_with_generic_broadcast": [
    "op",
    "x",
    "y"
  ],
  "calibrate": [
    "array",
    "how"
  ],
  "compute_scale_zero_point": [
    "calibration",
    "qtype"
  ],
  "quantize_with_scale_zero_point": [
    "array",
    "qtype",
    "scale",
    "zero_point",
    "noise_fn"
  ],
  "quantize_api": [
    "array",
    "qtype"
  ],
  "clip_to_calibration": [
    "array",
    "calibration",
    "tiled_axes"
  ],
  "clip_gradient_to_calibration": [
    "g",
    "array",
    "calibration",
    "calibration_method"
  ],
  "get_accumulator_and_result_type": [],
  "DotGeneralQtConfig": {},
  "_ranges_like": [],
  "_update_dimension_numbers_for_backward": [
    "fwd_dimension_numbers",
    "fwd_ndims"
  ],
  "_apply_rhs_scale_to_lhs": [
    "lhs",
    "rhs_scale",
    "dnums"
  ],
  "dot_general_qt_fwd": [
    "lhs",
    "rhs",
    "lhs_calibration",
    "rhs_calibration",
    "dimension_numbers",
    "config"
  ],
  "dot_general_qt_bwd": [
    "fwd_dimension_numbers",
    "config",
    "residuals",
    "g"
  ],
  "dot_general_qt_fwd_bwd": [
    "lhs",
    "rhs",
    "lhs_calibration",
    "rhs_calibration",
    "dimension_numbers",
    "config"
  ],
  "dot_general_qt": [
    "lhs",
    "rhs",
    "dimension_numbers",
    "config"
  ],
  "ConvGeneralQtConfig": {},
  "_conv_spec_transpose": [],
  "_conv_sdims": [],
  "_compute_dilated_shape": [
    "shape",
    "dilation"
  ],
  "_conv_general_vjp_lhs_padding": [
    "in_shape",
    "window_dimensions",
    "window_strides",
    "out_shape",
    "padding",
    "lhs_dilation",
    "rhs_dilation"
  ],
  "_conv_general_vjp_rhs_padding": [
    "in_shape",
    "window_dimensions",
    "window_strides",
    "out_shape",
    "padding",
    "lhs_dilation",
    "rhs_dilation"
  ],
  "_apply_fwd_scale_to_g": [
    "scale",
    "g",
    "g_axis"
  ],
  "conv_general_qt_fwd": [
    "lhs",
    "rhs",
    "config",
    "window_strides",
    "padding",
    "lhs_dilation",
    "rhs_dilation",
    "dimension_numbers",
    "feature_group_count",
    "batch_group_count"
  ],
  "conv_general_qt_bwd": [
    "config",
    "window_strides",
    "padding",
    "lhs_dilation",
    "rhs_dilation",
    "dimension_numbers",
    "feature_group_count",
    "batch_group_count",
    "res",
    "g"
  ],
  "conv_general_qt": [
    "lhs",
    "rhs",
    "config",
    "window_strides",
    "padding",
    "lhs_dilation",
    "rhs_dilation",
    "dimension_numbers",
    "feature_group_count",
    "batch_group_count"
  ],
  "NoiseFn": [],
  "_QUANTIZE_DTYPES": [],
  "should_quantize": [
    "dtype"
  ],
  "can_dequant_on_output": [
    "qtype"
  ],
  "get_asymmetric_bound": [
    "qtype"
  ],
  "get_symmetric_bound": [
    "qtype"
  ],
  "convert_to": [
    "x",
    "qtype",
    "noise_fn"
  ],
  "convert_from": [
    "x",
    "qtype"
  ],
  "get_nf4_buckets": [],
  "fp_to_nf4": [
    "array"
  ],
  "nf4_to_fp": [
    "array"
  ],
  "_get_scale_transpose": [
    "dimension_numbers",
    "ndims"
  ],
  "_broadcast_axes": [
    "array",
    "shape",
    "axes"
  ],
  "_fast_dot_general": [
    "lhs",
    "rhs",
    "dimension_numbers",
    "preferred_element_type"
  ],
  "_slow_dot_general": [
    "lhs",
    "rhs",
    "dimension_numbers"
  ],
  "loop_dot_general": [
    "lhs",
    "rhs",
    "dimension_numbers",
    "preferred_element_type"
  ],
  "MIN_TILE_SIZE_TO_DEQUANT_ON_OUTPUT": [],
  "RaggedDotQtConfig": {},
  "ragged_dot_qt_fwd": [
    "lhs",
    "rhs",
    "group_sizes",
    "config",
    "precision",
    "preferred_element_type",
    "group_offset"
  ],
  "ragged_dot_qt_bwd": [
    "config",
    "precision",
    "preferred_element_type",
    "group_offset",
    "residuals",
    "g"
  ],
  "ragged_dot_qt": [
    "lhs",
    "rhs",
    "group_sizes",
    "config",
    "precision",
    "preferred_element_type",
    "group_offset"
  ],
  "update_block_specs_for_qarray": [
    "block_specs",
    "args"
  ],
  "transform_block_specs_for_tpu": [
    "block_specs",
    "args"
  ],
  "_reorder": [
    "sequence",
    "order"
  ],
  "_can_fit_tpu_requirements": [
    "block_shape",
    "arg_shape"
  ],
  "_is_optimal_for_tpu": [
    "block_shape",
    "arg_shape"
  ],
  "QARRAY_KEEP_PADDED_SHAPE": [],
  "PaddedQArray": {},
  "pad_to_shape": [
    "array",
    "target_shape"
  ],
  "get_padded_shape": [
    "original_shape",
    "tiled_axes"
  ],
  "_pad_operand_if_qarray": [
    "x"
  ],
  "PaddedPtqProvider": [],
  "cholesky_inverse": [
    "L"
  ],
  "find_params": [
    "w",
    "how"
  ],
  "quantize_weight": [
    "W",
    "H",
    "how",
    "blocksize",
    "percdamp"
  ],
  "compute_hessian": [
    "X"
  ],
  "normalize_weight": [
    "x",
    "contraction_axis"
  ],
  "GptqRule": {},
  "GptqCalibrationProvider": {
    "dot_general": [
      "self",
      "lhs",
      "rhs",
      "dimension_numbers"
    ],
    "get_intercept_map": [
      "self"
    ]
  }
}