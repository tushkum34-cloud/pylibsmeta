{
  "__version__": [],
  "__all__": [],
  "EXTRA_REGISTRY": [],
  "install": [],
  "__docformat__": [],
  "MATArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "normalize_2nd_moment": [
    "x",
    "dim",
    "eps"
  ],
  "EasyDict": {
    "__getattr__": [
      "self",
      "name"
    ],
    "__setattr__": [
      "self",
      "name",
      "value"
    ],
    "__delattr__": [
      "self",
      "name"
    ]
  },
  "activation_funcs": [],
  "_bias_act_ref": [
    "x",
    "b",
    "dim",
    "act",
    "alpha",
    "gain",
    "clamp"
  ],
  "bias_act": [
    "x",
    "b",
    "dim",
    "act",
    "alpha",
    "gain",
    "clamp",
    "impl"
  ],
  "setup_filter": [
    "f",
    "device",
    "normalize",
    "flip_filter",
    "gain",
    "separable"
  ],
  "_get_filter_size": [
    "f"
  ],
  "_get_weight_shape": [
    "w"
  ],
  "_parse_scaling": [
    "scaling"
  ],
  "_parse_padding": [
    "padding"
  ],
  "_ntuple": [
    "n"
  ],
  "to_2tuple": [],
  "_upfirdn2d_ref": [
    "x",
    "f",
    "up",
    "down",
    "padding",
    "flip_filter",
    "gain"
  ],
  "upfirdn2d": [
    "x",
    "f",
    "up",
    "down",
    "padding",
    "flip_filter",
    "gain",
    "impl"
  ],
  "upsample2d": [
    "x",
    "f",
    "up",
    "padding",
    "flip_filter",
    "gain",
    "impl"
  ],
  "FullyConnectedLayer": {
    "__init__": [
      "self",
      "in_features",
      "out_features",
      "bias",
      "activation",
      "lr_multiplier",
      "bias_init"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "_conv2d_wrapper": [
    "x",
    "w",
    "stride",
    "padding",
    "groups",
    "transpose",
    "flip_weight"
  ],
  "conv2d_resample": [
    "x",
    "w",
    "f",
    "up",
    "down",
    "padding",
    "groups",
    "flip_weight",
    "flip_filter"
  ],
  "Conv2dLayer": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "bias",
      "activation",
      "up",
      "down",
      "resample_filter",
      "conv_clamp",
      "channels_last",
      "trainable"
    ],
    "forward": [
      "self",
      "x",
      "gain"
    ]
  },
  "ModulatedConv2d": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "style_dim",
      "demodulate",
      "up",
      "down",
      "resample_filter",
      "conv_clamp"
    ],
    "forward": [
      "self",
      "x",
      "style"
    ]
  },
  "StyleConv": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "style_dim",
      "resolution",
      "kernel_size",
      "up",
      "use_noise",
      "activation",
      "resample_filter",
      "conv_clamp",
      "demodulate"
    ],
    "forward": [
      "self",
      "x",
      "style",
      "noise_mode",
      "gain"
    ]
  },
  "ToRGB": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "style_dim",
      "kernel_size",
      "resample_filter",
      "conv_clamp",
      "demodulate"
    ],
    "forward": [
      "self",
      "x",
      "style",
      "skip"
    ]
  },
  "get_style_code": [
    "a",
    "b"
  ],
  "DecBlockFirst": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "activation",
      "style_dim",
      "use_noise",
      "demodulate",
      "img_channels"
    ],
    "forward": [
      "self",
      "x",
      "ws",
      "gs",
      "E_features",
      "noise_mode"
    ]
  },
  "MappingNet": {
    "__init__": [
      "self",
      "z_dim",
      "c_dim",
      "w_dim",
      "num_ws",
      "num_layers",
      "embed_features",
      "layer_features",
      "activation",
      "lr_multiplier",
      "w_avg_beta"
    ],
    "forward": [
      "self",
      "z",
      "c",
      "truncation_psi",
      "truncation_cutoff",
      "skip_w_avg_update"
    ]
  },
  "DisFromRGB": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DisBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "nf": [
    "stage",
    "channel_base",
    "channel_decay",
    "channel_max"
  ],
  "Mlp": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "window_partition": [
    "x",
    "window_size"
  ],
  "window_reverse": [
    "windows",
    "window_size",
    "H",
    "W"
  ],
  "Conv2dLayerPartial": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "kernel_size",
      "bias",
      "activation",
      "up",
      "down",
      "resample_filter",
      "conv_clamp",
      "trainable"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "WindowAttention": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "down_ratio",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x",
      "mask_windows",
      "mask"
    ]
  },
  "SwinTransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "num_heads",
      "down_ratio",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "calculate_mask": [
      "self",
      "x_size"
    ],
    "forward": [
      "self",
      "x",
      "x_size",
      "mask"
    ]
  },
  "PatchMerging": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "down"
    ],
    "forward": [
      "self",
      "x",
      "x_size",
      "mask"
    ]
  },
  "PatchUpsampling": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "up"
    ],
    "forward": [
      "self",
      "x",
      "x_size",
      "mask"
    ]
  },
  "BasicLayer": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "window_size",
      "down_ratio",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "norm_layer",
      "downsample",
      "use_checkpoint"
    ],
    "forward": [
      "self",
      "x",
      "x_size",
      "mask"
    ]
  },
  "ToToken": {
    "__init__": [
      "self",
      "in_channels",
      "dim",
      "kernel_size",
      "stride"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "EncFromRGB": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvBlockDown": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "activation"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "token2feature": [
    "x",
    "x_size"
  ],
  "feature2token": [
    "x"
  ],
  "Encoder": {
    "__init__": [
      "self",
      "res_log2",
      "img_channels",
      "activation",
      "patch_size",
      "channels",
      "drop_path_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ToStyle": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels",
      "activation",
      "drop_rate"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "DecBlockFirstV2": {
    "__init__": [
      "self",
      "res",
      "in_channels",
      "out_channels",
      "activation",
      "style_dim",
      "use_noise",
      "demodulate",
      "img_channels"
    ],
    "forward": [
      "self",
      "x",
      "ws",
      "gs",
      "E_features",
      "noise_mode"
    ]
  },
  "DecBlock": {
    "__init__": [
      "self",
      "res",
      "in_channels",
      "out_channels",
      "activation",
      "style_dim",
      "use_noise",
      "demodulate",
      "img_channels"
    ],
    "forward": [
      "self",
      "x",
      "img",
      "ws",
      "gs",
      "E_features",
      "noise_mode"
    ]
  },
  "Decoder": {
    "__init__": [
      "self",
      "res_log2",
      "activation",
      "style_dim",
      "use_noise",
      "demodulate",
      "img_channels"
    ],
    "forward": [
      "self",
      "x",
      "ws",
      "gs",
      "E_features",
      "noise_mode"
    ]
  },
  "DecStyleBlock": {
    "__init__": [
      "self",
      "res",
      "in_channels",
      "out_channels",
      "activation",
      "style_dim",
      "use_noise",
      "demodulate",
      "img_channels"
    ],
    "forward": [
      "self",
      "x",
      "img",
      "style",
      "skip",
      "noise_mode"
    ]
  },
  "FirstStage": {
    "__init__": [
      "self",
      "img_channels",
      "img_resolution",
      "dim",
      "w_dim",
      "use_noise",
      "demodulate",
      "activation"
    ],
    "forward": [
      "self",
      "images_in",
      "masks_in",
      "ws",
      "noise_mode"
    ]
  },
  "SynthesisNet": {
    "__init__": [
      "self",
      "w_dim",
      "img_resolution",
      "img_channels",
      "channel_base",
      "channel_decay",
      "channel_max",
      "activation",
      "drop_rate",
      "use_noise",
      "demodulate"
    ],
    "forward": [
      "self",
      "images_in",
      "masks_in",
      "ws",
      "noise_mode",
      "return_stg1"
    ]
  },
  "Generator": {
    "__init__": [
      "self",
      "z_dim",
      "c_dim",
      "w_dim",
      "img_resolution",
      "img_channels",
      "synthesis_kwargs",
      "mapping_kwargs"
    ],
    "forward": [
      "self",
      "images_in",
      "masks_in",
      "z",
      "c",
      "truncation_psi",
      "truncation_cutoff",
      "skip_w_avg_update",
      "noise_mode",
      "return_stg1"
    ]
  },
  "MAT": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "image",
      "mask"
    ]
  },
  "MPRNetArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "conv": [
    "in_channels",
    "out_channels",
    "kernel_size",
    "bias",
    "stride"
  ],
  "CALayer": {
    "__init__": [
      "self",
      "channel",
      "reduction",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CAB": {
    "__init__": [
      "self",
      "n_feat",
      "kernel_size",
      "reduction",
      "bias",
      "act"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SAM": {
    "__init__": [
      "self",
      "n_feat",
      "kernel_size",
      "bias"
    ],
    "forward": [
      "self",
      "x",
      "x_img"
    ]
  },
  "DownSample": {
    "__init__": [
      "self",
      "in_channels",
      "s_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UpSample": {
    "__init__": [
      "self",
      "in_channels",
      "s_factor"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "SkipUpSample": {
    "__init__": [
      "self",
      "in_channels",
      "s_factor"
    ],
    "forward": [
      "self",
      "x",
      "y"
    ]
  },
  "ORB": {
    "__init__": [
      "self",
      "n_feat",
      "kernel_size",
      "reduction",
      "act",
      "bias",
      "num_cab"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ORSNet": {
    "__init__": [
      "self",
      "n_feat",
      "scale_orsnetfeats",
      "kernel_size",
      "reduction",
      "act",
      "bias",
      "scale_unetfeats",
      "num_cab"
    ],
    "forward": [
      "self",
      "x",
      "encoder_outs",
      "decoder_outs"
    ]
  },
  "MPRNet": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x3_img"
    ]
  },
  "RestormerArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "to_3d": [
    "x"
  ],
  "to_4d": [
    "x",
    "h",
    "w"
  ],
  "BiasFree_LayerNorm": {
    "__init__": [
      "self",
      "normalized_shape"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "WithBias_LayerNorm": {
    "__init__": [
      "self",
      "normalized_shape"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "LayerNorm": {
    "__init__": [
      "self",
      "dim",
      "LayerNorm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "FeedForward": {
    "__init__": [
      "self",
      "dim",
      "ffn_expansion_factor",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Attention": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "TransformerBlock": {
    "__init__": [
      "self",
      "dim",
      "num_heads",
      "ffn_expansion_factor",
      "bias",
      "LayerNorm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "OverlapPatchEmbed": {
    "__init__": [
      "self",
      "in_c",
      "embed_dim",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Downsample": {
    "__init__": [
      "self",
      "n_feat"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Upsample": {
    "__init__": [
      "self",
      "n_feat"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Restormer": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inp_img"
    ]
  },
  "linear_rgb_to_lab": [
    "image"
  ],
  "lab_to_linear_rgb": [
    "image",
    "clip"
  ],
  "rgb_to_lab": [
    "image"
  ],
  "lab_to_rgb": [
    "image",
    "clip"
  ],
  "linear_rgb_to_xyz": [
    "image"
  ],
  "xyz_to_linear_rgb": [
    "image"
  ],
  "rgb_to_linear_rgb": [
    "image"
  ],
  "linear_rgb_to_rgb": [
    "image"
  ],
  "_call": [
    "model",
    "input"
  ],
  "_get_encoder_convnext_depths_and_dims": [
    "state_dict"
  ],
  "DDColorArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "PositionEmbeddingSine": {
    "__init__": [
      "self",
      "num_pos_feats",
      "temperature",
      "normalize",
      "scale"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ]
  },
  "DDColor": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "normalize": [
      "self",
      "img"
    ],
    "denormalize": [
      "self",
      "img"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiScaleColorDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_dim",
      "num_queries",
      "nheads",
      "dim_feedforward",
      "dec_layers",
      "pre_norm",
      "color_embed_dim",
      "enforce_input_project",
      "num_scales"
    ],
    "forward": [
      "self",
      "x",
      "img_features"
    ]
  },
  "SingleColorDecoder": {
    "__init__": [
      "self",
      "in_channels",
      "hidden_dim",
      "num_queries",
      "nheads",
      "dropout",
      "dim_feedforward",
      "enc_layers",
      "dec_layers",
      "pre_norm",
      "deep_supervision",
      "enforce_input_project"
    ],
    "forward": [
      "self",
      "img_features",
      "encode_feat"
    ]
  },
  "Block": {
    "__init__": [
      "self",
      "dim",
      "drop_path",
      "layer_scale_init_value"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ConvNeXt": {
    "__init__": [
      "self",
      "in_chans",
      "num_classes",
      "depths",
      "dims",
      "drop_path_rate",
      "layer_scale_init_value",
      "head_init_scale"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "NormType": {
    "Batch": [],
    "BatchZero": [],
    "Weight": [],
    "Spectral": []
  },
  "Hook": {
    "feature": [],
    "__init__": [
      "self",
      "module"
    ],
    "hook_fn": [
      "self",
      "module",
      "input",
      "output"
    ],
    "remove": [
      "self"
    ]
  },
  "SelfAttention": {
    "__init__": [
      "self",
      "n_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "batchnorm_2d": [
    "nf",
    "norm_type"
  ],
  "init_default": [
    "m",
    "func"
  ],
  "icnr": [
    "x",
    "scale",
    "init"
  ],
  "conv1d": [
    "ni",
    "no",
    "ks",
    "stride",
    "padding",
    "bias"
  ],
  "custom_conv_layer": [
    "ni",
    "nf",
    "ks",
    "stride",
    "padding",
    "bias",
    "is_1d",
    "norm_type",
    "use_activ",
    "transpose",
    "init",
    "self_attention",
    "extra_bn"
  ],
  "conv_layer": [
    "ni",
    "nf",
    "ks",
    "stride",
    "padding",
    "bias",
    "is_1d",
    "norm_type",
    "use_activ",
    "transpose",
    "init",
    "self_attention"
  ],
  "CustomPixelShuffle_ICNR": {
    "__init__": [
      "self",
      "ni",
      "nf",
      "scale",
      "blur",
      "norm_type",
      "extra_bn"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "UnetBlockWide": {
    "__init__": [
      "self",
      "up_in_c",
      "x_in_c",
      "n_out",
      "hook",
      "blur",
      "self_attention",
      "norm_type"
    ],
    "forward": [
      "self",
      "up_in"
    ]
  },
  "Transformer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "num_encoder_layers",
      "num_decoder_layers",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before",
      "return_intermediate_dec"
    ],
    "_reset_parameters": [
      "self"
    ],
    "forward": [
      "self",
      "src",
      "mask",
      "query_embed",
      "pos_embed"
    ]
  },
  "TransformerEncoder": {
    "__init__": [
      "self",
      "encoder_layer",
      "num_layers",
      "norm"
    ],
    "forward": [
      "self",
      "src",
      "mask",
      "src_key_padding_mask",
      "pos"
    ]
  },
  "TransformerDecoder": {
    "__init__": [
      "self",
      "decoder_layer",
      "num_layers",
      "norm",
      "return_intermediate"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ]
  },
  "TransformerEncoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos"
    ],
    "forward_pre": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos"
    ],
    "forward": [
      "self",
      "src",
      "src_mask",
      "src_key_padding_mask",
      "pos"
    ]
  },
  "TransformerDecoderLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward_pre": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "tgt_mask",
      "memory_mask",
      "tgt_key_padding_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ]
  },
  "_get_clones": [
    "module",
    "N"
  ],
  "_get_activation_fn": [
    "activation"
  ],
  "SelfAttentionLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "_reset_parameters": [
      "self"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ],
    "forward_pre": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ]
  },
  "CrossAttentionLayer": {
    "__init__": [
      "self",
      "d_model",
      "nhead",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "_reset_parameters": [
      "self"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt",
      "memory",
      "memory_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward_pre": [
      "self",
      "tgt",
      "memory",
      "memory_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ],
    "forward": [
      "self",
      "tgt",
      "memory",
      "memory_mask",
      "memory_key_padding_mask",
      "pos",
      "query_pos"
    ]
  },
  "FFNLayer": {
    "__init__": [
      "self",
      "d_model",
      "dim_feedforward",
      "dropout",
      "activation",
      "normalize_before"
    ],
    "_reset_parameters": [
      "self"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward_post": [
      "self",
      "tgt"
    ],
    "forward_pre": [
      "self",
      "tgt"
    ],
    "forward": [
      "self",
      "tgt"
    ]
  },
  "MLP": {
    "__init__": [
      "self",
      "input_dim",
      "hidden_dim",
      "output_dim",
      "num_layers"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CodeFormerArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "VectorQuantizer": {
    "__init__": [
      "self",
      "codebook_size",
      "emb_dim",
      "beta"
    ],
    "forward": [
      "self",
      "z"
    ],
    "get_codebook_feat": [
      "self",
      "indices",
      "shape"
    ]
  },
  "GumbelQuantizer": {
    "__init__": [
      "self",
      "codebook_size",
      "emb_dim",
      "num_hiddens",
      "straight_through",
      "kl_weight",
      "temp_init"
    ],
    "forward": [
      "self",
      "z"
    ]
  },
  "AttnBlock": {
    "__init__": [
      "self",
      "in_channels"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "VQAutoEncoder": {
    "__init__": [
      "self",
      "img_size",
      "nf",
      "ch_mult",
      "quantizer",
      "res_blocks",
      "attn_resolutions",
      "codebook_size",
      "emb_dim",
      "beta",
      "gumbel_straight_through",
      "gumbel_kl_weight",
      "model_path"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "calc_mean_std": [
    "feat",
    "eps"
  ],
  "adaptive_instance_normalization": [
    "content_feat",
    "style_feat"
  ],
  "TransformerSALayer": {
    "__init__": [
      "self",
      "embed_dim",
      "nhead",
      "dim_mlp",
      "dropout",
      "activation"
    ],
    "with_pos_embed": [
      "self",
      "tensor",
      "pos"
    ],
    "forward": [
      "self",
      "tgt",
      "tgt_mask",
      "tgt_key_padding_mask",
      "query_pos"
    ]
  },
  "normalize": [
    "in_channels"
  ],
  "swish": [
    "x"
  ],
  "ResBlock": {
    "__init__": [
      "self",
      "in_channels",
      "out_channels"
    ],
    "forward": [
      "self",
      "x_in"
    ]
  },
  "Fuse_sft_block": {
    "__init__": [
      "self",
      "in_ch",
      "out_ch"
    ],
    "forward": [
      "self",
      "enc_feat",
      "dec_feat",
      "w"
    ]
  },
  "CodeFormer": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "_init_weights": [
      "self",
      "module"
    ],
    "forward": [
      "self",
      "x",
      "weight"
    ]
  },
  "_inv_channel_query_dict": [],
  "_clean_state_dict": [
    "state_dict"
  ],
  "FeMaSRArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "NormLayer": {
    "__init__": [
      "self",
      "channels",
      "norm_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "ActLayer": {
    "__init__": [
      "self",
      "channels",
      "relu_type"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "CombineQuantBlock": {
    "__init__": [
      "self",
      "in_ch1",
      "in_ch2",
      "out_channel"
    ],
    "forward": [
      "self",
      "input1",
      "input2"
    ]
  },
  "SwinLayers": {
    "__init__": [
      "self",
      "input_resolution",
      "embed_dim",
      "blk_depth",
      "num_heads",
      "window_size"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MultiScaleEncoder": {
    "__init__": [
      "self",
      "in_channel",
      "max_depth",
      "input_res",
      "channel_query_dict",
      "norm_type",
      "act_type",
      "LQ_stage"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "DecoderBlock": {
    "__init__": [
      "self",
      "in_channel",
      "out_channel",
      "norm_type",
      "act_type"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "FeMaSRNet": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "encode_and_decode": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "MIRNet2Arch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "SKFF": {
    "__init__": [
      "self",
      "in_channels",
      "height",
      "reduction",
      "bias"
    ],
    "forward": [
      "self",
      "inp_feats"
    ]
  },
  "ContextBlock": {
    "__init__": [
      "self",
      "n_feat",
      "bias"
    ],
    "modeling": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RCB": {
    "__init__": [
      "self",
      "n_feat",
      "bias",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Down": {
    "__init__": [
      "self",
      "in_channels",
      "chan_factor",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "Up": {
    "__init__": [
      "self",
      "in_channels",
      "chan_factor",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MRB": {
    "__init__": [
      "self",
      "n_feat",
      "chan_factor",
      "bias",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "RRG": {
    "__init__": [
      "self",
      "n_feat",
      "n_MRB",
      "chan_factor",
      "bias",
      "groups"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "MIRNet_v2": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inp_img"
    ]
  },
  "AdaCodeArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "WeightPredictor": {
    "__init__": [
      "self",
      "in_channel",
      "cls",
      "weight_softmax"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "AdaCodeSRNet_Contrast": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "encode_and_decode": [
      "self",
      "input"
    ],
    "forward": [
      "self",
      "input"
    ]
  },
  "M3SNetArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "LayerNormFunction": {
    "forward": [
      "ctx",
      "x",
      "weight",
      "bias",
      "eps"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "LayerNorm2d": {
    "__init__": [
      "self",
      "channels",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "AvgPool2d": {
    "__init__": [
      "self",
      "kernel_size",
      "base_size",
      "auto_pad",
      "fast_imp",
      "train_size"
    ],
    "extra_repr": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "replace_layers": [
    "model",
    "base_size",
    "train_size",
    "fast_imp"
  ],
  "Local_Base": {
    "convert": [
      "self"
    ]
  },
  "SimpleGate": {
    "forward": [
      "self",
      "x"
    ]
  },
  "NAFBlock": {
    "__init__": [
      "self",
      "c",
      "DW_Expand",
      "FFN_Expand",
      "drop_out_rate"
    ],
    "forward": [
      "self",
      "inp"
    ]
  },
  "M3SNet": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "inp"
    ],
    "check_image_size": [
      "self",
      "x"
    ]
  },
  "M3SNetLocal": {
    "__init__": [
      "self"
    ]
  },
  "SRFormerArch": {
    "__init__": [
      "self"
    ],
    "load": [
      "self",
      "state_dict"
    ]
  },
  "pad_to_multiple": [
    "tensor",
    "multiple"
  ],
  "emptyModule": {
    "__init__": [
      "self"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "drop_path": [
    "x",
    "drop_prob",
    "training"
  ],
  "DropPath": {
    "__init__": [
      "self",
      "drop_prob"
    ],
    "forward": [
      "self",
      "x"
    ]
  },
  "dwconv": {
    "__init__": [
      "self",
      "hidden_features"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ]
  },
  "ConvFFN": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "act_layer",
      "drop"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ]
  },
  "PSA": {
    "__init__": [
      "self",
      "dim",
      "window_size",
      "num_heads",
      "qkv_bias",
      "qk_scale",
      "attn_drop",
      "proj_drop"
    ],
    "forward": [
      "self",
      "x",
      "mask"
    ],
    "extra_repr": [
      "self"
    ],
    "flops": [
      "self",
      "n"
    ]
  },
  "PSA_Block": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "num_heads",
      "window_size",
      "shift_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "act_layer",
      "norm_layer"
    ],
    "calculate_mask": [
      "self",
      "x_size"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ],
    "extra_repr": [
      "self"
    ],
    "flops": [
      "self"
    ]
  },
  "PSA_Group": {
    "__init__": [
      "self",
      "dim",
      "input_resolution",
      "depth",
      "num_heads",
      "window_size",
      "mlp_ratio",
      "qkv_bias",
      "qk_scale",
      "drop",
      "attn_drop",
      "drop_path",
      "norm_layer",
      "downsample",
      "use_checkpoint",
      "img_size",
      "patch_size",
      "resi_connection"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ],
    "flops": [
      "self"
    ]
  },
  "PatchEmbed": {
    "__init__": [
      "self",
      "img_size",
      "window_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x"
    ],
    "flops": [
      "self"
    ]
  },
  "PatchUnEmbed": {
    "__init__": [
      "self",
      "img_size",
      "window_size",
      "patch_size",
      "in_chans",
      "embed_dim",
      "norm_layer"
    ],
    "forward": [
      "self",
      "x",
      "x_size"
    ],
    "flops": [
      "self"
    ]
  },
  "UpsampleOneStep": {
    "__init__": [
      "self",
      "scale",
      "num_feat",
      "num_out_ch",
      "input_resolution"
    ],
    "flops": [
      "self"
    ]
  },
  "SRFormer": {
    "hyperparameters": [],
    "__init__": [
      "self"
    ],
    "_init_weights": [
      "self",
      "m"
    ],
    "no_weight_decay": [
      "self"
    ],
    "no_weight_decay_keywords": [
      "self"
    ],
    "forward_features": [
      "self",
      "x"
    ],
    "check_image_size": [
      "self",
      "x"
    ],
    "forward": [
      "self",
      "x"
    ],
    "flops": [
      "self"
    ]
  }
}