{
  "SentenceTokenizer": {
    "PERIOD": [],
    "PERIOD_SPECIAL": [],
    "PATTERNS": [],
    "__init__": [
      "self",
      "period",
      "patterns"
    ],
    "conv_period": [
      "self",
      "item"
    ],
    "tokenize": [
      "self",
      "document"
    ]
  },
  "__version__": [],
  "WordTokenizer": {
    "__init__": [
      "self",
      "tokenizer",
      "user_dictionary_path",
      "system_dictionary_path",
      "model_path",
      "mode",
      "dictionary_format",
      "endpoint",
      "ssl",
      "port"
    ],
    "_setup_tokenizer": [
      "self"
    ],
    "tokenize": [
      "self",
      "text"
    ],
    "batch_tokenize": [
      "self",
      "texts"
    ],
    "_tokenize_with_remote_host": [
      "endpoint",
      "payload",
      "headers"
    ],
    "_batch_tokenize_with_remote_host": [
      "endpoint",
      "payload",
      "headers"
    ],
    "tokenizer": [
      "self"
    ],
    "name": [
      "self"
    ],
    "get_endpoint": [
      "self",
      "method"
    ],
    "payload": [
      "self"
    ],
    "headers": [
      "self"
    ]
  },
  "FORMAT": [],
  "create_app": [],
  "TokenizeParameter": {},
  "router": [],
  "logger": [],
  "generate_cache_key": [
    "params"
  ],
  "batch_tokenize": [
    "params",
    "request"
  ],
  "tokenize": [
    "params",
    "request"
  ],
  "RED": [],
  "RST": [],
  "Resource": {
    "NBYTES": [],
    "KONOHA_DIR": [],
    "__init__": [
      "self",
      "path"
    ],
    "download_from_s3": [
      "self",
      "path"
    ],
    "path": [
      "self"
    ]
  },
  "Token": {
    "__init__": [
      "self",
      "surface",
      "postag",
      "postag2",
      "postag3",
      "postag4",
      "inflection",
      "conjugation",
      "base_form",
      "yomi",
      "pron",
      "normalized_form"
    ],
    "__repr__": [
      "self"
    ],
    "__eq__": [
      "self",
      "right"
    ],
    "surface": [
      "self"
    ],
    "postag": [
      "self"
    ],
    "postag2": [
      "self"
    ],
    "postag3": [
      "self"
    ],
    "postag4": [
      "self"
    ],
    "inflection": [
      "self"
    ],
    "conjugation": [
      "self"
    ],
    "base_form": [
      "self"
    ],
    "yomi": [
      "self"
    ],
    "pron": [
      "self"
    ],
    "normalized_form": [
      "self"
    ],
    "feature_names": [
      "_"
    ],
    "feature": [
      "self"
    ],
    "from_dict": [
      "cls",
      "dict"
    ],
    "dict": [
      "self"
    ]
  },
  "KonohaAPITokenizer": {
    "__init__": [
      "self",
      "tokenizer"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "JanomeTokenizer": {
    "__init__": [
      "self",
      "user_dictionary_path"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "SudachiTokenizer": {
    "__init__": [
      "self",
      "mode"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "parse_feature_for_ipadic": [
    "elem"
  ],
  "parse_feature_for_unidic": [
    "elem"
  ],
  "MeCabTokenizer": {
    "__init__": [
      "self",
      "user_dictionary_path",
      "system_dictionary_path",
      "dictionary_format"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "CharacterTokenizer": {
    "__init__": [
      "self"
    ],
    "tokenize": [
      "_",
      "text"
    ]
  },
  "NagisaTokenizer": {
    "__init__": [
      "self"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "BaseTokenizer": {
    "__init__": [
      "self",
      "name"
    ],
    "tokenize": [
      "_",
      "text"
    ],
    "name": [
      "self"
    ]
  },
  "KyTeaTokenizer": {
    "__init__": [
      "self",
      "model_path"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  },
  "WhitespaceTokenizer": {
    "__init__": [
      "_"
    ],
    "tokenize": [
      "_",
      "text"
    ]
  },
  "SentencepieceTokenizer": {
    "__init__": [
      "self",
      "model_path"
    ],
    "tokenize": [
      "self",
      "text"
    ]
  }
}