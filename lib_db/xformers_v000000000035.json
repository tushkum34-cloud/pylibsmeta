{
  "_scipy_is_available": [],
  "_additional_ignored_ops": [],
  "OPS_TO_ALWAYS_SKIP": [],
  "ProfileMetadata": {},
  "_get_default_policy": [
    "allow_list"
  ],
  "VerboseTorchDispatchMode": {
    "__init__": [
      "self"
    ],
    "__torch_dispatch__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "list_operators": [
    "function"
  ],
  "CachedTorchDispatchMode": {
    "__init__": [
      "self",
      "policy_fn",
      "storage",
      "allow_cache_entry_mutation"
    ],
    "pop_from_storage": [
      "self",
      "func",
      "args",
      "kwargs"
    ]
  },
  "NullTorchDispatchMode": {
    "__torch_dispatch__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "selective_checkpoint_context_fn": [
    "policy_fn"
  ],
  "checkpoint": [
    "function"
  ],
  "ProfileOperatorsTorchDispatchMode": {
    "__init__": [
      "self",
      "num_runs"
    ],
    "_get_inplace_metadata": [
      "self",
      "func",
      "out"
    ],
    "__torch_dispatch__": [
      "self",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "_analyze_operators": [
    "function"
  ],
  "get_optimal_checkpoint_policy": [
    "function"
  ],
  "_optimize_runtime_with_given_memory": [
    "memory",
    "runtimes",
    "max_memory",
    "view_like_ops",
    "inplace_ops",
    "random_ops",
    "force_store_random"
  ],
  "_OptimalPolicy": {
    "__init__": [
      "self",
      "optim_output"
    ],
    "__call__": [
      "self",
      "ctx",
      "func"
    ]
  },
  "SelectiveCheckpointWrapper": {
    "__init__": [
      "self",
      "mod",
      "memory_budget",
      "policy_fn"
    ],
    "_get_policy_fn": [
      "self"
    ],
    "get_policy_fn": [
      "self"
    ],
    "forward": [
      "self"
    ]
  },
  "selective_checkpoint_wrapper": [
    "module",
    "memory_budget",
    "policy_fn"
  ],
  "logger": [],
  "UNAVAILABLE_FEATURES_MSG": [],
  "_BuildInfo": {
    "cuda_version": [
      "self"
    ],
    "hip_version": [
      "self"
    ],
    "torch_version": [
      "self"
    ],
    "python_version": [
      "self"
    ],
    "flash_version": [
      "self"
    ],
    "use_torch_flash": [
      "self"
    ],
    "build_env": [
      "self"
    ]
  },
  "xFormersWasNotBuiltException": {
    "__str__": [
      "self"
    ]
  },
  "xFormersInvalidLibException": {
    "__init__": [
      "self",
      "build_info"
    ],
    "__str__": [
      "self"
    ]
  },
  "_register_extensions": [],
  "_cpp_library_load_exception": [],
  "_built_with_cuda": [],
  "Item": [],
  "import_all_modules": [
    "root",
    "base_module"
  ],
  "get_registry_decorator": [
    "class_registry",
    "name_registry",
    "reference_class",
    "default_config"
  ],
  "generate_matching_config": [
    "superset",
    "config_class"
  ],
  "do_bench_cudagraph": [
    "fn",
    "rep",
    "grad_to_none"
  ],
  "EventOverlapHolder": {
    "capture": [
      "cls",
      "device",
      "name"
    ],
    "__new__": [
      "cls",
      "event_overlap",
      "device",
      "name",
      "requires_grad"
    ],
    "__init__": [
      "self",
      "event_overlap",
      "device",
      "name",
      "requires_grad"
    ],
    "__tensor_flatten__": [
      "self"
    ],
    "__repr__": [
      "self"
    ],
    "current_stream_wait": [
      "self"
    ],
    "__torch_function__": [],
    "__torch_dispatch__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "_ExitCompute": {
    "forward": [
      "ctx"
    ],
    "backward": [
      "ctx",
      "gholder"
    ]
  },
  "_EnterCompute": {
    "forward": [
      "ctx",
      "holder"
    ],
    "backward": [
      "ctx"
    ]
  },
  "_FillGradientForOverlapHolder": {
    "forward": [
      "ctx",
      "holder"
    ],
    "backward": [
      "ctx",
      "gholder"
    ]
  },
  "enter_comm": [],
  "enter_compute": [
    "overlap_holder"
  ],
  "PhaseBoundary": {
    "__post_init__": [
      "self"
    ],
    "__str__": [
      "self"
    ],
    "__call__": [
      "self"
    ]
  },
  "InitialBw": {
    "__init__": [
      "self",
      "trigger_bw"
    ],
    "__call__": [
      "self"
    ]
  },
  "_GlobalAutogradThread": {
    "todo": [],
    "sem": [],
    "run": [
      "cls"
    ],
    "cleanup_at_exit": [
      "cls"
    ]
  },
  "async_bw": [
    "backward_fn"
  ],
  "_WaitInBW": {
    "forward": [
      "ctx",
      "boundary"
    ],
    "backward": [
      "ctx"
    ]
  },
  "_CurrentForwardState": {},
  "before_forward": [
    "record_fw_chunks"
  ],
  "enter_phase": [
    "enter"
  ],
  "flush_single_bw_chunk": [],
  "flush_pending_bw": [],
  "T": [],
  "overlap_fw_bw": [
    "trigger_fw",
    "trigger_bw",
    "initial_bw_chunks"
  ],
  "_overlap_fw_bw": [
    "trigger_fw",
    "trigger_bw",
    "initial_bw_chunks"
  ],
  "__version__": [],
  "get_features_status": [],
  "print_info": [],
  "deprecated_function": [
    "self"
  ],
  "_create_aligned_bias": [],
  "create_attn_bias": [
    "bias_type",
    "batch_size",
    "num_heads",
    "num_heads_groups",
    "q_len",
    "kv_len",
    "device",
    "dtype",
    "requires_grad",
    "fmt",
    "op",
    "page_size"
  ],
  "_rand_seqlens": [
    "r",
    "bs",
    "q_len",
    "kv_len",
    "max_q_minus_k"
  ],
  "_rand_maxed_partition": [
    "r",
    "total",
    "n",
    "mx",
    "positive"
  ],
  "_rand_seqlens_padded_k": [
    "r",
    "bs",
    "q_len",
    "kv_len"
  ],
  "ref_attention": [
    "q",
    "k",
    "v",
    "attn_bias",
    "drop_mask",
    "p",
    "scale"
  ],
  "ref_attention_bmhk": [
    "q",
    "k",
    "v",
    "attn_bias",
    "scale"
  ],
  "pack_kv_cache": [
    "cache_k",
    "cache_v",
    "kv_seqlens",
    "BLOCK_N"
  ],
  "compute_once": [
    "func"
  ],
  "_is_triton_available": [],
  "get_python_lib": [],
  "min_run_time": [],
  "device": [],
  "CASES": [],
  "quantize_kv_int4": [
    "k",
    "num_groups"
  ],
  "AttentionDecodingBase": {
    "__init__": [
      "self",
      "B",
      "Mq",
      "Mkv",
      "Hq",
      "Hkv",
      "K",
      "bw",
      "attn_bias_type"
    ],
    "get_inputs": [
      "self"
    ],
    "fw": [
      "self"
    ]
  },
  "AttentionDecodingCUTLASS": {
    "OP": []
  },
  "AttentionDecodingCK": {
    "OP": [],
    "__init__": [
      "self",
      "B",
      "Mq",
      "Mkv",
      "Hq",
      "Hkv",
      "K",
      "bw",
      "attn_bias_type"
    ]
  },
  "AttentionDecodingSplitKV": {
    "OP": []
  },
  "AttentionDecodingCKSplitKV": {
    "OP": []
  },
  "AttentionDecodingSplitInt4KV": {
    "OP": [],
    "__init__": [
      "self",
      "B",
      "Mq",
      "Mkv",
      "Hq",
      "Hkv",
      "K",
      "bw",
      "attn_bias_type"
    ]
  },
  "AttentionDecodingPyTorchRepeat": {
    "fw": [
      "self"
    ]
  },
  "TEST_CASES": [],
  "get_benchmark_names": [],
  "test_flash_attention_decoder": [
    "name",
    "case"
  ],
  "main": [],
  "TestCase": [],
  "NotSupportedInputError": {},
  "_triton_is_available": [],
  "get_func_name": [
    "fn"
  ],
  "pretty_print": [
    "results",
    "title",
    "units"
  ],
  "pretty_plot": [
    "results",
    "title",
    "units",
    "filename",
    "dash_key",
    "legend_loc"
  ],
  "pretty_barplot": [
    "results",
    "title",
    "units",
    "filename",
    "dash_key"
  ],
  "rmf": [
    "filename"
  ],
  "temp_files_ctx": [
    "num"
  ],
  "META_ALGORITHM": [],
  "BASELINE_DESCRIPTIONS": [],
  "_benchmark_results_from_csv": [
    "filename"
  ],
  "_benchmark_results_to_csv": [
    "filename",
    "results"
  ],
  "_finalize_results": [
    "results"
  ],
  "_render_bar_plot": [
    "results",
    "store_results_folder"
  ],
  "create_argparser": [],
  "benchmark_main_helper": [
    "benchmark_fn",
    "cases",
    "arg_parser"
  ],
  "benchmark_run_and_compare": [
    "benchmark_fn",
    "cases",
    "compare",
    "omit_baselines",
    "fail_if_regression",
    "quiet",
    "optimized_label"
  ],
  "_is_oom_error": [
    "e"
  ],
  "_fail_if_regressions": [
    "results",
    "reference",
    "atol_s",
    "rtol"
  ],
  "benchmark_main_helper2": [
    "name",
    "functions",
    "fw",
    "bw",
    "cuda_graph"
  ],
  "product_dict": [],
  "DTYPE2STR": [],
  "CASES_IADD": [],
  "CASES_ISELECT": [],
  "ScaledIndexAddBenchmark": {
    "__init__": [
      "self",
      "dtype",
      "scaling",
      "shape",
      "bw"
    ],
    "fw": [
      "self"
    ],
    "bw": [
      "self"
    ]
  },
  "ScaledIndexAddBenchmarkBaseline": {
    "fw": [
      "self"
    ]
  },
  "IndexSelectBenchmark": {
    "__init__": [
      "self",
      "dtype",
      "batches",
      "D",
      "keep_ratio",
      "bw"
    ],
    "fw": [
      "self"
    ],
    "bw": [
      "self"
    ]
  },
  "IndexSelectBenchmarkBaseline": {
    "fw": [
      "self"
    ]
  },
  "_merge_attentions_varargs_ref": [
    "attn_split",
    "lse_split"
  ],
  "benchmark_merge_attentions_backward": [
    "split_k",
    "B",
    "M",
    "G",
    "N_H_L",
    "D_H",
    "dtype"
  ],
  "NUM_THREADS": [],
  "VISION_SHAPES": [],
  "LLM_SHAPES": [],
  "OPS": [],
  "LLM_CASE_UPDATES": [],
  "create_tensors": [
    "shape_q",
    "Hkv",
    "dtype",
    "requires_grad",
    "packed"
  ],
  "mem_eff_attention_fw": [
    "shape_q",
    "num_threads",
    "attn_bias_cfg",
    "dropout_p",
    "dtype",
    "packed",
    "Hkv"
  ],
  "mem_eff_attention_bw": [
    "shape_q",
    "num_threads",
    "attn_bias_cfg",
    "dropout_p",
    "dtype",
    "Hkv"
  ],
  "SHAPES": [],
  "matmul_per_tile": [
    "a",
    "b"
  ],
  "benchmark_tiled_matmul": [
    "shape_name",
    "dtype"
  ],
  "Scenario": {},
  "Step": {
    "AllGather": [],
    "ReduceScatter": [],
    "__str__": [
      "self"
    ]
  },
  "Bench": {
    "__getitem__": [
      "self",
      "step"
    ]
  },
  "LLAMA_07B_SLEN": [],
  "LLAMA_07B_D": [],
  "LLAMA_70B_SLEN": [],
  "LLAMA_70B_D": [],
  "round_up_to_nearest_multiple": [
    "n",
    "m"
  ],
  "llama_07B_MHA": [
    "world_size"
  ],
  "llama_07B_FFN": [
    "world_size"
  ],
  "llama_70B_MHA": [
    "world_size"
  ],
  "llama_70B_FFN": [
    "world_size"
  ],
  "SCENARIOS": [],
  "DTYPES": [],
  "run_one_rank": [
    "my_rank",
    "world_size",
    "scenario_name",
    "step",
    "dtype_str",
    "num_rounds",
    "num_warmup_iters",
    "num_bench_iters",
    "profile",
    "conn_from_prev",
    "conn_to_next"
  ],
  "Mlp": {
    "LINEAR_CLS": [],
    "__init__": [
      "self",
      "B_in_hidden_out_ft",
      "dtype",
      "bias",
      "bw"
    ],
    "fw": [
      "self"
    ],
    "bw": [
      "self"
    ]
  },
  "MlpDenseMask": {
    "fw": [
      "self"
    ]
  },
  "MlpAct24": {
    "fw": [
      "self"
    ]
  },
  "LinearW24": {
    "forward": [
      "self",
      "input"
    ]
  },
  "MlpW24": {
    "LINEAR_CLS": []
  },
  "MicrobenchmarkBase": {
    "__init__": [
      "self",
      "B_in_hidden_out_ft",
      "dtype",
      "bias",
      "bw"
    ],
    "bw": [
      "self"
    ]
  },
  "MicrobenchmarkSparsify24": {
    "fw": [
      "self"
    ]
  },
  "MicrobenchmarkSp24ApplyDense": {
    "fw": [
      "self"
    ]
  },
  "MicrobenchmarkSp24ApplyDenseT": {
    "fw": [
      "self"
    ]
  },
  "MicrobenchmarkInputClone": {
    "fw": [
      "self"
    ]
  },
  "functions": [],
  "_ForLoopUnroller": {
    "__init__": [
      "self",
      "target",
      "inline_variables",
      "loop_iter"
    ],
    "visit_Name": [
      "self",
      "node"
    ],
    "visit_Subscript": [
      "self",
      "node"
    ]
  },
  "_VisitorVarargKernel": {
    "__init__": [
      "self",
      "N"
    ],
    "visit_AnnAssign": [
      "self",
      "node"
    ],
    "visit_arguments": [
      "self",
      "node"
    ]
  },
  "_VisitorUnrollKernel": {
    "visit_For": [
      "self",
      "node"
    ]
  },
  "_VisitorConditionalKernel": {
    "__init__": [
      "self"
    ],
    "visit_Subscript": [
      "self",
      "node"
    ],
    "visit_Call": [
      "self",
      "node"
    ]
  },
  "_getlines_orig": [],
  "_should_materialize_codegen": [],
  "_should_keep_materialized_source": [],
  "_tmp_dir": [],
  "_monkey_patched_getlines": [
    "filename",
    "module_globals"
  ],
  "VarargMode": {
    "UNROLL": [],
    "CONDITIONAL": []
  },
  "unroll_varargs": [
    "kernel",
    "N",
    "mode"
  ],
  "VAR_ARGS_ARRAY": [],
  "libdevice_find": [
    "name"
  ],
  "_coo_to_csr": [
    "m",
    "n",
    "row_indices",
    "column_indices"
  ],
  "_csr_to_coo": [
    "m",
    "n",
    "row_offsets",
    "column_indices"
  ],
  "_diffsort": [
    "a"
  ],
  "_get_transpose_info": [
    "m",
    "n",
    "row_indices",
    "row_offsets",
    "column_indices"
  ],
  "_transpose_with_info": [
    "values",
    "_transpose_info"
  ],
  "_transpose": [
    "m",
    "n",
    "row_indices",
    "values",
    "row_offsets",
    "column_indices"
  ],
  "_nonzero_mask_to_sparse_csr_indices": [
    "mask",
    "device"
  ],
  "_dense_to_sparse": [
    "matrix",
    "device"
  ],
  "_round_nnz": [
    "mask",
    "divisible_by"
  ],
  "_dense3d_to_sparse": [
    "matrix",
    "device"
  ],
  "_spmm": [
    "b",
    "layout",
    "values"
  ],
  "_softmax": [
    "layout",
    "values"
  ],
  "_sddmm": [
    "a",
    "b",
    "layout"
  ],
  "BlockSparseTensor": {
    "__new__": [
      "cls",
      "values",
      "layout"
    ],
    "__init__": [
      "self",
      "values",
      "layout"
    ],
    "__repr__": [
      "self"
    ],
    "values": [
      "self"
    ],
    "_raw_wrap": [
      "cls",
      "values",
      "layout"
    ],
    "_wrap": [
      "cls",
      "values",
      "bmat"
    ],
    "_bmm": [
      "cls",
      "arg0",
      "arg1"
    ],
    "_masked_matmul": [
      "cls",
      "a",
      "b",
      "mask"
    ],
    "_softmax": [
      "cls",
      "arg0",
      "dim"
    ],
    "_to": [
      "cls",
      "arg0",
      "device"
    ],
    "_copy": [
      "cls",
      "arg0",
      "arg1"
    ],
    "_equal": [
      "cls",
      "arg0",
      "arg1"
    ],
    "_to_dense": [
      "cls",
      "arg0"
    ],
    "__torch_function__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ],
    "__torch_dispatch__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "get_stack_strides": [
    "tensors",
    "dim"
  ],
  "_stack_or_none_fw": [
    "tensors",
    "dim"
  ],
  "_stack_fw": [
    "tensors",
    "dim"
  ],
  "_Unbind": {
    "forward": [
      "ctx",
      "x",
      "dim"
    ],
    "backward": [
      "cls",
      "ctx"
    ]
  },
  "_StackOrNone": {
    "forward": [
      "ctx",
      "dim"
    ],
    "backward": [
      "cls",
      "ctx",
      "grad"
    ]
  },
  "unbind": [
    "x",
    "dim"
  ],
  "stack_or_none": [
    "tensors",
    "dim"
  ],
  "rope_padded": [
    "xq",
    "xk",
    "xv",
    "cache_k",
    "cache_v",
    "attn_bias"
  ],
  "SparsifyBothWays": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "SparsifyApply": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "SparsifyApplyDenseOutput": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "Sp24Gemm": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "_get_cusparselt_torch_version": [],
  "_cusplt_version": [],
  "_cusplt_version_str": [],
  "Sp24GemmCuspltSearch": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "Sp24GemmCusplt": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "_has_cusparseLt": [],
  "sparse24_pointwise_op": [
    "func",
    "types",
    "args",
    "kwargs",
    "allow_sparsify_args_list"
  ],
  "sparse24_mm": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "sparse24_addmm": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "sparse24_linear": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "sparse24_t": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "sparse24_view": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "sparse24_detach": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "no_dispatch": [],
  "fallback_dispatcher": [
    "func",
    "types",
    "args",
    "kwargs"
  ],
  "SPARSE24_DISPATCH_CUTLASS": [],
  "SPARSE24_DISPATCH_CUSPARSELT": [],
  "Sparse24Tensor": {
    "__slots__": [],
    "__new__": [
      "cls",
      "shape",
      "packed",
      "meta",
      "packed_t",
      "meta_t",
      "threads_masks"
    ],
    "__repr__": [
      "self"
    ],
    "_sp24_to_dense": [
      "self"
    ],
    "_mm": [
      "self",
      "B"
    ],
    "__torch_function__": [],
    "__tensor_flatten__": [
      "self"
    ],
    "__tensor_unflatten__": [
      "cls",
      "inner_tensors",
      "flatten_spec",
      "outer_size",
      "outer_stride"
    ]
  },
  "Sparse24TensorCutlass": {
    "_mm": [
      "self",
      "B"
    ],
    "__torch_dispatch__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "_CUSPLT_TUNE": [],
  "_cusplt_find_alg": [
    "shape",
    "packed",
    "B",
    "bias",
    "transpose_result"
  ],
  "_cusplt_mm": [
    "shape",
    "packed",
    "B",
    "bias",
    "transpose_result"
  ],
  "_cusplt_mm_meta": [
    "shape",
    "packed",
    "B",
    "bias",
    "transpose_result"
  ],
  "Sparse24TensorCuSparseLt": {
    "_mm": [
      "self",
      "B"
    ],
    "__torch_dispatch__": [
      "cls",
      "func",
      "types",
      "args",
      "kwargs"
    ]
  },
  "GRADIENT_SP24": [],
  "GRADIENT_DENSE": [],
  "GRADIENT_STE": [],
  "BACKEND_CUTLASS": [],
  "BACKEND_CUSPARSELT": [],
  "BACKEND_DENSE": [],
  "_sparsify24_forward": [
    "x"
  ],
  "_Sparsify24Func": {
    "forward": [
      "ctx",
      "x",
      "algo",
      "gradient",
      "backend"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_Sparsify24STEFunc": {
    "forward": [
      "ctx",
      "x",
      "algo",
      "backend",
      "bw_mul0",
      "bw_mul1"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "_Sparsify24LikeFunc": {
    "forward": [
      "ctx",
      "x",
      "pattern",
      "gradient",
      "backend"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "F": [],
  "allow_in_graph": [
    "func"
  ],
  "sparsify24": [
    "x",
    "algo",
    "gradient",
    "backend"
  ],
  "sparsify24_ste": [
    "x",
    "algo",
    "backend",
    "bw_mul0",
    "bw_mul1"
  ],
  "sparsify24_like": [
    "x",
    "pattern",
    "gradient",
    "backend",
    "out_dense"
  ],
  "all_reduce": [
    "x"
  ],
  "gather_along_first_dim_async": [
    "input_"
  ],
  "reduce_scatter_along_first_dim_async": [
    "input_"
  ],
  "gather_along_first_dim": [
    "input_"
  ],
  "reduce_scatter_along_first_dim": [
    "input_"
  ],
  "_CopyToModelParallelRegion": {
    "forward": [
      "ctx",
      "input_",
      "process_group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "copy_to_model_parallel_region": [
    "x",
    "process_group"
  ],
  "_ReduceFromModelParallelRegion": {
    "forward": [
      "ctx",
      "input_",
      "process_group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "reduce_from_model_parallel_region": [
    "x",
    "process_group"
  ],
  "_GatherFromSequenceParallelRegion": {
    "forward": [
      "ctx",
      "x",
      "process_group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "gather_from_sequence_parallel_region": [
    "x",
    "process_group"
  ],
  "_ScatterToSequenceParallelRegion": {
    "forward": [
      "ctx",
      "x",
      "process_group"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "scatter_to_sequence_parallel_region": [
    "x",
    "process_group"
  ],
  "_init_2d_weight": [
    "weight",
    "init_method",
    "process_group",
    "partition_dim"
  ],
  "ColumnParallelLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "RowParallelLinear": {
    "__init__": [
      "self",
      "in_features",
      "out_features"
    ],
    "forward": [
      "self",
      "input_"
    ]
  },
  "TreeAttnMetadata": {
    "from_tree_choices_cached": [
      "cls",
      "tree_choices",
      "dtype",
      "device"
    ],
    "from_tree_choices": [
      "cls",
      "tree_choices",
      "dtype",
      "device"
    ]
  },
  "_get_subtree_size_and_num_children_per_node_at_level": [
    "num_nodes_per_level",
    "num_children_per_node",
    "device"
  ],
  "_get_depth_counts": [
    "sorted_tree_choices"
  ],
  "_get_num_nodes_per_level": [
    "depth_counts",
    "device"
  ],
  "_prepare_tree_attn_bias": [
    "sorted_tree_choices",
    "depth_counts",
    "dtype",
    "device"
  ],
  "_prepare_tree_indices": [
    "sorted_tree_choices",
    "depth_counts",
    "device"
  ],
  "_prepare_retrieval_indices": [
    "tree_choices",
    "device"
  ],
  "_prepare_tree_position_ids": [
    "depth_counts",
    "tree_len",
    "device"
  ],
  "_prepare_parent_node_indices": [
    "sorted_tree_choices",
    "device"
  ],
  "_prepare_child_node_indices": [
    "tree_choices",
    "device"
  ],
  "_prepare_candidate_idx": [
    "tree_choices",
    "device"
  ],
  "use_triton_splitk_for_prefix": [
    "B",
    "G",
    "tree_size"
  ],
  "select_prefix_op": [
    "B",
    "G",
    "tree_size",
    "autotune",
    "attn_bias",
    "kv_cache_dtype"
  ],
  "tree_attention": [
    "q",
    "spec_k",
    "spec_v",
    "cache_k",
    "cache_v",
    "spec_attn_bias",
    "prefix_attn_bias",
    "prefix_op",
    "suffix_op",
    "autotune",
    "quantized_kv_scales"
  ],
  "SplitKAutotune": {
    "AUTOTUNE": []
  },
  "construct_full_tree_choices": [
    "tree_depth",
    "branching"
  ],
  "construct_tree_choices": [
    "branching"
  ],
  "get_full_tree_size": [
    "tree_depth",
    "branching"
  ],
  "ScaledIndexAddFw": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "ScaledIndexAddBw": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "IndexSelect": {
    "OPERATOR": [],
    "OPERATOR_CATEGORY": [],
    "NAME": []
  },
  "_ScaledIndexAdd": {
    "forward": [
      "ctx",
      "x",
      "index",
      "source",
      "scaling",
      "alpha"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "scaled_index_add": [
    "input",
    "index",
    "source",
    "scaling",
    "alpha"
  ],
  "_IndexSelectCat": {
    "forward": [
      "ctx"
    ],
    "backward": [
      "ctx",
      "grad_output"
    ]
  },
  "index_select_cat": [
    "sources",
    "indices"
  ],
  "_should_use_triton": [
    "device",
    "dtype"
  ],
  "check_inputs": [
    "a",
    "b"
  ],
  "check_output": [
    "out",
    "ms",
    "ns"
  ],
  "tiled_matmul_out": [
    "a",
    "b",
    "out"
  ],
  "_flatten": [
    "x",
    "rows",
    "cols"
  ],
  "_unflatten": [
    "flat_x",
    "rows",
    "cols"
  ],
  "_flattened_transpose": [
    "flat_x",
    "rows",
    "cols"
  ],
  "tiled_matmul_fwd": [
    "flat_a",
    "flat_b",
    "ms",
    "ns",
    "ks"
  ],
  "tiled_matmul_fwd_fake": [
    "flat_a",
    "flat_b",
    "ms",
    "ns",
    "ks"
  ],
  "tiled_matmul_setup_context": [
    "ctx",
    "inputs",
    "output"
  ],
  "tiled_matmul_bwd": [
    "ctx",
    "flat_grad_c"
  ],
  "tiled_matmul": [
    "a",
    "b"
  ],
  "_SwiGLUDecomposedFunc": {
    "NAME": [],
    "FORCE_BW_F32": [],
    "_silu_backward": [
      "dy",
      "x"
    ],
    "forward": [
      "cls",
      "ctx",
      "x",
      "w1",
      "b1",
      "w2",
      "b2",
      "w3",
      "b3"
    ],
    "backward": [
      "cls",
      "ctx",
      "dx5"
    ]
  },
  "SwiGLUOp": {
    "__init__": [
      "self",
      "op",
      "packed_weights",
      "name",
      "constraints"
    ],
    "supports": [
      "self",
      "op"
    ],
    "__call__": [
      "self"
    ],
    "__str__": [
      "self"
    ]
  },
  "_ForwardToPythonAutogradFunc": {
    "supports": [
      "self",
      "op"
    ],
    "__call__": [
      "self"
    ]
  },
  "_ForwardToFunc": {
    "__call__": [
      "self"
    ],
    "info": [
      "self"
    ]
  },
  "_eager_functional_swiglu": [
    "x",
    "w1",
    "b1",
    "w2",
    "b2",
    "w3",
    "b3"
  ],
  "SwiGLUOpDispatch": {
    "op": [
      "self"
    ],
    "from_arguments": [
      "x",
      "w1",
      "b1",
      "w2",
      "b2",
      "w3",
      "b3"
    ]
  },
  "_bias_enabled": [
    "op"
  ],
  "_SwiGLUDecomposedOp": [],
  "SwiGLUEagerOp": [],
  "swiglu": [
    "x",
    "w1",
    "b1",
    "w2",
    "b2",
    "w3",
    "b3"
  ],
  "swiglu_packed": [
    "x",
    "w1w2",
    "b1b2",
    "w3",
    "b3"
  ],
  "SwiGLU": {
    "__init__": [
      "self",
      "in_features",
      "hidden_features",
      "out_features",
      "bias"
    ],
    "forward": [
      "self",
      "x"
    ],
    "_ordered_params": [
      "self"
    ],
    "_packed_ordered_params": [
      "self"
    ]
  },
  "get_operator": [
    "library",
    "name"
  ],
  "get_xformers_operator": [
    "name"
  ],
  "BaseOperator": {
    "is_available": [
      "cls"
    ]
  },
  "ClsT": [],
  "register_operator": [
    "cls"
  ],
  "_GET_TENSOR_STORAGE": [],
  "_get_storage_base": [
    "x"
  ],
  "sequence_parallel_leading_matmul_fwd": [
    "scattered_input",
    "weights",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_leading_matmul_fwd_fake": [
    "scattered_input",
    "weights",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_leading_matmul_bwd": [
    "scattered_input",
    "weights",
    "grad_gathered_outputs",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_leading_matmul_bwd_fake": [
    "scattered_input",
    "weights",
    "grad_gathered_outputs",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_leading_matmul_setup_context": [
    "ctx",
    "inputs",
    "output"
  ],
  "sequence_parallel_leading_matmul_bwd_bridge": [
    "ctx",
    "grad_gathered_outputs"
  ],
  "sequence_parallel_leading_matmul": [
    "x",
    "ws"
  ],
  "sequence_parallel_trailing_matmul_fwd": [
    "gathered_input",
    "weight",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_trailing_matmul_fwd_fake": [
    "gathered_input",
    "weight",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_trailing_matmul_bwd": [
    "gathered_input",
    "weight",
    "grad_scattered_output",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_trailing_matmul_bwd_fake": [
    "gathered_input",
    "weight",
    "grad_scattered_output",
    "fuse",
    "process_group_name"
  ],
  "sequence_parallel_trailing_matmul_setup_context": [
    "ctx",
    "inputs",
    "output"
  ],
  "sequence_parallel_trailing_matmul_bwd_bridge": [
    "ctx",
    "grad_scattered_output"
  ],
  "sequence_parallel_trailing_matmul": [
    "x",
    "w"
  ],
  "OP_FINISHED_CHANNEL": [],
  "COMMS_READY_CHANNEL": [],
  "MS_IN_S": [],
  "_is_fp8_dtype": [
    "dt"
  ],
  "_FusedSequenceParallel": {
    "__init__": [
      "self",
      "device",
      "group"
    ],
    "make_stream_factory": [
      "self",
      "current_stream"
    ],
    "allgather_and_linear": [
      "self",
      "scattered_inputs",
      "my_matmul",
      "timeout_s",
      "_wait",
      "_memcpy"
    ],
    "linear_and_reducescatter": [
      "self",
      "my_matmul",
      "gathered_outputs",
      "scattered_outputs",
      "timeout_s",
      "_wait",
      "_memcpy"
    ]
  },
  "_can_ranks_communicate_all_to_all_over_nvlink": [
    "group"
  ],
  "_lazy_init": [
    "device",
    "group"
  ],
  "_default_stream_factory": [],
  "fused_allgather_and_linear": [
    "scattered_input",
    "weight"
  ],
  "_fused_allgather_and_linear_custom_op": [
    "scattered_input",
    "weights",
    "process_group_name",
    "gathered_outputs",
    "timeout_s",
    "_wait",
    "_memcpy",
    "scale_scattered_input",
    "scales_weights"
  ],
  "fused_allgather_and_anything": [
    "scattered_inputs",
    "my_matmul"
  ],
  "fused_linear_and_reducescatter": [
    "gathered_input",
    "weight"
  ],
  "_fused_linear_and_reducescatter_custom_op": [
    "gathered_input",
    "weights",
    "process_group_name",
    "scattered_outputs",
    "timeout_s",
    "_wait",
    "_memcpy",
    "scale_gathered_input",
    "scales_weights"
  ],
  "fused_anything_and_reducescatter": [
    "my_matmul",
    "scattered_outputs"
  ],
  "AttentionMask": [],
  "masked_matmul": [
    "a",
    "b",
    "mask"
  ],
  "__all__": [],
  "rms_norm": [
    "x",
    "weight",
    "eps"
  ],
  "rms_norm_add": [
    "x",
    "y",
    "weight",
    "eps"
  ],
  "RMSNorm": {
    "__init__": [
      "self",
      "dim",
      "include_weight",
      "eps"
    ],
    "forward": [
      "self",
      "x"
    ],
    "increment_and_forward_": [
      "self",
      "x",
      "y"
    ]
  },
  "_to_device": [
    "t",
    "device"
  ],
  "_to_device_tensor": [
    "seq",
    "dtype",
    "device"
  ],
  "AttentionBias": {
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "_get_default_bias_device": [
    "device"
  ],
  "_materialize_causal_mask": [
    "shape",
    "dtype",
    "device"
  ],
  "LowerTriangularMask": {
    "__init__": [
      "self",
      "device"
    ],
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "add_bias": [
      "self",
      "bias"
    ]
  },
  "LocalAttentionFromBottomRightMask": {
    "to": [
      "self",
      "device"
    ],
    "__post_init__": [
      "self"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "LowerTriangularFromBottomRightMask": {
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "make_local_attention": [
      "self",
      "window_size"
    ]
  },
  "LowerTriangularFromBottomRightLocalAttentionMask": {
    "to": [
      "self",
      "device"
    ],
    "__post_init__": [
      "self"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "LowerTriangularMaskWithTensorBias": {
    "__init__": [
      "self",
      "bias"
    ],
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "_SeqLenInfo": {
    "to": [
      "self",
      "device"
    ],
    "intervals": [
      "self"
    ],
    "_get_seqstart": [
      "cls",
      "seqlens"
    ],
    "from_seqlens": [
      "cls",
      "seqlens"
    ],
    "from_seqlens_inplace": [
      "self",
      "seqlens"
    ],
    "split": [
      "self",
      "x",
      "batch_sizes"
    ]
  },
  "_PaddedSeqLenInfo": {
    "__post_init__": [
      "self"
    ],
    "to": [
      "self",
      "device"
    ],
    "intervals": [
      "self"
    ],
    "from_seqlens": [
      "cls",
      "seqlens"
    ],
    "from_seqlens_padded": [
      "cls",
      "seqlens",
      "padding"
    ],
    "from_seqlens_padded_inplace": [
      "self",
      "seqlens"
    ],
    "split": [
      "self",
      "x",
      "batch_sizes"
    ]
  },
  "_GappySeqInfo": {
    "to": [
      "self",
      "device"
    ],
    "intervals": [
      "self"
    ],
    "from_seqlens": [
      "cls",
      "seqlens"
    ],
    "from_seqlens_gappy": [
      "cls",
      "seqstarts",
      "seqlens",
      "paged"
    ],
    "split": [
      "self",
      "x",
      "batch_sizes"
    ]
  },
  "BlockDiagonalMask": {
    "to": [
      "self",
      "device"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens": [
      "cls",
      "q_seqlen",
      "kv_seqlen"
    ],
    "from_tensor_list": [
      "cls",
      "tensors"
    ],
    "from_tensor_lists_qkv": [
      "cls",
      "tensors_q",
      "tensors_k",
      "tensors_v"
    ],
    "split_queries": [
      "self",
      "tensor"
    ],
    "split_kv": [
      "self",
      "tensor"
    ],
    "split": [
      "self",
      "tensor"
    ],
    "make_causal": [
      "self"
    ],
    "make_causal_from_bottomright": [
      "self"
    ],
    "make_local_attention": [
      "self",
      "window_size"
    ],
    "make_local_attention_from_bottomright": [
      "self",
      "window_size"
    ]
  },
  "BlockDiagonalCausalMask": {
    "to": [
      "self",
      "device"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "BlockDiagonalCausalFromBottomRightMask": {
    "to": [
      "self",
      "device"
    ],
    "__post_init__": [
      "self"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "BlockDiagonalPaddedKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens": [
      "cls",
      "q_seqlen",
      "kv_padding",
      "kv_seqlen",
      "causal_diagonal"
    ],
    "make_paged": [
      "self",
      "block_tables",
      "page_size",
      "paged_type"
    ],
    "make_local_attention": [
      "self",
      "window_left",
      "window_right"
    ]
  },
  "BlockDiagonalCausalWithOffsetPaddedKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens": [
      "cls",
      "q_seqlen",
      "kv_padding",
      "kv_seqlen",
      "causal_diagonal"
    ]
  },
  "BlockDiagonalLocalAttentionPaddedKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens_local": [
      "cls",
      "q_seqlen",
      "kv_padding",
      "kv_seqlen",
      "window_left",
      "window_right"
    ]
  },
  "BlockDiagonalCausalLocalAttentionPaddedKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens_local": [
      "cls",
      "q_seqlen",
      "kv_padding",
      "kv_seqlen",
      "window_size"
    ]
  },
  "PagedBlockDiagonalPaddedKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens": [
      "cls",
      "q_seqlen",
      "kv_seqlen",
      "block_tables",
      "page_size"
    ]
  },
  "PagedBlockDiagonalCausalWithOffsetPaddedKeysMask": {
    "_UNPAGED_TYPE": [],
    "to": [
      "self",
      "device"
    ]
  },
  "BlockDiagonalGappyKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens": [
      "cls",
      "q_seqlen",
      "kv_seqstarts",
      "kv_seqlen"
    ],
    "make_paged": [
      "self",
      "block_tables",
      "page_size",
      "notional_padding",
      "paged_type"
    ]
  },
  "BlockDiagonalCausalWithOffsetGappyKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "PagedBlockDiagonalGappyKeysMask": {
    "to": [
      "self",
      "device"
    ],
    "materialize": [
      "self",
      "shape",
      "dtype",
      "device"
    ],
    "from_seqlens": [
      "cls",
      "q_seqlen",
      "kv_seqstarts",
      "kv_seqlen",
      "block_tables",
      "page_size"
    ]
  },
  "PagedBlockDiagonalCausalWithOffsetGappyKeysMask": {
    "_UNPAGED_TYPE": [],
    "to": [
      "self",
      "device"
    ]
  },
  "BlockDiagonalCausalLocalAttentionMask": {
    "to": [
      "self",
      "device"
    ],
    "__post_init__": [
      "self"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "BlockDiagonalCausalLocalAttentionFromBottomRightMask": {
    "to": [
      "self",
      "device"
    ],
    "__post_init__": [
      "self"
    ],
    "_create_block_mask": [
      "self",
      "shape",
      "dtype",
      "device"
    ]
  },
  "VARLEN_BIASES": [],
  "_strides": [
    "x"
  ],
  "_is_supported_causal_bias": [
    "attn_bias"
  ],
  "_is_supported_local_bias": [
    "attn_bias"
  ],
  "_is_supported_gappy_bias": [
    "attn_bias"
  ],
  "_is_supported_paged_bias": [
    "attn_bias"
  ],
  "InputsFp8": {
    "nbytes": [
      "self"
    ]
  },
  "_is_cuda": [],
  "_is_cuda_at_least_sm80": [
    "device"
  ],
  "FwOp": {
    "OPERATOR": [],
    "SUPPORTED_DEVICES": [],
    "CUDA_MINIMUM_COMPUTE_CAPABILITY": [],
    "SUPPORTED_DTYPES": [],
    "SUPPORTED_MAX_K": [],
    "SUPPORTS_DROPOUT": [],
    "SUPPORTS_CUSTOM_SCALE": [],
    "SUPPORTS_BMGHK": [],
    "SUPPORTS_OUTPUT_DTYPE": [],
    "SUPPORTS_PARTIAL": [],
    "NAME": [],
    "MAX_BLOCK_M": [],
    "AUTOTUNE": [],
    "NUM_GROUPS": [],
    "NUM_GROUPS_VALUES": [],
    "shape_not_supported_reasons": [
      "cls",
      "Mq",
      "Mkv",
      "K",
      "Kv"
    ],
    "not_supported_reasons": [
      "cls",
      "d"
    ],
    "get_split_k": [
      "cls",
      "B",
      "G",
      "H",
      "Mk",
      "Mq",
      "page_size",
      "is_paged"
    ],
    "get_kernel": [
      "cls"
    ],
    "get_fp8_scale_shift": [
      "cls",
      "inp"
    ],
    "get_extra_args": [
      "cls"
    ],
    "apply": [
      "cls",
      "inp",
      "needs_gradient"
    ],
    "get_operator": [
      "cls",
      "splitk"
    ]
  },
  "merge_attentions": [
    "attn_out",
    "lse_out",
    "attn_split",
    "lse_split"
  ],
  "merge_attentions_varargs": [
    "attn_split",
    "lse_split",
    "write_lse",
    "output_dtype",
    "B",
    "M",
    "G",
    "H",
    "Kq"
  ],
  "merge_attentions_varargs_fake": [
    "attn_split",
    "lse_split",
    "write_lse",
    "output_dtype",
    "B",
    "M",
    "G",
    "H",
    "Kq"
  ],
  "_merge_attentions_backward": [
    "ctx",
    "grad"
  ],
  "merge_attentions_varargs_backward": [
    "attn_split",
    "lse_split",
    "attn_out",
    "lse_out",
    "grad_attn",
    "grad_lse"
  ],
  "merge_attentions_varargs_backward_fake": [
    "attn_split",
    "lse_split",
    "attn_out",
    "lse_out",
    "grad_attn",
    "grad_lse"
  ],
  "_prepare_reduce_kernel_params": [
    "attn_out",
    "lse_out",
    "attn_split",
    "lse_split",
    "grad_attn",
    "grad_lse"
  ],
  "FwOp_Map": [],
  "FwOp_S1": [],
  "FwOp_S2": [],
  "FwOp_S4": [],
  "FwOp_S8": [],
  "FwOp_S16": [],
  "FwOp_S32": [],
  "FwOp_S64": [],
  "FwOp_S128": [],
  "_USE_FLASH_ATTENTION_3": [],
  "_set_use_fa3": [
    "use_flash_attention3"
  ],
  "_get_use_fa3": [],
  "fa3_available": [],
  "_format_inputs_description": [
    "inp"
  ],
  "_ensure_op_supports_or_raise": [
    "exc_type",
    "name",
    "op",
    "inp"
  ],
  "_format_not_supported_reasons": [
    "op",
    "reasons"
  ],
  "_run_priority_list": [
    "name",
    "priority_list",
    "inp",
    "extra_op_reasons"
  ],
  "_dispatch_fw_priority_list": [
    "inp",
    "needs_gradient"
  ],
  "_dispatch_fw": [
    "inp",
    "needs_gradient"
  ],
  "_dispatch_bw": [
    "inp",
    "varlen_lse_packed"
  ],
  "_get_operator": [
    "name"
  ],
  "_convert_input_format": [
    "inp"
  ],
  "_is_seqlen_q_le_seqlen_k": [
    "cu_seqlens_q_py",
    "cu_seqlens_k_py"
  ],
  "_is_causal": [
    "attn_bias"
  ],
  "_is_bottom_right": [
    "attn_bias"
  ],
  "_window_size": [
    "attn_bias"
  ],
  "BwOp": {
    "__doc__": [],
    "OPERATOR": [],
    "SUPPORTED_DEVICES": [],
    "SUPPORTED_DTYPES": [],
    "SUPPORTED_MAX_K": [],
    "SUPPORTED_MIN_K": [],
    "SUPPORTS_ATTN_BIAS_GRAD": [],
    "SUPPORTS_DROPOUT": [],
    "SUPPORTS_CUSTOM_SCALE": [],
    "SUPPORTS_DIFFERENT_VALUE_EMBED": [],
    "SUPPORTS_BMGHK": [],
    "VARLEN_LSE_PACKED": [],
    "SUPPORTS_PARTIAL": [],
    "CUDA_MINIMUM_COMPUTE_CAPABILITY": [],
    "NAME": [],
    "not_supported_reasons": [
      "cls",
      "d"
    ],
    "shape_not_supported_reasons": [
      "cls",
      "Mq",
      "Mkv",
      "K",
      "Kv"
    ],
    "apply": [
      "cls",
      "ctx",
      "inp",
      "grad"
    ]
  },
  "is_pt_cutlass_compatible": [
    "force"
  ],
  "ensure_pt_flash_ok": [],
  "_PartialFunc": {
    "forward": [
      "ctx",
      "query",
      "key",
      "value",
      "attn_bias",
      "p",
      "scale",
      "op",
      "output_dtype"
    ],
    "backward": [
      "ctx",
      "grad_attn",
      "lse",
      "out"
    ]
  },
  "_MergeFunc": {
    "forward": [
      "ctx"
    ],
    "backward": [
      "ctx",
      "grad_out"
    ]
  },
  "Partial": {
    "__init__": [
      "self",
      "attn",
      "lse",
      "placeholder"
    ],
    "is_bmghk": [
      "self"
    ],
    "apply": [
      "self",
      "fn"
    ],
    "_tuple": [
      "self"
    ]
  },
  "memory_efficient_attention_partial_autograd": [
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "merge_attentions_autograd": [],
  "_is_bias_type_supported_in_BMK": [
    "attn_bias_type"
  ],
  "_attn_bias_apply": [
    "attn_bias",
    "op"
  ],
  "ScaledTensor": {
    "__slots__": [],
    "__torch_function__": [],
    "__new__": [
      "cls",
      "data",
      "scale",
      "dequant_func",
      "original_dtype",
      "require_grad"
    ],
    "dequantize": [
      "self"
    ],
    "unpack": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "pack_fp8_tensorwise_per_head": [
    "x",
    "scale",
    "original_dtype"
  ],
  "Inputs": {
    "device": [
      "self"
    ],
    "scale_float": [
      "self"
    ],
    "get_qkv_in_bmghk": [
      "self"
    ],
    "normalize_bmhk": [
      "self"
    ],
    "validate_inputs": [
      "self"
    ],
    "get_output_dtype": [
      "self"
    ],
    "nbytes": [
      "self"
    ]
  },
  "Context": {
    "get_padded_lse": [
      "self",
      "pad_to",
      "force_pad_inf"
    ]
  },
  "Gradients": {},
  "AttentionOpBase": {
    "OPERATOR_CATEGORY": [],
    "supports": [
      "cls",
      "d"
    ],
    "shape_not_supported_reasons": [
      "cls",
      "Mq",
      "Mkv",
      "K",
      "Kv"
    ],
    "not_supported_reasons": [
      "cls",
      "d"
    ]
  },
  "AttentionFwOpBase": {
    "apply": [
      "cls",
      "inp",
      "needs_gradient"
    ]
  },
  "AttentionBwOpBase": {
    "SUPPORTS_ATTN_BIAS_GRAD": [],
    "SUPPORTS_PARTIAL": [],
    "not_supported_reasons": [
      "cls",
      "d"
    ],
    "apply": [
      "cls",
      "ctx",
      "inp",
      "grad"
    ]
  },
  "AttentionOp": [],
  "bmk2bmhk": [
    "tensor",
    "num_heads"
  ],
  "check_lastdim_alignment_stride1": [
    "reasons",
    "name",
    "x",
    "alignment"
  ],
  "FLASH_VERSION": [],
  "_TRY_PT_FLASH_ATTN": [],
  "_USE_PT_FLASH_ATTN": [],
  "_flash_attn_cuda": [],
  "_is_paged_attention_supported": [
    "attn_bias_type"
  ],
  "_check_needs_no_topleft": [
    "d",
    "reasons"
  ],
  "_check_strides_for_bmghk": [
    "x",
    "name",
    "reasons"
  ],
  "_post_process_lse": [
    "lse",
    "inp",
    "original_query_shape"
  ],
  "_minimum_gemm_alignment": [
    "inp"
  ],
  "_get_seqlen_info": [
    "inp"
  ],
  "_get_tensor_bias": [
    "attn_bias"
  ],
  "_check_bias_alignment": [
    "reasons",
    "attn_bias"
  ],
  "_CustomMaskType": {
    "NoCustomMask": [],
    "CausalFromTopLeft": [],
    "CausalFromBottomRight": []
  },
  "_custom_mask_type": [
    "bias"
  ],
  "MemoryEfficientAttentionCutlassOp": [],
  "MemoryEfficientAttentionCutlassBlackwellOp": [],
  "MemoryEfficientAttentionCutlassFwdFlashBwOp": [],
  "MemoryEfficientAttentionFlashAttentionOp": [],
  "MemoryEfficientAttentionCkOp": [],
  "MemoryEfficientAttentionSplitKCkOp": [],
  "_deserialize_bias": [
    "attn_bias_ctx",
    "attn_bias_tensor"
  ],
  "_OPS_LOOKUP": [],
  "_serialize_op": [
    "op"
  ],
  "_unserialize_op": [
    "op"
  ],
  "_fMHA": {
    "forward": [
      "ctx",
      "op_fw",
      "op_bw"
    ],
    "backward": [
      "ctx",
      "grad",
      "grad_lse"
    ]
  },
  "memory_efficient_attention": [
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "memory_efficient_attention_forward_meta": [
    "q",
    "k",
    "v"
  ],
  "memory_efficient_attention_forward_torch_wrapper": [
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "memory_efficient_attention_forward": [
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "memory_efficient_attention_forward_requires_grad": [
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "memory_efficient_attention_backward": [
    "grad",
    "output",
    "lse",
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "_memory_efficient_attention": [
    "inp",
    "op"
  ],
  "_memory_efficient_attention_forward": [
    "inp",
    "op"
  ],
  "_memory_efficient_attention_forward_requires_grad": [
    "inp",
    "op"
  ],
  "_detect_lse_packed_or_raise": [
    "lse",
    "inp"
  ],
  "_memory_efficient_attention_backward": [
    "ctx",
    "inp",
    "grad",
    "op"
  ],
  "memory_efficient_attention_partial": [
    "query",
    "key",
    "value",
    "attn_bias",
    "p",
    "scale"
  ],
  "_uses_tensorcores": [
    "sm",
    "is_half"
  ],
  "maybe_contiguous": [
    "x"
  ],
  "_flash_attention3_incompatible_reason": [],
  "FLASH3_HAS_PAGED_ATTENTION": [],
  "FLASH3_HAS_FLOAT8": [],
  "FLASH3_HAS_DETERMINISTIC_MODE": [],
  "_C_flashattention3": [],
  "_heuristic_kvsplit": [
    "inp",
    "enable_kvsplit_attn"
  ],
  "mask_non_zeros": [
    "s_q",
    "s_k",
    "window_left",
    "window_right"
  ],
  "sdpa_flop_count": [
    "query_shape",
    "key_shape",
    "value_shape",
    "window_left",
    "window_right"
  ],
  "_check_different_value_headdim_ampere": [
    "d",
    "reasons"
  ],
  "_get_blocktables": [
    "inp_attn_bias"
  ],
  "FwOp_KVSplit": {
    "NAME": [],
    "apply": [
      "cls",
      "inp",
      "needs_gradient"
    ]
  },
  "AUTOTUNER_KEY": [],
  "_fwd_kernel_splitK": [
    "Q",
    "K",
    "V",
    "sm_scale",
    "Out_splitK",
    "LSE_splitk",
    "block_tables",
    "Seq_len",
    "Seq_starts_k",
    "Seq_starts_q",
    "Seq_starts_q_multiplier",
    "additive_bias",
    "K_fp8_scale_shift",
    "V_fp8_scale_shift",
    "stride_qz",
    "stride_qm",
    "stride_qg",
    "stride_qh",
    "stride_qk",
    "stride_kz",
    "stride_kn",
    "stride_kg",
    "stride_kh",
    "stride_kk",
    "stride_vz",
    "stride_vn",
    "stride_vg",
    "stride_vh",
    "stride_vk",
    "stride_osk_z",
    "stride_osk_g",
    "stride_osk_h",
    "stride_osk_s",
    "stride_osk_m",
    "stride_osk_k",
    "stride_lsek_z",
    "stride_lsek_g",
    "stride_lsek_h",
    "stride_lsek_s",
    "stride_lsek_m",
    "stride_blocktablesz",
    "stride_blocktablesl",
    "stride_bias_b",
    "stride_bias_g",
    "stride_bias_h",
    "stride_bias_qm",
    "stride_bias_km",
    "stride_k_fp8_scale_shift_z",
    "stride_k_fp8_scale_shift_n",
    "stride_k_fp8_scale_shift_g",
    "stride_k_fp8_scale_shift_h",
    "stride_v_fp8_scale_shift_z",
    "stride_v_fp8_scale_shift_n",
    "stride_v_fp8_scale_shift_g",
    "stride_v_fp8_scale_shift_h",
    "kv_cache_blocks_per_row",
    "Z",
    "N_CTX_Q",
    "N_CTX_K",
    "BLOCK_N_PER_SPLIT",
    "H",
    "G",
    "BLOCK_DMODEL",
    "USE_SEQ_LEN",
    "PACKED_PER_VAL",
    "N_GROUPS",
    "BOUNDS_CHECKS_N",
    "BLOCK_M",
    "BLOCK_N",
    "IS_SPLITK",
    "SPLIT_K_EARLY_EXIT",
    "IS_CAUSAL",
    "IS_LOCAL",
    "NUM_QUERIES_CAUSAL",
    "USE_PAGED_ATTENTION",
    "PAGE_SIZE",
    "WINDOW_LEFT",
    "WINDOW_RIGHT",
    "WRITE_LSE",
    "HAS_ADDITIVE_BIAS",
    "NUM_PROGRAMS_DIM2_CONST",
    "IS_HIP"
  ],
  "gen_config": [
    "block_m",
    "block_n",
    "stages",
    "warps"
  ],
  "_get_splitk_kernel": [
    "num_groups"
  ],
  "early_config_prune": [
    "configs",
    "named_args"
  ],
  "autotune_kernel": [
    "kernel"
  ],
  "load_dequantize_k_v_group": [
    "K_block_ptr",
    "V_block_ptr",
    "K_scale_shift_block_ptr",
    "V_scale_shift_block_ptr",
    "BOUNDS_CHECKS_N",
    "PACKED_PER_VAL",
    "PACKED_D_PER_GROUP",
    "FP8_QUANTIZED",
    "dtype",
    "group_id",
    "IS_HIP"
  ],
  "cast_uint32_to_half2": [
    "scale_shift"
  ],
  "cast_uint32_to_float": [
    "scale_shift"
  ],
  "dequantize_k_hip": [
    "x_",
    "scale",
    "shift",
    "PACKED_PER_VAL"
  ],
  "dequantize": [
    "x_",
    "scale",
    "shift",
    "PACKED_PER_VAL",
    "IS_HIP"
  ],
  "_splitK_reduce": [
    "Out_splitK",
    "LSE_splitK",
    "Out",
    "LSE",
    "split_k",
    "splitK_pow2",
    "stride_osk_z",
    "stride_osk_g",
    "stride_osk_h",
    "stride_osk_s",
    "stride_osk_m",
    "stride_osk_k",
    "stride_lsek_z",
    "stride_lsek_g",
    "stride_lsek_h",
    "stride_lsek_s",
    "stride_lsek_m",
    "stride_oz",
    "stride_og",
    "stride_oh",
    "stride_om",
    "stride_ok",
    "stride_lse_z",
    "stride_lse_g",
    "stride_lse_h",
    "stride_lse_m",
    "head_dim",
    "head_dim_pow_2",
    "H",
    "G",
    "WRITE_LSE"
  ],
  "_splitK_reduce_varargs": [
    "Out_splitK",
    "LSE_splitK",
    "Out",
    "LSE",
    "stride_osk_z",
    "stride_osk_g",
    "stride_osk_h",
    "stride_osk_m",
    "stride_osk_k",
    "stride_lsek_z",
    "stride_lsek_g",
    "stride_lsek_h",
    "stride_lsek_m",
    "stride_oz",
    "stride_og",
    "stride_oh",
    "stride_om",
    "stride_ok",
    "stride_lse_z",
    "stride_lse_g",
    "stride_lse_h",
    "stride_lse_m",
    "head_dim",
    "head_dim_pow_2",
    "H",
    "G",
    "WRITE_LSE"
  ],
  "_splitK_reduce_varargs_backward": [
    "Out_splitK",
    "LSE_splitK",
    "Dout_splitK",
    "DLSE_splitK",
    "Out",
    "LSE",
    "DOut",
    "DLSE",
    "stride_osk_z",
    "stride_osk_g",
    "stride_osk_h",
    "stride_osk_m",
    "stride_osk_k",
    "stride_lsek_z",
    "stride_lsek_g",
    "stride_lsek_h",
    "stride_lsek_m",
    "stride_oz",
    "stride_og",
    "stride_oh",
    "stride_om",
    "stride_ok",
    "stride_lse_z",
    "stride_lse_g",
    "stride_lse_h",
    "stride_lse_m",
    "stride_doz",
    "stride_dog",
    "stride_doh",
    "stride_dom",
    "stride_dok",
    "stride_dlse_z",
    "stride_dlse_g",
    "stride_dlse_h",
    "stride_dlse_m",
    "BLOCK_SIZE",
    "H",
    "G"
  ],
  "get_clock_rate_in_khz": [],
  "get_tensorcore_tflops": [
    "device",
    "num_ctas",
    "num_warps",
    "dtype"
  ],
  "get_simd_tflops": [
    "device",
    "num_ctas",
    "num_warps",
    "dtype"
  ],
  "get_tflops": [
    "device",
    "num_ctas",
    "num_warps",
    "dtype"
  ],
  "estimate_matmul_time": [
    "num_warps",
    "num_stages",
    "A",
    "B",
    "C",
    "M",
    "N",
    "K",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "SPLIT_K",
    "debug"
  ],
  "init_to_zero": [],
  "BASIC_MATMUL_CONFIGS": [],
  "INT8_MATMUL_CONFIGS": [],
  "IO_BOUND_MATMUL_CONFIGS_STAGES": [],
  "IO_BOUND_MATMUL_CONFIGS_BLOCK_M": [],
  "IO_BOUND_MATMUL_CONFIGS_BLOCK_K": [],
  "IO_BOUND_MATMUL_CONFIGS_BLOCK_N": [],
  "IO_BOUND_MATMUL_CONFIGS_SPLIT_K": [],
  "IO_BOUND_MATMUL_CONFIGS": [],
  "TRITON_CONFIGS": [],
  "our_estimate_matmul_time": [
    "A11",
    "B11",
    "C11",
    "M1",
    "M2",
    "M3",
    "N1",
    "N2",
    "N3",
    "K1",
    "K2",
    "K3"
  ],
  "our_early_config_prune": [
    "config",
    "named_args"
  ],
  "_xformers_tiled_matmul_kernel": [
    "A11",
    "A12",
    "A13",
    "A21",
    "A22",
    "A23",
    "A31",
    "A32",
    "A33",
    "B11",
    "B12",
    "B13",
    "B21",
    "B22",
    "B23",
    "B31",
    "B32",
    "B33",
    "C11",
    "C12",
    "C13",
    "C21",
    "C22",
    "C23",
    "C31",
    "C32",
    "C33",
    "M1",
    "M2",
    "M3",
    "N1",
    "N2",
    "N3",
    "K1",
    "K2",
    "K3",
    "stride_am1",
    "stride_am2",
    "stride_am3",
    "stride_ak1",
    "stride_ak2",
    "stride_ak3",
    "stride_bk1",
    "stride_bk2",
    "stride_bk3",
    "stride_bn1",
    "stride_bn2",
    "stride_bn3",
    "stride_cm1",
    "stride_cm2",
    "stride_cm3",
    "stride_cn1",
    "stride_cn2",
    "stride_cn3",
    "BLOCK_M",
    "BLOCK_N",
    "BLOCK_K",
    "GROUP_M",
    "SPLIT_K",
    "EVEN_K",
    "ACC_TYPE"
  ],
  "_check_row_or_column": [
    "row_or_col_type",
    "row_or_col_idx",
    "tensor_name",
    "dim_name",
    "vals"
  ],
  "_get_strides": [
    "ts",
    "tensor_name",
    "dim_0_name",
    "dim_1_name"
  ],
  "_launch_triton_matmul": [
    "a",
    "b",
    "c",
    "ms",
    "ns",
    "ks"
  ],
  "pow": [],
  "_rope_padded_kernel": [
    "xq",
    "xk",
    "xv",
    "out_q",
    "cache_k",
    "cache_v",
    "seqstartq",
    "seqstartk",
    "seqlenk",
    "theta",
    "linear_scale",
    "use_dynamic_scaling",
    "dynamic_old_context_len",
    "dynamic_scale_factor",
    "dynamic_low_freq_factor",
    "dynamic_high_freq_factor",
    "first_seqpos",
    "seqpos",
    "k_start",
    "v_start",
    "n_groups",
    "dim",
    "stride_xqM",
    "stride_xqG",
    "stride_xqH",
    "stride_xkM",
    "stride_xkG",
    "stride_xkH",
    "stride_xvM",
    "stride_xvG",
    "stride_xvH",
    "stride_cachekM",
    "stride_cachekG",
    "stride_cachekH",
    "stride_cachevM",
    "stride_cachevG",
    "stride_cachevH",
    "stride_seqstartq",
    "stride_seqstartk",
    "stride_seqlenk",
    "stride_outqM",
    "stride_outqG",
    "stride_outqH",
    "stride_seqpos",
    "internal_dtype",
    "const_batch_strides",
    "cache_padding_length",
    "seqlenk_shift",
    "BLOCK_SIZE",
    "adjacents"
  ],
  "index_select_cat_fwd_kernel": [
    "output_ptr",
    "source_ptr",
    "index_ptr",
    "num_indices",
    "num_cols",
    "stride0",
    "stride1",
    "BLOCK_SIZE_INDEX",
    "BLOCK_SIZE_COL"
  ],
  "index_select_cat_fwd": [
    "output",
    "source",
    "index"
  ],
  "index_select_cat_bwd_kernel": [
    "grad_source_ptr",
    "index_ptr",
    "grad_output_ptr",
    "num_rows",
    "num_indices",
    "num_cols",
    "stride0",
    "stride1",
    "BLOCK_SIZE_INDEX",
    "BLOCK_SIZE_COL"
  ],
  "index_select_cat_bwd": [
    "grad_source",
    "index",
    "grad_output"
  ],
  "scaled_index_add_fwd_kernel": [
    "input_ptr",
    "index_ptr",
    "source_ptr",
    "scaling_ptr",
    "alpha",
    "num_inp_indices",
    "num_src_indices",
    "num_rows",
    "num_cols",
    "stride0",
    "stride1",
    "stride2",
    "BLOCK_SIZE_INDEX",
    "BLOCK_SIZE_ROW",
    "BLOCK_SIZE_COL",
    "HAS_SCALING"
  ],
  "scaled_index_add_fwd": [
    "x",
    "index",
    "source",
    "scaling",
    "alpha"
  ],
  "scaled_index_add_bwd_kernel": [
    "grad_output_ptr",
    "grad_source_ptr",
    "grad_scaling_ptr",
    "source_ptr",
    "scaling_ptr",
    "index_ptr",
    "alpha",
    "num_inp_indices",
    "num_src_indices",
    "num_rows",
    "num_cols",
    "stride0",
    "stride1",
    "stride2",
    "BLOCK_SIZE_INDEX",
    "BLOCK_SIZE_ROW",
    "BLOCK_SIZE_COL",
    "HAS_SCALING"
  ],
  "scaled_index_add_bwd": [
    "grad_output",
    "grad_source",
    "grad_scaling",
    "source",
    "scaling",
    "index",
    "alpha"
  ],
  "rsqrt": [],
  "_rms_norm_kernel": [
    "x_ptr",
    "h1_ptr",
    "w_ptr",
    "eps",
    "stride",
    "N_COLS",
    "BLOCK_SIZE",
    "INCLUDE_WEIGHT"
  ],
  "_rms_norm_add_kernel": [
    "x_ptr",
    "y_ptr",
    "h1_ptr",
    "w_ptr",
    "eps",
    "stride",
    "N_COLS",
    "BLOCK_SIZE",
    "INCLUDE_WEIGHT"
  ],
  "_rms_norm_forward": [
    "x",
    "attn_norm_weights",
    "eps"
  ],
  "_rms_norm_add_forward": [
    "x",
    "y",
    "attn_norm_weights",
    "eps"
  ],
  "print_json_as_dataframe": [
    "json_list"
  ],
  "compute_std_dev_of_event_durations_over_ranks": [
    "events",
    "top"
  ],
  "sort_nccl_events": [
    "nccl_events",
    "top_k",
    "last_k"
  ],
  "read_one_file": [
    "profile_trace_path"
  ],
  "parse_one_file": [
    "profile_trace_path"
  ],
  "print_profiling_info": [
    "cuda_profile_dir"
  ],
  "NsightProfiler": {
    "__init__": [
      "self",
      "main_profiler"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "step": [
      "self"
    ]
  },
  "PyTorchProfiler": {
    "ACTIVITIES": [],
    "__init__": [
      "self",
      "main_profiler"
    ],
    "_on_trace": [
      "self",
      "prof"
    ],
    "_preprocess_trace": [
      "self",
      "prof",
      "file_name"
    ],
    "_analyze_trace": [
      "self",
      "prof"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "step": [
      "self"
    ]
  },
  "PyTorchProfiler_CUDAOnly": {
    "ACTIVITIES": [],
    "_analyze_trace": [
      "self",
      "prof"
    ]
  },
  "MemSnapshotsProfiler": {
    "__init__": [
      "self",
      "main_profiler"
    ],
    "_has_trace_plot": [
      "self"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "step": [
      "self"
    ]
  },
  "_ProfilerState": {},
  "_Profiler": {
    "_CURRENT_PROFILER": [],
    "__init__": [
      "self",
      "output_dir",
      "schedule",
      "module"
    ],
    "init_schedule": [
      "self",
      "offset"
    ],
    "check_schedule": [
      "self",
      "schedule"
    ],
    "update_profilers_on_step": [
      "self"
    ],
    "_create_output_filename": [
      "self",
      "filename"
    ],
    "start": [
      "self"
    ],
    "stop": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "step": [
      "self"
    ],
    "format_summary": [
      "self"
    ]
  },
  "DCGMProfiler": {
    "__init__": [
      "self",
      "main_profiler",
      "gpus_to_profile",
      "field_ids_to_profile",
      "updateFreq"
    ],
    "create_dcgm_group": [
      "self",
      "gpus_to_profile"
    ],
    "get_profilable_fields": [
      "self"
    ],
    "create_profiling_field_group": [
      "self",
      "fieldIdsToProfile"
    ],
    "__enter__": [
      "self"
    ],
    "__exit__": [
      "self",
      "exc_type",
      "exc_val",
      "exc_tb"
    ],
    "step": [
      "self"
    ]
  },
  "DeviceLimit": {},
  "get_device_limits": [
    "device"
  ],
  "DEFAULT_SCHEDULE": [],
  "profile": [
    "output_dir",
    "module",
    "schedule"
  ],
  "step": [],
  "FakeKinetoEvent": {
    "__init__": [
      "self",
      "e"
    ]
  },
  "_attention_flops": [
    "queries",
    "values",
    "causal",
    "fmt"
  ],
  "_get_arg_idx": [
    "op"
  ],
  "_replace_if_needed": [
    "e"
  ],
  "AnalyzedTrace": {
    "compute_num_ops": [
      "self",
      "dtype",
      "fw",
      "bw"
    ],
    "compute_hfu": [
      "self",
      "hardware_flops"
    ],
    "compute_mfu": [
      "self",
      "hardware_flops"
    ],
    "_find_all_root_events_with_flops": [
      "all_events"
    ],
    "from_profile": [
      "events"
    ]
  },
  "DCGM_PROFILER_AVAILABLE": []
}