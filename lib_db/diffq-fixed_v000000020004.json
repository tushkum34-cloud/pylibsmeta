{
  "BaseQuantizer": {
    "__init__": [
      "self",
      "model",
      "min_size",
      "float16",
      "exclude",
      "detect_bound"
    ],
    "_find_params": [
      "self"
    ],
    "_register_param": [
      "self",
      "name",
      "param",
      "module",
      "other"
    ],
    "_forward_pre_hook": [
      "self",
      "module",
      "input"
    ],
    "_forward_hook": [
      "self",
      "module",
      "input",
      "output"
    ],
    "quantize": [
      "self"
    ],
    "enter_quantize": [
      "self"
    ],
    "unquantize": [
      "self"
    ],
    "_pre_forward_train": [
      "self"
    ],
    "_post_forward_train": [
      "self"
    ],
    "_fix_rnns": [
      "self",
      "flatten"
    ],
    "_bit_pack_param": [
      "self",
      "qparam",
      "quantized",
      "pack_fn"
    ],
    "_bit_unpack_param": [
      "self",
      "qparam",
      "packed",
      "unpack_fn"
    ],
    "_quantize_param": [
      "self",
      "qparam"
    ],
    "_unquantize_param": [
      "self",
      "qparam",
      "quantized"
    ],
    "get_quantized_state": [
      "self",
      "packed",
      "torch_pack"
    ],
    "restore_quantized_state": [
      "self",
      "state"
    ],
    "detach": [
      "self"
    ],
    "model_size": [
      "self"
    ],
    "true_model_size": [
      "self"
    ],
    "packed_model_size": [
      "self"
    ],
    "compressed_model_size": [
      "self",
      "compress_level",
      "num_workers"
    ]
  },
  "restore_quantized_state": [
    "model",
    "state"
  ],
  "_compress_len": [
    "data",
    "compress_level"
  ],
  "_parallel_compress_len": [
    "data",
    "compress_level",
    "num_workers"
  ],
  "simple_repr": [
    "obj",
    "attrs",
    "overrides"
  ],
  "capture_init": [
    "init"
  ],
  "__version__": [],
  "LSQ": {
    "__init__": [
      "self",
      "model",
      "bits",
      "min_size",
      "float16",
      "suffix",
      "exclude",
      "detect_bound"
    ],
    "_register_param": [
      "self",
      "name",
      "param",
      "module",
      "other"
    ],
    "clear_optimizer": [
      "self",
      "optimizer"
    ],
    "setup_optimizer": [
      "self",
      "optimizer"
    ],
    "no_optimizer": [
      "self"
    ],
    "model_size": [
      "self",
      "exact"
    ],
    "true_model_size": [
      "self"
    ],
    "_pre_forward_train": [
      "self"
    ],
    "_post_forward_train": [
      "self"
    ],
    "_quantize_param": [
      "self",
      "qparam"
    ],
    "_unquantize_param": [
      "self",
      "qparam",
      "quantized"
    ],
    "_bit_pack_param": [
      "self",
      "qparam",
      "quantized",
      "pack_fn"
    ],
    "_bit_unpack_param": [
      "self",
      "qparam",
      "packed",
      "unpack_fn"
    ],
    "detach": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "roundpass": [
    "x"
  ],
  "gradscale": [
    "x",
    "scale"
  ],
  "quantize": [
    "tensor",
    "scale",
    "bits"
  ],
  "DiffQuantizer": {
    "__init__": [
      "self",
      "model",
      "min_size",
      "float16",
      "group_size",
      "min_bits",
      "max_bits",
      "param",
      "noise",
      "init_bits",
      "extra_bits",
      "suffix",
      "exclude",
      "detect_bound"
    ],
    "_get_bits": [
      "self",
      "logit"
    ],
    "_get_noise_scale": [
      "self",
      "logit"
    ],
    "_register_param": [
      "self",
      "name",
      "param",
      "module",
      "other"
    ],
    "clear_optimizer": [
      "self",
      "optimizer"
    ],
    "setup_optimizer": [
      "self",
      "optimizer",
      "lr"
    ],
    "no_optimizer": [
      "self"
    ],
    "check_unused": [
      "self"
    ],
    "model_size": [
      "self",
      "exact"
    ],
    "true_model_size": [
      "self"
    ],
    "_pre_forward_train": [
      "self"
    ],
    "_post_forward_train": [
      "self"
    ],
    "_quantize_param": [
      "self",
      "qparam"
    ],
    "_unquantize_param": [
      "self",
      "qparam",
      "quantized"
    ],
    "_bit_pack_param": [
      "self",
      "qparam",
      "quantized",
      "pack_fn"
    ],
    "_bit_unpack_param": [
      "self",
      "qparam",
      "packed",
      "unpack_fn"
    ],
    "detach": [
      "self"
    ],
    "__repr__": [
      "self"
    ]
  },
  "as_rectangle": [
    "p",
    "side"
  ],
  "_storage_size": [
    "dtype"
  ],
  "pack": [
    "indexes",
    "nbits",
    "storage_dtype"
  ],
  "unpack": [
    "packed",
    "length"
  ],
  "_DiffQPacked": [],
  "TEMPLATE": [],
  "UNPACK_ASSIGN": [],
  "UNPACK_ASSIGN_SAME": [],
  "export": [
    "quantizer",
    "path"
  ],
  "_unpack_param": [
    "packed",
    "group_size",
    "min_bits"
  ],
  "recompress": [
    "path"
  ],
  "_get_full_name_access": [
    "full_name"
  ],
  "_codegen": [
    "quantizer"
  ],
  "uniform_quantize": [
    "p",
    "bits"
  ],
  "uniform_unquantize": [
    "levels",
    "scales",
    "bits"
  ],
  "UniformQuantizer": {
    "__init__": [
      "self",
      "model",
      "bits",
      "min_size",
      "float16",
      "qat",
      "exclude",
      "detect_bound"
    ],
    "__repr__": [
      "self"
    ],
    "_pre_forward_train": [
      "self"
    ],
    "_post_forward_train": [
      "self"
    ],
    "_quantize_param": [
      "self",
      "qparam"
    ],
    "_unquantize_param": [
      "self",
      "qparam",
      "quantized"
    ],
    "_bit_pack_param": [
      "self",
      "qparam",
      "quantized",
      "pack_fn"
    ],
    "_bit_unpack_param": [
      "self",
      "qparam",
      "packed",
      "unpack_fn"
    ],
    "model_size": [
      "self"
    ],
    "true_model_size": [
      "self"
    ]
  }
}