{
  "__all__": [],
  "_check_gradio_env": [],
  "ClassifyTIMMModel": {
    "__init__": [
      "self",
      "repo_id",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "_open_model": [
      "self"
    ],
    "_open_tags": [
      "self"
    ],
    "_open_preprocess": [
      "self"
    ],
    "_raw_predict": [
      "self",
      "image",
      "preprocessor"
    ],
    "predict": [
      "self",
      "image",
      "preprocessor",
      "fmt"
    ],
    "make_ui": [
      "self"
    ],
    "launch_demo": [
      "self",
      "server_name",
      "server_port"
    ]
  },
  "_open_models_for_repo_id": [
    "repo_id",
    "hf_token"
  ],
  "classify_timm_predict": [
    "image",
    "repo_id",
    "preprocessor",
    "fmt",
    "hf_token"
  ],
  "ImageEnhancer": {
    "_process_rgb": [
      "self",
      "rgb_array"
    ],
    "_process_alpha_channel_with_model": [
      "self",
      "alpha_array"
    ],
    "_process_rgba": [
      "self",
      "rgba_array"
    ],
    "process": [
      "self",
      "image"
    ]
  },
  "_MODEL_LOAD_LOCKS": [],
  "_G_ML_LOCK": [],
  "_model_load_lock": [],
  "_v_fix": [
    "v"
  ],
  "_bbox_fix": [
    "bbox"
  ],
  "_yolo_xywh2xyxy": [
    "x"
  ],
  "_yolo_nms": [
    "boxes",
    "scores",
    "iou_threshold"
  ],
  "_image_preprocess": [
    "image",
    "max_infer_size",
    "allow_dynamic",
    "align"
  ],
  "_xy_postprocess": [
    "x",
    "y",
    "old_size",
    "new_size"
  ],
  "_end2end_postprocess": [
    "output",
    "conf_threshold",
    "iou_threshold",
    "old_size",
    "new_size",
    "labels"
  ],
  "_nms_postprocess": [
    "output",
    "conf_threshold",
    "iou_threshold",
    "old_size",
    "new_size",
    "labels"
  ],
  "_yolo_postprocess": [
    "output",
    "conf_threshold",
    "iou_threshold",
    "old_size",
    "new_size",
    "labels"
  ],
  "_rtdetr_postprocess": [
    "output",
    "conf_threshold",
    "iou_threshold",
    "old_size",
    "new_size",
    "labels"
  ],
  "_safe_eval_names_str": [
    "names_str"
  ],
  "_OFFLINE": [],
  "YOLOModel": {
    "__init__": [
      "self",
      "repo_id",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "model_names": [
      "self"
    ],
    "_check_model_name": [
      "self",
      "model_name"
    ],
    "_open_model": [
      "self",
      "model_name"
    ],
    "_get_model_type": [
      "self",
      "model_name"
    ],
    "_get_default_thresholds": [
      "self",
      "model_name"
    ],
    "predict": [
      "self",
      "image",
      "model_name",
      "conf_threshold",
      "iou_threshold",
      "allow_dynamic"
    ],
    "clear": [
      "self"
    ],
    "make_ui": [
      "self",
      "default_model_name",
      "default_conf_threshold",
      "default_iou_threshold",
      "apply_default_threshold"
    ],
    "launch_demo": [
      "self",
      "default_model_name",
      "default_conf_threshold",
      "default_iou_threshold",
      "apply_default_threshold",
      "server_name",
      "server_port"
    ]
  },
  "yolo_predict": [
    "image",
    "repo_id",
    "model_name",
    "conf_threshold",
    "iou_threshold",
    "hf_token"
  ],
  "SigLIPModel": {
    "__init__": [
      "self",
      "repo_id",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "model_names": [
      "self"
    ],
    "_check_model_name": [
      "self",
      "model_name"
    ],
    "_open_image_encoder": [
      "self",
      "model_name"
    ],
    "_open_image_preprocessor": [
      "self",
      "model_name"
    ],
    "_open_text_encoder": [
      "self",
      "model_name"
    ],
    "_open_text_tokenizer": [
      "self",
      "model_name"
    ],
    "_get_logit_scale": [
      "self",
      "model_name"
    ],
    "_image_encode": [
      "self",
      "images",
      "model_name",
      "fmt"
    ],
    "image_encode": [
      "self",
      "images",
      "model_name",
      "fmt"
    ],
    "_text_encode": [
      "self",
      "texts",
      "model_name",
      "fmt"
    ],
    "text_encode": [
      "self",
      "texts",
      "model_name",
      "fmt"
    ],
    "predict": [
      "self",
      "images",
      "texts",
      "model_name",
      "fmt"
    ],
    "clear": [
      "self"
    ],
    "make_ui": [
      "self",
      "default_model_name"
    ],
    "launch_demo": [
      "self",
      "default_model_name",
      "server_name",
      "server_port"
    ]
  },
  "siglip_image_encode": [
    "images",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "siglip_text_encode": [
    "texts",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "siglip_predict": [
    "images",
    "texts",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "CLIPModel": {
    "__init__": [
      "self",
      "repo_id",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "model_names": [
      "self"
    ],
    "_check_model_name": [
      "self",
      "model_name"
    ],
    "_open_image_encoder": [
      "self",
      "model_name"
    ],
    "_open_image_preprocessor": [
      "self",
      "model_name"
    ],
    "_open_text_encoder": [
      "self",
      "model_name"
    ],
    "_open_text_tokenizer": [
      "self",
      "model_name"
    ],
    "_get_logit_scale": [
      "self",
      "model_name"
    ],
    "_image_encode": [
      "self",
      "images",
      "model_name",
      "fmt"
    ],
    "image_encode": [
      "self",
      "images",
      "model_name",
      "fmt"
    ],
    "_text_encode": [
      "self",
      "texts",
      "model_name",
      "fmt"
    ],
    "text_encode": [
      "self",
      "texts",
      "model_name",
      "fmt"
    ],
    "predict": [
      "self",
      "images",
      "texts",
      "model_name",
      "fmt"
    ],
    "clear": [
      "self"
    ],
    "make_ui": [
      "self",
      "default_model_name"
    ],
    "launch_demo": [
      "self",
      "default_model_name",
      "server_name",
      "server_port"
    ]
  },
  "clip_image_encode": [
    "images",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "clip_text_encode": [
    "texts",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "clip_predict": [
    "images",
    "texts",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "crop_mask": [
    "masks",
    "boxes"
  ],
  "scale_masks": [
    "masks",
    "shape",
    "padding"
  ],
  "_yolo_seg_postprocess": [
    "output",
    "protos",
    "conf_threshold",
    "iou_threshold",
    "old_size",
    "new_size",
    "labels"
  ],
  "YOLOSegmentationModel": {
    "__init__": [
      "self",
      "repo_id",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "model_names": [
      "self"
    ],
    "_check_model_name": [
      "self",
      "model_name"
    ],
    "_open_model": [
      "self",
      "model_name"
    ],
    "_get_model_type": [
      "self",
      "model_name"
    ],
    "_get_default_thresholds": [
      "self",
      "model_name"
    ],
    "predict": [
      "self",
      "image",
      "model_name",
      "conf_threshold",
      "iou_threshold",
      "allow_dynamic"
    ],
    "clear": [
      "self"
    ],
    "make_ui": [
      "self",
      "default_model_name",
      "default_conf_threshold",
      "default_iou_threshold",
      "apply_default_threshold"
    ],
    "launch_demo": [
      "self",
      "default_model_name",
      "default_conf_threshold",
      "default_iou_threshold",
      "apply_default_threshold",
      "server_name",
      "server_port"
    ]
  },
  "yolo_seg_predict": [
    "image",
    "repo_id",
    "model_name",
    "conf_threshold",
    "iou_threshold",
    "hf_token"
  ],
  "_img_encode": [
    "image",
    "size",
    "normalize"
  ],
  "_labels_scores_to_topk": [
    "labels",
    "scores",
    "topk"
  ],
  "ImagePreprocessFunc": [],
  "ClassifyModel": {
    "__init__": [
      "self",
      "repo_id",
      "fn_preprocess",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "model_names": [
      "self"
    ],
    "_check_model_name": [
      "self",
      "model_name"
    ],
    "_open_model": [
      "self",
      "model_name"
    ],
    "_open_label": [
      "self",
      "model_name"
    ],
    "_open_preprocess": [
      "self",
      "model_name"
    ],
    "_raw_predict": [
      "self",
      "image",
      "model_name"
    ],
    "predict_score": [
      "self",
      "image",
      "model_name",
      "label_group",
      "topk"
    ],
    "predict": [
      "self",
      "image",
      "model_name",
      "label_group"
    ],
    "predict_fmt": [
      "self",
      "image",
      "model_name",
      "fmt"
    ],
    "clear": [
      "self"
    ],
    "make_ui": [
      "self",
      "default_model_name"
    ],
    "launch_demo": [
      "self",
      "default_model_name",
      "server_name",
      "server_port"
    ]
  },
  "classify_predict_score": [
    "image",
    "repo_id",
    "model_name",
    "label_group",
    "topk",
    "hf_token"
  ],
  "classify_predict": [
    "image",
    "repo_id",
    "model_name",
    "label_group",
    "hf_token"
  ],
  "classify_predict_fmt": [
    "image",
    "repo_id",
    "model_name",
    "fmt",
    "hf_token"
  ],
  "FMT_UNSET": [],
  "MultiLabelTIMMModel": {
    "__init__": [
      "self",
      "repo_id",
      "hf_token"
    ],
    "_get_hf_token": [
      "self"
    ],
    "_open_model": [
      "self"
    ],
    "_open_tags": [
      "self"
    ],
    "_open_preprocess": [
      "self"
    ],
    "_open_default_category_thresholds": [
      "self"
    ],
    "_raw_predict": [
      "self",
      "image",
      "preprocessor"
    ],
    "predict": [
      "self",
      "image",
      "preprocessor",
      "thresholds",
      "use_tag_thresholds",
      "fmt"
    ],
    "make_ui": [
      "self",
      "default_thresholds",
      "default_use_tag_thresholds"
    ],
    "launch_demo": [
      "self",
      "default_thresholds",
      "default_use_tag_thresholds",
      "server_name",
      "server_port"
    ]
  },
  "multilabel_timm_predict": [
    "image",
    "repo_id",
    "preprocessor",
    "thresholds",
    "use_tag_thresholds",
    "fmt",
    "hf_token"
  ],
  "ascii_drawing": [
    "img",
    "max_width",
    "max_height",
    "resample",
    "levels",
    "aspect"
  ],
  "squeeze": [
    "image",
    "mask"
  ],
  "_get_mask_of_transparency": [
    "image",
    "threshold",
    "median_filter"
  ],
  "squeeze_with_transparency": [
    "image",
    "threshold",
    "median_filter"
  ],
  "BaseCensor": {
    "censor_area": [
      "self",
      "image",
      "area"
    ]
  },
  "PixelateCensor": {
    "censor_area": [
      "self",
      "image",
      "area",
      "radius"
    ]
  },
  "BlurCensor": {
    "censor_area": [
      "self",
      "image",
      "area",
      "radius"
    ]
  },
  "ColorCensor": {
    "censor_area": [
      "self",
      "image",
      "area",
      "color"
    ]
  },
  "_KNOWN_CENSORS": [],
  "register_censor_method": [
    "name",
    "cls"
  ],
  "_get_censor_instance": [
    "name"
  ],
  "censor_areas": [
    "image",
    "method",
    "areas"
  ],
  "censor_nsfw": [
    "image",
    "method",
    "nipple_f",
    "penis",
    "pussy",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "_image_rotate_and_sq": [
    "image",
    "degrees"
  ],
  "SingleImage": {
    "__init__": [
      "self",
      "image"
    ],
    "width": [
      "self"
    ],
    "height": [
      "self"
    ],
    "_find_for_fixed_area": [
      "self",
      "width",
      "height"
    ],
    "find_for_area": [
      "self",
      "width",
      "height"
    ]
  },
  "ImageBasedCensor": {
    "__init__": [
      "self",
      "images",
      "rotate",
      "step"
    ],
    "_find_censor": [
      "self",
      "area",
      "ratio_threshold"
    ],
    "censor_area": [
      "self",
      "image",
      "area",
      "ratio_threshold"
    ]
  },
  "_get_file_in_censor_assets": [
    "file"
  ],
  "_get_emoji_img": [
    "emoji",
    "style"
  ],
  "_EmojiStyleTyping": [],
  "_NativeEmojiBasedCensor": {
    "__init__": [
      "self",
      "emoji",
      "style",
      "rotate",
      "step"
    ]
  },
  "_get_native_emoji_censor": [
    "emoji",
    "style",
    "rotate",
    "step"
  ],
  "EmojiBasedCensor": {
    "__init__": [
      "self",
      "rotate",
      "step"
    ],
    "censor_area": [
      "self",
      "image",
      "area",
      "emoji",
      "style",
      "ratio_threshold"
    ]
  },
  "align_maxsize": [
    "image",
    "max_size"
  ],
  "read_geninfo_parameters": [
    "image"
  ],
  "read_geninfo_exif": [
    "image"
  ],
  "read_geninfo_gif": [
    "image"
  ],
  "write_geninfo_parameters": [
    "image",
    "dst_filename",
    "geninfo"
  ],
  "write_geninfo_exif": [
    "image",
    "dst_filename",
    "geninfo"
  ],
  "write_geninfo_gif": [
    "image",
    "dst_filename",
    "geninfo"
  ],
  "correctable_bits": [],
  "block_length": [],
  "code_block_len": [],
  "bit_shuffle": [
    "data_bytes",
    "w",
    "h"
  ],
  "split_byte_ranges": [
    "data_bytes",
    "n",
    "w",
    "h"
  ],
  "pad": [
    "data_bytes"
  ],
  "fec_encode": [
    "data_bytes",
    "w",
    "h"
  ],
  "LSBInjector": {
    "__init__": [
      "self",
      "data"
    ],
    "put_32bit_integer": [
      "self",
      "integer_value"
    ],
    "put_bytes": [
      "self",
      "bytes_list"
    ],
    "put_string": [
      "self",
      "string"
    ],
    "finalize": [
      "self"
    ]
  },
  "serialize_pnginfo": [
    "metadata"
  ],
  "serialize_json": [
    "metadata"
  ],
  "inject_data": [
    "image",
    "data"
  ],
  "write_lsb_raw_bytes": [
    "image",
    "data"
  ],
  "write_lsb_metadata": [
    "image",
    "data"
  ],
  "LSBExtractor": {
    "__init__": [
      "self",
      "data"
    ],
    "_extract_next_bit": [
      "self"
    ],
    "get_one_byte": [
      "self"
    ],
    "get_next_n_bytes": [
      "self",
      "n"
    ],
    "read_32bit_integer": [
      "self"
    ]
  },
  "ImageLsbDataExtractor": {
    "__init__": [
      "self",
      "magic"
    ],
    "extract_data": [
      "self",
      "image"
    ]
  },
  "LSBReadError": {
    "__init__": [
      "self",
      "err"
    ]
  },
  "read_lsb_raw_bytes": [
    "image"
  ],
  "read_lsb_metadata": [
    "image"
  ],
  "psnr": [
    "img1",
    "img2"
  ],
  "_image_resize": [
    "image",
    "size"
  ],
  "_image_encode": [
    "image"
  ],
  "_lpips_feature_model": [],
  "lpips_extract_feature": [
    "image"
  ],
  "_lpips_diff_model": [],
  "_FEAT1_NAMES": [],
  "_FEAT2_NAMES": [],
  "_batch_lpips_difference": [
    "feats1",
    "feats2"
  ],
  "AutoFeatTyping": [],
  "_auto_feat": [
    "img"
  ],
  "lpips_difference": [
    "img1",
    "img2"
  ],
  "lpips_clustering": [
    "images",
    "threshold"
  ],
  "_normalize": [
    "data",
    "mean",
    "std"
  ],
  "_preprocess_image": [
    "image",
    "size"
  ],
  "_open_feat_model": [
    "model"
  ],
  "_open_metric_model": [
    "model"
  ],
  "_open_metrics": [
    "model"
  ],
  "_open_cluster_metrics": [
    "model"
  ],
  "_VALID_MODEL_NAMES": [],
  "_DEFAULT_MODEL_NAMES": [],
  "ccip_extract_feature": [
    "image",
    "size",
    "model"
  ],
  "ccip_batch_extract_features": [
    "images",
    "size",
    "model"
  ],
  "_FeatureOrImage": [],
  "_p_feature": [
    "x",
    "size",
    "model"
  ],
  "ccip_default_threshold": [
    "model"
  ],
  "ccip_difference": [
    "x",
    "y",
    "size",
    "model"
  ],
  "ccip_same": [
    "x",
    "y",
    "threshold",
    "size",
    "model"
  ],
  "ccip_batch_differences": [
    "images",
    "size",
    "model"
  ],
  "ccip_batch_same": [
    "images",
    "threshold",
    "size",
    "model"
  ],
  "CCIPClusterMethodTyping": [],
  "_METHOD_MAPPING": [],
  "ccip_default_clustering_params": [
    "model",
    "method"
  ],
  "ccip_clustering": [
    "images",
    "method",
    "eps",
    "min_samples",
    "size",
    "model"
  ],
  "ccip_merge": [
    "images",
    "size",
    "model"
  ],
  "_variance_of_laplacian": [
    "d_image"
  ],
  "laplacian_score": [
    "image"
  ],
  "_open_aesthetic_model": [],
  "_preprocess": [
    "image"
  ],
  "get_aesthetic_score": [
    "image"
  ],
  "_DEFAULT_MODEL_NAME": [],
  "_REPO_ID": [],
  "_LABELS": [],
  "_DEFAULT_LABEL_MAPPING": [],
  "AestheticModel": {
    "__init__": [
      "self",
      "repo_id"
    ],
    "get_aesthetic_score": [
      "self",
      "image",
      "model_name"
    ],
    "_get_xy_samples": [
      "self",
      "model_name"
    ],
    "score_to_percentile": [
      "self",
      "score",
      "model_name"
    ],
    "percentile_to_label": [
      "cls",
      "percentile",
      "mapping"
    ],
    "get_aesthetic": [
      "self",
      "image",
      "model_name",
      "fmt"
    ],
    "clear": [
      "self"
    ]
  },
  "_MODEL": [],
  "anime_dbaesthetic": [
    "image",
    "model_name",
    "fmt"
  ],
  "_get_model": [],
  "get_isnetis_mask": [
    "image",
    "scale"
  ],
  "segment_with_isnetis": [
    "image",
    "background",
    "scale"
  ],
  "segment_rgba_with_isnetis": [
    "image",
    "scale"
  ],
  "_check_compatibility": [],
  "_open_nudenet_yolo": [],
  "_open_nudenet_nms": [],
  "_nn_preprocessing": [
    "image",
    "model_size"
  ],
  "_make_np_config": [
    "topk",
    "iou_threshold",
    "score_threshold"
  ],
  "_nn_postprocess": [
    "selected",
    "global_ratio"
  ],
  "detect_with_nudenet": [
    "image",
    "topk",
    "iou_threshold",
    "score_threshold"
  ],
  "_try_get_font_from_matplotlib": [
    "fp",
    "fontsize"
  ],
  "detection_visualize": [
    "image",
    "detection",
    "labels",
    "text_padding",
    "fontsize",
    "max_short_edge_size",
    "mask_alpha",
    "fp",
    "no_label"
  ],
  "BBoxTyping": [],
  "BBoxWithScoreAndLabel": [],
  "MaskWithScoreAndLabel": [],
  "detect_censors": [
    "image",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "detect_hands": [
    "image",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "detect_halfbody": [
    "image",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "detect_person": [
    "image",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "_DEFAULT_MODEL": [],
  "_open_text_detect_model": [
    "model"
  ],
  "_get_heatmap_of_text": [
    "image",
    "model"
  ],
  "_get_bounding_box_of_text": [
    "image",
    "model",
    "threshold"
  ],
  "detect_text": [
    "image",
    "model",
    "threshold",
    "max_area_size"
  ],
  "detect_faces": [
    "image",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "calculate_iou": [
    "box1",
    "box2"
  ],
  "bboxes_similarity": [
    "bboxes1",
    "bboxes2",
    "mode"
  ],
  "detection_similarity": [
    "detect1",
    "detect2",
    "mode"
  ],
  "_mask_to_bool_mask": [
    "mask",
    "threshold"
  ],
  "calculate_mask_iou": [
    "mask1",
    "mask2",
    "threshold"
  ],
  "masks_similarity": [
    "masks1",
    "masks2",
    "mode"
  ],
  "detection_with_mask_similarity": [
    "detect1",
    "detect2",
    "mode"
  ],
  "detect_heads": [
    "image",
    "level",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "detect_with_booru_yolo": [
    "image",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "detect_eyes": [
    "image",
    "level",
    "version",
    "model_name",
    "conf_threshold",
    "iou_threshold"
  ],
  "_MODELS": [],
  "_MODEL_NAMES": [],
  "_MODEL_TO_SIZE": [],
  "_open_nsfw_model": [
    "model"
  ],
  "_raw_scores": [
    "image",
    "model_name"
  ],
  "nsfw_pred_score": [
    "image",
    "model_name"
  ],
  "nsfw_pred": [
    "image",
    "model_name"
  ],
  "_G_PNSR_THRESHOLD": [],
  "is_greyscale": [
    "image"
  ],
  "get_ai_created_score": [
    "image",
    "model_name"
  ],
  "is_ai_created": [
    "image",
    "model_name",
    "threshold"
  ],
  "anime_portrait_score": [
    "image",
    "model_name"
  ],
  "anime_portrait": [
    "image",
    "model_name"
  ],
  "anime_bangumi_char_score": [
    "image",
    "model_name"
  ],
  "anime_bangumi_char": [
    "image",
    "model_name"
  ],
  "anime_classify_score": [
    "image",
    "model_name"
  ],
  "anime_classify": [
    "image",
    "model_name"
  ],
  "get_monochrome_score": [
    "image",
    "model_name"
  ],
  "is_monochrome": [
    "image",
    "threshold",
    "model_name"
  ],
  "anime_dbrating_score": [
    "image",
    "model_name"
  ],
  "anime_dbrating": [
    "image",
    "model_name"
  ],
  "anime_real_score": [
    "image",
    "model_name"
  ],
  "anime_real": [
    "image",
    "model_name"
  ],
  "anime_style_age_score": [
    "image",
    "model_name"
  ],
  "anime_style_age": [
    "image",
    "model_name"
  ],
  "DEFAULT_MODEL": [],
  "_open_model": [
    "model_name"
  ],
  "_DEFAULT_ORDER": [],
  "_get_hwc_map": [
    "order_"
  ],
  "_encode_channels": [
    "image",
    "channels_order"
  ],
  "_raw_predict": [
    "images",
    "model_name"
  ],
  "_pred": [
    "image",
    "model_name",
    "max_batch_size"
  ],
  "safe_check_score": [
    "image",
    "model_name",
    "max_batch_size"
  ],
  "safe_check": [
    "image",
    "model_name",
    "max_batch_size"
  ],
  "anime_teen_score": [
    "image",
    "model_name"
  ],
  "anime_teen": [
    "image",
    "model_name"
  ],
  "anime_furry_score": [
    "image",
    "model_name"
  ],
  "anime_furry": [
    "image",
    "model_name"
  ],
  "anime_completeness_score": [
    "image",
    "model_name"
  ],
  "anime_completeness": [
    "image",
    "model_name"
  ],
  "_LOCK": [],
  "_mock_load_truncated_images": [
    "value"
  ],
  "is_truncated_file": [
    "path"
  ],
  "anime_rating_score": [
    "image",
    "model_name"
  ],
  "anime_rating": [
    "image",
    "model_name"
  ],
  "__TITLE__": [],
  "__VERSION__": [],
  "__DESCRIPTION__": [],
  "__AUTHOR__": [],
  "__AUTHOR_EMAIL__": [],
  "NotParseTarget": {},
  "_INT_TO_PILLOW": [],
  "_STR_TO_PILLOW": [],
  "_PILLOW_TO_STR": [],
  "_get_pillow_resample": [
    "value"
  ],
  "_PTRANS_CREATORS": [],
  "register_pillow_transform": [
    "name"
  ],
  "_PTRANS_PARSERS": [],
  "register_pillow_parse": [
    "name"
  ],
  "PillowResize": {
    "__init__": [
      "self",
      "size",
      "interpolation",
      "max_size",
      "antialias"
    ],
    "_get_resize_size": [
      "self",
      "img"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_resize": [
    "size",
    "interpolation",
    "max_size",
    "antialias"
  ],
  "_parse_resize": [
    "obj"
  ],
  "PillowCenterCrop": {
    "__init__": [
      "self",
      "size"
    ],
    "__call__": [
      "self",
      "img"
    ],
    "_center_crop": [
      "self",
      "img"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_center_crop": [
    "size"
  ],
  "_parse_center_crop": [
    "obj"
  ],
  "PillowToTensor": {
    "__call__": [
      "self",
      "pic"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_to_tensor": [],
  "_parse_to_tensor": [
    "obj"
  ],
  "PillowMaybeToTensor": {
    "__call__": [
      "self",
      "image"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_maybe_to_tensor": [],
  "_parse_maybe_to_tensor": [
    "obj"
  ],
  "PillowNormalize": {
    "__init__": [
      "self",
      "mean",
      "std",
      "inplace"
    ],
    "__call__": [
      "self",
      "array"
    ],
    "_normalize_multi": [
      "self",
      "array"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_normalize": [
    "mean",
    "std",
    "inplace"
  ],
  "_parse_normalize": [
    "obj"
  ],
  "PillowConvertRGB": {
    "__init__": [
      "self",
      "force_background"
    ],
    "__call__": [
      "self",
      "pic"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_convert_rgb": [
    "force_background"
  ],
  "_parse_convert_rgb": [
    "obj"
  ],
  "PillowRescale": {
    "__init__": [
      "self",
      "rescale_factor"
    ],
    "__call__": [
      "self",
      "array"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_rescale": [
    "rescale_factor"
  ],
  "_parse_rescale": [
    "obj"
  ],
  "PillowPadToSize": {
    "__init__": [
      "self",
      "size",
      "background_color",
      "interpolation"
    ],
    "__call__": [
      "self",
      "pic"
    ],
    "__repr__": [
      "self"
    ]
  },
  "_create_pad_to_size": [
    "size",
    "background_color",
    "interpolation"
  ],
  "_parse_pad_to_size": [
    "obj"
  ],
  "PillowCompose": {
    "__init__": [
      "self",
      "transforms"
    ],
    "__call__": [
      "self",
      "image"
    ],
    "__repr__": [
      "self"
    ]
  },
  "create_pillow_transforms": [
    "tvalue"
  ],
  "parse_pillow_transforms": [
    "value"
  ],
  "_check_torchvision": [],
  "_get_interpolation_mode": [
    "value"
  ],
  "_get_int_from_interpolation_mode": [
    "value"
  ],
  "_get_interpolation_str_from_mode": [
    "value"
  ],
  "_TRANS_CREATORS": [],
  "_register_transform": [
    "name",
    "safe"
  ],
  "register_torchvision_transform": [
    "name"
  ],
  "_TRANS_PARSERS": [],
  "_register_parse": [
    "name",
    "safe"
  ],
  "register_torchvision_parse": [
    "name"
  ],
  "create_torchvision_transforms": [
    "tvalue"
  ],
  "parse_torchvision_transforms": [
    "value"
  ],
  "VALID_SIZE_DICT_KEYS": [],
  "is_valid_size_dict": [
    "size_dict"
  ],
  "convert_to_size_dict": [
    "size",
    "max_size",
    "default_to_square",
    "height_width_order"
  ],
  "get_size_dict": [
    "size",
    "max_size",
    "height_width_order",
    "default_to_square",
    "param_name"
  ],
  "_check_transformers": [],
  "IMAGENET_DEFAULT_MEAN": [],
  "IMAGENET_DEFAULT_STD": [],
  "IMAGENET_STANDARD_MEAN": [],
  "IMAGENET_STANDARD_STD": [],
  "OPENAI_CLIP_MEAN": [],
  "OPENAI_CLIP_STD": [],
  "_DEFAULT": [],
  "NotProcessorTypeError": {},
  "_FN_CREATORS": [],
  "register_creators_for_transformers": [],
  "create_transforms_from_transformers": [
    "processor"
  ],
  "_DEFAULT_SIZE": [],
  "_DEFAULT_CROP_PCT": [],
  "create_convnext_transforms": [
    "do_resize",
    "size",
    "crop_pct",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std"
  ],
  "create_transforms_from_convnext_processor": [
    "processor"
  ],
  "create_siglip_transforms": [
    "do_resize",
    "size",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_convert_rgb"
  ],
  "create_transforms_from_siglip_processor": [
    "processor"
  ],
  "_DEFAULT_CROP_SIZE": [],
  "create_clip_transforms": [
    "do_resize",
    "size",
    "resample",
    "do_center_crop",
    "crop_size",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_convert_rgb"
  ],
  "create_transforms_from_clip_processor": [
    "processor"
  ],
  "create_blip_transforms": [
    "do_resize",
    "size",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_convert_rgb"
  ],
  "create_transforms_from_blip_processor": [
    "processor"
  ],
  "create_mobilenetv2_transforms": [
    "do_resize",
    "size",
    "resample",
    "do_center_crop",
    "crop_size",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std"
  ],
  "create_transforms_from_mobilenetv2_processor": [
    "processor"
  ],
  "create_bit_transforms": [
    "do_resize",
    "size",
    "resample",
    "do_center_crop",
    "crop_size",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_convert_rgb"
  ],
  "create_transforms_from_bit_processor": [
    "processor"
  ],
  "create_vit_transforms": [
    "do_resize",
    "size",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std"
  ],
  "create_transforms_from_vit_processor": [
    "processor"
  ],
  "get_edge_by_canny": [
    "image",
    "low_threshold",
    "high_threshold"
  ],
  "edge_image_with_canny": [
    "image",
    "low_threshold",
    "high_threshold",
    "backcolor",
    "forecolor"
  ],
  "cv2_resize": [
    "input_image",
    "width",
    "height"
  ],
  "resize_image": [
    "input_image",
    "resolution",
    "align"
  ],
  "_get_image_edge": [
    "image",
    "edge_func",
    "backcolor",
    "forecolor"
  ],
  "_open_la_anime_model": [],
  "get_edge_by_lineart_anime": [
    "image",
    "detect_resolution"
  ],
  "edge_image_with_lineart_anime": [
    "image",
    "detect_resolution",
    "backcolor",
    "forecolor"
  ],
  "_open_la_model": [
    "coarse"
  ],
  "get_edge_by_lineart": [
    "image",
    "coarse",
    "detect_resolution"
  ],
  "edge_image_with_lineart": [
    "image",
    "coarse",
    "detect_resolution",
    "backcolor",
    "forecolor"
  ],
  "_PARAM_PATTERN": [],
  "_SIZE_PATTERN": [],
  "_NEG_LINE_PATTERN": [],
  "_PRE_KEYS": [],
  "_POST_KEYS": [],
  "_sdmeta_quote": [
    "value"
  ],
  "SDMetaData": {
    "__str__": [
      "self"
    ],
    "_sdmeta_text": [
      "self"
    ],
    "text": [
      "self"
    ],
    "pnginfo": [
      "self"
    ]
  },
  "_parse_parameters": [
    "param_text"
  ],
  "parse_sdmeta_from_text": [
    "x"
  ],
  "_InvalidSDMetaError": {},
  "_sdtext_validate": [
    "text"
  ],
  "_get_raw_sdtext": [
    "image"
  ],
  "get_sdmeta_from_image": [
    "image"
  ],
  "_save_png_with_sdmeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "_save_exif_with_sdmeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "_save_gif_with_sdmeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "_FN_IMG_SAVE": [],
  "save_image_with_sdmeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "NAIMetaData": {
    "json": [
      "self"
    ],
    "pnginfo": [
      "self"
    ]
  },
  "NAIMetadata": [],
  "_InvalidNAIMetaError": {},
  "_naimeta_validate": [
    "data"
  ],
  "_naimeta_text_validate": [
    "data"
  ],
  "_get_naimeta_raw": [
    "image"
  ],
  "get_naimeta_from_image": [
    "image"
  ],
  "add_naimeta_to_image": [
    "image",
    "metadata"
  ],
  "_save_png_with_naimeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "_save_exif_with_naimeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "_save_gif_with_naimeta": [
    "image",
    "dst_file",
    "metadata"
  ],
  "_LSB_ALLOWED_TYPES": [],
  "save_image_with_naimeta": [
    "image",
    "dst_file",
    "metadata",
    "add_lsb_meta",
    "save_metainfo"
  ],
  "_check_env": [],
  "read_metadata": [
    "model_file"
  ],
  "save_with_metadata": [
    "src_model_file",
    "dst_model_file",
    "metadata",
    "clear"
  ],
  "SCUNetModelTyping": [],
  "_open_scunet_model": [
    "model"
  ],
  "_Enhancer": {
    "__init__": [
      "self",
      "model",
      "tile_size",
      "tile_overlap",
      "batch_size",
      "silent"
    ],
    "_process_rgb": [
      "self",
      "rgb_array"
    ]
  },
  "_get_enhancer": [
    "model",
    "tile_size",
    "tile_overlap",
    "batch_size",
    "silent"
  ],
  "restore_with_scunet": [
    "image",
    "model",
    "tile_size",
    "tile_overlap",
    "batch_size",
    "silent"
  ],
  "_check_environment": [],
  "remove_adversarial_noise": [
    "image",
    "diameter_min",
    "diameter_max",
    "sigma_color_min",
    "sigma_color_max",
    "sigma_space_min",
    "sigma_space_max",
    "radius_min",
    "radius_max",
    "eps_min",
    "eps_max",
    "b_iters",
    "g_iters"
  ],
  "NafNetModelTyping": [],
  "_open_nafnet_model": [
    "model"
  ],
  "restore_with_nafnet": [
    "image",
    "model",
    "tile_size",
    "tile_overlap",
    "batch_size",
    "silent"
  ],
  "sigmoid": [
    "x"
  ],
  "_ensure_onnxruntime": [],
  "alias": [],
  "get_onnx_provider": [
    "provider"
  ],
  "_open_onnx_model": [
    "ckpt",
    "provider",
    "use_cpu"
  ],
  "open_onnx_model": [
    "ckpt",
    "mode"
  ],
  "LevelTyping": [],
  "_get_context_key": [
    "level"
  ],
  "ts_lru_cache": [
    "level"
  ],
  "area_batch_run": [
    "origin_input",
    "func",
    "scale",
    "tile_size",
    "tile_overlap",
    "batch_size",
    "input_channels",
    "output_channels",
    "silent",
    "process_title",
    "rebuild_title"
  ],
  "get_storage_dir": [],
  "vreplace": [
    "v",
    "mapping"
  ],
  "_v_iternames": [
    "v"
  ],
  "vnames": [
    "v",
    "str_only"
  ],
  "tqdm": [],
  "_float_types": [],
  "rgb_decode": [
    "data",
    "order_"
  ],
  "_FORMAT_REPLACE": [],
  "to_blob_url": [
    "image",
    "format"
  ],
  "load_image_from_blob_url": [
    "blob_url"
  ],
  "_IMAGE_BLOB_URI_REGEX": [],
  "is_valid_image_blob_url": [
    "blob_url"
  ],
  "download_image_from_url": [
    "url",
    "silent",
    "expected_size"
  ],
  "is_http_url": [
    "url"
  ],
  "_GITHUB_SUFFIX": [],
  "_is_github_url": [
    "url"
  ],
  "_process_github_url_for_downloading": [
    "url"
  ],
  "_HF_SUFFIX": [],
  "_is_hf_url": [
    "url"
  ],
  "_process_hf_url_for_downloading": [
    "url"
  ],
  "_parse_size": [
    "size"
  ],
  "_parse_color_to_rgba": [
    "color"
  ],
  "_parse_color_to_mode": [
    "color",
    "mode"
  ],
  "pad_image_to_size": [
    "pic",
    "size",
    "background_color",
    "interpolation"
  ],
  "_load_image_or_color": [
    "image"
  ],
  "_process": [
    "item"
  ],
  "_AlphaTyping": [],
  "_add_alpha": [
    "image",
    "alpha"
  ],
  "istack": [],
  "_is_readable": [
    "obj"
  ],
  "ImageTyping": [],
  "MultiImagesTyping": [],
  "has_alpha_channel": [
    "image"
  ],
  "load_image": [
    "image",
    "mode",
    "force_background"
  ],
  "load_images": [
    "images",
    "mode",
    "force_background"
  ],
  "add_background_for_rgba": [
    "image",
    "background"
  ],
  "grid_background": [
    "height",
    "width",
    "step",
    "forecolor",
    "backcolor"
  ],
  "grid_transparent": [
    "image",
    "step",
    "forecolor",
    "backcolor"
  ],
  "rgb_encode": [
    "image",
    "order_",
    "use_float"
  ],
  "_BG_REPO": [],
  "_global_df": [],
  "_bg_root_dir": [],
  "BackgroundImageSet": {
    "__init__": [
      "self",
      "width",
      "height",
      "strict_level",
      "min_selected",
      "min_width",
      "min_height",
      "min_resolution"
    ],
    "list_image_files": [
      "self"
    ],
    "get_image_file": [
      "self",
      "filename"
    ],
    "get_image": [
      "self",
      "filename"
    ],
    "_random_filename": [
      "self"
    ],
    "random_image_file": [
      "self"
    ],
    "random_image": [
      "self"
    ],
    "_load_local_image_file": [
      "self",
      "filename"
    ]
  },
  "_get_default_set": [],
  "list_bg_image_files": [],
  "get_bg_image_file": [
    "filename"
  ],
  "get_bg_image": [
    "filename"
  ],
  "random_bg_image_file": [],
  "random_bg_image": [],
  "_OP18_BODY_CONNECTS": [],
  "_OP18_BODY_COLORS": [],
  "_op18_body": [
    "keypoints",
    "draw",
    "threshold"
  ],
  "_OP18_HAND_EDGES": [],
  "_op18_hands": [
    "keypoints",
    "draw",
    "threshold"
  ],
  "_OP18_FOOT_EDGES": [],
  "_op18_feet": [
    "keypoints",
    "draw",
    "threshold"
  ],
  "_FACE_POINT_SIZE": [],
  "_op18_face": [
    "keypoints",
    "draw",
    "threshold"
  ],
  "op18_visualize": [
    "image",
    "keypoints_list",
    "threshold",
    "min_edge_size",
    "draw_body",
    "draw_hands",
    "draw_feet",
    "draw_face"
  ],
  "_dwpose_preprocess": [
    "img",
    "out_bbox",
    "input_size"
  ],
  "_dwpose_inference": [
    "session",
    "img"
  ],
  "_dwpose_postprocess": [
    "outputs",
    "model_input_size",
    "center",
    "scale",
    "simcc_split_ratio"
  ],
  "_bbox_xyxy2cs": [
    "bbox",
    "padding"
  ],
  "_fix_aspect_ratio": [
    "bbox_scale",
    "aspect_ratio"
  ],
  "_rotate_point": [
    "pt",
    "angle_rad"
  ],
  "_get_3rd_point": [
    "a",
    "b"
  ],
  "_get_warp_matrix": [
    "center",
    "scale",
    "rot",
    "output_size",
    "shift",
    "inv"
  ],
  "_top_down_affine": [
    "input_size",
    "bbox_scale",
    "bbox_center",
    "img"
  ],
  "_get_simcc_maximum": [
    "simcc_x",
    "simcc_y"
  ],
  "_output_decode": [
    "simcc_x",
    "simcc_y",
    "simcc_split_ratio"
  ],
  "mmpose_idx": [],
  "openpose_idx": [],
  "_dwpose_reorder_body_points": [
    "keypoints",
    "scores"
  ],
  "_split_data": [
    "keypoints",
    "scores"
  ],
  "_open_dwpose_model": [],
  "dwpose_estimate": [
    "image",
    "auto_detect",
    "out_bboxes",
    "person_detect_cfgs"
  ],
  "OP18_BODY_MIN": [],
  "OP18_BODY_MAX": [],
  "OP18_LEFT_FOOT_MIN": [],
  "OP18_LEFT_FOOT_MAX": [],
  "OP18_RIGHT_FOOT_MIN": [],
  "OP18_RIGHT_FOOT_MAX": [],
  "OP18_FACE_MIN": [],
  "OP18_FACE_MAX": [],
  "OP18_LEFT_HAND_MIN": [],
  "OP18_LEFT_HAND_MAX": [],
  "OP18_RIGHT_HAND_MIN": [],
  "OP18_RIGHT_HAND_MAX": [],
  "OpenPose18": {
    "NOSE": [],
    "NECK": [],
    "RIGHT_SHOULDER": [],
    "RIGHT_ELBOW": [],
    "RIGHT_WRIST": [],
    "LEFT_SHOULDER": [],
    "LEFT_ELBOW": [],
    "LEFT_WRIST": [],
    "RIGHT_HIP": [],
    "RIGHT_KNEE": [],
    "RIGHT_ANKLE": [],
    "LEFT_HIP": [],
    "LEFT_KNEE": [],
    "LEFT_ANKLE": [],
    "RIGHT_EYE": [],
    "LEFT_EYE": [],
    "RIGHT_EAR": [],
    "LEFT_EAR": [],
    "LEFT_BIG_TOE": [],
    "LEFT_SMALL_TOE": [],
    "LEFT_HEEL": [],
    "RIGHT_BIG_TOE": [],
    "RIGHT_SMALL_TOE": [],
    "RIGHT_HEEL": []
  },
  "OP18KeyPointSet": {
    "__init__": [
      "self",
      "all_"
    ],
    "body": [
      "self"
    ],
    "left_foot": [
      "self"
    ],
    "right_foot": [
      "self"
    ],
    "face": [
      "self"
    ],
    "left_hand": [
      "self"
    ],
    "right_hand": [
      "self"
    ],
    "__mul__": [
      "self",
      "multiplier"
    ],
    "__truediv__": [
      "self",
      "divisor"
    ]
  },
  "SWIN_MODEL_REPO": [],
  "CONV_MODEL_REPO": [],
  "CONV2_MODEL_REPO": [],
  "VIT_MODEL_REPO": [],
  "MOAT_MODEL_REPO": [],
  "CONV_V3_MODEL_REPO": [],
  "SWIN_V3_MODEL_REPO": [],
  "VIT_V3_MODEL_REPO": [],
  "VIT_LARGE_MODEL_REPO": [],
  "EVA02_LARGE_MODEL_DSV3_REPO": [],
  "MODEL_FILENAME": [],
  "LABEL_FILENAME": [],
  "_IS_V3_SUPPORT": [],
  "MODEL_NAMES": [],
  "_version_support_check": [
    "model_name"
  ],
  "_get_wd14_model": [
    "model_name"
  ],
  "_get_wd14_weights": [
    "model_name"
  ],
  "_get_wd14_labels": [
    "model_name",
    "no_underline"
  ],
  "_mcut_threshold": [
    "probs"
  ],
  "_prepare_image_for_tagging": [
    "image",
    "target_size"
  ],
  "_postprocess_embedding": [
    "pred",
    "embedding",
    "model_name",
    "general_threshold",
    "general_mcut_enabled",
    "character_threshold",
    "character_mcut_enabled",
    "no_underline",
    "drop_overlap",
    "fmt"
  ],
  "get_wd14_tags": [
    "image",
    "model_name",
    "general_threshold",
    "general_mcut_enabled",
    "character_threshold",
    "character_mcut_enabled",
    "no_underline",
    "drop_overlap",
    "fmt"
  ],
  "_DEFAULT_DENORMALIZER_NAME": [],
  "convert_wd14_emb_to_prediction": [
    "emb",
    "model_name",
    "general_threshold",
    "general_mcut_enabled",
    "character_threshold",
    "character_mcut_enabled",
    "no_underline",
    "drop_overlap",
    "fmt",
    "denormalize",
    "denormalizer_name"
  ],
  "_open_denormalize_model": [
    "model_name",
    "denormalizer_name"
  ],
  "denormalize_wd14_emb": [
    "emb",
    "model_name",
    "denormalizer_name"
  ],
  "_get_deepdanbooru_labels": [],
  "_get_deepdanbooru_model": [],
  "get_deepdanbooru_tags": [
    "image",
    "use_real_name",
    "general_threshold",
    "character_threshold",
    "drop_overlap"
  ],
  "_CATEGORY_MAPS": [],
  "_get_camie_model": [
    "model_name",
    "is_full"
  ],
  "_get_camie_labels": [
    "model_name",
    "no_underline"
  ],
  "_get_camie_preprocessor": [
    "model_name"
  ],
  "CamieModeTyping": [],
  "_get_camie_threshold": [
    "model_name",
    "mode"
  ],
  "_postprocess_embedding_values": [
    "pred",
    "logits",
    "embedding",
    "model_name",
    "mode",
    "thresholds",
    "no_underline",
    "drop_overlap"
  ],
  "get_camie_tags": [
    "image",
    "model_name",
    "mode",
    "thresholds",
    "no_underline",
    "drop_overlap",
    "fmt"
  ],
  "_get_camie_emb_to_pred_model": [
    "model_name",
    "is_refined"
  ],
  "convert_camie_emb_to_prediction": [
    "emb",
    "model_name",
    "is_refined",
    "mode",
    "thresholds",
    "no_underline",
    "drop_overlap",
    "fmt"
  ],
  "_open_mldanbooru_model": [],
  "_resize_align": [
    "image",
    "size",
    "keep_ratio",
    "align"
  ],
  "_to_tensor": [
    "image"
  ],
  "_get_mldanbooru_labels": [
    "use_real_name"
  ],
  "get_mldanbooru_tags": [
    "image",
    "use_real_name",
    "threshold",
    "size",
    "keep_ratio",
    "drop_overlap"
  ],
  "sort_tags": [
    "tags",
    "mode"
  ],
  "_get_repo_id": [
    "model_name"
  ],
  "_open_tags": [
    "model_name"
  ],
  "_open_preprocess": [
    "model_name"
  ],
  "_open_default_category_thresholds": [
    "model_name"
  ],
  "get_pixai_tags": [
    "image",
    "model_name",
    "thresholds",
    "fmt"
  ],
  "CHAR_WHITELIST_SUFFIX": [],
  "CHAR_WHITELIST_PREFIX": [],
  "CHAR_WHITELIST_WORD": [],
  "CHAR_SUFFIXES": [],
  "CHAR_PREFIXES": [],
  "_WordTupleTyping": [],
  "_WordPool": {
    "__init__": [
      "self",
      "words"
    ],
    "_append": [
      "self",
      "text"
    ],
    "__contains__": [
      "self",
      "text"
    ]
  },
  "_SuffixPool": {
    "__init__": [
      "self",
      "suffixes"
    ],
    "_append": [
      "self",
      "text"
    ],
    "__contains__": [
      "self",
      "text"
    ]
  },
  "_PrefixPool": {
    "__init__": [
      "self",
      "prefixes"
    ],
    "_append": [
      "self",
      "text"
    ],
    "__contains__": [
      "self",
      "text"
    ]
  },
  "CharacterTagPool": {
    "__init__": [
      "self",
      "whitelist_suffixes",
      "whitelist_prefixes",
      "whitelist_words",
      "suffixes",
      "prefixes"
    ],
    "_is_in_whitelist": [
      "self",
      "tag"
    ],
    "_is_in_common": [
      "self",
      "tag"
    ],
    "is_basic_character_tag": [
      "self",
      "tag"
    ],
    "drop_basic_character_tags": [
      "self",
      "tags"
    ]
  },
  "_DEFAULT_CHARACTER_POOL": [],
  "is_basic_character_tag": [
    "tag"
  ],
  "drop_basic_character_tags": [
    "tags"
  ],
  "RE_SPECIAL": [],
  "_KAOMOJIS": [],
  "add_underline": [
    "tag"
  ],
  "remove_underline": [
    "tag"
  ],
  "tags_to_text": [
    "tags",
    "use_spaces",
    "use_escape",
    "include_score",
    "score_descend"
  ],
  "_cached_singular_form": [
    "word"
  ],
  "_cache_plural_form": [
    "word"
  ],
  "_split_to_words": [
    "text"
  ],
  "_words_to_matcher": [
    "words",
    "enable_forms"
  ],
  "tag_match_suffix": [
    "text",
    "suffix"
  ],
  "tag_match_prefix": [
    "text",
    "prefix"
  ],
  "tag_match_full": [
    "t1",
    "t2"
  ],
  "_open_preprocessor": [],
  "get_deepgelbooru_tags": [
    "image",
    "general_threshold",
    "character_threshold",
    "drop_overlap",
    "fmt"
  ],
  "_get_overlap_tags": [],
  "drop_overlap_tags": [
    "tags"
  ],
  "_load_online_blacklist": [],
  "_online_blacklist_set": [],
  "_is_blacklisted": [
    "tag",
    "blacklist_set"
  ],
  "is_blacklisted": [
    "tag"
  ],
  "drop_blacklisted_tags": [
    "tags",
    "use_presets",
    "custom_blacklist"
  ],
  "_DEFAULT_DET_MODEL": [],
  "_DEFAULT_REC_MODEL": [],
  "list_det_models": [],
  "list_rec_models": [],
  "detect_text_with_ocr": [
    "image",
    "model",
    "heat_threshold",
    "box_threshold",
    "max_candidates",
    "unclip_ratio"
  ],
  "ocr": [
    "image",
    "detect_model",
    "recognize_model",
    "heat_threshold",
    "box_threshold",
    "max_candidates",
    "unclip_ratio",
    "rotation_threshold",
    "is_remove_duplicate"
  ],
  "_HF_CLIENT": [],
  "_REPOSITORY": [],
  "_open_ocr_recognition_model": [
    "model"
  ],
  "_open_ocr_recognition_dictionary": [
    "model"
  ],
  "_text_decode": [
    "text_index",
    "model",
    "text_prob",
    "is_remove_duplicate"
  ],
  "_text_recognize": [
    "image",
    "model",
    "is_remove_duplicate"
  ],
  "_list_rec_models": [],
  "_MIN_SIZE": [],
  "_open_ocr_detection_model": [
    "model"
  ],
  "_box_score_fast": [
    "bitmap",
    "_box"
  ],
  "_unclip": [
    "box",
    "unclip_ratio"
  ],
  "_get_mini_boxes": [
    "contour"
  ],
  "_boxes_from_bitmap": [
    "pred",
    "_bitmap",
    "dest_width",
    "dest_height",
    "box_threshold",
    "max_candidates",
    "unclip_ratio"
  ],
  "_ALIGN": [],
  "_get_text_points": [
    "image",
    "model",
    "heat_threshold",
    "box_threshold",
    "max_candidates",
    "unclip_ratio"
  ],
  "_detect_text": [
    "image",
    "model",
    "heat_threshold",
    "box_threshold",
    "max_candidates",
    "unclip_ratio"
  ],
  "_list_det_models": [],
  "_open_cdc_upscaler_model": [
    "model"
  ],
  "_CDC_INPUT_UNIT": [],
  "_upscale_for_rgb": [
    "input_",
    "model",
    "tile_size",
    "tile_overlap",
    "batch_size",
    "silent"
  ],
  "upscale_with_cdc": [
    "image",
    "model",
    "tile_size",
    "tile_overlap",
    "batch_size",
    "silent"
  ]
}